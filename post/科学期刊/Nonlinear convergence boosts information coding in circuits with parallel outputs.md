
---
title: Nonlinear convergence boosts information coding in circuits with parallel outputs
categories: 
    - 科学期刊
    - PNAS - 最新文章（可筛选领域）
author: PNAS - 最新文章（可筛选领域）
comments: false
date: Tue, 23 Feb 2021 00:00:00 GMT
thumbnail: 
---

<div>   
<h2 class>Significance</h2><p id="p-5">Computation in neural circuits relies on a common set of motifs, including divergence of common inputs to parallel pathways, convergence of multiple inputs to a single neuron, and nonlinearities that select some signals over others. Convergence and circuit nonlinearities, considered separately, can lead to a loss of information about inputs. Past work has detailed how optimized nonlinearities and circuit weights can maximize information, but here, we show that incorporating noninvertible nonlinearities into a circuit with divergence and convergence can enhance encoded information, despite the suboptimality of these components individually. This study extends a broad literature on efficient coding to convergent circuits. Our results suggest that neural circuits may preserve more information using suboptimal components than one might expect.</p><h2>Abstract</h2><p id="p-6">Neural circuits are structured with layers of converging and diverging connectivity and selectivity-inducing nonlinearities at neurons and synapses. These components have the potential to hamper an accurate encoding of the circuit inputs. Past computational studies have optimized the nonlinearities of single neurons, or connection weights in networks, to maximize encoded information, but have not grappled with the simultaneous impact of convergent circuit structure and nonlinear response functions for efficient coding. Our approach is to compare model circuits with different combinations of convergence, divergence, and nonlinear neurons to discover how interactions between these components affect coding efficiency. We find that a convergent circuit with divergent parallel pathways can encode more information with nonlinear subunits than with linear subunits, despite the compressive loss induced by the convergence and the nonlinearities when considered separately.</p>  
</div>
            