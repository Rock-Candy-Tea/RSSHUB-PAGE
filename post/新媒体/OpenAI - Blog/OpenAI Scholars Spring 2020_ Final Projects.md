
---
title: OpenAI Scholars Spring 2020_ Final Projects
categories: 
    - 新媒体
    - OpenAI - Blog
author: OpenAI - Blog
comments: false
date: Thu, 09 Jul 2020 00:00:00 GMT
thumbnail: ''
---

<div>   
<div class="js-excerpt">
<p>Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months. These projects investigated problems such as analyzing how GPT-2 represents grammar, measuring the interpretability of models trained on Coinrun, and predicting epileptic seizures using brain recordings. More information about the next class of Scholars and how to apply will be announced this fall.</p>
</div>
<div class="full mt-2 mb-3">
<div class="scholars-header-image"></div>
</div>
<p>The <a href="https://openai.com/blog/openai-scholars/">OpenAI Scholars program</a> provides stipends and mentorship to individuals from underrepresented groups to study deep learning and open-source a project.</p>
<p>Our Scholars have demonstrated core technical skills across various expert domains and self-motivation—critical competencies for a self-directed program like this one. They each entered the field of machine learning as relative newcomers, and we hope their progress shows how accessible machine learning is.</p>
<figure class="my-2">
<iframe width="560" height="315" src="https://www.youtube.com/embed/JZOHW-eYBtQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<div class="caption mt-0">Demo Day introductions by Sam Altman and Greg Brockman</div>
</figure>
<p><em>Learn more about our <a href="https://openai.com/blog/openai-scholars-spring-2020/">Scholars program</a>.</em></p>
<div class="full py-3 bg-fg-2">
<div class="container p-relative">
<div class="row">
<div class="d-none d-xl-block col-3">
<nav class="sticky js-sticky pt-1 mt-n1 pb-1" style="left: 0;">
<ul class="list-unstyled mb-0">
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#alethea">Alethea Power</a></li>
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#andre">Andre Carerra</a></li>
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#cathy">Cathy Yeh</a></li>
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#jorge">Jorge Orbay</a></li>
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#kamal">Kamal Ndousse</a></li>
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#kata">Kata Slama</a></li>
<li><a class="scholars-nav-item js-scrollspy d-block small-copy no-underline" href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/#pamela">Pamela Mishkin</a></li>
</ul>
</nav>
</div>
<div class="content" style="margin-left: 0">
<div id="alethea">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/6gilgehNTNw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<h3 class="my-0">Alethea Power</h3>
<div class="large-copy mb-0.75 balance-text">Looking for Grammar in All The Right Places</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor: Christine Payne<br>
Previous Roles: B.S. in Applied Mathematics, MSc in Philosophy of Mind from Ediburgh, Software and Site Reliability Engineer at Facebook
</aside>
<p>I’m fascinated by neural network interpretability. Understanding how networks of various architectures represent information can help us build simpler and more efficient networks, as well as predict how the networks we’ve built will behave, and perhaps even give us some insight into how human beings think. Along these lines, I analyzed how GPT-2 represents English grammar, and found smaller sub-networks that seem to correspond to various grammatical structures. I will present my methodology and results.</p>
<blockquote>
<p>Next, I want to work on understanding how neural networks represent information, and use that understanding to better predict how deep learning systems behave. I believe this work will make such systems safer and more beneficial to humanity, as well as making them simpler, faster, and more computationally efficient.</p>
</blockquote>
<section class="btns">
    <a href="https://aletheap.github.io/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
<hr>
<div id="andre">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/liMJS5DrnlQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<h3 class="my-0">Andre Carerra</h3>
<div class="large-copy mb-0.75 balance-text">Semantic Parsing English to GraphQL</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor: Melanie Subbiah<br>
Previous Roles: CTO at Droplii, Founder at Lambdo
</aside>
<p>My scholars program project is semantic parsing English-to-GraphQL. Given an English prompt such as “How many employees do we have?”, find a corresponding GraphQL query to return the information. The project involved creating a dataset, training models, and creating an interaction tool to see results.</p>
<blockquote>
<p>I wanted to have a say in how AI is shaped—the Scholars program has been a great opportunity to learn and participate.</p>
</blockquote>
<section class="btns">
    <a href="https://blog.lambdo.com/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
<hr>
<div id="cathy">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/jjmTmYMsET0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<h3 class="my-0">Cathy Yeh</h3>
<div class="large-copy mb-0.75 balance-text">Long Term Credit Assignment with Temporal Reward Transport</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor: Jerry Tworek<br>
Previous Roles: Data Scientist at Square and Driver
</aside>
<p>Standard reinforcement learning algorithms struggle with poor sample efficiency in the presence of sparse rewards with long temporal delays between action and effect. To address the long term credit assignment problem, we use “temporal reward transport” (TRT) to augment the immediate rewards of significant state-action pairs with rewards from the distant future, using an attention mechanism to identify candidates for TRT. A series of gridworld experiments show clear improvements in learning when TRT is used in conjunction with a standard advantage actor critic algorithm.</p>
<blockquote>
<p>I appreciate that this program gave me the freedom to learn deeply and flex my creativity.</p>
</blockquote>
<section class="btns">
    <a href="https://www.efavdb.com/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
<hr>
<div id="jorge">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aEe_dTUfK4c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<h3 class="my-0">Jorge Orbay</h3>
<div class="large-copy mb-0.75 balance-text">Quantifying Interpretability of Models Trained on Coinrun</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor:  Karl Cobbe<br>
Previous Roles: CS Engineering at Columbia, Research at the Creative Machines Lab, Software Engineer at Autonomic
</aside>
<p>This project’s purpose is to create a scalar that measures the interpretability of an A2C model trained on Procgen’s Coinrun. The scalar is generated using a combination of attribution on the model and masks of Coinrun’s assets. The scalar is used to test the validity of the diversity hypothesis.</p>
<blockquote>
<p>This program, and specifically my mentor, has fostered a self-confidence in me to dive into a field I don’t understand and breakdown problems until I can solve them. I’m hoping to take the self-confidence I’ve learned from this program to continue breaking-down problems in and with AI.</p>
</blockquote>
<section class="btns">
    <a href="https://jorbay.github.io/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
<hr>
<div id="kamal">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qy9J5519s68" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<h3 class="my-0">Kamal Ndousse</h3>
<div class="large-copy mb-0.75 balance-text">Social Learning in Independent Multi-Agent Reinforcement Learning</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor: Natasha Jaques<br>
Previous Roles: Math and Physics at MIT, Algorithms Research Scientist at Fitbit, Independent Algorithms/ML consultant, ML Engineer at Coinbase
</aside>
<p>My project has explored the social transfer of expertise among completely independent RL agents trained in shared environments. The motivating question is whether novice agents can learn to mimic expert behavior to solve hard-exploration tasks that they couldn't master in isolation. I’ll discuss my observations as well as the environments I developed to experiment with social skill transfer.</p>
<blockquote>
<p>I joined the Scholars program in order to learn from the brilliant folks at OpenAI and to immerse myself in AI research. I’m grateful to have had the opportunity to explore state of the art research with the support of such talented researchers (special thanks to my mentor Natasha Jaques!)</p>
</blockquote>
<section class="btns">
    <a href="https://kam.al/blog/marl1/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
<hr>
<div id="kata">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/AT2XkqJAZns" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<figure>
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/jjmTmYMsET0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
</figure>
<h3 class="my-0">Kata Slama</h3>
<div class="large-copy mb-0.75 balance-text">Towards Epileptic Seizure Prediction with Deep Network</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor: Johannes Otterbach<br>
Previous Roles: PhD in Neuroscience at UC Berkeley, Behavioral Research at Harvard and Brown
</aside>
<p>I have been working on a project to predict epileptic seizures using brain recordings. I framed it as an image classification problem based on the spectrogram representation of the brain data. My most successful model so far has been a ResNet18. In my post-Scholars life, I plan to continue working on this project, and make my way to interpretability of spectrogram classification networks.</p>
<blockquote>
<p>I wanted to learn how to apply deep learning for solving scientific and real-world problems. The OpenAI Scholars program was this magical opportunity to get started by learning from the very best minds in the field.</p>
</blockquote>
<section class="btns">
    <a href="https://katarinaslama.github.io/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
<hr>
<div id="pamela">
<figure>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7wqmXo0Jqa4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>
<figure>
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/jjmTmYMsET0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
</figure>
<h3 class="my-0">Pamela Mishkin</h3>
<div class="large-copy mb-0.75 balance-text">Universal Adversarial Perturbations and Language Models</div>
<aside class="aside-right small-copy color-fg-60 mb-1">
Mentor: Alec Radford<br>
Previous Roles: Math and CS at Williams College, Research Analyst at the Federal Reserve Bank of NY, Herchel Smith Scholar at Cambridge, Product Manager at The Whistle, Researcher at Lumi Labs
</aside>
<p>Adversarial perturbations are well-understood for images but less so for language. My presentation will review the literature on how universal adversarial examples can inform understanding of generative models, replicating results generating universal adversarial triggers for GPT-2 and for attacking NLI models.</p>
<blockquote>
<p>This program strengthened my technical basis in machine learning and helped me understand how AI researchers understand policy implications of their work.</p>
</blockquote>
<section class="btns mb-0">
    <a href="https://manlikemishap.github.io/year-archive/" class="btn btn-padded icon-external right">Blog</a><!-- <a href="" class="btn btn-padded icon-code right">GitHub Repo</a> -->
</section>
</div>
</div><!-- end div.content -->
</div><!-- end div.row -->
</div><!-- end div.container -->
</div><!-- end div.full -->
<p>Diversity is core to AI having a positive effect on the world—it’s necessary to ensure the advanced AI systems in the future are built to <a href="https://openai.com/charter">benefit everyone</a>.</p>
<p>If you’re excited to begin your own journey into ML, check out some of our <a href="https://openai.com/resources/">educational materials</a>. More information about the next class of scholars and how to apply will be announced this fall. Stay tuned!</p>
<p><em>Huge thanks to Microsoft for providing Azure compute credits to scholars, to our mentors for their time and commitment, and to all the supporters that made this program possible.</em></p>
<!--kg-card-end: markdown-->
      
</div>
            