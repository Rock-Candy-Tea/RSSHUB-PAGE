
---
title: 'Stacking our way to more general robots'
categories: 
 - 新媒体
 - DeepMind
 - Blog
headimg: 'https://picsum.photos/400/300?random=9691'
author: DeepMind
comments: false
date: Mon, 11 Oct 2021 00:00:00 GMT
thumbnail: 'https://picsum.photos/400/300?random=9691'
---

<div>   
<p><strong>Introducing RGB-Stacking as a new benchmark for vision-based robotic manipulation.</strong></p>
<p>Picking up a stick and balancing it atop a log or stacking a pebble on a stone may seem like simple — and quite similar — actions for a person. However, most robots struggle with handling more than one such task at a time. Manipulating a stick requires a different set of behaviours than stacking stones, never mind piling various dishes on top of one another or assembling furniture. Before we can teach robots how to perform these kinds of tasks, they first need to learn how to interact with a far greater range of objects. As part of <a href="https://deepmind.com/about" rel="noopener" target="_blank">DeepMind’s mission</a> and as a step toward making more generalisable and useful robots, we’re exploring how to enable robots to better understand the interactions of objects with diverse geometries.</p>  
</div>
            