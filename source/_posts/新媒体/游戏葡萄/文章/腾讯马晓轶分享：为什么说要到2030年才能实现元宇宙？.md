
---
title: '腾讯马晓轶分享：为什么说要到2030年才能实现元宇宙？'
categories: 
 - 新媒体
 - 游戏葡萄
 - 文章
headimg: 'https://picsum.photos/400/300?random=9627'
author: 游戏葡萄
comments: false
date: Mon, 25 Apr 2022 04:11:09 GMT
thumbnail: 'https://picsum.photos/400/300?random=9627'
---

<div>   
<p>4月24日，腾讯高级副总裁马晓轶在复旦大学管理学院校友会上，分享了他对元宇宙、VR/AR等内容的看法。</p><p>近两年，元宇宙概念大火：Facebook把公司名改成了Meta，VR设备Oculus Quest 2销量近千万台，其早期预订量就超初代5倍。VR业内人士曾告诉葡萄君，一些人士已经将大涨的销量视为风向标，认为这次元宇宙热潮将带来不少变化。</p><p>但马晓轶给出了与之不太一样的看法：对元宇宙短期2-3年内的变化，他还是抱以悲观态度，因为尽管现在很多技术都寻找到了突破，但都是专用向的摸索，距离元宇宙本身所畅想的概念，还有相当的技术、商业距离。这也让人想起在之前的采访中，他曾表示游戏是一个超级数字场景，而元宇宙只是后者的其中一种形态。</p><p>不过，他对元宇宙长线的10年发展前景，其实有着比他人更强的信心。一方面，元宇宙这个概念在近两年得到更多的技术支持，正在从多方面解决自身的瓶颈问题；而另一方面，社会对其认知也正在突破，从仅局限于游戏、软件中的概念，朝着跨越多个场景的方向发展。而这个质变的时间点，他认为是2030年。</p><p>元宇宙的技术部分现在发展到了什么状态？对比过去互联网、家用设备的发展，它正处于什么样的阶段？马晓轶又为何认为元宇宙发生质变的节点是在2030年？在这场分享当中，你或许能找到其中的答案。</p><p><br></p><p><span style="color:rgb(0,176,80);"><strong>以下为整理后的分享内容：</strong></span></p><p>非常荣幸能够有这样一个机会，和大家一起交流、讨论元宇宙（Metaverse）这个问题。</p><p>元宇宙最近非常火，不过倒推来看，这并不是一个新鲜话题。</p><p>1997年，有款叫《Ultima Online》的游戏，就在当时提出概念：这是一个持续运转的世界。这个理念下，游戏即使没有人在线参与互动，它的世界也在持续存在和持续发展。这个理念已经和现在元宇宙的理念是完全一致的。</p><p>其实差不多也是1995-1998年这几年，各个互联网公司开始创业，大家也是考虑怎么把生活中的场景、关系放到线上来。</p><p>最近的一次尝试是一款叫做《Second Life》的游戏，2006年左右上线。就在两个月前，我和当年的初创团队聊了一下他们当时的想法。从他们的愿景来看，那款游戏就是今天讨论的元宇宙的话题。</p><p>Metaverse这个词，大家都知道是来自于1992年的一本小说，最近一次在商业界被提及，是在2018年的时候，有一个美国的分析师写了一篇文章，这个文章标题是说：腾讯的梦想到底是什么。</p><p>文章里分析了腾讯为什么投资了Epic Games，为什么投资了Roblox、Reddit、Snapchat，以及各种各样的内容和平台型的公司......当他把这些布局组起来后，他觉得用一个叫Metaverse的词再好不过。</p><p>......后来随着Roblox的上市，Facebook改名Meta，这已经变成一个越来越热的概念。</p><p>为什么这么早的概念，在今天突然热起来了？我觉得这是因为相较于过去，这几年发生了很多变化。</p><p>第一个是整个计算能力到了临界点。在2016年的时候有一波VR的浪潮，当时我就比较保守，也相对悲观一点，和很多行业里的人聊了，我们觉得要真正在VR的设备上支持一个好的体验，能够做到大规模应用，它所需的技术远远没有成熟。</p><p>举个例子，当时的移动计算芯片完全无法支持高分辨率的显示，再加上电池、显示设备本身的限制，使得这个体验做的很差。</p><p>其次，是一些关键的新技术没到位。我们最近也很关心这部分，我也一直在看很多上游的关键技术，甚至一些器部件生产的进展。我们已经看到一些路线图正逐步清晰起来，可以看到在未来的几年里，这些关键技术都会有一个突破性的发展。</p><p>第三，我自己觉得比较重要的是，互联网的渗透率也到了临界点。特别是经历了这两年的全球疫情之后，大家可以发现在家办公正变成主流——如果你是科技公司，如果不提供给员工在家上班的选项，那么你就失去了吸引力。因为大家已经习惯在线上购买东西、购买服务，大家看腾讯视频、奈飞所有线上的视频也越来越便捷，大家也习惯在这上面看最新的电影、电视。这些部分也让更多人愿意把他生活的很大一部分通过网络实现。</p><p>最后，我们站到用户的角度，从需求来看。</p><p>大家都知道人作为一个物种，最大的特征是「协同」，能够有很多人一起来完成某一件事情。随着整个社会越来越复杂，我们需要的技术也复杂起来。这些需求本身，当社会看到一些技术是有机会去满足的话，便会推动它去实现一个非常大的突破。</p><p>基于以上几点来看，2006年《Second Life》的第一次尝试，明显是太早了，到了2015年、2016年第一波VR的时代，我觉得也是太早了。</p><p>到了今天，或许便是一个合适的时间点。</p><p>所以正好借着这次会议，我们可以谈一下对未来Metaverse的畅想——说实话，我个人和外面很多媒体的报道有一些不一样的观点，就比如我会觉得现在谈论Metaverse的细节还是太早了。</p><p>毕竟元宇宙到底该长什么模样、由什么部分组成......还是个很难清晰、精准定义的工作。</p><p>但是，我们现在可以将元宇宙，视为一种未来新技术、新应用的可能集成方式，是对未来人机交互、人人交互想象的合集。</p><p>所以今天聊的很多东西，也只是和大家有一个探讨和分享，很难说这就是我们能够预测的未来到底长什么模样。</p><p>谈到对未来整个想象，我觉得主要是2个方向——其实这有点争议，本来一共有3个方向</p><p>1.沉浸感；2.内容；3.商业模式。</p><p>不过我多少觉得，Metaverse尚处非常早期的阶段，当我们对于Metaverse的定义都还不清晰时，商业模式就存在非常大的变量，难给到一个非常精准的预测。所以商业模式这块，我今天就先不说了，我主要还是说沉浸感的体验，以及内容这上面的发展。</p><p><br></p><p></p><h2><span style="color:rgb(0,176,80);">01 沉浸感：2030年后，Metaverse或开始普及</span></h2><p>首先，沉浸感，我觉得主要是两个方向：</p><p>1.人机接口&交互方式；</p><p>2.VR等设备的体验问题。</p><p>现在我们提到Metaverse，大家会不由自主地将它和VR联系在一起。当然，这是基于两个原因，一方面是因为前段时间Facebook下了非常大的赌注在这个VR的方向；另一个方向，我们如果要达成Metaverse的概念，那么VR这样的全新设备是免不了的。</p><p>为什么呢？普通人借助键盘、鼠标、触控等设备输入给电脑的信息，从电脑的技术角度来看，它们带宽其实很窄，能输入的信息很有限。而电脑只能根据这些东西，做出反馈，更多的信息都没有办法直接地输入进去。</p><p>但是，随着输入的带宽增加，其实我们可以有更多的维度加入进去。</p><p>举个例子，现在VR的方向是做环境的感知，我们可以给VR设备增加更多的摄像头、更多的传感器，将环境信息也输入到电脑当中，让计算机计算达成一些新功能。</p><p>再举一个例子，我们可以追踪人体的状态。现在最新的技术可以实现6个维度——前后左右上下——的3D追踪，包括你头的位置、眼睛朝向，方便你和周围的环境互动起来。</p><p>其中最值得关注的，便是手的操作。你看现在最新的Oculus Quest 2，它还需要用手柄来输入信息，但是我们在业内都有一个共识，更自然的交互，是用你的手来交互。</p><p>这个进步，在手机上就出现过：早期的手机都是用触控笔来写的，但苹果就站出来说，这是违反人直觉的，人的直觉，应当是用手指去触摸屏幕——这个道理放在VR设备上也是一样。所以现在我们很多的进展，就是去捕捉手指的动作。</p><p>另外，我们看到一个些最新的技术专注做面部识别，捕捉你的表情。大家都知道人和人交流的时候，对方的反应是很重要的反馈。</p><p>比如说我们现在的线上会议，我的体验其实并不好，因为我看不到大家的表情，我不知道现在我的演讲是讲快了，还是讲慢了。可如果在线下，我就能马上看到观众的反应。所以未来我们也需要借助面部识别，去追踪人实时的表情，然后投射到虚拟的场景当中去......</p><p>这些新的输入方式，集成在一起，让信息带宽更大，能极大地改变电脑的信息输入。</p><p>其次，也有一些让人非常兴奋的技术发展。</p><p>比如最近我们看VR头显上的显示单元。大家如果试过Oculus Quest 2，就知道它上面使用了Fast-LCD的技术。不过这个技术有一个问题，那就是纱窗效应。当设备离眼睛太近的时候，你能看到pixel像素点就在你的眼前，好像隔着一个纱窗在看。这个其实就和当年低分辨率的手机显示屏一样。</p><p>之后的故事大家都知道，iPhone能成功的很大一个原因，就是他们在iPhone4提出了视网膜屏幕的概念，极大地改善了大家使用手机屏幕的体验。</p><p>VR发展到了今天，针对这些问题，也有一些新的技术在诞生。比如说已经在生产线上的，4K分辨率的硅基OLED显示屏，它已经能够为VR头显提供足够高的分辨率。</p><p>这里可以说一个概念：如何在VR头显上达成视网膜屏幕的效果？</p><p>现在有一个标准，即，人的每一度视角上应该有多少个像素点。大致来说，有30个的时候，你已经开始感受不到像素的边界，如果到了60个/度，你就可以完全看不出像素点。</p><p>所以，我们看到4K硅基OLED显示屏已经足够让大家有一个非常好的体验。</p><p>亮度，也是一个VR头显的改变点。</p><p>从现在的硅基OLED显示屏，到未来的MicroOLED显示，都可以提供更高的亮度。之前，LCD大致大概只有400-500nit的亮度，现在我们已经能看到2000nit，而且从未来发展的路线图来说，我们已经看到10000nit的在研设备。</p><p>这个就解决了一个非常大的瓶颈问题，即，提升显示单元的技术，增加用户的沉浸感。市场上也有了一些成型的产品。</p><p>但未来，还有一个很重要的发展方向，那就是折叠光路的技术。</p><p>大家如果还记得以前的VR设备的话，会发现VR设备通常又厚又重又大，戴在头上很不舒服。这是一个很大的瓶颈。未来我们能看到折叠光路的设备，可以将VR头显单元做得非常薄，更接近于普通戴眼镜的感觉。</p><p>还有一个突破，就是VR/AR的争论。VR说，所有的内容都来自显示单元，但AR说，得将内容和现实环境做重叠结合。</p><p>现在来看，行业大家做的都是折叠光路的方案——依旧用显示屏来呈现所有的内容，但是会在外界增加更多的感应器，来捕捉用户的周围情况，最后叠加在你的显示屏上——行业里还有一个传闻，大概在明年年初的时候，苹果就会出这样的一个设备，运用折叠光路的方案，实现VR/AR的效果。</p><p>我们相信，随着更多的人进来，整个体验会实现一个非常好的效果。而且，未来将会有一天，会有一个让大家对比现在的手机、电脑，更具突破性的进展。</p><p>综上所述，人机接口方面的技术路线图发展得很清晰。除了电池受到不少限制以外，其他方面，几乎都有了解决方案，且都在进展当中。</p><p>这也是我们对于元宇宙、VR/AR的发展抱有信心的原因。</p><p>另一个点，要想让这款技术的体验足够好，单是设备内部有硬件支持还不够，还得有软件的发展。</p><p>需要指出的是，这里的软件，指的是技术，不是内容。我们将其归结为3个维度：</p><p>1.可信的环境：Metaverse的场景越来越真实，让用户能相信这是一个真实的世界。</p><p>2.可信的人物：人是社交属性很重的生物，我需要与群体互动、交流、协作。这个当中，最需要的便是一个可信的人物。我相信大家都对这一点多少有所体会。</p><p>过去几年，疫情已经让大家习惯了远程会议，但各位肯定会多少有些不舒服的感受，感觉相比线下会议，很多问题讨论得没有那么透。当我面对面谈论一个观点时，我可以看到对方认同与否的表情，反对赞成的情绪，你可以感受到这是一个真实的人在说话。但是现在的远程会议，你就是对着一个屏幕说话。</p><p>而这，自然延伸到了第三个点：</p><p>3.可信的交互：还是聊线上会议，这种形式更像一个演讲，而不是讨论，线下会有人插入进来讨论，有碰撞，但现在的线上没有这些东西。</p><p>如果要做一个更真实的交互，要涉及到很多让人足够相信的细节。比如我让你拿一瓶水，我和你握手，我能感受到其中的温度、重量，而这些，都是传统的电脑、Pad完全做不到的交互......不过现在已经有技术在这方面有了不少进展。</p><p>总结一下就是，随着技术的发展，我们需要提供很多的工具给做Metaverse、VR/AR的公司，同时，帮助大家可以做出更可信的世界&人物关系。</p><p><br></p><p></p><h2><span style="color:rgb(0,176,80);">02 内容量：谁来提供足够多的内容？</span></h2><p>这是一个挺大的话题。因为我们仍然不知道Metaverse需要包含哪些内容。不过现在来看，我们会觉得分几个维度：</p><p>1.专业内容；2.通用内容。</p><p>这部分我会比较悲观。因为尽管这些技术在路线图上发展着，但它们都需要更多的时间去准备。</p><p>因为当一个技术还没有到举足轻重的地步时，它往往只是一个相对专业、专用的应用，比如说游戏、影视等方面；而通用类，比如说大家正在用的手机，现在已经有成千上万种办法去使用它。</p><p>专用到通用，还需要更多的时间。</p><p>大致拍脑袋说一下，我其实和内部团队交流的时候，一般是将2030年作为一根基准线，在那之前，Metaverse还会是专用的阶段，到了之后，才可能会有些机会走向更通用的状态，开始挑战现有的电脑、手机的使用场景。现在更多是一个新的、补充的场景定位。</p><p>这里可能需要更细致地说一下专用和通用的差别。</p><p>差不多一个半月之前，我和Epic Games CEO Tim Sweeney开会，讨论到这个问题的时候，我的总结是：我们现在的游戏，就是一个「游戏」，你看视频，看的也只是一个「视频」，但是Metaverse不一样，你应当是在Metaverse当中「生活」。期间有本质的区别。</p><p>比如当你去一个线上的电影院，那是一个专门的世界，割离出现实。但是Meta是将大家的生活融入、整合到这个虚拟世界当中。所以这就需要有足够多的内容，让你愿意生活在其中。</p><p>这些足够多的内容可以分为几个路线：</p><p>1.PGC的专业制作，例如腾讯这样的公司制作电影、游戏、电视剧，这是一个专业的制作。PGC仍然是Metaverse很重要的部分。</p><p>2.UGC。也就是用户产生的内容。</p><p>3.虚实结合。我们刚刚说了很多技术，便是要将现实世界整合、融入到虚拟的世界当中。</p><p>这三个部分，都是非常关键的内容组成部分。</p><p>那么如何实现呢？</p><p>首先，大规模的PGC内容，其实最近也有一些突破。关注新游戏的同学就知道，前段时间，Epic Games有一个非常震撼的demo，他们在《Matrix》上映的同时，做了一个虚拟的城市，这个城市的规模大概有10-20平方公里，当中有3万个市民，有大量的交通、建筑。</p><p>关键是，当中的车辆有自己的动作：到了红绿灯会停下来，看到人会停下来，而且这3万个市民，每一个人的穿着、行为、长相都不一样——若放在以往，要完成这么大规模的虚拟世界创造，几乎是一个不可能的任务。</p><p>但在今天，随着技术的发展，这些不可能的任务都在逐步实现，因为，一方面技术能力在增长，另一方面，这些东西有了更多的好方法去解决。</p><p>比如，我们和Epic Games有两个项目正在合作。一个项目，是可以通过AI来导入现实世界。之前我们去新西兰的一个山谷，那是一个10平方公里的山谷，我们在那里拍了7000-8000张照片，然后把照片导入引擎，这个引擎就会把山谷大致地还原出90%，然后再经过我们手动的一些微调，就可以实现在短时间内生成一个非常大的世界，而且这个世界看起来还非常的真实。</p><p>另一个项目，我们做的是一个虚拟人的项目——国内叫做Siren。后来Epic Games也发布了Meta Human的项目，一个高度仿真的人。这其实都回到刚才我们提到的概念：一个可信的人是虚拟世界当中重要的构成。</p><p>同样放到以前，你要做一个虚拟人物需要花费相当多的时间。</p><p>大家也许听说过这个故事：好莱坞很多电影要做一个虚拟人，线上渲染10s的片子需要几个月的时间，但以现在的技术，好莱坞要4个月做出来的内容，我们能在0.01秒就渲染、达成前者95%的质量。</p><p>这些，都使得大规模的制作有了更好的办法。包括动作捕捉等内容，在AI的加持下，可以让创建一个内容变得更加容易。</p><p>其次是UGC这边......其实这个部分，我和外部看法多少也不太一样。</p><p>比如，外部谈到UGC，那最关键的就是去中心化，但这个点上，我和Roblox的CEO David有很多的交流——我们很早就参与了Roblox的建设，2015年左右就开始参与，做了不少的投资——我们说到UGC内容成功的关键时，都提到社区的原则、透明性，尤其其中维持秩序、状态的部分，是需要强中心化的执行。</p><p>但这倒不是说我与外部意见相左，我认为，去中心化应该是指能力的去中心化：把工具、能力、资源给到用户，让大家无需一个中心化的平台，就能创建属于自己的内容。而能够支撑这些内容的，便是刚才所说的，一个持续、有原则、长线稳定的平台。我认为，这是一个做出UGC最重要的点。</p><p>而第三点，虚实的结合，很大程度上回到刚才我们所说的Metaverse、VR/AR新技术。其实我们所希望达到的目标，和互联网、人类社会以往的努力是一致的。人类一直想打破物理的限制，比如飞机、汽车都是为了消除物理的限制，缩短物理的损耗，提高大规模协同的效率。</p><p>所以长远来看，Metaverse更多是考量如何引入更多外部、现实世界的服务和内容，打破物理的界限。</p><p>比如，今天我们现在用腾讯会议来分享，实际效果我们觉得肯定是不如咱们在复旦线下教室里的沟通，互动会让信息传递变得更好。所以希望未来如果有机会，我们会将腾讯会议Metaverse化，大家可以看到更真实的人物，看到真实的场景。这些都是可以预期的。</p><p>再比如，线上的演唱会，大家可能已经听说过了，《堡垒之夜》之前办了一个活动，让超过1000万人线上听一场演唱会。这是一个创纪录的事情。</p><p>而我们其实也在和很多体育界的人士聊，如何引入更多的新技术，去让整场比赛的观赏体验更好，其中，电子竞技便一直在考虑这件事。</p><p>所以现在依旧有很多现实的东西，受到了物理距离等方面的限制，亟待通过虚拟化的方式，提升效率。我觉得在Metaverse、VR/AR的发展上，还会有很多的机会。</p><p><br></p><p></p><h2><span style="color:rgb(0,176,80);">03 更现实的问题</span></h2><p>最后，我想聊一聊Metaverse、VR/AR存在的问题。</p><p>虽然我刚才所讲到的内容好像都很乐观，但是我个人内心深处，还是略带一些悲观。</p><p>平时，我和大家聊的时候都会这么说：看短期1-3年，我比大部分人更加悲观，看长线的10年之后，我会比大部分人更乐观，会认为这些新技术的场景会为整个人类社会带去很大的变化。</p><p>就我的观点而言，现在的这些技术会在2025-2027年之间大规模面世，但是要铺开来做，还是得等到2030年。这是我心目中的一个时间表。</p><p>举个简单的例子，价格就是一个重要的参考。比如刚才所说的4K硅基OLED显示屏，它的体验非常好，但价格太贵，光是一个显示单元的价格，就和整个Oculus Quest 2的整机价格是一样的。所以，价格下来还需要很长的时间。</p><p>其次，商业模式本身也还存在一些问题。如刚才我所说，现在还为时太早。</p><p>如果要将我们当下的阶段去对应到过去的历史，那么有这样两个时间点：</p><p>1.通用设备的普及。</p><p>在座的很多年轻人可能不知道，最先家用的专用设备，其实是游戏机——雅达利2600，1977年发布，它可以对标到现在Oculus Quest 2的情况。</p><p>而大家熟知的IBM PC，是在1981年进入的市场，家用PC真正普及，是在Windows面世之后，85年是第一个版本，大规模推广的3.0版本是92年才有的，而更广为人知Windows95已经是95年的事情了。</p><p>可以看到，这个过程起码有6-10年的发展。</p><p>2.商业模式的成立。</p><p>第二个例子是互联网。其实90年就有互联网出现，但是大家知道的互联网公司，包括腾讯、Google等，都是在98年才成立。而且，这些公司真正找到支持他们的商业模式，大概都是在2004年左右。这过程同样花了很多年。</p><p>所以，短线来看，整个Metaverse的发展，还需要好几年的培育，但是培育的方向是清晰的，潜力也是非常清晰的。</p><p>上一个20年，整个互联网对人类社会、经济、技术的贡献，大家有目共睹，所以我相信未来20-30年里，以Metaverse为核心的、集成的互联网体验，会给整个社会带去更大的冲击。</p><p>而这其中，还会有很多的点，值得大家探讨、协作、推动。</p><p>这是我今天的大致分享，感谢各位。</p>
                      
</div>
            