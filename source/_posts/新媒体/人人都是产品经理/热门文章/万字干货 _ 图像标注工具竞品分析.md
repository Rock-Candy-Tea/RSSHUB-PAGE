
---
title: '万字干货 _ 图像标注工具竞品分析'
categories: 
 - 新媒体
 - 人人都是产品经理
 - 热门文章
headimg: 'https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/LQZHU1C3kKftwJHiuDqB.jpg'
author: 人人都是产品经理
comments: false
date: Wed, 08 Jul 2020 00:00:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/LQZHU1C3kKftwJHiuDqB.jpg'
---

<div>   
<blockquote><p>编辑导语：图像标注是机器视觉（Computer Vision, 下面将简称为“CV”）模型开发流程中的重要一环，也是十分耗时的一环。随着深度学习的兴起，企业对于图像标注工具的需求也愈演愈烈。据知名行研机构<a href="https://www.grandviewresearch.com/industry-analysis/data-annotation-tools-market" target="_blank" rel="noopener noreferrer nofollow">估算</a>，2025年全球标注工具的市场规模将达到16亿美元。本文选取了3款行业中较有代表性的产品：CVAT、ModelArts、 Supervisely，从产品视角来试图探究标注工具行业现状及未来趋势。</p></blockquote>
<p><img data-action="zoom" class="aligncenter size-full wp-image-4074376" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/LQZHU1C3kKftwJHiuDqB.jpg" alt width="900" height="420" referrerpolicy="no-referrer"></p>
<h2 id="toc-1">1. 什么是图像标注</h2>
<p>图像标注是在原始图像打上标签的行为。在训练深度学习模型前，需要准备足量的，已被标注的样本用于训练。而图像标注就是样本准备中的一个步骤，如图1：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/i7k3oYbdyqASlPQNqUMj.png" alt width="598" height="305" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图1：Supervisely中的图片标注</p>
<p>原始图像类型包括：二维图片、三维图片、视频等。</p>
<p>标注形式包括：标签、包围框（二维和三维形式）、点、线、多边形、像素图（Bitmap）。</p>
<p>根据不同的标注形式，图像标注类型可分为：</p>
<ol>
<li><strong>分类 (Classification)</strong>：识别出图片中有什么物体，如上图中的1号箭头，表示整张图片中有people，通过标签进行标注。</li>
<li><strong>检测 (Detection)</strong>：比图片分类再进一步，不仅知道图片里有什么，还检测出物体大概位置，即物体所属包围框（<a href="https://computersciencewiki.org/index.php/Bounding_boxes" target="_blank" rel="noopener noreferrer nofollow">Bounding Box</a>）的位置，如上图中的2号用包围框标注了一个行人。通过包围框/线+标签进行标注。</li>
<li><strong>分割 (Segmentation)</strong>：比目标检测再进一步，知道每个像素属于哪个标签，如上图中的3号描绘出了行人像素级别的轮廓。具体还可细分成语义分割 (Semantic Segmentation)和实例分割 (Instance Segmentation)两类，语义分割用于识别不同种类的物体，而实例分割在语义分割的基础上进一步区分了同类物体中的不同实例。通过多边形/像素图+标签进行标注。</li>
<li><strong>姿态估计 (Pose Estimation)</strong>：又称关键点检测，主要用于识别图像内的关键区域，例如表情识别，运动姿势检测等。通过点/线+标签进行标注。</li>
<li><strong>视频行为识别(Video Action Recognition)</strong>：识别目标的意图，例如识别打架行为，这种场景很难仅凭单张图片判断（比如在单张图片下打架和拥抱是类似的），通常需要识别一段视频才能判断目标意图。仅通常使用包围框/点/线+标签的在插值模式下进行标注。</li>
</ol>
<p>下图为各个标注类型的示例：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/6wsp81vDMSfvck9xbpCt.png" alt width="479" height="889" referrerpolicy="no-referrer"></p>
<p align="center">图2：各类标注类型的示例，来源：<a href="https://gluon-cv.mxnet.io/contents.html" target="_blank" rel="noopener noreferrer nofollow">https://gluon-cv.mxnet.io/contents.html</a></p>
<p>通常，企业会有各式各样的标注需求，作为一款通用的标注产品，产品功能（如支持各种输入格式，各种标注类型，各种标注形式，以及额外功能）会是我们关注的一个重点。</p>
<p>另一方面，实际情况中标注是一件十分费时费力的工作，例如需要标出上图中的大部分行人，而这样的图片至少得有几百上千张。由此可见，因此用户体验是我们需要关注的另一个重点。</p>
<p>综上，本文将主要从产品功能和用户体验这两个维度来分析行业中的代表性产品。</p>
<h2 id="toc-2">2. 核心业务流程</h2>
<p>完成图片标注训练的整个工作流程，通常需要经历”数据准备”、”数据标注”、“数据进化”三个环节。具体业务流程如下图所示：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/lCv1AobbdpPADuGMdShR.png" alt width="601" height="336" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图3：图像标注通用业务流程</p>
<h3>2.1 数据准备</h3>
<p>数据准备包含：数据采集、数据预处理两步。</p>
<p><strong>1. 数据采集</strong>：采集途径很多如：本地上传，调用其他数据集数据，摄像头数据导入，从云服务调用获取数据等。</p>
<p><strong>2. 数据预处理</strong>：数据清洗是获取高质量训练数据的前提，并且通过清洗不合格的数据也可以减少无意义的标注工作，提高标注效率。数据清洗通常的操作包括：清洗模糊数据，清洗相似数据，裁剪，旋转，镜像，图片亮度，图片对比度，图片锐化等。</p>
<h3>2.2 数据标注</h3>
<p>数据标注包括：建立标注集、数据标注、标注审核。</p>
<p><strong>2.2.1 建立标注集</strong></p>
<p>标注集是标注工作的基本任务管理单元，在此不做过多赘述。</p>
<p><strong>2.2.2 数据标注</strong></p>
<p>具体方式见表1：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/ebvrnPHgwKFRhvPpqmXV.png" alt width="626" height="310" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">表1：数据标注具体方式</p>
<p><strong>2.2.3 标注审核</strong></p>
<p>针对“任务标注”，标注审核是对下发的标注任务进行管理并对标注结果审核，一般审核维度包括：标注进度、验收情况、标签数量、难例、标注质量等。</p>
<p>针对“自动标注”，标注审核是对自动标注的结果进行逐一检查确认，并修改标注有误的图片。</p>
<h3>2.3 数据进化</h3>
<p>数据进化包括：模型训练、模型推理。</p>
<p><strong>2.3.1 模型训练</strong>：</p>
<p>是将标注数据进行训练得出模型结果的过程。</p>
<p><strong>2.3.2 模型推理</strong>：</p>
<p>用于对训练的模型结果进行校验预测，并将错误或者有误差的校验结果记录下来带入到下一次模型训练中用于模型的优化迭代，从而形成由数据标注到模型训练再到模型迭代优化的闭合环路。</p>
<h2 id="toc-3">3. 竞品简介</h2>
<p>目前市面上标注工具较多，首先需要确定竞品选取原则：</p>
<ul>
<li>基于Web的应用，排除本地应用及移动端应用，理由：和笔者公司产品形态一致</li>
<li>有线上体验环境，理由：能够体验才能给出准确分析</li>
<li>功能较为完善，有代表性，理由： 完善的产品参考意义更大</li>
<li>因众包模式与笔者公司的产品战略有偏差，排除基于数据众包模式的产品，如Amazon Mechanical Turk。</li>
</ul>
<p>综上，选取了以下3款竞品：</p>
<ol>
<li><a href="https://github.com/opencv/cvat" target="_blank" rel="noopener noreferrer nofollow">CVAT</a>: Intel出品的开源标注工具，发布于2018年6月。其支持视频、图片等多种数据类型的标注，功能全面。</li>
<li><a href="https://www.huaweicloud.com/product/modelarts.html" target="_blank" rel="noopener noreferrer nofollow">ModelArts</a>: 华为出品的机器学习平台，发布于2018年10月，其中包含了数据标注模块。其支持从数据导入到模型运维的全流程开发，训练速度较快。</li>
<li><a href="https://supervise.ly/" target="_blank" rel="noopener noreferrer nofollow">Supervisely</a>: 俄罗斯Deep System旗下的模型训练平台，发布于2017年8月。其数据标注功能强大，特别是Smart Tool令人影响深刻：可以快速完成语义分割任务的标注。</li>
</ol>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/Bq9sFQ3QdwvdLBAJVowU.png" alt width="628" height="231" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">表2：3款产品的概括对比</p>
<h2 id="toc-4">4. 功能对比</h2>
<p>本节中，针对3款产品，我们从根据第2章的核心业务流程来探究产品功能间差异。</p>
<h3>4.1 CVAT</h3>
<p>CVAT的使用流程虽然十分简单，但功能十分全面和丰富。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/PgONg3jdyOBoNrzmZDoh.png" alt width="426" height="472" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图4：CVAT的标注流程</p>
<p><strong>4.1.1 创建数据集</strong></p>
<p>CVAT中以标注任务（Task）的概念替代数据集，一个任务可以包含多个作业，每个作业可以分配一个标注人员。</p>
<p>在创建标注任务时，CVAT也提供了丰富的高级选项，例如：</p>
<ol>
<li>支持使用<a href="https://git-lfs.github.com/" target="_blank" rel="noopener noreferrer nofollow">Git LFS:</a> Git Large File Storage, 大文件的git管理插件。</li>
<li>调整图片质量：通过降低图片质量（压缩比）来加快高清图片的加载。</li>
<li>作业数和重叠数：如果一个任务中的图片量很大，可以将其分成多个作业。再配合重叠数，可以实现分配一张图片到多个作业的效果，不过暂时没有想到重叠数的使用场景。</li>
</ol>
<p>总结来看，CVAT在标注任务模块汇中的一个优势是支持直接上传视频类型文件，上传完的视频会被根据用户设定的帧率（Frame）转换成图片。</p>
<p>CVAT在该模块中也有个明显的劣势：缺少一个统一的视角去总览任务中所有的图片（如下图所示，任务详情页中仅能看到首张图的照片），以及每张图片上所有的标注，推测是因为由于一张图片可能存在在多个作业中所导致。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/xP7TtuUieFoILA09lvMS.png" alt width="599" height="402" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图5：CVAT的标注任务详情页</p>
<p><strong>4.1.2 自动标注</strong></p>
<p>由于CVAT并未提供模型服务的能力，其自动标注功能还处在发展的初期，仅能满足个人实验。</p>
<p>添加自动标注模型需要用户上传模型文件，而非镜像或API，这种非服务化的方式很容易因为运行环境差异（例如2个服务器上安装了不同版本的依赖包），而影响标注成功率以及准确率。</p>
<p><strong>4.1.3 人工标注</strong></p>
<p>4.1.3.1 人工标注支持3种标注模式，且各个模式之前可来回切换：</p>
<ol>
<li><strong>标准模式（Standard）</strong>：用于常规标注。</li>
<li><strong>属性标注模式（Attribute Annotation）</strong>：在“属性模式”下用户可以专注于修改标注框属性和标签属性，提升了对标注属性检查和修改的效率。此模式专门用于对同一个物体设置一个或多个属性的场景，如人脸标注中需要标注年龄，性别等。</li>
<li><strong>标签标注模式（Tag Annotation）</strong>：在“标签模式”下用户可以迅速实现增删标签和对标签属性的选择和修改。同时为图片分类型标注定制的模式，还可为每个标签设置快捷键。极大提升了图片分类的标注效率。</li>
</ol>
<p>4.1.3.2 针对CVAT我们体验下来总结了以下几点优势：</p>
<p>1）灵活的标签和属性定义</p>
<p>同一图片可以标注多个标签，且一个标签可以设置多个属性且平台将属性定义分为：多选（Select）、单选（Radio）、是否（Checkbox）、文本（Text）、数字（Number）五种。CVAT标签自定义的自由度基本满足了绝大部分的标注需求。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/sO2Nz7BdrdDaSJefYb3L.png" alt width="598" height="306" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图6：CVAT中的5种标签属性</p>
<p>2）丰富的标注形式</p>
<p>为了支持各种类型的标注，CVAT提供了6种的标注形式，包括：标签、点、矩形、折线、多边形、长方体等。同时支持AI多边形标注：只需指定至少四个点就可以在系统的帮助下框选出一个目标的轮廓，这点同Supervisely相同，我们者体验下来在AI识别速度上还是期待进一步提升。</p>
<p>3）标注方式快捷键的统一</p>
<p>选择一个标注方式则快捷键”N“就代表这种标注方式。重新选择标注方式则”N”代表的方式随之对应改变。快捷键的统一进一步降低了用户的操作成本。</p>
<p>4）任务分析</p>
<p>通过任务分析仪表板中的分析，您可以查看每个用户在每个任务上花费了多少时间，以及他们在任何时间范围内完成了多少工作，任务分析拓展了CVAT的团队标注能力。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/IZDCyFYvZjw22VDjGrTy.png" alt width="598" height="284" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图7：CVAT中的Analytics仪表板（图片来源CVAT用户手册）</p>
<p>5）追踪模式（Track mode）</p>
<p>用于对视频文件进行标注。视频会按照帧率被分割成若干画面（Frame）。用户仅需在关键画面（Key frame，和Flash中的关键帧很类似）上进行标注，关键画面之间的画面也会自动带上标注。CVAT目前仅支持包围框和点使用插值模式。Propagate功能很实用，场景：如果想将当前图片中的标注传递（Propagate）给后面的n张图片。同时CVAT的追踪模式结合合并（Merge）功能、分割（Split）功能共同支撑起CVAT独具优势的视频或动图标注能力。</p>
<p>4.1.3.3 可能正因为其支持的功能过于丰富，导致使用起来有一定的学习成本，用户体验会有些差强人意。例如：</p>
<ol>
<li>标注时图片无法预览无法获知图片的总体标注情况，当下次在进入作业时不能快速定位到未标注的图片，这点虽说对与效率不会有太大影响但会影响用户的操作体验。</li>
<li>另外如果是做用户图片分类的标注，则需要使用属性模式，这一点用户难以感知。（我们一开始还以为只能通过画一个完全覆盖图片的框才能实现）</li>
</ol>
<h3>4.2 ModelArts</h3>
<p>Modelarts在2019年10月17日版本更新后（特别是团队标注功能），业务流程覆盖趋于完整。整体用户流程如下：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/FE0YdYhPW8dPKhKDF7nl.png" alt width="601" height="331" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图8：ModelArts的标注流程（图片来自ModelArts官网）</p>
<p>由于本文以数据标注功能的讨论为主，数据标注之后的功能（包括训练、推理、数据校正等）不在本文的讨论范围内。</p>
<p><strong>4.2.1 创建数据集</strong></p>
<p>在创建图片数据集时，ModelArts将图像标注类型设定在了数据集层面，即创建数据集时就需要区分标注类型.</p>
<p>这一点与Supervisely和CVAT区别较大，具体分析见Supervisely的人工标注章节。目前支持图片分类及目标检测两种任务。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/a6ertlSCXkw3tjJVaEpH.png" alt width="599" height="385" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图9：ModelArts中放入创建数据集</p>
<p><strong>4.2.2 数据处理</strong></p>
<p>华为的数据处理功能位于对象存储服务中，其提供了便利且功能全面的图片处理能力。</p>
<p>华为对象存储服务中提供了“图形界面模式”和“代码编辑模式”两种图片处理操作方式，适用了普通用户和开发者用户的使用。</p>
<p>同时最终的处理结果存放于内容分发网络（Content Delivery Network，CDN）加速，后续请求可以通过URL直接从CDN下载，可以将结果用于任意可以通过URL导入数据的标注平台，极大的拓展了平台的功能拓展性。</p>
<p>华为图片处理提供的能力主要包括：设置图片效果（亮度、对比度、锐化、模糊）、设置缩略、旋转图片、剪切图片、设置水印、转化格式、压缩图片。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/DVLcEdEKQwFvmHIGVaPN.png" alt width="599" height="291" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图10：华为对象存储中的图片处理模块</p>
<p><strong>4.2.3 智能标注 </strong></p>
<p>ModelArts智能标注包含：主动学习（半自动标注）和预标注（全自动标注）， 目前只有“图像分类”和“物体检测”类型的数据集支持智能标注功能。下面简单分析一下智能标注模块：</p>
<ol>
<li>系统只对未标注图片进行标注，这样可以减少重复标注，减少对于运算资源的浪费。</li>
<li>使用效果不理想，系统实际体验下来标注的准确性大概只能维持在60%。系统筛选难例的准确性也较低。</li>
<li>全自动标注支持选择自行训练的模型或ModelArts自带模型，在模型选择上灵活性较高，在下次进行作业时可以继承每次标注的结果进一步提升模型的准确率。</li>
<li>智能标注结果展示页面可以进行条件筛选，可选的条件包括：难例级，标签，样本创建时间，文件名，标注人，样本属性，置信度。精准的筛选可以满足大部分场景的需求。</li>
</ol>
<p><strong>4.2.4 人工标注</strong></p>
<p>华为ModelArts人工标注的特点主要有以下三点：</p>
<p>4.2.4.1 目标检测标注支持多达6种形式的标注</p>
<p>包括方形、多边形、正圆、点、单线、虚线（见图11），丰富的标注方式覆盖了更广泛的标注场景，同时可以提高标注的精度。</p>
<p>4.2.4.2 高效的标签选择方式</p>
<p>在数据标注的交互上，华为ModelArts在画完选框后会自动弹出标签下拉框已经展开的添加标签弹窗（见图11），省去了用户框选完成后自行点击标签下拉框的步骤。且弹出的标签选项卡就在选框旁边（见图11），这样减短了滑动鼠标选择标签的鼠标移动行程。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/DKwenE02GGkwtDgnEBWb.png" alt width="600" height="277" referrerpolicy="no-referrer"></p>
<p class="ql-long-39333334 ql-align-center" style="text-align: center;" align="center">图11：ModelArts图像检测的数据标注界面</p>
<p>4.2.4.3 图片分组</p>
<p>在标注预览页面华为ModelArts提供了图片分组功能（见图12），此功能会使用聚类算法或根据清晰度、亮度、图像色彩对图片进行分组。自动分组可以理解为数据标注的预处理，用户可根据分组结果，进行分组打标、图片清洗等操作。此功能可以提高图片标注效率，尤其是在图片分类标注的情况下再配合批量标注功能可以在标注速度上有质的提升。但我们在实际体验后感觉此功能分组的成功率较低。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/Fe7ATgqlbdU5iO0GYZld.png" alt width="739" height="199" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图12：ModelArts中的图片自动分组</p>
<p><strong>4.2.5 团队标注</strong></p>
<p>华为ModelArts的团队标注功能设置很齐全，有很多亮点，这里从创建，标注，审核三个方面探讨：</p>
<p>4.2.5.1 创建</p>
<p>华为启用团队标注后可以直接指定标注团队，也可以选择指定管理员然后由管理员分配标注人力并做审核工作。选则完类型后团队成员会收到系统邮件，按邮件提示可以很轻松的完成标注和审核。</p>
<p>可以选择是否将新增文件自动同步至标注团队。同时可以选择标注团队的文件是否加载智能标注结果。这些操作增加了管理员对任务分配和自动标注之间关系的调节自由度。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/G9Wm091QiedkR3Fl5bUJ.png" alt width="599" height="255" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图13：ModelArts团队标注创建页面</p>
<p>4.2.5.2 标注</p>
<p>标注一张图片并保存后，图片自动进入“待审核”状态。我们认为这样的状态切换超出用户预期，特别是用户如果还想再检查标注是否有误的话还需切换到“待审核”页面去检查，这样会给用户带来不便。</p>
<p>“待审核”的图片仍然可以修改，在管理员发起验收前，修改有效。但在验收时，如果图片被抽样到则修改不会保存在数据集中，如果图片未被抽样到则修改会被保存在数据集中。这样的审核逻辑限定可以减少在审核中产生不必要的混乱，防止审核结果产生误差。</p>
<p>4.2.5.3 审核</p>
<p>ModelArts将审核称为“验收”，验收分了2个层级：单张图片的验收和一批次图片的验收。流程是用户对一批图片做验收。审核层级过多，逻辑复杂，导致操作结果可能不符合用户预期。</p>
<p>标注状态混乱：例如管理员分配图片A给到标注人a，a标注完，管理员使用智能标注同时标注图片A，如果2个结果都被管理员确认，无论先确认哪种标注，最后只有智能标注的结果有效，而标注人a的标注则无效。</p>
<p>ModelArts提供了审核的仪表盘，仪表盘方便了审核的统计环节，用可视化的方式展示了任务进度。仪表盘的评判指标包括：验收进展统计、难例集数量、标签数与含标签的样本数、标注人进展统计等5个，见图14：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/VcbaEySIaU70e2IL6jZJ.png" alt width="603" height="295" referrerpolicy="no-referrer"></p>
<p class="ql-long-10005458 ql-align-center" align="center">图14：ModelArts中的标注审核仪表盘</p>
<h3>4.3 Supervisely</h3>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/OgnBekyzbMzlV86HX8QD.png" alt width="601" height="798" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图15：Supervisely的标注流程</p>
<p>从图中可以看到团队标注一块的逻辑相比其他产品更加复杂，分析背后的原因：</p>
<p>表面上看很多步骤是为了满足团队标注这一需求（特别是外部标注团队），包括创建团队、邀请成员、创建标注作业、标注审核等等，但本质上则是安全把控和质量把控需求：</p>
<ol>
<li>安全把控体现在管理员可以分配给团队成员不同的角色以控制成员的权限，例如标注者（Annotator）只能查看自己任务中的图片；</li>
<li>质量把控体现在标注完后还会有管理员审核标注情况以保证标注质量。</li>
</ol>
<p>因此，这样复杂的链路是一个企业级标注产品应有的设计，尽管这样不可避免会造成用户认知成本的升高，以及用户体验的降低。</p>
<p><strong>4.3.1 创建数据集</strong></p>
<p>在Supervisely中，用户可以在一个数据集中完成4种标注（视频标注除外），即分类、检测、分割、姿态估计。</p>
<p>与ModelArts不同，Supervisely对数据集的定位更像是图片集。一批图片只需要导入一次，无论做哪种类型的标注都可以在同一个数据集上完成。且后续做训练时，可以直接得到一张图片上的所有标注。</p>
<p>综上，Supervisely统一的数据集模块，提升了图片导入，图片标注以及图片后处理的效率。但这种方式也有缺点：所有标注类型的操作模式固定，无法针对特定类型（例如Modelarts的图片分类可同时选择多张图片一起标注）做深入优化。</p>
<p><strong>4.3.2 数据处理</strong></p>
<p>Supervisely的数据处理模块叫做DTL, Data Transformation Language，是一种基于JSON的脚本语言，通过配置DTL脚本可以完成合并数据集、标签映射、图片增强、格式转换、图片去噪、图片翻转等46种操作，满足各类数据处理需求。<br>
<img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/4rDsME9GwBvLFwKP2k0C.png" alt width="695" height="215" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图16：Supervisely中为图片加入高斯模糊</p>
<p>虽然功能相比ModelArts来说更加强大，但是由于仅提供代码形式操作，仅适合工程师，然而大部分工程师已掌握通过python处理图片的方式，再额外学习一种语言无疑会增加学习成本。</p>
<p>另一方面这种特殊的语言对效率的提升也存在未知数，例如用户想进行某种图片操作，但调研了半天发现该语言不支持，最后还是要通过python来完成，到头来降低了效率。</p>
<p><strong>4.3.3 自动标注</strong></p>
<p>Supervisely目前提供了14款预训练的模型，训练用数据大部分来自COCO（微软发布的大型图像数据集），少部分来自PASCAL VOC2012, Cityscapes, ADE20K等其他公开数据集。</p>
<p>在自动标注部分，Supervisely的优势在于支持语义分割型的自动标注，加上产品在语义分割型的人工标注上拥有出色的体验，使这类型任务的标注效率得以大幅提升。</p>
<p>Supervisely的自动标注模块产品化程度较低，主要体现在以下两点：</p>
<ol>
<li>由于本身不提供模型训练及推理服务，需要用户自行准备自动标注所需的硬件环境，且限制较多（仅支持Nvidia GPU，需要Linux和Cuda驱动）。</li>
<li>通过JSON格式的配置文件来配置模型推理参数（见图17）。相比华为简单的配置界面，这种形式的灵活性虽然更高，但用户真的需要那么配置还是指想系统直接给出一个自动标注的结果就好呢？</li>
</ol>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/qqTwT1bv8TOMTEimVWnu.png" alt width="747" height="327" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">图17：Supervisely（左）与华为ModelArts（右）的全自动标注配置对比</p>
<p><strong>4.3.4 人工标注</strong></p>
<p>Supervisely的标注功能十分强大，主要有以下2个特点：</p>
<ol>
<li>丰富的标注形式：为了支持各种类型的标注，Supervisely提供了多达9种的标注形式，包括：标签、点、矩形、折线、多边形、长方体、像素图、智能工具 (Smart Tool)、关键点等。</li>
<li>复杂的标签系统：抽象出了对象（Object），类（Class），标签（Tag）三个实体，在复杂场景中提高了实体之间的复用性。</li>
</ol>
<p>4.3.4.1 丰富的标注形式</p>
<p>在所有9种标注形式中，智能工具令人印象深刻：</p>
<p>智能工具用于分割类型的标注，用户只需要2次点击框选一个物体，通过算法对目标进行描边即可完成一个初步的分割，再通过标注积极点和消极点完成精确标注，大大降低了分割类任务的标注成本。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/AfTzU91jtIqn1Yq690Bv.png" alt width="594" height="396" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图18：Supervisely中经过11次点击后完成了一个语义分割</p>
<p>4.3.4.2 复杂的标签系统</p>
<p>为了满足一个数据集涵盖多种标注类型的需求，Supervisely有一套复杂的标签系统。我们通过对3款产品的ER图来具体分析一下这套标签系统的优劣。</p>
<p>在图19的行人识别场景中，我们会画一个个行人包围框。那么我们就需要定义一个标签叫：行人。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/i7k3oYbdyqASlPQNqUMj.png" alt width="599" height="305" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图19：Supervisely中的行人标注场景</p>
<p>但是每个行人的属性又有不同，例如行人A戴帽，行人B不戴帽.如果我们需要区分戴帽的行人和不戴帽的行人，一种做法是创建两个标签：戴帽的行人、不戴帽的行人。</p>
<p>但这样的两个标签会丧失关联性——如果模型只要检测行人，还需要对这两个标签进行转换，效率较低。</p>
<p>比较合理的做法是在行人标签下创建一个属性——是否戴帽；并抽象出一个概念：对象。</p>
<p>用户每画一个包围框，系统就会创建一个对象（例如：行人A），每个对象会对应一个标签（例如：行人），然后每个对象可以设置该标签所具有的属性值（例如：是否戴帽=是）。</p>
<p>CVAT和ModelArts都是这样的做法，区别是CVAT可以直接为图片加上标签，用于图片分类。而ModelArts由于划分了图片分类和目标检测数据集，因此标签仅能在图片分类型数据中被应用在图片上。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/ohlYY5uKrBDYiLv7X6FH.png" alt width="597" height="336" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图20：CVAT（左）和ModelArts（右）的图片-对象-标签ER图对比</p>
<p>而Supervisely则是把标签和属性拆分成了两个实体（如下图）：</p>
<p>这种做法可以提高属性的复用，例如在Supervisely中，用户只需要定义一遍颜色属性，之后无论是标注行人还是车辆的颜色都可以应用同一个“颜色”下面的属性，提高了复杂标注集的准备效率。</p>
<p>但同时这种做法对用户体验设计提出了较大挑战，从上手难度来看，Supervisely无疑是三款产品中最难上手的。</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/nY2EJfJtBulTNkhlklux.png" alt width="602" height="341" referrerpolicy="no-referrer"></p>
<p style="text-align: center;" align="center">图21：Supervisely的图片-对象-标签-对象ER图</p>
<h2 id="toc-5">5. 总结与展望</h2>
<h3>5.1 总结对比</h3>
<p>下表为三款标注产品的功能总结：</p>
<p><img data-action="zoom" class="aligncenter" src="https://cors.zfour.workers.dev/?http://image.woshipm.com/wp-files/2020/07/GELVgO7ZDrfypo3IPx7f.png" alt width="1140" height="848" referrerpolicy="no-referrer"></p>
<p style="text-align: center;">表3：三款产品的功能总结对比</p>
<ol>
<li>CVAT: 人工标注功能最为强大，但自动标注功较为薄弱。独有的追踪模式免去了对视频的预处理，对标注效率的提升也十分巨大。CVAT的任务分析功能由于环境原因未能完全体验，从介绍来看应该会在这块发力。</li>
<li>ModelArts: 作为华为云的一个功能模块，ModelArts的产品战略也更加偏向通用性，平台性。通过与华为OBS系统的结合给其带来了强大的数据处理能力也强化了其平台的可拓展性和兼容性。同时自动标注和半自动标注作为ModelArts的优势是CVAT和Supervisely所不具备的，也从侧面体现了ModelArts依靠华为云所带来的强大运算力和算法优势。总体来说ModelArts是一个均衡的选手，具有优秀的业务拓展能力。</li>
<li>Supervisely：整体功能最为完善，适合企业级应用。对语义分割类任务支持较好，但部分功能（如数据处理，自动标注）需要通过代码方式完成，效率提升有限。</li>
</ol>
<p>当然我们也发现有一些功能在3款产品中都没有看到，例如水印功能，会适用于保密要求的场景，如监狱，银行等。</p>
<h3>5.2 标注工具的未来趋势</h3>
<p><strong>5.2.1 人工标注这个环节不会消失</strong></p>
<p>这其实是个悖论：假设我需要训练一个CV模型，训练模型需要准备标注好的图片，如果图片标注只需要自动标注而无需人工干预，那意味着模型已经能够准确预测出结果.</p>
<p>如果能做到准确预测，说明已经这个模型已经被训练完全，不再需要训练，这就和假设相悖了。</p>
<p><strong>5.2.2 自动标注的价值主要体现在单个标注需要花费较长时间的标注类型中，如分割和姿态估计</strong></p>
<p>既然人工标注一定会存在，那么自动标注存在意义就是提高人工标注效率，而非代替人工标注。在分类和检测任务这类单次标注耗时较短的场景中，自动标注的价值较小。</p>
<p>假设从0开始完成一个标注花费5秒钟，而已经进行了自动标注的情况下，修改一个标注需要花2秒，标注效率提升60%（假设跑自动标注模型是在下班之后，不影响人工标注时间）。</p>
<p>但我们看到可能有些图片上模型的标注结果偏差太大，这样用户还需要话1秒来删掉自动标注的结果，反而这次标注的效率降低了20% （IE,1/5），如此高的负收益使得整体效率算下来没有提高很多。</p>
<p><strong>5.2.3 人工标注的主要内容将从创建标注转变为修改标注</strong></p>
<p>虽然人工标注环节不会消失，但显然自动标注将会在标注环节起到越来越重要的作用，今后常见的标注流程将会从创建一个新标注，转变为修改一个由模型创建的标注。</p>
<p>因此，优化修改标注时的用户体验将会是一个提高标注效率的突破点。</p>
<p> </p>
<p>作者：薛康杰，AIoT产品经理，AIops, CV和IoT等平台类产品；江海龙，AI产品实习生，主攻CV产品设计。</p>
<p class="ql-heading-title">本文由 @薛康杰 原创发布于人人都是产品经理，未经许可，禁止转载</p>
<p>题图来自 <a href="https://unsplash.com/">Unsplash</a>，基于 CC0 协议</p>
<div class="support-author"><div class="support-title">给作者打赏，鼓励TA抓紧创作！</div><button class="button--pay" data-post-id="4072490" data-author="770081" data-avatar="http://image.woshipm.com/wp-files/2020/07/8BbEZyap1hD5rxQ82Ihp.jpg"><svg width="13" height="16" class="svgIcon--use" viewBox="0 0 13 16"><path d="M9.113,4.571 C9.951,3.771 10.895,2.742 10.685,2.057 C10.475,1.485 10.056,0.799 9.427,0.571 C8.903,0.342 8.379,0.456 7.750,0.799 C7.540,0.342 7.016,0.114 6.596,-0.001 C5.863,-0.001 5.234,0.228 4.814,0.914 C4.080,0.571 3.451,0.685 2.927,1.028 C2.613,1.256 2.298,1.713 2.298,2.628 C2.298,3.542 3.137,4.228 3.766,4.685 C2.508,5.599 -0.218,7.885 -0.008,12.228 C-0.218,15.656 2.613,15.999 2.613,15.999 L10.371,15.999 C11.314,15.885 12.991,14.971 12.991,12.571 L12.991,12.228 C13.201,7.771 10.371,5.371 9.113,4.571 L9.113,4.571 ZM8.932,11.835 L6.940,11.835 L6.940,13.207 C6.940,13.435 6.731,13.549 6.521,13.549 C6.311,13.549 6.102,13.435 6.102,13.207 L6.102,11.835 L4.110,11.835 C3.900,11.835 3.795,11.606 3.795,11.378 C3.795,11.149 3.900,10.921 4.110,10.921 L6.102,10.921 L6.102,10.121 L4.949,10.121 C4.739,10.121 4.634,9.892 4.634,9.664 C4.634,9.435 4.739,9.206 4.949,9.206 L5.892,9.206 L4.739,7.950 C4.634,7.835 4.739,7.606 4.949,7.492 C5.158,7.378 5.368,7.264 5.473,7.378 L6.521,8.635 L7.674,7.264 C7.779,7.149 7.989,7.264 8.198,7.378 C8.408,7.492 8.408,7.721 8.408,7.835 L7.150,9.321 L8.094,9.321 C8.303,9.321 8.408,9.549 8.408,9.778 C8.408,10.007 8.303,10.235 8.094,10.235 L6.940,10.235 L6.940,11.035 L8.932,11.035 C9.142,11.035 9.247,11.264 9.247,11.493 C9.247,11.606 9.037,11.835 8.932,11.835 L8.932,11.835 Z"/></svg>
赞赏</button></div>                      
</div>
            