
---
title: '利用集體心智創作的機器與藝術家'
categories: 
 - 新媒体
 - Matters
 - 最新、熱議、精華
headimg: 'https://assets.matters.news/embed/d70c5278-b836-4fdb-ba25-86529e778b91.jpeg'
author: Matters
comments: false
date: Sun, 12 Dec 2021 06:23:30 GMT
thumbnail: 'https://assets.matters.news/embed/d70c5278-b836-4fdb-ba25-86529e778b91.jpeg'
---

<div>   
<p>高中時代很愛一部科幻小說，由星雲、雨果、坎伯三大獎得主羅伯特．索耶（Robert J. Sawyer）撰寫，叫做《<a href="https://www.books.com.tw/products/0010567306" rel="noopener noreferrer" target="_blank">WWW.甦醒</a>》（www:wake），故事大概是一名聰慧的盲眼女孩自從裝上電子眼之後，因為某些 bug 見證了網路心靈的誕生，網路心靈因主角的電子眼而有了與世界互動的機會...。</p><p>時間快轉十年來到此時此刻，OpenAI 與 Google 在這幾年間推出了革命性的人工智慧工具，包括 AlphaGo（自動博弈）、GPT-3（語言生成）、AlphaFold（蛋白質預測），每一個都讓我覺得世界在光速進化。</p><hr><p>今年一月，OpenAI 將魔爪伸向了圖像生成領域，Dall-E（達利）系統可以藉由輸入語句做出變幻無窮的圖片（Text-to-Image），其中的核心靈魂 — 文字圖片配對引擎 CLIP （Contractive Language-Image Pre-Training）是開源軟體，這幾個月圖像演算界像是著了魔般突飛猛進，演化出看次無窮無盡的新玩法。</p><p>就在上週<a href="http://pixray.gob.io/text2image/?fbclid=IwAR3JTkxV4esS-PTWCJ8r70jC-mgJKCa2Cmu7LrjcOJNcDo1u52rbt9RuXgY" rel="noopener noreferrer" target="_blank"> Pixray 網站</a>出現，讓一般人可以輸入語句，換取由 AI 工具生成的魔幻圖片，甚至可以一鍵鑄造 NFT。兩週前我分享這個應用的文章，竟然獲得八百多個分享，讓我在訝異之餘，深深覺得新的時代已經到來。</p><p>不知不覺中，集體共識的時代已經來臨，所有人都中了網際網路的瞳術。</p><hr><p>我把 Pixray 傳給藝術家朋友 <a href="https://www.facebook.com/eddie8342372?__tn__=-]K*F" rel="noopener noreferrer" target="_blank">張明曜</a> 看，他彷彿著了魔，沒日沒夜的算圖，藉由調整字句與骰圖，讓圖片展現其意圖，目前應該已算超過一萬張圖。踩在其他圖片的屍體上，目前有九張圖誕生，構成了系列作《創世紀 Genesis》，這幾天瞬間熱銷一空。</p><figure class="image"><img src="https://assets.matters.news/embed/d70c5278-b836-4fdb-ba25-86529e778b91.jpeg" data-asset-id="d70c5278-b836-4fdb-ba25-86529e778b91" referrerpolicy="no-referrer"><figcaption><span>創世紀：創造夏娃（張明曜 2021）</span></figcaption></figure><p>今天不講 NFT 銷售策略或是圖像美學，純討論什麼是從網際網路誕生的集體共識；與張明曜的行為，是否是一種集體心智共同創作。</p><hr><p>其實 AI 藝術已不是新鮮事，AI 藝術先驅 Mario Klingemann 於 2018 年獲得〈流明獎〉（Lumen Prize），其作品〈屠夫之子〉便是使用 GAN（Generative Adversarial Network, 生成式對抗網絡）訓練製作；之前提到由 Memo Akten 創作的分散式意識（章魚），也是以 GAN 進行創作。台灣藝術家賴宗昀的〈Ancestor〉應也是類似的創作方式。</p><figure class="image"><img src="https://assets.matters.news/embed/fde725bc-c946-4831-904a-30afad6ca853.png" data-asset-id="fde725bc-c946-4831-904a-30afad6ca853" referrerpolicy="no-referrer"><figcaption><span>Imposture Series - The Butcher's Son, 2017</span></figcaption></figure><blockquote>“How will we be able to make a living if machines take over our creative jobs?” <br class="smart">- Mario Klingemann</blockquote><p>就在十月底，Mario Klingemann 打造了一名 AI 機器藝術家 <a href="https://botto.com/" rel="noopener noreferrer" target="_blank">Botto</a>，與其背後支撐他的代幣經濟 $Botto，其背後的創作原理與文前提到的 Pixrary 相同，這部機器會定時接受社群提出的文字語句進行創作，其作品的交易量已經超過三千三百萬台幣。整個策略與行動發人省思，作品也很美。</p><figure class="image"><img src="https://assets.matters.news/embed/c3f4414a-9135-414c-89d2-367e5a43a4bd.png" data-asset-id="c3f4414a-9135-414c-89d2-367e5a43a4bd" referrerpolicy="no-referrer"><figcaption><span>Botto.com</span></figcaption></figure><p>〈張明曜 x Pixray〉與〈Botto〉這兩個案例讓我久久不能自已，我感到空前的震撼與深刻，有一種伸手碰觸到繁星的感覺。</p><p>我仔細窮究這個震撼源自何處，發現其原因不是 AI 會創作、會自動演化；而是因為這兩台機器背後使用的核心靈魂 — 演算法 CLIP。</p><figure class="image"><img src="https://assets.matters.news/embed/5ce09260-d64e-4d90-9e3a-ea4670584d15.png" data-asset-id="5ce09260-d64e-4d90-9e3a-ea4670584d15" referrerpolicy="no-referrer"><figcaption><span>openAI.com</span></figcaption></figure><p><strong>這個演算法的糧食，來自全人類的網路足跡。</strong></p><p>忝為一名就讀 AI 相關研究所的菜鳥碩士生，我對程式碼與方法論沒那麼熟稔，過程中若有疏漏請多指正。</p><p>先講結論，CLIP 在誕生時不是經過事先準備好的資料集訓練的，而是使用網路上能找到的一切具有文字標籤的圖片來訓練，因此我們很難去預判 CLIP 到底學到了什麼。使用 CLIP 時，不需要再次準備圖片資料集去做訓練，這個方式稱為 Zero-shot learning。</p><hr><p><strong>網路上一切有文字解釋之圖片，是誰的解釋？解釋權在誰手上？</strong></p><p>不是科學家的解釋、不是工讀生的解釋，是「我們」的解釋。</p><p>更進一步來說，是自古以來網路使用者的解釋。</p><p>我們想到什麼，記下什麼，人工智慧就會去消化它，學習它，成為一部沒有靈魂，但有淵博知識的藝術家。人類藉由唸出一段咒語來召喚人工智慧，他生出一件作品給你，請問這件作品是由誰創作的呢？唸咒者、人工智慧、還是全人類？</p><p>打個比方，當你在 Pixray 寫下艾菲爾鐵塔（Eiffel Tower）時，機器吐出來的圖片是一個鐵製尖塔，不是從艾菲爾鐵塔底下往上看的樣子，也不是站在塔頂往外看的樣子，為什麼呢？因為全人類都一致認為，艾菲爾鐵塔便應該一幢從遠方凝視的尖塔。</p><p>艾菲爾鐵塔的符號非常明確，大家的心像大致上相同。</p><p>這就是集體心智，AI 演算法奪去了這個心智，展現給大家看。</p><hr><p>那張明曜與 $Botto 持有者做了什麼？他們成為應用新工具的創作者。</p><p><strong>Prompt Engineering</strong>（中文不確定怎麼翻譯，我先稱之為引導工程）是這種創作方式的名稱，藉由不同詞彙的堆疊，彷彿畫筆不斷將顏料堆疊在畫布上。</p><p>這可不是一件容易的事，顏料有色調、運筆有技法、構圖有各種消失法（拿出我國中美術班的知識...），Prompt Engineering 必須逆向工程出 AI 吐哺集體心智誕生的新詞彙，名詞、形容詞、動詞、介系詞、方向導引等等。</p><p>但同一個句子，機器會骰出不同的圖片，因為訓練集與演算法特性使然。</p><p>多麼詩意的創作過程呀。</p><hr><p><strong>因為人工智慧進步，今天的人類已可以使用詩句來進行圖像創作。</strong></p><p>這是我感到震撼的原因。</p><p>這是全新的畫布與畫筆，折射出我們內心習以為成的事物。</p><p>（文章到此已經結束，如果你對原理有興趣，可以繼續往下看。）</p><hr><figure class="image"><img src="https://assets.matters.news/embed/83ed3e52-06e4-4565-9003-45ee1b224ddc.jpeg" data-asset-id="83ed3e52-06e4-4565-9003-45ee1b224ddc" referrerpolicy="no-referrer"><figcaption><span>張明曜作品 Genesis: Creation of Adam（創世紀：創造亞當）（2021）黃豆泥收藏</span></figcaption></figure><p>摘錄張明曜作品敘述</p><p>「藉由人工智能生成圖像的技術日益成熟，生成藝術似乎只剩下兩種狀況：藉由編程來影響機器的運算邏輯，或是將創作的意識全權交付給機器。無論何者，圖像的創造性似乎已不再由人所掌握。那麼，透過與機器不斷協商的方式，取回一部分的創造性，是否能稱得上是生成藝術的文藝復興呢？」</p><p>「《Genesis》這系列作品，使用Pixray的圖象生成網站，不停修正字串與機器進行協商，且不使用任何指令與語法，來生成符合期望的圖象。作品名除了指向生成藝術外，亦連結至米開朗基羅的《創世紀》，來談論與機器攜手之創造可能性，思考在放棄編程卻不捨棄圖象創作意識的狀況下的「人本」精神。」</p><hr><p><strong>VQGAN+CLIP 演算法原理</strong></p><p>回過頭來講 Pixray 的演算法組合，工程師 Dribnet 融合了 Perception Engines、VQGAN+CLIP、Sampling Generative Networks，打造 Pixray 創作平台，大家有興趣可以上去玩玩看，簡單又好玩。今天只稍微解釋什麼是 VQGAN+CLIP。</p><p>上文提到 CLIP 於今年一月由 OpenAI 提出， 更新的融合技術 CLIP guided GAN imagery 於今年四月由 Ryan Murdoch 與 Katherine Crowson 提出。十一月時已經可以看到應用其技術的 GUI （圖像式介面，就可你不用開終端機就能玩的服務）民間使用平台，實在令我訝異科技進步之神速，果然開源精神是一條最有效率的道路。</p><p>簡單來講， VQGAN+CLIP 是一個文字轉圖片的工具（text-to-image），只要設定文本導引（Text prompt），它就會給你圖片。這個工具已經替 AI 創作工具（Creative AI）創造新浪潮。</p><p>VQGAN 與 CLIP 分別是兩個神經網路架構， VQGAN 全名為 Vector Quantized Generative Adversarial Network（量子化向量生成式對抗網絡），使用卷積神經網絡加上知名的文字演算法（Transformer, BERT & GPT的爸爸），白話一點來講它讀取文字，產出圖片。CLIP 全名為 Contrastive Language-Image Pre-Training （預先訓練對照式語言圖形演算法），它判斷哪一張圖片最匹配文字敘述。OpenAI 同一個時間推出的 Dall-E 達利系統，是採用數億張已知的圖片資料庫來訓練，而 CLIP 本身採用未知的網路圖片進行訓練。</p><p>創作者提出文字，VQGAN 產出圖片，CLIP 告訴 VQGAN 圖片對不對，對錯的準則由網路全人類的結晶決定，以此方式反覆迭代到創作者說停為止。</p><p>我認為這個工具將產生巨大的創作能量，現在只是一個開頭而已。</p><hr><p>盡我所能提出解釋，以下索引歡迎參考。</p><ol><li><a href="http://pixray.gob.io/text2image/?fbclid=IwAR3JTkxV4esS-PTWCJ8r70jC-mgJKCa2Cmu7LrjcOJNcDo1u52rbt9RuXgY" rel="noopener noreferrer" target="_blank">Pixray 創作平台</a></li><li><a href="https://akaswap.com/tz/tz1cdYognc8ijJHSyvKemon5MWA9Vuyiz2Yx?fbclid=IwAR1L14Eax8xzVTG2JNLGpHIZ3lCZMEHBlg8yUjA8ki8aRPFm7Vnmdm-N1HM" rel="noopener noreferrer" target="_blank">張明曜作品</a></li><li><a href="https://matters.news/@mashbean/%E5%88%A9%E7%94%A8%E9%9B%86%E9%AB%94%E5%BF%83%E6%99%BA%E5%89%B5%E4%BD%9C%E7%9A%84%E6%A9%9F%E5%99%A8%E8%88%87%E8%97%9D%E8%A1%93%E5%AE%B6-bafyreifargnp7ji53sidde6atbewsycnrzkpfsriqjhzrwzjxw5arspuye" rel="noopener noreferrer" target="_blank">Mario Klingemann's Botto Project</a></li><li><a href="https://docs.botto.com/details/bottos-art-%20engine" rel="noopener noreferrer" target="_blank">Botto 的技術文件</a></li><li><a href="https://openai.com/blog/clip/?fbclid=IwAR2prZqdnh6Wv9de07tFDSObbvcNa1lO7vRj4tXzgHZC94Pgg3Ofv6bhf-Q" rel="noopener noreferrer" target="_blank">OpenAI's CLIP</a></li><li><a href="https://blog.infuseai.io/openai-%E7%9A%84-multimodal-%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-%E4%B8%8B-clip-connecting-text-and-images-2e9962905504" rel="noopener noreferrer" target="_blank">CLIP 中文介紹 from Infuse AI</a></li><li><a href="https://alexasteinbruck.medium.com/vqgan-clip-how-does-it-work-210a5dca5e52" rel="noopener noreferrer" target="_blank">VQGAN+CLIP — How does it work? by Alexa Steinbrück</a>ㄇㄛ</li></ol>  
</div>
            