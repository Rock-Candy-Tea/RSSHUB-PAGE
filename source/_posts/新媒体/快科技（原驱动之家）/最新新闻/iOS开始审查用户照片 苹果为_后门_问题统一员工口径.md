
---
title: 'iOS开始审查用户照片 苹果为_后门_问题统一员工口径'
categories: 
 - 新媒体
 - 快科技（原驱动之家）
 - 最新新闻
headimg: 'https://img1.mydrivers.com/img/20210815/s_4c0e4f27da7b4bd6bbb7820fdd95eb12.jpg'
author: 快科技（原驱动之家）
comments: false
date: Sun, 15 Aug 2021 08:22:21 GMT
thumbnail: 'https://img1.mydrivers.com/img/20210815/s_4c0e4f27da7b4bd6bbb7820fdd95eb12.jpg'
---

<div>   
<p class="MsoNormal">苹果一直标榜自家的手机及<span lang="EN-US">iOS</span>系统在用户隐私上的牢不可破，甚至不惜跟美国政府打官司。不过现在苹果改了一个政策，<span lang="EN-US">iOS</span>会审查用户的照片，以致于苹果都要开始为此统一员工口径。</p>
<p class="MsoNormal">本月初，苹果宣布了一项新政策，<span style="color:#ff0000;"><strong>将推出名为“<span lang="EN-US">neuralMatch”</span>的新技术，它会在图片上传到<span lang="EN-US">iCloud</span>之前进行扫描。如果它找到了匹配的<span lang="EN-US">CSAM</span>（儿童性虐待照片），</strong></span>将会通知审核人员检查。若确认存在儿童色情内容，那么苹果方面将关闭账户，并通知美国国家失踪和被剥削儿童中心。</p>
<p class="MsoNormal">苹果这一举动受到了儿童保护组织的认可，但有更多的人认为苹果审查用户照片是个不好的苗头，觉得被植入了后门，担心该系统遭到滥用。</p>
<p class="MsoNormal">苹果此前解释过该系统的运作方式，<strong>称这一系统并不能真正“看到”用户的照片，</strong>而是采用“数字指纹”的技术，通过辨识图片中的关键信息，与现有的儿童性侵图像数据库内容对比。</p>
<p class="MsoNormal">虽然内部员工都有强烈的反对倾向，但苹果还是会执行这一政策，本周还给员工下发了最新的备忘录，<strong>要求员工在<span lang="EN-US">CSAM</span>后门问题上统一口径，强调这一政策只针对<span lang="EN-US">iCloud</span>中的<span lang="EN-US">CSAM</span>内容，不会容忍被滥用。</strong></p>


<p align="center"><a href="https://img1.mydrivers.com/img/20210815/4c0e4f27da7b4bd6bbb7820fdd95eb12.jpg" target="_blank"><img alt="iOS开始审查用户照片 苹果为“后门”问题统一员工口径" h="399" src="https://img1.mydrivers.com/img/20210815/s_4c0e4f27da7b4bd6bbb7820fdd95eb12.jpg" style="border: black 1px solid;" w="600" referrerpolicy="no-referrer"></a></p>

           
           
<p class="end"> - THE END -</p> 
          <p class="zhuanzai">转载请注明出处：快科技</p>  
 <p class="bqian"><a href="https://news.mydrivers.com/tag/pingguo.htm"><i>#</i>苹果</a><a href="https://news.mydrivers.com/tag/iphoneshouji.htm"><i>#</i>iPhone手机</a><a href="https://news.mydrivers.com/tag/ios.htm"><i>#</i>iOS</a></p>
<p class="url">
     
<span>责任编辑：宪瑞</span>
</p>
        
</div>
            