
---
title: '512颗GPU、10万亿参数！阿里达摩院发布全球最大AI预训练模型'
categories: 
 - 新媒体
 - 快科技（原驱动之家）
 - 最新新闻
headimg: 'https://img1.mydrivers.com/img/20211108/s_acd71f679c4f4153b1d49d4487aaa0ca.png'
author: 快科技（原驱动之家）
comments: false
date: Mon, 08 Nov 2021 19:43:46 GMT
thumbnail: 'https://img1.mydrivers.com/img/20211108/s_acd71f679c4f4153b1d49d4487aaa0ca.png'
---

<div>   
<p>11月8日，阿里巴巴达摩院公布了多模态大模型“M6”的最新进展，其参数已从万亿跃迁至10万亿，成为全球最大的AI预训练模型。</p>
<p><strong>作为通用性AI大模型，M6拥有多模态、多任务能力，尤其擅长设计、写作、问答，在电商、制造业、文学艺术、科学研究等领域有广泛应用前景。</strong></p>
<p>与传统AI相比，大模型拥有成百上千倍“神经元”数量，认知和创造能力也更胜一筹，被普遍认为是未来的“基础模型”。</p>
<p>但是，大模型的算力成本相当高昂，比如训练1750亿参数语言大模型GPT-3所需能耗，能让一辆汽车在地月之间往返一趟。</p>
<p>今年5月，通过专家并行策略及优化技术，达摩院M6团队将万亿模型能耗降低超过80％，效率提升近11倍。</p>
<p>10月，M6再次突破业界极限，<strong><span style="color:#ff0000;">使用512颗GPU，在10天内就训练出了具有可用水平的10万亿模型，相比去年发布的大模型GPT-3，M6实现了同等参数规模，能耗却只有1％。</span></strong></p>
<p style="text-align: center;"><a href="https://img1.mydrivers.com/img/20211108/acd71f679c4f4153b1d49d4487aaa0ca.png" style="text-align: -webkit-center;" target="_blank"><img alt="512颗GPU、10万亿参数！阿里达摩院发布全球最大AI预训练模型" h="383" src="https://img1.mydrivers.com/img/20211108/s_acd71f679c4f4153b1d49d4487aaa0ca.png" style="border: 1px solid black;" w="600" referrerpolicy="no-referrer"></a></p>
<p>另一方面，AI大模型扩展到千亿及以上参数的超大规模时，很难放在一台机器上，为此达摩院<strong>在阿里云PAI自研Whale框架上搭建了MoE模型，并通过更细粒度的CPU offload技术，最终实现将10万亿参数放进512张GPU：</strong></p>
<p><strong>自研Whale框架：</strong></p>
<p>自研Whale分布式深度学习训练框架，针对数据并行、模型并行、流水并行、混合并行等多种并行模型进行了统一架构设计，让用户在仅仅添加几行API调用的情况下就可以实现丰富的分布式并行策略。</p>
<p><strong>MoE专家并行策略：</strong></p>
<p>在Whale架构中实现Mixture-of-Experts（MoE）专家并行策略，在扩展模型容量、提升模型效果的基础上，不显著增加运算FLOPs（每秒所执行的浮点运算次数），从而实现高效训练大规模模型的目的。</p>
<p><strong>CPU offload创新技术：</strong></p>
<p>在自研的分布式框架Whale中通过更细粒度的CPU offload，解决了有限资源放下极限规模的难题，并通过灵活地选择offload的模型层，进一步地提高GPU利用率。</p>
<p>此外，针对训练效率问题，M6团队设计了Pseudo-to-Real（共享解除）机制，即利用训练好的共享参数模型初始化大模型，让收敛效率进一步提升7倍，解决大模型训练速度慢的问题。</p>
<p>对比不使用该机制，预训练达到同样loss用时仅需6％；和此前万亿模型相比，训练样本量仅需40％。</p>
<p style="text-align: center;"><a href="https://img1.mydrivers.com/img/20211108/cb72c5c76c38490fb0968ce56bbfde12.png" target="_blank"><img alt="512颗GPU、10万亿参数！阿里达摩院发布全球最大AI预训练模型" h="491" src="https://img1.mydrivers.com/img/20211108/s_cb72c5c76c38490fb0968ce56bbfde12.png" style="border: 1px solid black;" w="600" referrerpolicy="no-referrer"></a></p>
<p><strong>作为国内首个商业化落地的多模态大模型，M6已在超40个场景中应用，日调用量上亿。</strong></p>
<p>今年，大模型首次支持双11，应用包括但不限于：</p>
<p>－ M6在犀牛智造为品牌设计的服饰已在淘宝上线；</p>
<p>－ 凭借流畅的写作能力，M6正为天猫虚拟主播创作剧本；</p>
<p>－ 依靠多模态理解能力，M6正在增进淘宝、支付宝等平台的搜索及内容认知精度。</p>
<p align="center"><a href="https://img1.mydrivers.com/img/20211108/cd7aec4bda7b4c5baadf1d849b40a50e.png" target="_blank"><img alt="512颗GPU、10万亿参数！阿里达摩院发布全球最大AI预训练模型" h="365" src="https://img1.mydrivers.com/img/20211108/s_cd7aec4bda7b4c5baadf1d849b40a50e.png" style="border: black 1px solid;" w="600" referrerpolicy="no-referrer"></a><br>
M6设计的飞行汽车</p>
<p>未来，M6将积极探索与科学应用的结合，通过AI for science让大模型的潜力充分发挥，并加强M6与国产芯片的软硬一体化研究。</p>
<p>目前，达摩院联合阿里云已推出<a class="f14_link" href="https://m6.aliyun.com/" target="_blank">M6服务化平台</a>，为大模型训练及应用提供完备工具，首次让大模型实现“开箱即用”，算法人员及普通用户均可方便地使用平台。</p>

           
           
<p class="end"> - THE END -</p> 
          <p class="zhuanzai">转载请注明出处：快科技</p>  
 <p class="bqian"><a href="https://news.mydrivers.com/tag/alibaba.htm"><i>#</i>阿里巴巴</a><a href="https://news.mydrivers.com/tag/rengongzhineng.htm"><i>#</i>人工智能</a><a href="https://news.mydrivers.com/tag/damoyuan.htm"><i>#</i>达摩院</a></p>
<p class="url">
     
<span>责任编辑：上方文Q</span>
</p>
        
</div>
            