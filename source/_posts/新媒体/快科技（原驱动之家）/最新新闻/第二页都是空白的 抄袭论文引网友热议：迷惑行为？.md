
---
title: '第二页都是空白的 抄袭论文引网友热议：迷惑行为？'
categories: 
 - 新媒体
 - 快科技（原驱动之家）
 - 最新新闻
headimg: 'https://img1.mydrivers.com/img/20211103/S74cf4cd6-a051-41bc-9867-39db05fb4c57.png'
author: 快科技（原驱动之家）
comments: false
date: Wed, 03 Nov 2021 17:11:09 GMT
thumbnail: 'https://img1.mydrivers.com/img/20211103/S74cf4cd6-a051-41bc-9867-39db05fb4c57.png'
---

<div>   
<p>最近，越来越多关于论文抄袭的消息被爆出来，ICLR 2022 也成了“在逃之鱼”。</p>
<p>网友：第二页都是空白的！</p>
<p><span style="text-align: center;">这是又发生了啥？</span></p>
<p><span style="text-align: center;">ICLR，全称 International Conference on Learning Representations（国际学习表征会议），2013 年由位列深度学习三巨头之二的 Yoshua Bengio 和 Yann LeCun 牵头创办。</span></p>
<p><span style="text-align: center;">众所周知，Yoshua Bengio 是蒙特利尔大学教授，深度学习三巨头之一，他领导蒙特利尔大学的人工智能实验室（MILA）进行 AI 技术的学术研究。MILA 是世界上最大的人工智能研究中心之一，与谷歌也有着密切的合作。</span></p>
<p><span style="text-align: center;">而 Yann LeCun 就自不用提，同为深度学习三巨头之一的他现任 Facebook 人工智能研究院（FAIR）院长、纽约大学教授。作为卷积神经网络之父，他为深度学习的发展和创新作出了重要贡献。</span></p>
<p><span style="text-align: center;">因此，这个一年一度的会议虽成立时间不长，但已获得学术界广泛认可，被认为是深度学习的顶级会议。然而，如此权威的学术会议上竟出现论文抄袭现象，ICLR 2022 出现抄袭论文在 reddit 引起网友热议。仅针对此事，AI科技评论带大家吃一波瓜。</span></p>
<p><span style="text-align: center;">事件回顾：https://www.reddit.com/r/MachineLearning/comments/qkb6ga/plagiarism_case_detected_iclr_2022_newsdiscussion/</span></p>
<p>这篇文论讲了什么？</p>
<p>这篇被 ICLR 2022 认为抄袭的论文提出了 Text-Gen，一种新的对抗性文本生成技术。论文的研究人员发现，Text-Gen 在给定输入文本的情况下，可以快速有效地生成对抗性文本。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/74cf4cd6-a051-41bc-9867-39db05fb4c57.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="237" src="https://img1.mydrivers.com/img/20211103/S74cf4cd6-a051-41bc-9867-39db05fb4c57.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>论文地址：https://openreview.net/pdf?id=EO4VJGAllb</p>
<p>例如，为了攻击情感分类模型，Text-Gen 可以使用产品类别作为不应改变评论情感的属性。研究人员在真实世界的 NLP 数据集上进行了实验，从而证明与许多现有的对抗性文本生成方法相比，Text-Gen 可以生成更有意义和多样化的对抗性文本。</p>
<p>然后，论文的作者们还进一步使用生成的对抗性示例通过对抗性训练来改进模型，并且证明了生成的攻击对于模型重新训练和不同的模型架构更加稳健。</p>
<p>匆匆一瞥，这貌似是一篇站在“巨人肩膀上”的又一推陈出新之作，且截止被发现抄袭前，这篇论文已经通过双盲评审（double-blind review）。那么，这篇论文为何会被认为抄袭呢？</p>
<p><strong>三大罪证，属实不冤从</strong></p>
<p>ICLR 2022 给出的官方声明中，我们发现，这篇论文被认为抄袭，属实不冤。那它究竟触犯了哪些大忌，让创作者们的心血自此付之一炬？</p>
<p><strong>首先，该论文的多处“采用”其实是直接复制/粘贴自其它论文，但作者却表明这是“引用”。</strong></p>
<p>例如，论文的图 1，包括标题，就完全复制/粘贴自另一篇论文 CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation. Wang et al. EMNLP 2020.。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/269149a4-ca5b-437f-b885-e76673dd8f82.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="186" src="https://img1.mydrivers.com/img/20211103/S269149a4-ca5b-437f-b885-e76673dd8f82.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p><strong>其次，该论文有两处直接截图自其他论文，但作者没有注明来源。</strong></p>
<p>比如，文中的算法 1 来自论文 FreeLB: Enhanced Adversarial Training for Natural Language Understanding. Zhu et al. ICLR 2020.</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/e8b832a2-ea85-47d0-974b-c40eaf4fcf83.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="188" src="https://img1.mydrivers.com/img/20211103/Se8b832a2-ea85-47d0-974b-c40eaf4fcf83.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>最后，也许作者在抄袭的过程中良心发现，<strong>对参考文献做了一些修改，但却遭到 ICLR 2022 工作人员的无情吐槽：改了还不如不改。</strong>例如，这篇论文表 3 的一些修改就没有原文的好。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/08a196fa-2176-49b2-9e1f-0184f1ae361e.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="187" src="https://img1.mydrivers.com/img/20211103/S08a196fa-2176-49b2-9e1f-0184f1ae361e.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>此番看来，这篇抄袭论文可谓罪行累累且证据充足。目前，这篇论文已退回至原作者手中。</p>
<p><strong>网友热议：迷惑行为？</strong></p>
<p>reddit上关于此事的议论，大概是这几种声音：论文质量太差漏洞百出；害，这种事情见多了；这位作者难道在反向测试，看有没有评审会发现论文抄袭了？</p>
<p>帖子地址：https://www.reddit.com/r/MachineLearning/comments/qkb6ga/plagiarism_case_detected_iclr_2022_newsdiscussion/</p>
<p>有的网友对这种行为感到很迷惑：非常奇怪，也许作者根本不是ML研究人员，他们看起来像研究数据库安全方面的。</p>
<p>还有网友指出论文粗制滥造，都没有刻意想要隐瞒抄袭这件事情。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/f98b5027-18e5-42b4-ab7d-a8242af11ff8.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="98" src="https://img1.mydrivers.com/img/20211103/Sf98b5027-18e5-42b4-ab7d-a8242af11ff8.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>于是就有网友猜测，难道是为了钓鱼可以在博客写一篇文章——我在ML顶会投了一篇满是废话的论文，而同行评审没有发现！ </p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/ed9b4161-e650-48d8-95d3-506b5e510742.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="209" src="https://img1.mydrivers.com/img/20211103/Sed9b4161-e650-48d8-95d3-506b5e510742.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>不仅论文本身漏洞百出、疑点重重，还有网友表示马上要发布评审却撤回了，这很奇怪。</p>
<p>这位网友还提出了自己的疑问：不太了解ICLR的评审过程：难不成论文在评审发布前被撤回，就不发布评审/评论？还是如果论文进入评审阶段，无论如何都会发布评审？</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/9f1f772f-4abe-48b5-9321-8e52f7c26a4f.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="293" src="https://img1.mydrivers.com/img/20211103/S9f1f772f-4abe-48b5-9321-8e52f7c26a4f.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>另一波网友对论文抄袭事件已经见怪不怪了。他们认为ML和DL顶会论文被曝抄袭事件已经很多次了，不是没有人发现，只是管控不到位，让抄袭的人越来越放肆，漏洞百出公然挑衅评审。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20211103/dab37980-25bf-430a-9d43-1ad3ece304bc.png" target="_blank"><img alt="第二页都是空白的 抄袭论文引网友热议：迷惑行为？" h="171" src="https://img1.mydrivers.com/img/20211103/Sdab37980-25bf-430a-9d43-1ad3ece304bc.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>一位网友表示，如果作者认为没有人会注意到这篇论文低质量和抄袭痕迹，那就真的是妄想了！对于此事，手机前的你怎么看，欢迎加入前排吃瓜大队~</p>

           
           
<p class="end"> - THE END -</p> 
            
 <p class="bqian"><a href="https://news.mydrivers.com/tag/lunwen.htm"><i>#</i>论文</a><a href="https://news.mydrivers.com/tag/chaoxi.htm"><i>#</i>抄袭</a></p>
<p class="url">
     <span>原文链接：<a href="https://www.leiphone.com/category/academic/4znjd5XDuhwQGybn.html">雷锋网</a></span>
<span>责任编辑：随心</span>
</p>
        
</div>
            