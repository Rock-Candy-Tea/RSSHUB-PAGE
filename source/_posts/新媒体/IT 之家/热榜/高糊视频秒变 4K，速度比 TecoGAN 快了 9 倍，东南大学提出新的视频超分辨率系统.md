
---
title: '高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统'
categories: 
 - 新媒体
 - IT 之家
 - 热榜
headimg: 'https://img.ithome.com/newsuploadfiles/2021/7/d249ab50-68f9-4992-8155-f436f80f832c.gif'
author: IT 之家
comments: false
date: Fri, 16 Jul 2021 03:27:06 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/7/d249ab50-68f9-4992-8155-f436f80f832c.gif'
---

<div>   
<p>把高糊视频变清晰，对于 AI 而言算不上新鲜事。</p><p>但如果是实时处理，而且速度比主流方法还快了 9 倍呢？</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/d249ab50-68f9-4992-8155-f436f80f832c.gif" w="704" h="576" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="704" height="576" referrerpolicy="no-referrer"></p><p>而且计算量降低了，重建图像的质量却还非常能打：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/506ddf8b-6084-48a3-8167-291d0494a719.png" w="1080" h="282" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="1080" height="214" referrerpolicy="no-referrer"></p><p>这种图像质量和速度性能之间的平衡到底是怎么做到的？</p><p>今天就来看看东南大学的研究者们带来的最新研究：4K 视频实时超分辨率系统 EGVSR。</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/f5e6f491-c36e-4595-89fb-2026a66e159c.png" w="1080" h="149" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="1080" height="113" referrerpolicy="no-referrer"></p><h2>GAN 保证重建质量</h2><p>为了使模型具有良好的感知质量，生成对抗网络 GAN 成为了超分辨率研究中广泛使用的一种方法。</p><p>比如，要处理 VSR 任务中大规模的分辨率退化，就常常依靠 GAN 的深度特征学习能力。</p><p>于是参考 TecoGAN 的设计，EGVSR 系统引入了空间-时间对抗结构，用来帮助判别器理解和学习空间-时间信息的分布。</p><p>也避免了传统 GAN 在时域遇到的不稳定效应。</p><p>同时，研究者参照高效 CNN 架构，为 EGVSR 设计了一个轻量级的网络结构：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/f3378470-864e-4ebb-92b0-45b046e7d5a7.png" w="634" h="278" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="634" height="278" referrerpolicy="no-referrer"></p><p>▲ EGVSR 生成器的部分框架</p><p>其中，生成器部分分为 FNet 模块和 SRNet 模块，分别用于光流估计和视频帧超分辨率。</p><p>接下来，就是增强 EGVSR 的实时处理能力了。</p><h2>三种方法提升速度</h2><p>研究者主要通过三种方法来提高网络训练和推理的速度。</p><p><strong>一、对 BN 层进行优化。</strong></p><p>在 EGVSR 网络中，FNet 模块里大量使用了 BN（批量归一化）层。</p><p>因此，研究者省去计算 BN 的环节，将其转换为矩阵形式，利用 1×1 卷积层来实现和替换 BN 层：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/542160a6-2560-4020-aed6-fa240081b853.png" w="624" h="298" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="624" height="298" referrerpolicy="no-referrer"></p><p>优化之后，速度就提高了 5% 左右。</p><p><strong>二、寻找高效的上采样方法。</strong></p><p>上采样层（Upsampling layer）是超分辨率网络中最重要的部分之一。</p><p>因此，在保持其他网络结构和配置的情况下，研究者希望从以下三种上采样方法中，选择出一种在实际 SR 网络中效率最高的：</p><p>A. 调整大小卷积（使用双线性插值）</p><p>B. 去卷积（Deconvolution）</p><p>C. 子像素卷积（Sub-pixel convolution）</p><p>在使用这三种方法训练了多组 SR 网络后，可以看到子像素卷积方法的效果最佳：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/62d266fc-6615-445c-831f-031ff9d80f2e.png" w="668" h="282" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="668" height="282" referrerpolicy="no-referrer"></p><p><strong>三、设计一种适合硬件部署的高效卷积算法</strong></p><p>传统的朴素卷积（Nnaïve Convolution）方法使用了 6 个循环结构，这导致它的计算效率相当低。</p><p>因此，研究者们使用矩阵乘法（MatMul）算法通过逆向 col2im 转换得到所需的输出特征结果。</p><p>这样，就将卷积计算转换为了矩阵乘法。</p><p>也就通过内存空间节省了推理时间，最终提高计算效率。</p><h2>性能提升 7.92 倍</h2><p>那么最终速度提升的效果如何呢？</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/db75f402-baf9-41a4-bde4-f72480705218.png" w="1080" h="372" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="1080" height="282" referrerpolicy="no-referrer"></p><p>可以看到，在使用 CPU 时，对比经典的 TecoGAN 算法，VESPCN 的速度最高能提升 9.05 倍。</p><p>而在使用 GPU 加速时，VESPCN 最高也能比 TecoGAN 的性能提升 7.92 倍。</p><p>如果从总计算成本来看，EGVSR 仅为 VESPCN 的 29.57%，SOFVSR 的 12.63%，FRVSR 和 TecoGAN 的 14.96%。</p><p>与此同时，EGVSR 也取得了较高的图像细节重建质量，结果最接近 GT（Ground Truth）图像：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/461ab932-8b90-423a-a5de-bb90e27ad91a.png" w="1080" h="822" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="1080" height="624" referrerpolicy="no-referrer"></p><p>而对于多张图像之间的连贯性评估，研究者们引入了两个指标来衡量 VSR 结果与相应的 GT 参考结果之间的差异：</p><p>tOF：测量从序列中估计的运动的像素差异；</p><p>tLP：使用深度特征图测量感知上的变化。</p><p>从结果可以看到 VESPCN 的分数最小：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/7/78ccf655-6e4d-46eb-b53d-1867d140f0bc.png" w="1080" h="385" title="高糊视频秒变 4K，速度比 TecoGAN 快了 9 倍，东南大学提出新的视频超分辨率系统" width="1080" height="292" referrerpolicy="no-referrer"></p><p>这说明了在满足时间连贯性的情况下，EGVSR 网络可以恢复更多的空间细节，满足人眼的主观感受。</p><p>所有实验的结果都表明，EGVSR 确实在保证 VSR 高视觉质量的前提下，将计算负载降低到最低要求，完成了 4K VSR 在硬件平台上的实时实现。</p><h2>研究团队</h2><p>论文的前三位作者都来自东南大学的国际信息显示与可视化联合研究实验室。</p><p>一作 Yanpeng Cao 目前研究生在读，主要研究方向为加密域图像处理和图像超分辨率等领域。</p><p>其余两位分别是 Chengcheng Wang 和 Changjun Song。</p><p>最后一位作者 He Li 来自剑桥大学的工程系。</p><p>论文地址：</p><p>https://arxiv.org/abs/2107.05307</p><p>下载：</p><p>https://github.com/Thmen/EGVSR</p>
          
</div>
            