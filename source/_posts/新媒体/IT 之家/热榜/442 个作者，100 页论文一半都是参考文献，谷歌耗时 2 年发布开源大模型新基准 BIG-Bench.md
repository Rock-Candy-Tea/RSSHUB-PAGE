
---
title: '442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench'
categories: 
 - 新媒体
 - IT 之家
 - 热榜
headimg: 'https://img.ithome.com/newsuploadfiles/2022/6/a5e8af92-4636-4169-9755-fb7577af2183.png'
author: IT 之家
comments: false
date: Sat, 11 Jun 2022 05:21:24 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/6/a5e8af92-4636-4169-9755-fb7577af2183.png'
---

<div>   
<p data-vmark="4763">一篇 AI 论文，442 个作者，其中还专门留了一章节写作者贡献，<span class="accentTextColor">100 页里超过一半都是参考文献……</span></p><p data-vmark="2551">谷歌最新发布的论文 ——Beyond The Imitation Game: Quantifying And Extrapolating The Capabilities Of Language Models 作者那一栏就变成了这样……</p><p style="text-align: center;" data-vmark="ad1c"><img src="https://img.ithome.com/newsuploadfiles/2022/6/a5e8af92-4636-4169-9755-fb7577af2183.png" w="996" h="1200" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="996" height="988" referrerpolicy="no-referrer"></p><p data-vmark="bf65">来自 132 个机构的研究学者，耗时两年提出了一个大语言模型新基准 <span class="accentTextColor">BIG-bench</span>。并在此基础上评估了 OpenAI 的 GPT 模型，Google-internal dense transformer 架构等，模型规模横 6 个数量级。</p><p data-vmark="b36c">最终结果显示，<span class="accentTextColor">模型性能虽然随着规模的扩大而提高，但跟人类的表现相差还很远</span>。</p><p data-vmark="8d4f">对于这项工作，Jeff Dean 转发点赞：Great Work。</p><p style="text-align: center;" data-vmark="3f99"><img src="https://img.ithome.com/newsuploadfiles/2022/6/914cc30a-a35b-41cf-8bac-855ba05f2b60.png" w="932" h="188" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="932" height="165" referrerpolicy="no-referrer"></p><h2 data-vmark="7f3e">大语言模型新基准</h2><p data-vmark="d19f">来康康这篇论文究竟说了什么。</p><p data-vmark="5263">随着规模的扩大，模型的性能和质量都有一定的改进，这当中可能还存在一些变革性影响，但这些性能此前都没有很好的描述。</p><p data-vmark="e68e">现存的一些基准都有一定的局限性，评估范围比较狭窄，性能分数迅速达到饱和。</p><p data-vmark="aa81">比如 SuperGLUE，在该基准推出后的 18 个月内，模型就实现了“超过人类水平”的性能。</p><p style="text-align: center;" data-vmark="53b4"><img src="https://img.ithome.com/newsuploadfiles/2022/6/f0869e11-4acf-46ae-a37c-71b19a744b3c.png" w="1080" h="486" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="1080" height="369" referrerpolicy="no-referrer"></p><p data-vmark="0410">基于这样的背景，BIG-bench 就诞生了。</p><p data-vmark="7013"><span class="accentTextColor">目前它由 204 个任务组成</span>，内容涵盖语言学、儿童发展、数学、常识推理、生物学、物理学、社会偏见、软件开发等方面的问题。</p><p style="text-align: center;" data-vmark="99a0"><img src="https://img.ithome.com/newsuploadfiles/2022/6/ec90229d-e6cb-47b8-a2cd-9f73ffe2e586.png" w="1080" h="382" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="1080" height="290" referrerpolicy="no-referrer"></p><p data-vmark="7e7c">此外还有个人类专家评审团，也执行了所有任务，以提供基线水平。</p><p data-vmark="f41c">为了方便更多机构使用，研究人员还给出了 <span class="accentTextColor">BIG-bench Lite</span>，一个小型但有代表性的任务子集，方便更快地评估。</p><p style="text-align: center;" data-vmark="230c"><img src="https://img.ithome.com/newsuploadfiles/2022/6/e35bbc2e-6e9f-4993-89cd-73c273573b90.png" w="1080" h="384" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="1080" height="292" referrerpolicy="no-referrer"></p><p data-vmark="c201">以及开源了实现基准 API 的代码，支持在公开可用的模型上进行任务评估，以及新任务的轻量级创建。</p><p data-vmark="49fc">最终评估结果可以看到，规模横跨六个数量级，BIG-bench 上的总体性能随着模型规模的扩大、训练样本数量的增加而提高。</p><p data-vmark="9289">但跟人类基线水平相比，<span class="accentTextColor">还是表现得比较差</span>。</p><p style="text-align: center;" data-vmark="ef45"><img src="https://img.ithome.com/newsuploadfiles/2022/6/ef416c46-b996-4ae9-b649-d4da681585bc.png" w="1080" h="428" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="1080" height="325" referrerpolicy="no-referrer"></p><p data-vmark="0e62">具体在一些任务上，模型性能会随着规模的增加而平稳地提高。但有时候，会在特定规模上突然出现突破性表现。</p><p style="text-align: center;" data-vmark="f66e"><img src="https://img.ithome.com/newsuploadfiles/2022/6/555bbe75-eb64-4471-9da8-ed40f7f89cbf.jpg@s_2,w_820,h_264" w="1080" h="348" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" srcset="https://img.ithome.com/newsuploadfiles/2022/6/555bbe75-eb64-4471-9da8-ed40f7f89cbf.jpg 2x" width="1080" height="264" referrerpolicy="no-referrer"></p><p data-vmark="a50d">此外，它还可以评估模型存在的社会偏见。</p><p style="text-align: center;" data-vmark="116f"><img src="https://img.ithome.com/newsuploadfiles/2022/6/4c3cbf75-a2e7-4b1f-9b54-d17b70708f22.jpg@s_2,w_820,h_519" w="1080" h="683" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" srcset="https://img.ithome.com/newsuploadfiles/2022/6/4c3cbf75-a2e7-4b1f-9b54-d17b70708f22.jpg 2x" width="1080" height="519" referrerpolicy="no-referrer"></p><p data-vmark="63ab">此外，他们还意外发现模型还可以 get 一些隐藏技能。比如，如何在国际象棋中合乎规则的移动。</p><p style="text-align: center;" data-vmark="daa0"><img src="https://img.ithome.com/newsuploadfiles/2022/6/7c1ca9bb-a9b1-416c-815d-3afef2746217.png" w="1080" h="491" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="1080" height="373" referrerpolicy="no-referrer"></p><h2 data-vmark="96f2">作者贡献写了 14 页</h2><p data-vmark="c6c2">值得一提的是，可能因为作者过多，论文最后还专门留了一章写作者贡献。<span class="accentTextColor">洋洋洒洒的写了 14 页</span>，其中包括核心贡献者、Review 的、提供任务的……</p><p style="text-align: center;" data-vmark="28d1"><img src="https://img.ithome.com/newsuploadfiles/2022/6/647065ee-5642-4dd7-8135-6f91e4beb803.png" w="1080" h="838" title="442 个作者，100 页论文一半都是参考文献，谷歌耗时 2 年发布开源大模型新基准 BIG-Bench" width="1080" height="636" referrerpolicy="no-referrer"></p><p data-vmark="6921">剩下的，<span class="accentTextColor">还有 50 页的参考文献</span>。</p><p data-vmark="4e58">好了，感兴趣的旁友可戳下方链接康康论文。</p><p data-vmark="6066"><strong>论文链接：</strong></p><p data-vmark="5def"><a href="https://arxiv.org/abs/2206.04615" target="_blank"><span class="link-text-start-with-http">https://arxiv.org/abs/2206.04615</span></a></p><p data-vmark="084d"><strong>GitHub 链接：</strong></p><p data-vmark="5c37"><a href="https://github.com/google/BIG-bench" target="_blank"><span class="link-text-start-with-http">https://github.com/google/BIG-bench</span></a></p>
          
</div>
            