
---
title: '英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了'
categories: 
 - 新媒体
 - IT 之家
 - 热榜
headimg: 'https://img.ithome.com/newsuploadfiles/2022/3/ce4fd21c-3486-4b98-93a3-a68428742b4d.jpg@s_2,w_820,h_349'
author: IT 之家
comments: false
date: Tue, 22 Mar 2022 23:41:08 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/3/ce4fd21c-3486-4b98-93a3-a68428742b4d.jpg@s_2,w_820,h_349'
---

<div>   
<p data-vmark="308d">今日，NVIDIA（英伟达）携基于最新 Hopper 架构的 H100 GPU 系列新品高调回归！</p><p data-vmark="ad0b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/ce4fd21c-3486-4b98-93a3-a68428742b4d.jpg@s_2,w_820,h_349" w="900" h="383" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" srcset="https://img.ithome.com/newsuploadfiles/2022/3/ce4fd21c-3486-4b98-93a3-a68428742b4d.jpg 2x" width="900" height="349" referrerpolicy="no-referrer"></p><p data-vmark="f138">英伟达创始人兼 CEO 黄仁勋依然穿着皮衣，不过这次他没有出现在几乎已成 GTC 大会“标配”的厨房场景中，而是在一个更具科幻感的虚拟空间。</p><p data-vmark="e366" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/386e5cc6-92d3-4194-b803-8d79b5368b6b.gif" w="1078" h="598" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1078" height="455" referrerpolicy="no-referrer"></p><p data-vmark="180b">延续以往风格，黄仁勋在主题演讲中继续秒天秒地秒空气，公布多个“全球首款”。这次他带来一系列堪称“地表最强”的 AI 重磅新品，随便一个精度的 AI 性能，<span class="accentTextColor">都比上一代 A100 高出 3~6 倍</span>。</p><p data-vmark="7dcf">虽然英伟达并购 Arm 的计划刚刚告吹，但它的数据中心“三芯”总路线（GPU+DPU+CPU）依然不动摇 —— 继去年推出其首款数据中心 CPU 后，今天，英伟达又亮出一款基于 Arm 架构的 Grace CPU 超级芯片。</p><p data-vmark="f73b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/b728565d-f8a4-445c-ac4a-a2b57ecb33a5.png" w="1000" h="563" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1000" height="462" referrerpolicy="no-referrer"></p><p data-vmark="cb43">此外，黄仁勋再次派出自己的虚拟数字人化身“玩偶老黄”Toy Jensen，并跟这个表情生动的玩偶进行了一番流畅的实时问答对话。</p><p data-vmark="d531" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/43d4d037-cd02-4612-a84d-b04bff989453.gif" w="1079" h="608" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1079" height="462" referrerpolicy="no-referrer"></p><p data-vmark="a9ef">凭借押中图形处理和人工智能（AI）两大赛道，英伟达已经成为全球半导体市值 TOP1。截至文章发布时间，英伟达的市值超过 6600 亿美元，比第二名台积电足足多了近 1100 亿美元。</p><p data-vmark="b86e">下面就让我们来看看本场 GTC 大会的完整干货：</p><p data-vmark="d4af">1、<strong>H100 GPU</strong>：采用台积电 4N 工艺，拥有 800 亿个晶体管，实现了首个 GPU 机密计算，相比 A100，FP8 性能提升 6 倍，FP16、TF32、FP64 性能各提升 3 倍。</p><p data-vmark="a277">2、<strong>全新 NVLink Switch 系统</strong>：高度可扩展，支持 256 块 H100 GPU 互连。</p><p data-vmark="db7e">3、<strong>融合加速器 H100 CNX</strong>：耦合 H100 GPU 与 ConnectX-7 和以太网智能网卡，可为 I / O 密集型应用提供更强劲的性能。</p><p data-vmark="28b8">4、<strong>DGX H100</strong>：配备 8 块 H100 GPU，总计有 6400 亿个晶体管，在全新的 FP8 精度下 AI 性能比上一代高 6 倍，可提供 900GB / s 的带宽。</p><p data-vmark="75a7">5、<strong>DGX SuperPOD</strong>：最多由 32 个 DGX H100 组成，AI 算力可达 1EFLOPS。</p><p data-vmark="9fee">6、<strong>Eos 超级计算机</strong>：全球运行速度最快的 AI 超级计算机，配备 576 台 DGX H100 系统，FP8 算力达到 18EFLOPS，FP64 算力达到 275PFLOPS。</p><p data-vmark="d92d">7、<strong>Grace CPU 超级芯片</strong>：由两个 CPU 芯片组成，采用最新 Armv9 架构，拥有 144 个 CPU 核心和 1TB / s 的内存带宽，将于 2023 年上半年供货。</p><p data-vmark="838c">8、<strong>为定制芯片集成开放 NVLink</strong>：采用先进封装技术，与英伟达芯片上的 PCIe Gen 5 相比，能源效率高 25 倍，面积效率高 90 倍。英伟达还将支持通用小芯片互连传输通道 UCIe 标准。</p><p data-vmark="d48a">9、<strong>CUDA-X</strong>：60 多个针对 CUDA-X 的一系列库、工具和技术的更新。</p><p data-vmark="72d7">10、<strong>Riva 2.0</strong>：对话式 AI 服务 Riva 全面发行，2.0 版本支持识别 7 种语言，可将神经文本转换为不同性别发声的语音。</p><p data-vmark="9380">11、<strong>Merlin 1.0</strong>：可帮助企业快速构建、部署和扩展先进的 AI 推荐系统。</p><p data-vmark="1d6f">12、<strong>Sionna</strong>：一款用于 6G 通信研究的 AI 框架。</p><p data-vmark="3e12">13、<strong>OVX 与 OVX SuperPod</strong>：面向工业数字孪生的数据中心级服务器和超级集群。</p><p data-vmark="437d">14、<strong>Spectrum-4</strong>：全球首个 400Gbps 端到端网络平台，交换吞吐量比前几代产品高出 4 倍，达到 51.2Tbps。</p><p data-vmark="0382">15、<strong>Omniverse Cloud</strong>：支持协作者们随时随地实现远程实时协同工作。</p><p data-vmark="9e17">16、<strong>DRIVE Hyperion 9</strong>：汽车参考设计，拥有 14 个摄像头、9 个雷达、3 个激光雷达和 20 个超声传感器，总体传感器数量是上一代的两倍。</p><p data-vmark="e735">17、<strong>DRIVE Map</strong>：多模态地图引擎，包含摄像头、激光雷达和雷达的数据，同时兼顾安全性。</p><p data-vmark="566a">18、<strong>Clara Holoscan MGX</strong>：可供医疗设备行业在边缘开发和部署实时 AI 应用的计算平台，AI 算力可达每秒 254~610 万亿次运算。</p><p data-vmark="f2ae">19、<strong>Isaac for AMR</strong>：提供自主移动机器人系统参考设计。</p><p data-vmark="b8e5">20、<strong>Jetson AGX Orin 开发者套件</strong>：在边缘实现服务器级的 AI 性能。</p><p data-vmark="449d">黄仁勋还介绍了英伟达创建的 NVIDIA AI 加速计划，通过与 AI 生态系统中的开发者合作，开发工程化解决方案，以确保客户放心部署。</p><p data-vmark="2bbb" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/05a67cd9-2354-46b1-85ed-67ce700f4020.png" w="1080" h="601" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="456" referrerpolicy="no-referrer"></p><h2 data-vmark="6c3e">01. H100 GPU：800 亿晶体管、六大创新</h2><p data-vmark="be25">每次英伟达的 GPU 新架构都会以一位科学家的名字来命名，这次同样如此。</p><p data-vmark="ce38">新 Hopper 架构的命名取自美国计算机科学家格蕾丝・赫柏（Grace Hopper），她是耶鲁大学第一位数学女博士、世界上第三位程序员、全球首个编译器的发明者，也是第一个发现“bug”的人。</p><p data-vmark="1f73" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/a3e1d550-c4ba-489b-b5f4-ac2f513790c7.jpg@s_2,w_820,h_633" w="1080" h="834" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" srcset="https://img.ithome.com/newsuploadfiles/2022/3/a3e1d550-c4ba-489b-b5f4-ac2f513790c7.jpg 2x" width="1080" height="633" referrerpolicy="no-referrer"></p><p data-vmark="3efb">▲ 格蕾丝・赫柏正在教学 COBOL 编程语言</p><p data-vmark="bfbe">1945 年 9 月 9 日，格蕾丝使用的 Mark Ⅱ 机出现故障，经过近一天的排查，她找到了故障的原因：继电器中有一只死掉的蛾子。后来，“bug”（小虫）和“debug”（除虫）这两个词汇就作为计算机领域的专用词汇流传至今。</p><p data-vmark="4219">基于 Hopper 架构的一系列 AI 计算新品，被冠上各种“全球首款”。按行业惯例，但凡比较 AI 算力，必会拿英伟达最新旗舰 GPU 作为衡量标准。</p><p data-vmark="848c">英伟达也不例外，先“碾压”一下自己两年前发布的上一代 A100 GPU。</p><p data-vmark="0b9a">作为全球首款基于 Hopper 架构的 GPU，英伟达 H100 接过为加速 AI 和高性能计算（HPC）扛旗的重任，FP64、TF32、FP16 精度下 AI 性能都达到 A100 的 3 倍。</p><p data-vmark="70a8" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/1fd088b2-fc5c-4cb0-9c78-141d529aeaa6.png" w="1080" h="601" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="456" referrerpolicy="no-referrer"></p><p data-vmark="d5b4">可以看到，NVIDIA 越来越热衷于走稀疏化路线。过去六年，英伟达相继研发了使用 FP32、FP16 进行训练的技术。此次 H100 的性能介绍又出现了新的 Tensor 处理格式 FP8，而 FP8 精度下的 AI 性能可达到 4PFLOPS，约为 A100 FP16 的 6 倍。</p><p data-vmark="d3ab">从技术进展来看，H100 有 6 项突破性创新：</p><p data-vmark="b2ac">1）先进芯片：H100 采用台积电 4N 工艺、台积电 CoWoS 2.5D 封装，有 800 亿个晶体管（A100 有 540 亿个晶体管），搭载了 HBM3 显存，可实现近 5TB / s 的外部互联带宽。</p><p data-vmark="587c">H100 是首款支持 PCIe 5.0 的 GPU，也是首款采用 HBM3 标准的 GPU，单个 H100 可支持 40Tb / s 的 IO 带宽，实现 3TB / s 的显存带宽。黄仁勋说，20 块 H100 GPU 便可承托相当于全球互联网的流量。</p><p data-vmark="8794">2）新 Transformer 引擎：该引擎将新的 Tensor Core 与能使用 FP8 和 FP16 数字格式的软件结合，动态处理 Transformer 网络的各个层，在不影响准确性的情况下，可将 Transformer 模型的训练时间从数周缩短至几天。</p><p data-vmark="d115">3）第二代安全多实例 GPU：MIG 技术支持将单个 GPU 分为 7 个更小且完全独立的实例，以处理不同类型的作业，为每个 GPU 实例提供安全的多租户配置。H100 能托管 7 个云租户，而 A100 仅能托管 1 个，也就是将 MIG 的部分能力扩展了 7 倍。每个 H100 实例的性能相当于两个完整的英伟达云推理 T4 GPU。</p><p data-vmark="d6fd">4）机密计算：H100 是全球首款具有机密计算功能的 GPU 加速器，能保护 AI 模型和正在处理的客户数据，可以应用在医疗健康和金融服务等隐私敏感型行业的联邦学习，以及共享云基础设施。</p><p data-vmark="2a95" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/6d06ec8a-4e18-4674-be87-4c5e6e5af0fa.png" w="1080" h="564" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="428" referrerpolicy="no-referrer"></p><p data-vmark="df5c">5）第 4 代英伟达 NVLink：为了加速大型 AI 模型，NVLink 结合全新外接 NVLink Switch，可将 NVLink 扩展为服务器间的互联网络，最多连接多达 256 个 H100 GPU，相较于上一代采用英伟达 HDR Quantum InfiniBand 网络，带宽高出 9 倍。</p><p data-vmark="c9a0">6）DPX 指令：Hopper 引入了一组名为 DPX 的新指令集，DPX 可加速动态编程算法，解决路径优化、基因组学等算法优化问题，与 CPU 和上一代 GPU 相比，其速度提升分别可达 40 倍和 7 倍。</p><p data-vmark="712e">总体来说，H100 的这些技术优化，将对跑深度推荐系统、大型 AI 语言模型、基因组学、复杂数字孪生、气候科学等任务的效率提升非常明显。</p><p data-vmark="3ea9">比如，用 H100 支持聊天机器人使用的 monolithic Transformer 语言模型 Megatron 530B，吞吐量比上一代产品高出 30 倍，同时能满足实时对话式 AI 所需的次秒级延迟。</p><p data-vmark="5d29">再比如用 H100 训练包含 3950 亿个参数的混合专家模型，训练速度可加速高达 9 倍，训练时间从几周缩短到几天。</p><p data-vmark="d286" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/aa52387e-02cd-4489-8002-7a94ab35313a.png" w="1080" h="599" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="455" referrerpolicy="no-referrer"></p><p data-vmark="f7f0">H100 将提供 SXM 和 PCIe 两种规格，可满足各种服务器设计需求。</p><p data-vmark="77a8">其中 H100 SXM 提供 4 GPU 和 8 GPU 配置的 HGX H100 服务器主板；H100 PCIe 通过 NVLink 连接两块 GPU，相较 PCIe 5.0 可提供 7 倍以上的带宽。PCIe 规格便于集成到现有的数据中心基础设施中。</p><p data-vmark="9cd3">这两种规格的电力需求都大幅增长。H100 SXM 版的散热设计功耗（TDP）达到 700W，比 A100 的 400W 高出 75%。据黄仁勋介绍，H100 采用风冷和液冷设计。</p><p data-vmark="ae53" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/dc4db918-4549-4b8c-8d73-d9a578944379.png" w="1080" h="571" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="434" referrerpolicy="no-referrer"></p><p data-vmark="ad6f">这款产品预计于今年晚些时候全面发售。阿里云、AWS、百度智能云、谷歌云、微软 Azure、Oracle Cloud、腾讯云和火山引擎等云服务商均计划推出基于 H100 的实例。</p><p data-vmark="52fa">为了将 Hopper 的强大算力引入主流服务器，英伟达推出了全新的融合加速器 H100 CNX。它将网络与 GPU 直接相连，耦合 H100 GPU 与英伟达 ConnectX-7 400Gb / s InfiniBand 和以太网智能网卡，使网络数据通过 DMA 以 50GB / s 的速度直接传输到 H100，能够避免带宽瓶颈，为 I / O 密集型应用提供更强劲的性能。</p><p data-vmark="46a1" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/f94c143b-7474-402b-b396-b270643b27ec.png" w="1080" h="577" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="438" referrerpolicy="no-referrer"></p><h2 data-vmark="3a00">02. 更强企业级 AI 系统，全球最快 AI 超算</h2><p data-vmark="5c19">基于 H100，英伟达最先进的企业级 AI 基础设施 DGX H100 系统、DGX POD、DGX SuperPOD 以及一一登场。它们将从今年第三季度开始供应。</p><p data-vmark="cda4">黄仁勋称，在财富 10 强企业和 100 强企业中，分别有 8 家和 44 家企业使用 DGX 作为 AI 基础架构。</p><p data-vmark="8977">英伟达 DGX 系统现在包含英伟达 AI Enterprise 软件套件，该套件新增了对裸金属基础设施的支持。DGX 客户可使用软件套件中的预训练 AI 平台模型、工具包和框架来加快工作速度。</p><h3 data-vmark="42b3">1、DGX H100：最先进的企业级 AI 基础设施</h3><p data-vmark="5496">第四代英伟达 DGX 系统 DGX H100 是一款基于英伟达 H100 Tensor Core GPU 的 AI 平台。</p><p data-vmark="1b28" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/7034baf2-bb83-43b8-ab84-70083048c60d.png" w="1080" h="545" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="414" referrerpolicy="no-referrer"></p><p data-vmark="7626">每个 DGX H100 系统配备 8 块 H100 GPU，总计有 6400 亿个晶体管，由 NVLink 连接，在全新的 FP8 精度下 AI 性能可达 32Petaflops，比上一代系统性能高 6 倍。</p><p data-vmark="f47d">DGX H100 系统中每块 GPU 都通过第四代 NVLink 连接，可提供 900GB / s 的带宽，是上一代系统的 1.5 倍。DGX H100 的显存带宽可达 24TB / s。</p><p data-vmark="29b5">该系统支持双 x86 CPU，每个系统还包含 2 个英伟达 BlueField-3 DPU，用于卸载、加速和隔离高级网络、存储及安全服务。</p><p data-vmark="983c">8 个英伟达 ConnectX-7 Quantum-2 InfiniBand 网卡能够提供 400GB / s 的吞吐量，可用于连接计算和存储，这一速度比上一代系统提升了 1 倍。</p><p data-vmark="5e95" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/0dbfe5e7-6469-4ff8-8a9f-fcec9be13f69.png" w="1080" h="597" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="453" referrerpolicy="no-referrer"></p><h3 data-vmark="dd7f">2、DGX SuperPOD：FP8 AI 性能达 1Exaflops</h3><p data-vmark="8b54">DGX H100 系统是新一代英伟达 DGX POD 和 DGX SuperPOD 超级计算机的构建模块。</p><p data-vmark="e1aa" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/6183a6f3-23e7-40f4-ab6b-80da19605b29.png" w="1080" h="608" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="462" referrerpolicy="no-referrer"></p><p data-vmark="cdfb">借助 NVLink Switch 系统，拥有 32 个节点、256 个 GPU 的 DGX Pod，其 HBM3 显存达 20.5TB，显存带宽高达 768TB / s。</p><p data-vmark="9bf3">“相比之下，整个互联网不过只有 100TB / s。”黄仁勋感慨道。每个 DGX 都可借助 4 端口光学收发器连接到 NVLink Switch，每个端口都有 8 个 100G-PAM4 通道，每秒能够传输 100GB，32 个 NVLink 收发器连接到 1 个机架单元的 NVLink Switch 系统。</p><p data-vmark="f229" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/f31df357-daa4-431e-93ff-96d637ec8452.png" w="1080" h="590" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="448" referrerpolicy="no-referrer"></p><p data-vmark="05d0">新一代 DGX SuperPOD 可提供 1Exaflops 的 FP8 AI 性能，比上一代产品性能高 6 倍，能够运行具有数万亿参数的大型语言模型工作负载；还有 20TB 的 HBM3 显存、192TFLOPS 的 SHARP 网络计算性能。</p><p data-vmark="90ff">通过采用 Quantum-2 InfiniBand 连接及 NVLink Switch 系统，新 DGX SuperPOD 架构在 GPU 之间移动数据的带宽高达 70TB / s，比上一代高 11 倍。</p><p data-vmark="9c29">Quantum-2 InfiniBand 交换机芯片拥有 570 亿个晶体管，能提供 64 个 400Gbps 端口。多个 DGX SuperPOD 单元可组合使用。</p><p data-vmark="7ed9" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/15e89e8f-4628-4d24-9314-42e9fc4570f3.png" w="1080" h="577" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="438" referrerpolicy="no-referrer"></p><p data-vmark="590d">此外，英伟达推出新的 DGX-Ready 托管服务计划，以助力简化 AI 部署。其 DGX Foundry 托管的开发解决方案正在全球扩展，北美、欧洲和亚洲的新增地点支持远程访问 DGX SuperPOD。</p><p data-vmark="df03">DGX Foundry 中包含英伟达 Base Command 软件，该软件能够使客户基于 DGX SuperPOD 基础设施，轻松管理端到端 AI 开发生命周期。</p><h3 data-vmark="e8df">3、Eos：全球运行速度最快的 AI 超算</h3><p data-vmark="7e66">黄仁勋还透露说，英伟达正在打造 Eos 超级计算机，并称这是“首个 Hopper AI 工厂”，将于数月后推出。</p><p data-vmark="8093">该超算包含 18 个 DGX POD、576 台 DGX H100 系统，共计 4608 块 DGX H100 GPU，预计将提供 18.4Exaflops 的 AI 算力，这比目前运行速度最快的日本富岳（Fugaku）超级计算机快 4 倍。在传统科学计算方面，Eos 预计可提供 275Petaflops 的性能。</p><p data-vmark="34aa" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/727607e9-5f88-401d-b2d0-d9bd18585e82.png" w="1080" h="589" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="447" referrerpolicy="no-referrer"></p><h2 data-vmark="ef63">03. 由两个 CPU 组成的超级芯片</h2><p data-vmark="1a4d">除了 GPU 外，英伟达数据中心“三芯”战略中另一大支柱 CPU 也有新进展。</p><p data-vmark="4c41">今日，英伟达推出首款面向 HPC 和 AI 基础设施的基于 Arm Neoverse 的数据中心专属 CPU——Grace CPU 超级芯片。</p><p data-vmark="c9ed">这被黄仁勋称作“AI 工厂的理想 CPU”。</p><p data-vmark="b84d" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/55f6a427-23eb-48b6-95cc-733187004c5a.png" w="1080" h="607" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="461" referrerpolicy="no-referrer"></p><p data-vmark="5bd1">据介绍，Grace Hopper 超级芯片模组能在 CPU 与 GPU 之间进行芯片间的直接连接，其关键驱动技术是内存一致性芯片之间的 NVLink 互连，每个链路的速度达到 900GB / s。</p><p data-vmark="0f7e">Grace CPU 超级芯片也可以是由两个 CPU 芯片组成。它们之间通过高速、低延迟的芯片到芯片互连技术 NVLink-C2C 连在一起。</p><p data-vmark="bed4" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/f0e17c65-7fac-40d8-8a09-9c40a658dae5.png" w="1080" h="601" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="456" referrerpolicy="no-referrer"></p><p data-vmark="fad3">它基于最新的 Armv9 架构，单个 socket 拥有 144 个 CPU 核心，具备最高的单线程核心性能，支持 Arm 新一代矢量扩展。</p><p data-vmark="867b">在 SPECrate®2017_int_base 基准测试中，Grace CPU 超级芯片的模拟性能得分为 740，据英伟达实验室使用同类编译器估算，这一结果相比当前 DGX A100 搭载的双 CPU 高 1.5 倍以上。</p><p data-vmark="cde6">此外，Grace CPU 超级芯片可实现当今领先服务器芯片内存带宽和能效的 2 倍。</p><p data-vmark="692f">其依托带有纠错码的 LPDDR5x 内存组成的创新的内存子系统，能实现速度和功耗的最佳平衡。LPDDR5x 内存子系统提供两倍于传统 DDR5 设计的带宽，可达到 1TB / s，同时功耗也大幅降低，CPU 加内存整体功耗仅 500 瓦。</p><p data-vmark="4cde">Grace CPU 超级芯片可运行所有的英伟达计算软件栈，结合英伟达 ConnectX-7 网卡，能够灵活地配置到服务器中，或作为独立的纯 CPU 系统，或作为 GPU 加速服务器，可以搭配 1 块、2 块、4 块或 8 块基于 Hopper 的 GPU。</p><p data-vmark="a776" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/77626f92-ef11-407c-83b9-6e0ba0b05a0a.png" w="1080" h="601" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="456" referrerpolicy="no-referrer"></p><p data-vmark="2877">也就是说，用户只维护一套软件栈，就能针对自身特定的工作负载做好性能优化。</p><p data-vmark="285b">黄仁勋说，Grace 超级芯片有望明年开始供货。</p><h2 data-vmark="ac8c">04. 为定制芯片集成开放 NVLink 将支持 UCIe 小芯片标准</h2><p data-vmark="2f35">我们单独来说一下 NVLink-C2C 技术。</p><p data-vmark="b852">前面说的 Grace CPU 超级芯片系列、去年发布的 Grace Hopper 超级芯片都采用了这一技术来连接处理器芯片。</p><p data-vmark="3bcd">NVIDIA 超大规模计算副总裁 Ian Buck 认为：“为应对摩尔定律发展趋缓的局面，必须开发小芯片和异构计算。”</p><p data-vmark="eb75">因此，英伟达利用其在高速互连方面的专业知识开发出统一、开放的 NVLink-C2C 互连技术。</p><p data-vmark="2707">该技术将支持定制裸片与英伟达 GPU、CPU、DPU、NIC 和 SoC 之间实现一致的互连，从而通过小芯片构建出新型的集成产品，助力数据中心打造新一代的系统级集成。</p><p data-vmark="da6e" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/e2184b28-86b8-45bb-b0f9-2650b990dfd7.png" w="1080" h="598" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="454" referrerpolicy="no-referrer"></p><p data-vmark="0662">NVLink-C2C 现已为半定制芯片开放，支持其与 NVIDIA 技术的集成。</p><p data-vmark="dd4a">通过采用先进的封装技术，英伟达 NVLink-C2C 互连链路的能效最多可比 NVIDIA 芯片上的 PCIe Gen 5 高出 25 倍，面积效率高出 90 倍，可实现每秒 900GB 乃至更高的一致互联带宽。</p><p data-vmark="2b61">NVLink-C2C 支持 Arm AMBA 一致性集线器接口（AMBA CHI）协议，或 CXL 工业标准协议，可实现设备间的互操作性。当前英伟达和 Arm 正在密切合作，以强化 AMBA CHI 来支持与其他互连处理器完全一致且安全的加速器。</p><p data-vmark="e6eb">NVIDIA NVLink-C2C 依托于英伟达的 SERDES 和 LINK 设计技术，可从 PCB 级集成和多芯片模组扩展到硅插入器和晶圆级连接。这可提供极高的带宽，同时优化能效和裸片面积效率。</p><p data-vmark="5210">除 NVLink-C2C 之外，NVIDIA 还将支持本月早些时候发布的通用小芯片互连传输通道 UCIe 标准。</p><p data-vmark="fe43" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/f534085e-053f-4d71-813f-0a6fb117835d.png" w="1080" h="895" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="680" referrerpolicy="no-referrer"></p><p data-vmark="b1f3">▲ UCIe 标准</p><p data-vmark="5b6f">与 NVIDIA 芯片的定制芯片集成既可以使用 UCIe 标准，也可以使用 NVLink-C2C，而后者经过优化，延迟更低、带宽更高、能效更高。</p><h2 data-vmark="84b5">05. AI 软件：对话式 AI 服务全面发行 推出推荐系统 AI 框架 1.0 版本</h2><p data-vmark="4ed0">如今英伟达已经能提供全栈 AI，除了 AI 计算硬件外，其 AI 软件也有不少进展。</p><p data-vmark="6afd">黄仁勋说，AI 已经从根本上改变了软件的能力以及开发软件的方式，过去十年，英伟达加速计算在 AI 领域实现了百万倍的加速。</p><p data-vmark="9101">今日，英伟达发布了 60 多个针对 CUDA-X 的一系列库、工具和技术的更新，以加速量子计算和 6G 研究、网络安全、基因组学、药物研发等领域的研究进展。</p><p data-vmark="6645">英伟达将使用其首台 AI 数字孪生超级计算机 Earth-2 来应对气候变化挑战，并创建了 Physics-ML 模型来模拟全球天气模式的动态变化。</p><p data-vmark="1f05" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/43e7006e-18d8-43f3-ba7d-63ae96779412.gif" w="1053" h="597" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1053" height="465" referrerpolicy="no-referrer"></p><p data-vmark="aa49">英伟达还与来自加州理工学院、伯克利实验室等高校及科研机构的研究人员们开发了一个天气预报 AI 模型 FourCastNet，该模型基于 10TB 的地球系统数据进行训练，首次在降水预测上达到比先进的数值模型更高的准确率，并使预测速度提高了 4~5 个数量级。以前，传统的数值模拟需要一年时间，而现在只需几分钟。</p><p data-vmark="1f56" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/1089c0f0-0a21-4cc3-aca8-1de966948fd5.jpg@s_2,w_820,h_462" w="1000" h="563" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" srcset="https://img.ithome.com/newsuploadfiles/2022/3/1089c0f0-0a21-4cc3-aca8-1de966948fd5.jpg 2x" width="1000" height="462" referrerpolicy="no-referrer"></p><p data-vmark="06ba">NVIDIA Triton 是一款开源的、超大规模的模型推理服务器，是 AI 部署的“中央车站”，它支持 CNN、RNN、GNN、Transformer 等各种模型、各类 AI 框架及各类机器学习平台，支持在云、本地、边缘或嵌入式设备运行。</p><p data-vmark="4212">同时，黄仁勋宣布英伟达对话式 AI 服务 Riva 全面发行，Riva 2.0 版本支持识别 7 种语言，可将神经文本转换为不同性别发声的语音，用户可通过其 TAO 迁移学习工具包进行自定义调优。</p><p data-vmark="f51d">Maxine 是一个 AI 模型工具包，现已拥有 30 个先进模型，可优化实时视频通信的视听效果。比如开远程视频会议时，Maxine 可实现说话者与所有参会者保持眼神交流，并能将说的语言实时切换成另一种语言，而且音色听起来不变。</p><p data-vmark="61ae" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/1a8c8a3a-faa7-4eec-b021-fe37d9e62969.gif" w="1080" h="495" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="376" referrerpolicy="no-referrer"></p><p data-vmark="e72b">本次 GTC 发布的版本增加了用于回声消除和音频超分辨率的新模型。</p><p data-vmark="1158">此外，黄仁勋也宣布推出英伟达面向推荐系统的 AI 框架 Merlin 的 1.0 版本。</p><p data-vmark="9834">Merlin 可帮助企业快速构建、部署和扩展先进的 AI 推荐系统。比如，微信用 Merlin 将短视频推荐延迟缩短为原来的 1/4，并将吞吐量提升了 10 倍。从 CPU 迁移至 GPU，腾讯在该业务上的成本减少了 1/2。</p><p data-vmark="8746">在医疗健康领域，黄仁勋谈道，过去几年，AI 药研初创公司获得了超 400 亿美元的投资，数字生物学革命的条件已经成熟，他称这将是“NVIDIA AI 迄今为止最伟大的使命”。</p><p data-vmark="abe4">6G 标准于 2026 年左右问世，一些相关基础技术逐渐成形。对此，黄仁勋宣布推出了一款用于 6G 通信研究的 AI 框架 Sionna。</p><h2 data-vmark="246c">06. Omniverse：首推数字孪生 专用服务器和超级集群</h2><p data-vmark="9502">黄仁勋认为，第一波 AI 学习是感知和推理，下一波 AI 的发展方向是机器人，也就是使用 AI 规划行动。英伟达 Omniverse 平台也正成为制造机器人软件时必不可少的工具。</p><p data-vmark="a323" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/11ec9cba-a30b-495a-beb5-8e9e263f0b00.png" w="1080" h="609" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="462" referrerpolicy="no-referrer"></p><p data-vmark="11ff">作为虚拟世界的仿真引擎，Omniverse 平台能遵循物理学定律，构建一个趋真的数字世界，可以应用于使用不同工具的设计师之间的远程协作，以及工业数字孪生。</p><p data-vmark="bc55">黄仁勋认为，工业数字孪生需要一种专门构建的新型计算机，因此英伟达打造了面向工业数字孪生的 OVX 服务器和 OVX SuperPOD 超级集群。</p><p data-vmark="1579" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/ea4643d4-fb8f-4196-99d4-d8c3a64955d7.png" w="1080" h="598" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="454" referrerpolicy="no-referrer"></p><p data-vmark="301e">OVX 是首款 Omniverse 计算系统，由 8 个英伟达 A40 RTX GPU、3 个 ConnectX-6 200Gbps 网卡（NIC）和 2 个英特尔至强 Ice Lake CPU 组成。</p><p data-vmark="518c">32 台 OVX 服务器可构成 OVX SuperPOD 超级集群，实现这一连接的关键设施是英伟达今日新推出的 Spectrum-4 以太网平台。</p><p data-vmark="9dc5" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/eeb0e3f8-3bd5-4c90-96ed-162b6bf1a2d1.png" w="1080" h="597" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="453" referrerpolicy="no-referrer"></p><p data-vmark="7f79">据悉，这是全球首个 400Gbps 端到端网络平台，其交换吞吐量比前几代产品高出 4 倍，聚合 ASIC 带宽达到 51.2Tbps，支持 128 个 400GbE 端口。</p><p data-vmark="79a5">Spectrum-4 实现了纳秒级计时精度，相比典型数据中心毫秒级抖动提升了 5~6 个数量级。这款交换机还能加速、简化和保护网络架构。与上一代产品相比，其每个端口的带宽提高了 2 倍，交换机数量减少到 1/4，功耗降低了 40%。</p><p data-vmark="c524">该平台由英伟达 Spectrum-4 交换机系列、ConnectX-7 智能网卡、BlueField-3 DPU 和 DOCA 数据中心基础设施软件组成，可提高 AI 应用、数字孪生和云基础架构的性能和可扩展性，大幅加速大规模云原生应用。</p><p data-vmark="9ec0">Spectrum-4 ASIC 和 SN5000 交换机系列基于 4nm 工艺，有 1000 亿个晶体管，并经过简化的收发器设计，实现领先的能效和总拥有成本。</p><p data-vmark="6af7" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/1404da3d-fac3-4875-a694-4e86f63f87cb.png" w="1080" h="604" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="459" referrerpolicy="no-referrer"></p><p data-vmark="86c8">Spectrum-4 可在所有端口之间公平分配带宽，支持自适应路由选择和增强拥塞控制机制，能显著提升数据中心的应用速度。</p><p data-vmark="b10a">Spectrum-4 ASIC 具有 12.8Tbp 加密带宽和领先的安全功能，例如支持 MACsec 和 VXLANsec，并通过硬件信任根将安全启动作为默认设置，帮助确保数据流和网络管理的安全性和完整性。</p><p data-vmark="947a">现在各大计算机制造商纷纷推出 OVX 服务器，对于想在 OVX 试用 Omniverse 的客户，英伟达在全球多地提供 LaunchPad 计划，第一代 OVX 正由英伟达和早期客户运行，第二代 OVX 正被构建中。Spectrum-4 的样机将在今年第四季度末发布。</p><p data-vmark="866e">随后，曾在往届 GTC 大会展示过的黄仁勋虚拟化身“玩偶老黄”Toy Jensen 再度现身。</p><p data-vmark="d7fa" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/08ad55a6-9f22-44e8-ba51-22bd00a9e710.gif" w="667" h="372" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="667" height="372" referrerpolicy="no-referrer"></p><p data-vmark="e6f4">它不是录像，而能做到完全实时地进行眼神交流与对话。黄仁勋现场问它“什么是合成生物学”、“你是如何制作出来的”等问题，它都对答如流。</p><p data-vmark="5975">使用英伟达 Omniverse Avatar 框架，企业就能快速构建和部署像 Toy Jensen 这样的虚拟形象，从模仿声音到细微的头部及身体运动，乃至高保真度的形象塑造，都让虚拟人更加灵动。</p><p data-vmark="658b">最后，得益于 Riva 中的最新对话式 AI 技术和超大语言模型 Megatron 530B NLP，虚拟人可以听懂你问的问题，也能跟你实时聊天互动。</p><p data-vmark="84e2" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/ae443dd1-15f9-40b4-88a4-503fb14ba3e4.png" w="1080" h="599" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="455" referrerpolicy="no-referrer"></p><p data-vmark="bf75">在此基础上，英伟达宣布将推出 Omniverse Cloud。通过 Omniverse Cloud 连接，协作者们使用英伟达 RTX PC、笔记本电脑和工作站，均可实现远程实时协同工作。</p><p data-vmark="f456">用户如果没有 RTX 计算机，只需点击一下，即可从 GeForce Now 上启动 Omniverse。</p><h2 data-vmark="d435">07. 汽车：预告 DRIVE Hyperion 9 推出多模态地图引擎</h2><p data-vmark="1a9b">Omniverse 平台是整个工作流程的核心，DRIVE 平台则相当于 AI 司机。</p><p data-vmark="326e">黄仁勋宣布下一代 DRIVE Hyperion 9 将从 2026 年起搭载到汽车中，它将拥有 14 个摄像头、9 个雷达、3 个激光雷达和 20 个超声传感器，总体传感器数量将是 Hyperion 8 的两倍。</p><p data-vmark="e670" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/4c44b992-e82f-42c9-93db-a2f8126a1b53.png" w="1080" h="600" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="456" referrerpolicy="no-referrer"></p><p data-vmark="0e98">此外，英伟达推出了一种多模态地图引擎 NVIDIA DRIVE Map，包含摄像头、激光雷达和雷达的数据，同时兼顾安全性。</p><p data-vmark="6747">DRIVE Map 有两个地图引擎，真值测绘地图引擎和众包车队地图引擎。黄仁勋谈道，到 2024 年，他们预计绘制并创建北美、西欧和亚洲所有主要公路的数字孪生，总长度约为 50 万公里。</p><p data-vmark="0ae4">“我们正在构建地球级别的自动驾驶车队数字孪生。”黄仁勋说。</p><p data-vmark="29c4">合作方面，全球第二大电动汽车制造商比亚迪将在 2023 年上半年开始投产的汽车中搭载 DRIVE Orin 计算平台。自动驾驶独角兽企业元戎启行、中国自动驾驶创企云骥智行也宣布将在其 L4 级自动驾驶车规级量产方案中搭载 NVIDIA DRIVE Orin SoC 芯片。</p><p data-vmark="660b">美国电动汽车公司 Lucid Motors、中国 L4 级自动驾驶科技公司文远知行、中国新型电动车公司悠跑科技均宣布将应用英伟达 DRIVE Hyperion 自动驾驶汽车平台。</p><h2 data-vmark="df02">08. 机器人平台：从医疗设备到自主移动机器人</h2><p data-vmark="2bb1">黄仁勋认为下一波 AI 浪潮是机器人，英伟达正在构建多个机器人平台，包括用于自动驾驶汽车的 DRIVE、用于操纵和控制系统的 Isaac、用于自主式基础架构的 Metropolis、用于医疗设备的 Holoscan 等。</p><p data-vmark="99c0">他将机器人系统的工作流程简化为真值数据生成、AI 模型训练、Omniverse 数字孪生、机器人技术栈四大支柱。</p><p data-vmark="703d">Clara Holoscan MGX 是一个开放可扩展的机器人平台，其设计符合 IEC-62304 医疗级规格，核心计算机为 Jetson AGX Orin 和 ConnectX-7 智能网卡，并可选配 NVIDIA RTX A6000 GPU。</p><p data-vmark="71e5">该平台 AI 算力可达每秒 254~610 万亿次运算，目前向早期体验客户开放，正式上市时间是 5 月，并将于 2023 年第一季度完成医疗级准备。</p><p data-vmark="ac25" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/b2a2a7b5-9e7a-4db4-ad38-3db3cc4cdaf7.png" w="1080" h="586" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="445" referrerpolicy="no-referrer"></p><p data-vmark="a4c1">Metropolis 平台的下载量已经达到 30 万次，拥有 1000 多个生态系统合作伙伴，并在超过 100 万个设施中运营。</p><p data-vmark="bec5">机器人发展最快的领域之一是自主移动机器人（AMR），它本质上是室内无人驾驶，速度偏低但环境高度非结构化。</p><p data-vmark="6275">今天，英伟达推出 Isaac for AMR，它有四大核心：用于真值生成的 NVIDIA DeepMap、用于训练模型的 NVIDIA AI、搭载 Orin 的 AMR 机器人参考设计、Isaac 机器人技术堆栈中的新 Gem 及基于 Omniverse 的新版 Isaac Sim，每个都单独可用且完全开放。</p><p data-vmark="8951">与 DRIVE Hyperion 类似，Isaac Nova 是一个 AMR 机器人系统参考设计，整个 Isaac 堆栈都基于此构建。Nova 有 2 个摄像头、2 个激光雷达、8 个超声波雷达和 4 个鱼眼摄像头。</p><p data-vmark="c827">英伟达还宣布推出 Jetson Orin 开发者套件，以在边缘实现服务器级的 AI 性能。</p><p data-vmark="d563">Nova AMR 将于第二季度上市，它将配备英伟达新的 DeepMap 雷达制图系统，可以扫描和重建环境，以进行路线规划和数字孪生仿真。</p><p data-vmark="e1c6" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/3/cd6a6e81-5e78-4c72-9ade-e140066d1d68.png" w="1080" h="571" title="英伟达连甩 20 枚 AI 核弹：800 亿晶体管 GPU、144 核 CPU 来了" width="1080" height="434" referrerpolicy="no-referrer"></p><h2 data-vmark="3efe">09. 结语：AI 开发者的前沿技术盛宴</h2><p data-vmark="1d8c">这些年来，英伟达 GTC 大会已经成为一场面向 AI、HPC、科学计算、数字孪生及自动驾驶等诸多前沿领域的技术盛宴。</p><p data-vmark="6c6b">在这场盛宴中，我们不仅看到技术突破如果改变各行各业的生产效率和工作方式，也看到英伟达围绕计算世界的最新布局。</p><p data-vmark="93d6">随着新一代大规模云技术的出现，数据中心架构有待转型。在稳拥 GPU 基本盘的基础之上，英伟达的角色正从图形显示和加速计算“偏科学霸”，转向围绕数据中心三大芯片支柱全面发展。</p><p data-vmark="9bf9">黄仁勋认为，数据中心正在转变成“AI 工厂”，它通过处理海量的数据来实现智能，而今日推出的 H100 便是实现企业 AI 业务加速的引擎。</p><p data-vmark="10b8">H100 的多项技术创新，数据中心专属 Grace CPU 超级芯片的特殊设计，以及 AI 和 Omniverse 平台的持续升级，进一步扩大了英伟达在加速 AI 训练及推理领域的领导地位。</p><p data-vmark="448e">在为期 4 天的英伟达 GTC 大会上，我们还将看到更多不同细分领域的专家，分享他们如何利用 AI 和加速计算领域的技术创新，来开展各类开创性的研究或解决正面临的挑战。</p>
          
</div>
            