
---
title: '_一句话生成视频_AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了'
categories: 
 - 新媒体
 - IT 之家
 - 热榜
headimg: 'https://img.ithome.com/newsuploadfiles/2022/6/37da3cf8-5ebf-428c-827b-a0007cf69422.gif'
author: IT 之家
comments: false
date: Fri, 03 Jun 2022 03:53:35 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/6/37da3cf8-5ebf-428c-827b-a0007cf69422.gif'
---

<div>   
<p data-vmark="886b">一周不到，AI 画师又“进阶”了，还是一个大跨步 —— <span class="accentTextColor">直接 1 句话生成视频</span>的那种。</p><p data-vmark="a1fb">输入“一个下午在海滩上奔跑的女人”，立刻就蹦出一个 4 秒 32 帧的小片段：</p><p data-vmark="ac73" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/37da3cf8-5ebf-428c-827b-a0007cf69422.gif" w="108" h="108" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="108" height="108" referrerpolicy="no-referrer"></p><p data-vmark="833a">又或是输入“一颗燃烧的心”，就能看见一只被火焰包裹的心：</p><p data-vmark="2585" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/ead4afc4-9932-4bd9-a566-25f5696b2dbc.gif" w="108" h="96" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="108" height="96" referrerpolicy="no-referrer"></p><p data-vmark="558b">这个最新的文本-视频生成 AI，是清华 & 智源研究院出品的模型 <span class="accentTextColor">CogVideo</span>。</p><p data-vmark="4d73">Demo 刚放到网上就火了起来，有网友已经急着要论文了：</p><p data-vmark="62a9" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/20f8d848-0569-4403-a9ab-ea8ae8ea2013.gif" w="480" h="661" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="480" height="661" referrerpolicy="no-referrer"></p><p data-vmark="6142" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/ed7da8b0-ce7d-4ac0-8a3f-ed12587ebe6b.png" w="962" h="212" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="962" height="181" referrerpolicy="no-referrer"></p><p data-vmark="3960">CogVideo“一脉相承”于文本-图像生成模型 CogView2，这个系列的 AI 模型<span class="accentTextColor">只支持中文输入</span>，外国朋友们想玩还得借助谷歌翻译：</p><p data-vmark="440a" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/bd8ec398-280f-401a-b3c8-bd2f45ce16e4.png" w="1080" h="265" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="201" referrerpolicy="no-referrer"></p><p data-vmark="871b">看完视频的网友直呼“这进展也太快了，要知道文本-图像生成模型 DALL-E2 和 Imagen 才刚出”</p><p data-vmark="3b79" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/30d96dd5-494a-4b44-8389-4f05d2bad30a.png" w="1080" h="206" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="156" referrerpolicy="no-referrer"></p><p data-vmark="cba3">还有网友想象：照这个速度发展下去，马上就能看到 AI 一句话生成 VR 头显里的 3D 视频效果了：</p><p data-vmark="1df3" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/103fbea4-7159-4b27-96f8-15c32c2c2f82.png" w="1080" h="430" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="326" referrerpolicy="no-referrer"></p><p data-vmark="aa2e">所以，这只名叫 CogVideo 的 AI 模型究竟是什么来头？</p><h2 data-vmark="2751">生成低帧视频后再插帧</h2><p data-vmark="5e6f">团队表示，CogVideo 应该是当前最大的、也是首个开源的文本生成视频模型。</p><p data-vmark="dc7a">在设计模型上，模型一共有 90 亿参数，基于预训练文本-图像模型 CogView2 打造，一共分为两个模块。</p><p data-vmark="da29">第一部分先基于 CogView2，<span class="accentTextColor">通过文本生成几帧图像</span>，这时候合成视频的帧率还很低；</p><p data-vmark="e189">第二部分则会基于双向注意力模型对生成的几帧图像进行<span class="accentTextColor">插帧</span>，来生成帧率更高的完整视频。</p><p data-vmark="79e7" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/77f231e9-d9ad-4f43-9102-a7b4b44e90b0.png" w="1080" h="650" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="494" referrerpolicy="no-referrer"></p><p data-vmark="892d">在训练上，CogVideo 一共用了 <span class="accentTextColor">540 万个</span>文本-视频对。</p><p data-vmark="39d8">这里不仅仅是直接将文本和视频匹配起来“塞”给 AI，而是需要先将视频拆分成几个帧，并额外给每帧图像添加一个帧标记。</p><p data-vmark="ee73">这样就避免了 AI 看见一句话，直接给你生成几张一模一样的视频帧。</p><p data-vmark="0e7b">其中，每个训练的视频原本是 160×160 分辨率，被 CogView2 上采样（放大图像）至 480×480 分辨率，因此最后生成的也是 480×480 分辨率的视频。</p><p data-vmark="6d4e">至于 AI 插帧的部分，设计的双向通道注意力模块则是为了让 AI 理解前后帧的语义。</p><p data-vmark="ae2b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/6b860e6d-ad06-4cae-8176-ea10612be72d.png" w="446" h="464" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="446" height="464" referrerpolicy="no-referrer"></p><p data-vmark="0706">最后，生成的视频就是比较丝滑的效果了，输出的 4 秒视频帧数在 32 张左右。</p><h2 data-vmark="88b6">在人类评估中得分最高</h2><p data-vmark="2b5c">这篇论文同时用数据测试和人类打分两种方法，对模型进行了评估。</p><p data-vmark="2a62">研究人员首先将 CogVideo 在 UCF-101 和 Kinetics-600 两个人类动作视频数据集上进行了测试。</p><p data-vmark="9c2b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/4eb325b2-0c82-4d97-85a1-065167dbe652.png" w="1080" h="393" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="298" referrerpolicy="no-referrer"></p><blockquote><p data-vmark="5e25">其中，FVD（Fréchet 视频距离）用于评估视频整体生成的质量，数值越低越好；IS（Inception score）主要从清晰度和生成多样性两方面来评估生成图像质量，数值越高越好。</p></blockquote><p data-vmark="1eac">整体来看，CogVideo 生成的视频质量处于中等水平。</p><p data-vmark="5258">但从人类偏好度来看，CogVideo 生成的视频效果就比其他模型要高出不少，甚至在当前最好的几个生成模型之中，取得了最高的分数：</p><p data-vmark="eb26" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/a752f5b3-9060-43f0-b052-f7405c87e9f7.png" w="1080" h="363" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="276" referrerpolicy="no-referrer"></p><p data-vmark="c633">具体来说，研究人员会给志愿者一份打分表，让他们根据视频生成的效果，对几个模型生成的视频进行随机评估，最后判断综合得分：</p><p data-vmark="2487" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/866e7fa6-11f0-4af8-a3b1-f7e9b51ceb67.png" w="1080" h="583" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="443" referrerpolicy="no-referrer"></p><p data-vmark="d774">CogVideo 的共同一作洪文逸和丁铭，以及二作郑问迪，三作 Xinghan Liu 都来自清华大学计算机系。</p><p data-vmark="1eca">此前，洪文逸、丁铭和郑问迪也是 CogView 的作者。</p><p data-vmark="a712">论文的指导老师唐杰，清华大学计算机系教授，智源研究院学术副院长，主要研究方向是 AI、数据挖掘、机器学习和知识图谱等。</p><p data-vmark="7b18">对于 CogVideo，有网友表示仍然有些地方值得探究，例如 DALL-E2 和 Imagen 都有一些不同寻常的提示词来证明它们是从 0 生成的，但 CogVideo 的效果更像是从数据集中“拼凑”起来的：</p><p data-vmark="2847" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/6e600bce-8b74-4cce-bd67-2993aab2df52.png" w="1080" h="458" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="348" referrerpolicy="no-referrer"></p><p data-vmark="7d10">例如，狮子直接“用手”喝水的视频，就不太符合我们的常规认知（虽然很搞笑）：</p><p data-vmark="9fce" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/4bf808bb-f0ad-48c2-adf1-01dbd09f712f.gif" w="102" h="96" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="102" height="96" referrerpolicy="no-referrer"></p><p data-vmark="669c">（是不是有点像给鸟加上两只手的魔性表情包）</p><p data-vmark="d2d2" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/b47eda73-6a33-4518-b9db-07b6eb81ae91.gif" w="480" h="307" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="480" height="307" referrerpolicy="no-referrer"></p><p data-vmark="8128">但也有网友指出，这篇论文给语言模型提供了一些新思路：</p><p data-vmark="ee4c">用视频训练可能会进一步释放语言模型的潜力。因为它不仅有大量的数据，还隐含了一些用文本比较难体现的常识和逻辑。</p><p data-vmark="27f5" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2022/6/951e2c55-29c6-4a76-9bfd-c6ae24faeaba.png" w="1080" h="193" title="“一句话生成视频”AI 爆火：分辨率达到 480×480，只支持中文输入，轮到国外网友学翻译了" width="1080" height="147" referrerpolicy="no-referrer"></p><p data-vmark="f1e9">目前 CogVideo 的代码还在施工中，感兴趣的小伙伴可以去蹲一波了~</p><p data-vmark="74c1"><strong>项目 & 论文地址：</strong></p><p data-vmark="3957"><a href="https://github.com/THUDM/CogVideo" target="_blank"><span class="link-text-start-with-http">https://github.com/THUDM/CogVideo</span></a></p>
          
</div>
            