
---
title: 'OpenAI 学会_你说我画_：参数缩水 2_3 性能却更强，还 get 局部编辑新技能'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/12/ecf3625e-9cfd-407a-b965-4b76d34e29d7.png'
author: IT 之家
comments: false
date: Thu, 23 Dec 2021 07:29:37 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/12/ecf3625e-9cfd-407a-b965-4b76d34e29d7.png'
---

<div>   
<p data-vmark="a2f7">OpenAI 刚刚推出了一个新的文本生成图像模型，名叫 <span class="accentTextColor">GLIDE</span>。</p><p data-vmark="b721"><img src="https://img.ithome.com/newsuploadfiles/2021/12/ecf3625e-9cfd-407a-b965-4b76d34e29d7.png" w="932" h="1196" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="932" height="1052" referrerpolicy="no-referrer"></p><p data-vmark="fa46">相比今年年初诞生的大哥 DALL・E，<span class="accentTextColor">它只有 35 亿参数（DALL・E 有 120 亿）</span>。</p><p data-vmark="99e7">规模虽然小了，质量却不赖。</p><p data-vmark="9813">大家仔细看这效果，“使用计算器的刺猬”、“星空下的狐狸”、“彩色玻璃窗风格的熊猫吃竹子”、“太空升降舱蜡笔画”：</p><p data-vmark="47d1"><img src="https://img.ithome.com/newsuploadfiles/2021/12/1e4a05b0-dd47-4b6f-8327-fe0774dd6e83.png" w="1062" h="1196" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1062" height="923" referrerpolicy="no-referrer"></p><p data-vmark="ea4f">是不是很像样儿？</p><p data-vmark="3241">一位码农兼艺术家的网友则形容它“和真的难以区分”。</p><p data-vmark="63d4"><img src="https://img.ithome.com/newsuploadfiles/2021/12/87d395e0-e012-4044-9abc-d42ef0729fcb.png" w="948" h="534" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="948" height="462" referrerpolicy="no-referrer"></p><p data-vmark="2577">GLIDE 在人类评估员的打分中，确实 PK 掉了使用 CLIP 给图片排序的 DALL・E。</p><p data-vmark="264a"><img src="https://img.ithome.com/newsuploadfiles/2021/12/176364c1-31c0-4d85-978c-f2512b9b8482.png" w="292" h="350" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="292" height="350" referrerpolicy="no-referrer"></p><p data-vmark="d8f6">最有趣的是，这个 GLIDE 似乎具有“智力”—— 会否决你画出八条腿的猫的主意，也不认为老鼠可以捕食狮子。</p><p data-vmark="fce0"><img src="https://img.ithome.com/newsuploadfiles/2021/12/aa3743e4-097f-4d40-a608-332dd694c6e1.png" w="1080" h="442" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1080" height="336" referrerpolicy="no-referrer"></p><h2 data-vmark="efca">OpenAI 岁末新作 GLIDE</h2><p data-vmark="77b7">GLIDE 全称 Guided Language to Image Diffusion for Generation and Editing，是一种<span class="accentTextColor">扩散模型 （diffusion model）</span>。</p><p data-vmark="3c77">扩散模型最早于 2015 提出，它定义了一个马尔可夫链，用于在扩散步骤中缓慢地向数据添加随机噪声，然后通过学习逆转扩散过程从噪声中构建所需的数据样本。</p><p data-vmark="4210">相比 GAN、VAE 和基于流的生成模型，扩散模型在性能上有不错的权衡，最近已被证明在图像生成方面有很大的潜力，尤其是与引导结合来兼得保真度和多样性。</p><p data-vmark="7740"><img src="https://img.ithome.com/newsuploadfiles/2021/12/ddf33782-57e8-4961-beac-0a66b1062659.png" w="1080" h="746" alt="扩散模型与其他三种生成模型的对比" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1080" height="566" referrerpolicy="no-referrer"></p><p data-vmark="49ef">▲ 扩散模型与其他三种生成模型的对比</p><p data-vmark="046c">研究人员训练了一个 64×64 分辨率的文本条件扩散模型，参数 35 亿；以及一个 256×256 分辨率的文本条件上采样扩散模型，参数 15 亿。</p><p data-vmark="88ff">模型有两种引导形式来获得更好的生成效果：<span class="accentTextColor">无分类器引导（classifier-free guidance）和 CLIP 引导</span>。</p><p data-vmark="1154">对于 CLIP 引导，他们还训练了一个噪声感知的 64×64 ViT-L CLIP 模型 (vit)。</p><p data-vmark="4cfe">模型采用了 SOTA 论文《Improved Denoising Diffusion Probabilistic Models》（改进的去噪扩散概率模型）的架构，使用文本条件信息对其进行增强。</p><p data-vmark="41c4">对于每个带噪图像 xt 和相应的提示文本 caption，该模型预测出 p (xt-1|xt，caption)。</p><p data-vmark="ad5a">为了对文本进行条件处理，模型还将文本编码为 K 个 token 的序列，并将这些 token 馈送到 Transformer 中，此 Transformer 的输出有两个用处：</p><p data-vmark="0772">1、在 ADM 模型中使用最终 token embedding 来代替 class embedding;</p><p data-vmark="be25">2、token embedding 的最后一层在整个 ADM 模型中分别映射每个注意层的维度，然后连接到每个层的注意上下文。</p><p data-vmark="598b"><span class="accentTextColor">研究人员在与 DALL・E 相同的数据集上训练 GLIDE</span>，batch size 为 2048，共经过 250 万次迭代；对于上采样模型，则进行了 batch size 为 512 的 160 万次迭代。</p><p data-vmark="b99e">这些模型训练稳定，总训练计算量大致等于 DALL・E。</p><p data-vmark="6af6">在初始训练完成之后，研究人员还微调了基础模型以支持无条件图像生成。</p><p data-vmark="fb3a">训练过程与预训练完全一样，只是将 20% 的文本 token 序列替换为空序列。这样模型就能既保留文本条件生成的能力，也可以无条件生成。</p><p data-vmark="fa4b">为了让 GLIDE 在<span class="accentTextColor">图像编辑</span>任务中产生不必要的伪影，研究人员在微调时将 GLIDE 训练样本的随机区域擦除，其余部分与掩码通道一起作为附加条件信息输入模型。</p><p data-vmark="d74b"><img src="https://img.ithome.com/newsuploadfiles/2021/12/a76c63b4-475e-47f2-a5cf-1ba23104c93e.png" w="1080" h="969" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1080" height="736" referrerpolicy="no-referrer"></p><h2 data-vmark="f287">相比 DALL・E，GLIDE 的效果更逼真</h2><ul class=" list-paddingleft-2"><li><p data-vmark="4d76"><strong>定性实验</strong></p></li></ul><p data-vmark="8bdf">研究人员首先比较了 GLIDE 两种不同的引导策略：CLIP 引导和无分类器引导。</p><p data-vmark="4bc8">分别用 XMC-GAN、DALL・E（使用 CLIP 重排 256 个样本，从中选择最佳结果）和 CLIDE 模型（CLIP 引导 / 无分类器引导）在相同的文本条件下生成了一些结果。</p><p data-vmark="e772">CLIDE 模型的结果未经挑选。</p><p data-vmark="0b16"><img src="https://img.ithome.com/newsuploadfiles/2021/12/7e6933f3-e49f-4bf7-9727-ce8aba8e6708.png" w="1080" h="1082" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1080" height="822" referrerpolicy="no-referrer"></p><p data-vmark="53b7">可以发现，无分类器引导的样本通常比 CLIP 引导的看起来更逼真，当然，两者都胜过了 DALL・E。</p><p data-vmark="4cab">对于复杂的场景，CLIDE 可以使用修复功能进行迭代生成：比如下图就是先生成一个普通客厅，再加画、加茶几、加花瓶……</p><p data-vmark="09ce"><img src="https://img.ithome.com/newsuploadfiles/2021/12/a7ae81ca-8739-43af-bdf0-be641ca22722.png" w="1080" h="273" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1080" height="207" referrerpolicy="no-referrer"></p><p data-vmark="6bdb">此外，CLIDE 还可以在 SDedit 模型上利用草图与文本相结合的方式，对图像进行更多受控修改。</p><p data-vmark="db52"><img src="https://img.ithome.com/newsuploadfiles/2021/12/fdea45df-0214-43b5-a906-581fde9f87ef.png" w="586" h="780" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="586" height="780" referrerpolicy="no-referrer"></p><ul class=" list-paddingleft-2"><li><p data-vmark="7958"><strong>定量实验</strong></p></li></ul><p data-vmark="80f6">研究人员首先通过衡量质量和保真度的帕累托边界（Pareto frontier）来评估无分类引导和 CLIP 引导之间的差异。</p><p data-vmark="7748"><img src="https://img.ithome.com/newsuploadfiles/2021/12/3f991aa4-5c25-4c8e-ba33-c0b40df765b2.png" w="1080" h="293" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="1080" height="222" referrerpolicy="no-referrer"></p><p data-vmark="2a8c">在前两组曲线中，可以发现无分类器引导几乎都是最优的 —— 不管是在准确率 / 召回率上，还是在 IS / FID 距离上。</p><p data-vmark="33a2">而在绘制 CLIP 分数与 FID 的关系时，出现了完全相反的趋势。</p><p data-vmark="c45a">研究人员假设这是 CLIP 引导正在为评估 CLIP 模型寻找对抗性示例，而并非真正优于无分类器引导。为了验证这一假设，他们聘请了人工评估员来判断生成图像的质量。</p><p data-vmark="35ff">在这个过程中，人类评估者会看到两个 256×256 的图像，选择哪个样本更好地匹配给定文本或看起来更逼真。如果实在分辨不出，每个模型各得一半分数。</p><p data-vmark="a91f">结果如下：</p><p data-vmark="9d71"><img src="https://img.ithome.com/newsuploadfiles/2021/12/2ed29d4b-2d47-4ee6-88c7-ab9d1a2ce6d9.png" w="538" h="750" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="538" height="750" referrerpolicy="no-referrer"></p><p data-vmark="9f07"><span class="accentTextColor">无分类器引导产生了更符合相应提示的高质量样本</span>。</p><p data-vmark="2d90">同时，研究人员也将 CLIDE 与其他生成模型的质量进行了评估：CLIDE 获得了最有竞争力的 FID 分数。</p><p data-vmark="edd5"><img src="https://img.ithome.com/newsuploadfiles/2021/12/6a989683-5634-47e6-a76f-110ab73fb699.png" w="706" h="410" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="706" height="410" referrerpolicy="no-referrer"></p><p data-vmark="8fb7">再将 GLIDE 与 DALL-E 进行人工评估。</p><p data-vmark="7b8a">包含三种比法：两种模型都不使用 CLIP 重排序；仅对 DALL・E 使用 CLIP 重排序；对 DALL-E 使用 CLIP 重排序，并通过 DALL-E 使用的离散 VAE 映射 GLIDE 样本。</p><p data-vmark="0817">结果是不管哪种配置，人类评估员都更倾向于 GLIDE 的结果（每项第一行代表 GLIDE）。</p><p data-vmark="aeae"><img src="https://img.ithome.com/newsuploadfiles/2021/12/bf6fea14-bf40-4020-ab7a-8042dadfd1a6.png" w="682" h="348" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="682" height="348" referrerpolicy="no-referrer"></p><p data-vmark="d2ad">当然，说这么多，GLIDE 也有它的不足，就如开头的例子，它没法画出不合常理的“八条腿的猫”，<span class="accentTextColor">也就是有智力但缺乏想象力</span>。</p><p data-vmark="edd4">此外，未优化的 GLIDE 需要 15 秒才能在单张 A100 GPU 上生成一张图像，这比 GAN 慢多了。</p><p data-vmark="61c0">最后，po 一张我们在官方发布的 Colab 链接上亲手试的一张效果，还凑合（an illustration of a rabbit，demo 上的模型比较小）：</p><p data-vmark="6a94"><img src="https://img.ithome.com/newsuploadfiles/2021/12/125ddf9b-327b-4740-a9bb-c66f87634615.png" w="256" h="256" title="OpenAI 学会“你说我画”：参数缩水 2/3 性能却更强，还 get 局部编辑新技能" width="256" height="256" referrerpolicy="no-referrer"></p><p data-vmark="35db"><strong>论文地址：</strong></p><p data-vmark="ad93"><span class="link-text-start-with-http">https://arxiv.org/abs/2112.10741</span></p><p data-vmark="2e96"><strong>GitHub 地址 (是一个在过滤后的数据集上训练的小模型)：</strong></p><p data-vmark="0756"><span class="link-text-start-with-http">https://github.com/openai/glide-text2im</span></p><p data-vmark="ee5e"><strong>Colab 试玩：</strong></p><p data-vmark="296e"><span class="link-text-start-with-http">https://colab.research.google.com/github/openai/glide-text2im/blob/main/notebooks/text2im.ipynb#scrollTo=iuqVCDzbP1F0</span></p>
          
</div>
            