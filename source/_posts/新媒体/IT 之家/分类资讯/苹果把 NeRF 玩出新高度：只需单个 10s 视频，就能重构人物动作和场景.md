
---
title: '苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2022/8/14a36807-f992-46c8-8c91-26bed3f34494.gif'
author: IT 之家
comments: false
date: Sun, 21 Aug 2022 05:43:18 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/8/14a36807-f992-46c8-8c91-26bed3f34494.gif'
---

<div>   
<p data-vmark="c54f">有了这个发明，以后演员拍戏再也不用抠图了？答：可以直接一键合成。（手动狗头）</p><p data-vmark="ad15">让我们赶紧来看看，<strong>这个由苹果最新研发的 NeuMan 框架</strong>：只需输入一段 10s 左右的人物视频，<strong>就能合成该人物在新场景下做着各种新动作的影像</strong>。前空翻？so easy！</p><p style="text-align: center;" data-vmark="7bf9"><img src="https://img.ithome.com/newsuploadfiles/2022/8/14a36807-f992-46c8-8c91-26bed3f34494.gif" w="618" h="216" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="618" height="216" referrerpolicy="no-referrer"></p><p data-vmark="fd40">跳舞那也是不在话下。这妖娆的舞姿，看来 NeuMan 心里也有一个舞魂～</p><p style="text-align: center;" data-vmark="90d7"><img src="https://img.ithome.com/newsuploadfiles/2022/8/23ebe727-a049-4f04-9533-330d8f039db1.gif" w="940" h="504" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="940" height="440" referrerpolicy="no-referrer"></p><p data-vmark="0cea">有网友看完就表示：喔～简直是电影界未来的发展方向。</p><p style="text-align: center;" data-vmark="d5ec"><img src="https://img.ithome.com/newsuploadfiles/2022/8/9ffbbe89-0000-4027-b0ba-f941355dcaa7.png" w="876" h="170" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="876" height="159" referrerpolicy="no-referrer"></p><p data-vmark="9851">目前，有关 NeuMan 的研究论文已被 ECCV’22 收录，并且已在 GitHub 上开源。</p><p style="text-align: center;" data-vmark="14f3"><img src="https://img.ithome.com/newsuploadfiles/2022/8/05bdaa9b-0e00-46f7-a946-a7586d0d6dfb.png" w="1080" h="271" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1080" height="206" referrerpolicy="no-referrer"></p><h2 data-vmark="915a">全新场景渲染</h2><p data-vmark="3e1c">在介绍 NeuMan 的原理之前，让我们再来欣赏几个酷炫的例子～如下图所示，左上角是输入的训练视频，左下角是新的背景，右边则是合成后小哥在新背景下跳跃的效果。</p><p style="text-align: center;" data-vmark="c76d"><img src="https://img.ithome.com/newsuploadfiles/2022/8/02e9d149-63e7-4ff7-ad60-9d0f97edb12a.gif" w="610" h="216" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="610" height="216" referrerpolicy="no-referrer"></p><p data-vmark="ad90">不仅是跳跃这种常规操作，广播体操也完全没问题。</p><p style="text-align: center;" data-vmark="6c3d"><img src="https://img.ithome.com/newsuploadfiles/2022/8/60a9a05c-7d23-4f92-8d81-6b7d2b3c6be2.gif" w="1079" h="582" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1079" height="442" referrerpolicy="no-referrer"></p><p data-vmark="a08e">更厉害的是，<strong>NeuMan 还可以将上面例子中的两个人合成到一起</strong>。</p><p style="text-align: center;" data-vmark="eef9"><img src="https://img.ithome.com/newsuploadfiles/2022/8/5e82983c-c432-410d-bcdb-bbc811c4dc16.gif" w="1024" h="584" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1024" height="468" referrerpolicy="no-referrer"></p><p data-vmark="290d">再加上一个人，立马变成魔性的广场舞视频。</p><p style="text-align: center;" data-vmark="f150"><img src="https://img.ithome.com/newsuploadfiles/2022/8/baf3786b-3098-40c4-9edd-957eca21259d.gif" w="632" h="341" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="632" height="341" referrerpolicy="no-referrer"></p><p data-vmark="8320">这微笑的小表情，真的很难解释不是本人亲自跳的（手动狗头）。那么话说回来，这个神奇的 NeuMan 背后的原理是什么呢？</p><h2 data-vmark="28bb">基于 NeRF 的新突破</h2><p data-vmark="d2a4">事实上，自从伯克利和谷歌联合打造的 NeRF（Neural Radiance Fields 神经辐射场）横空出世，各种重建三维场景的研究层出不穷。</p><p data-vmark="9805">NeuMan 原理也是基于此，简单来说，就是用单个视频训练一个人物 NeRF 模型和一个场景 NeRF 模型，然后再合成在一起生成新的场景。</p><p style="text-align: center;" data-vmark="808d"><img src="https://img.ithome.com/newsuploadfiles/2022/8/e6a13840-5f14-4674-97fd-1b25ff137659.png" w="1080" h="345" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1080" height="262" referrerpolicy="no-referrer"></p><p data-vmark="2672">首先，在训练场景 NeRF 模型时，我们先从输入的视频中提取相机姿态、稀疏场景模型和多视角-立体深度图。</p><p data-vmark="bea2">对于原视频中被人体遮挡的部分，则使用 Mask R-CNN 进行图像实体分割，将人体掩模膨胀 4 倍，以确保人体被完全遮蔽。此时，就能做到仅在背景上训练场景 NeRF 模型。</p><p data-vmark="8dc3">至于人体 NeRF 模型训练，研究人员引入了一种端到端的 SMPL 优化（end-to-end SMPL optimization）和纠错神经网络（error-correction network）。</p><p data-vmark="d257">SMPL（Skinned Multi-Person Linear Model）是一种基于顶点的人体三维模型，能够精确地表示人体的不同形状和姿态。</p><p data-vmark="48a4">如下图所示，使用端到端的 SMPL 优化的人体模型，能够更好地表现人体的典型体积。</p><p style="text-align: center;" data-vmark="0596"><img src="https://img.ithome.com/newsuploadfiles/2022/8/baf2948d-c327-42f2-917f-2a70c0d5f687.png" w="944" h="452" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="944" height="393" referrerpolicy="no-referrer"></p><p data-vmark="2d35">纠错神经网络则是用来弥补 SMPL 模型无法表达的细节。值得一提的是，<strong>它只在训练过程中使用，在进行全新场景渲染时会被放弃，以免造成过度拟合</strong>。</p><p data-vmark="ce84">接下来，在两个模型对齐的阶段，研究人员先使用 COLMAP 解决任意尺度下的对齐问题。然后通过假设人类始终与地面有至少一个接触点，来进一步估计该场景的比例。</p><p style="text-align: center;" data-vmark="14c5"><img src="https://img.ithome.com/newsuploadfiles/2022/8/1a1d8dd2-3757-4844-8bef-463bb0d3b521.png" w="946" h="446" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="946" height="387" referrerpolicy="no-referrer"></p><p data-vmark="682e">最后，再应用 SMPL 网格和场景的点云叠加，就形成了新图像的渲染效果。</p><p style="text-align: center;" data-vmark="6cca"><img src="https://img.ithome.com/newsuploadfiles/2022/8/0d042d66-dac8-4dba-8a84-a3f01e37f9fd.png" w="1080" h="329" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1080" height="250" referrerpolicy="no-referrer"></p><p data-vmark="cd63">最终成品显示，该场景 NeRF 模型方面模型能够有效地去除场景中的人类，并在有限的场景覆盖下生成高质量的新背景渲染图像。</p><p style="text-align: center;" data-vmark="0773"><img src="https://img.ithome.com/newsuploadfiles/2022/8/9f801f78-dc28-47da-b2c1-1e0b98a9522f.png" w="1080" h="470" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1080" height="357" referrerpolicy="no-referrer"></p><p data-vmark="8d37">人物 NeRF 模型方面也能很好的捕捉人体的细节，包括袖子、衣领甚至衣服拉链，甚至在渲染新动作时，能执行难度极大的侧翻动作。</p><p style="text-align: center;" data-vmark="f9b3"><img src="https://img.ithome.com/newsuploadfiles/2022/8/9bfea445-daea-4cdf-a3b6-a00c27c8528d.png" w="1080" h="650" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1080" height="494" referrerpolicy="no-referrer"></p><p data-vmark="8a9e">值得一提的是，不同于现行的其他 NeRF 模型对训练视频要求很高，比如需要多个机位拍摄、曝光要保持不变、背景要干净等等，NeuMan 的最大亮点是仅通过用户随意上传的单个视频就能达到同款效果。</p><p style="text-align: center;" data-vmark="1984"><img src="https://img.ithome.com/newsuploadfiles/2022/8/81f88e35-75f3-4610-8de8-4f515c1e68a5.png" w="1080" h="325" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="1080" height="247" referrerpolicy="no-referrer"></p><p data-vmark="d015">并且，在分别输入六组不同的视频后，数据显示，与此前方法相比，NeuMan 的方法生成的视频渲染质量最佳。</p><p style="text-align: center;" data-vmark="2e8c"><img src="https://img.ithome.com/newsuploadfiles/2022/8/11f58e1b-d3d8-4523-a12d-92bfc18e097b.png" w="964" h="446" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="964" height="379" referrerpolicy="no-referrer"></p><p data-vmark="0b6a">不过，研究团队也承认，<strong>NeuMan 的设计目前还存在一些缺陷</strong>。例如，由于人在活动时手势的变化细微又多变，因此生成视频中对手部细节的把握还不是很准确。</p><p data-vmark="bd30">另外，在 NeRF 模型渲染时，由于系统假设人类始终与地面有至少一个接触点，因此 NeuMan 不能适用于人与地面接触为零的视频，比如人做后空翻的视频。</p><p data-vmark="1a37">要想解决这个问题，需要更智能的几何推理知识，这也是未来研究的一个发展方向。</p><h2 data-vmark="9bf9">研究团队</h2><p data-vmark="57c4">这项研究由苹果机器学习研究中心和英属哥伦比亚大学合作完成。第一作者 Wei Jiang，是英属哥伦比亚大学计算机科学专业的一名四年级博士生，目前在苹果机器学习研究中心实习。主要研究方向是新视角合成、视觉定位和三维视觉。</p><p style="text-align: center;" data-vmark="fc26"><img src="https://img.ithome.com/newsuploadfiles/2022/8/62820d15-5c59-4add-9055-be1f07df1b86.jpg" w="241" h="256" title="苹果把 NeRF 玩出新高度：只需单个 10s 视频，就能重构人物动作和场景" width="241" height="256" referrerpolicy="no-referrer"></p><p data-vmark="8892">他还是英属哥伦比亚大学计算机视觉实验室的一员，导师是 Kwang Moo Yi 教授。硕士毕业于波士顿大学计算机科学专业，本科毕业于浙江工业大学软件工程专业。</p><p data-vmark="72a0">参考链接：</p><ul class=" list-paddingleft-2"><li><p data-vmark="d434">[1]<span class="link-text-start-with-http">https://twitter.com/anuragranj/status/1559606408789708800</span></p></li><li><p data-vmark="b7c1">[2]<span class="link-text-start-with-http">https://arxiv.org/abs/2203.12575</span></p></li><li><p data-vmark="335e">[3]<span class="link-text-start-with-http">https://machinelearning.apple.com/research/neural-human-radiance-field</span></p></li><li><p data-vmark="ee37">[4]<span class="link-text-start-with-http">https://github.com/apple/ml-neuman</span></p></li><li><p data-vmark="a322">[5]<span class="link-text-start-with-http">https://jiangwei221.github.io/</span></p></li></ul>
          
</div>
            