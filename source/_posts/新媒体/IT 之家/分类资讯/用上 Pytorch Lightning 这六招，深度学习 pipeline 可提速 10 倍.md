
---
title: '用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/10/f8a70bde-802b-4ea3-afde-d140663f3875.gif'
author: IT 之家
comments: false
date: Sat, 02 Oct 2021 05:59:26 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/10/f8a70bde-802b-4ea3-afde-d140663f3875.gif'
---

<div>   
<p data-vmark="1ef1">面对数以亿计的图片数据，到底该用什么样的方法才能快速搞实验？</p><p data-vmark="aba2">这样的问题，或许在做机器学习研究的你，也会经常遇到。</p><p data-vmark="ded9">而就在最近，一个国外小哥就提出了一种建议：</p><blockquote><p data-vmark="357a">在 Pytorch lightning 基础上，让深度学习 pipeline 速度提升 10 倍！</p></blockquote><p data-vmark="9bd4"><img src="https://img.ithome.com/newsuploadfiles/2021/10/f8a70bde-802b-4ea3-afde-d140663f3875.gif" w="308" h="225" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="308" height="225" referrerpolicy="no-referrer"></p><p data-vmark="cc82">用他自己的话来说就是 ——“爬楼时像给了你一个电梯”。</p><p data-vmark="8d70">这般“酸爽”，到底是如何做到的呢？</p><p data-vmark="2aef"><img src="https://img.ithome.com/newsuploadfiles/2021/10/0a659945-daed-446d-ad89-31309dedddd8.jpg" w="348" h="209" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="348" height="209" referrerpolicy="no-referrer"></p><h2 data-vmark="c399">优化机器学习 pipeline，很重要</h2><p data-vmark="5ef2">无论你是身处学术界还是工业界，时间和资源等各种因素，往往会成为你在搞实验的枷锁。</p><p data-vmark="fa7c">尤其是随着数据集规模和机器学习模型，变得越发庞大和复杂，让实验变得既费时又耗力。</p><p data-vmark="00b5"><img src="https://img.ithome.com/newsuploadfiles/2021/10/de988d16-58db-42f9-bb02-e6f5cfde4b72.png" w="1004" h="930" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="1004" height="760" referrerpolicy="no-referrer"></p><p data-vmark="5374">提速这件事，就变得至关重要。</p><p data-vmark="a1e5">例如在 2012 年的时候，训练一个 AlexNet，要花上 5 到 6 天的时间。</p><p data-vmark="0e7b">而现如今，只需要短短几分钟就可以在更大的数据集上训练更大的图像模型。</p><p data-vmark="b266">这位小哥认为，从某种角度上来说，这是得益于各种各样的“利器”的出现。</p><p data-vmark="d36f">例如 Pytorch Lingtning，就是其中一种。</p><p data-vmark="17ed">于是，他便“死磕”pipeline，总结了六种“闪电加速”实验周期的方法。</p><p data-vmark="773b"><strong>并行数据加载</strong></p><p data-vmark="1e65">数据加载和增强（augmentation）往往被认为是训练 pipeline 时的瓶颈之一。</p><p data-vmark="7dae">一个典型的数据 pipeline 包含以下步骤：</p><ul class=" list-paddingleft-2"><li><p data-vmark="ec20">从磁盘加载数据</p></li><li><p data-vmark="f1a0">在运行过程中创建随机增强</p></li><li><p data-vmark="65ba">将每个样本分批整理</p></li></ul><p data-vmark="9448">在这个过程中，倒是可以用多个 CPU 进程并行加载数据来优化。</p><p data-vmark="6be6">但与此同时，还可以通过下面的操作来加速这一过程：</p><p data-vmark="8ecd">1、将 DataLoader 中的 num_workers 参数设置为 CPU 的数量。</p><p data-vmark="81b4">2、当与 GPU 一起工作时，将 DataLoader 中的 pin_memory 参数设置为 True。这可以将数据分配到页锁定的内存中，从而加快数据传输到 GPU 的速度。</p><p data-vmark="fc6b"><strong>使用分布式数据并行的多 GPU 训练</strong></p><p data-vmark="0802"><img src="https://img.ithome.com/newsuploadfiles/2021/10/50b0215c-ee1b-4ff2-825c-ec7cdf034fa9.png" w="972" h="750" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="972" height="633" referrerpolicy="no-referrer"></p><p data-vmark="cb7f">与 CPU 相比，GPU 已经大大加速了训练和推理时间。</p><p data-vmark="5934">但有没有比一个 GPU 更好的方法？或许答案就是：</p><blockquote><p data-vmark="c8d2">多个 GPU！</p></blockquote><p data-vmark="b949">在 PyTorch 中，有几种范式可以用多个 GPU 训练你的模型。</p><p data-vmark="404b">两个比较常见的范式是“DataParallel”和“DistributedDataParallel”。</p><p data-vmark="ccb4">而小哥采用的方法是后者，因为他认为这是一种更可扩展的方法。</p><p data-vmark="56fd">但在 PyTorch（以及其他平台）中修改训练 pipeline 并非易事。</p><p data-vmark="0eac">必须考虑以分布式方式加载数据以及权重、梯度和指标的同步等问题。</p><p data-vmark="70e9">不过，有了 PyTorch Lightning，就可以非常容易地在多个 GPU 上训练 PyTorch 模型，还是几乎不需要修改代码的那种！</p><p data-vmark="377a"><img src="https://img.ithome.com/newsuploadfiles/2021/10/c7704070-ed98-4fa3-a230-edf61141e2f9.png" w="1080" h="171" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="1080" height="130" referrerpolicy="no-referrer"></p><p data-vmark="8e90"><strong>混合精度</strong></p><p data-vmark="b73b">在默认情况下，输入张量以及模型权重是以单精度（float32）定义的。</p><p data-vmark="b6d4">然而，某些数学运算可以用半精度（float16）进行。</p><p data-vmark="2023">这样一来，就可以显著提升速度，并降低了模型的内存带宽，还不会牺牲模型的性能。</p><p data-vmark="240b">通过在 PyTorch Lightning 中设置混合精度标志（flag），它会在可能的情况下自动使用半精度，而在其他地方保留单精度。</p><p data-vmark="b244">通过最小的代码修改，模型训练的速度可以提升 1.5 至 2 倍。</p><p data-vmark="e8e5"><img src="https://img.ithome.com/newsuploadfiles/2021/10/d7709740-e10e-4ec7-bd6b-b89cc36c8d27.png" w="1080" h="167" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="1080" height="127" referrerpolicy="no-referrer"></p><p data-vmark="2580"><strong>早停法</strong></p><p data-vmark="874c">当我们训练深度学习神经网络的时候，通常希望能获得最好的泛化性能。</p><p data-vmark="d2e4">但是所有的标准深度学习神经网络结构，比如全连接多层感知机都很容易过拟合。</p><p data-vmark="2f10">当网络在训练集上表现越来越好，错误率越来越低的时候，实际上在某一刻，它在测试集的表现已经开始变差。</p><p data-vmark="cace">因此，早停法 （Early Stopping）便在训练过程中加入了进来。</p><p data-vmark="eb80">具体来说，就是当验证损失在预设的评估次数（在小哥的例子中是 10 次评估）后停止训练。</p><p data-vmark="b596">这样一来，不仅防止了过拟合的现象，而且还可以在几十个 epoch 内找到最佳模型。</p><p data-vmark="3687"><img src="https://img.ithome.com/newsuploadfiles/2021/10/c097ced0-0375-4053-90ba-94ac0440e0a8.png" w="1080" h="351" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="1080" height="266" referrerpolicy="no-referrer"></p><p data-vmark="238e"><strong>Sharded Training</strong></p><p data-vmark="dbbf">Sharded Training 是基于微软的 ZeRO 研究和 DeepSpeed 库。</p><p data-vmark="bbfa">它显著的效果，就是让训练大模型变得可扩展和容易。</p><p data-vmark="c1b6">否则，这些模型就不适合在单个 GPU 上使用了。</p><p data-vmark="be52">而在 Pytorch Lightning 的 1.2 版本中，便加入了对 Shared Training 的支持。</p><p data-vmark="b07b">虽然在小哥的实验过程中，并没有看到训练时间或内存占用方面有任何改善。</p><p data-vmark="df4d">但他认为，这种方法在其它实验中可能会提供帮助，尤其是在不使用单一 GPU 的大模型方面。</p><p data-vmark="f799"><img src="https://img.ithome.com/newsuploadfiles/2021/10/7a92a9e5-ea82-4141-b731-f949ae247824.png" w="1080" h="194" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="1080" height="147" referrerpolicy="no-referrer"></p><p data-vmark="52cd"><strong>模型评估和推理中的优化</strong></p><p data-vmark="f388">在模型评估和推理期间，梯度不需要用于模型的前向传递。</p><p data-vmark="9050">因此，可以将评估代码包裹在一个 torch.no_grad 上下文管理器中。</p><p data-vmark="7ef1">这可以防止在前向传递过程中的存储梯度，从而减少内存占用。</p><p data-vmark="1eaa">如此一来，就可以将更大的 batch 送入模型，让评估和推理变得更快。</p><h2 data-vmark="bdfb">效果如何？</h2><p data-vmark="48d0">介绍了这么多，你肯定想知道上述这些方法，具体起到了怎样的作用。</p><p data-vmark="fbce">小哥为此做了一张表格，详解了方法的加速效果。</p><p data-vmark="0d47"><img src="https://img.ithome.com/newsuploadfiles/2021/10/b7190132-35f4-4c02-9788-e0392e61d024.png" w="1004" h="1244" title="用上 Pytorch Lightning 这六招，深度学习 pipeline 可提速 10 倍" width="1004" height="1016" referrerpolicy="no-referrer"></p><p data-vmark="1e88">那么这些方法，是否对在做机器学习实验的你有所帮助呢？</p><p data-vmark="9c4c">快去试试吧~</p><p data-vmark="c6d9">参考链接：</p><p data-vmark="bd3c">https://devblog.pytorchlightning.ai/how-we-used-pytorch-lightning-to-make-our-deep-learning-pipeline-10x-faster-731bd7ad318a</p>
          
</div>
            