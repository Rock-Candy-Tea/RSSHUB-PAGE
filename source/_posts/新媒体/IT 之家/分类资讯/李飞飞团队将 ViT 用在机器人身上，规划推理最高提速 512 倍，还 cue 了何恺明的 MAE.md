
---
title: '李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2022/6/c5007956-2422-4058-aa75-2567d1c80c25.gif'
author: IT 之家
comments: false
date: Sat, 25 Jun 2022 05:32:18 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/6/c5007956-2422-4058-aa75-2567d1c80c25.gif'
---

<div>   
<p data-vmark="886a">人类的预测能力 + ViT，会产生什么样的化学反应？会让机器人的行动规划能力又快又准。</p><p style="text-align: center;" data-vmark="b34c"><img src="https://img.ithome.com/newsuploadfiles/2022/6/c5007956-2422-4058-aa75-2567d1c80c25.gif" w="640" h="280" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="640" height="280" referrerpolicy="no-referrer"></p><p data-vmark="2908">这是李飞飞团队的最新研究 ——MaskViT，<span class="accentTextColor">通过 MVM，掩码视觉建模对 Transformer 进行预训练，从而建立视频预测模型。</span></p><p style="text-align: center;" data-vmark="d21d"><img src="https://img.ithome.com/newsuploadfiles/2022/6/c63534c8-b955-4bc5-a293-4f6a39551311.png" w="1060" h="444" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="1060" height="343" referrerpolicy="no-referrer"></p><p data-vmark="826e">结果显示，MaskViT 不仅能生成 256*256 视频，还可以让机器人行动规划的推理速度最高提高了 512 倍。</p><p style="text-align: center;" data-vmark="b97b"><img src="https://img.ithome.com/newsuploadfiles/2022/6/cf2595bb-d905-4ef3-84d5-15a3b1c8904d.gif" w="640" h="332" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="640" height="332" referrerpolicy="no-referrer"></p><p data-vmark="51b4">来看看这是项什么样的研究？</p><h3 data-vmark="fd2c">从人类身上找灵感</h3><p data-vmark="06cf">神经科学领域的研究表明，人类的认知、感知能力是有一种预测机制来支持的。这种对世界的预测模型，可以用来模拟、评估和选择不同的可能行动。对人类来说，这一过程是快速和准确的。</p><p data-vmark="cb29">如果能赋予机器人类似的预测能力。那么他们就可以在复杂的动态环境中快速规划、执行各类任务。</p><p data-vmark="12d1">比如，通过视觉模型来预测控制，也许就是一种方式，但也对算力和准确性提出了更高的要求。于是，李飞飞团队就想到了最近诸多进展的 ViT 架构，以及以何恺明 MAE 为代表的基于 MVM，Masked Visual Modeling 这一自监督预训练表征。</p><p data-vmark="c936">但具体要操作起来，仍有不少的技术挑战。</p><p data-vmark="f020">一方面，全局注意力机制的复杂度与输入序列长度的平方呈正比，导致视频处理成本过高。另一方面，视频预测任务和自回归掩码视觉预训练之间存在不一致。实际测试时，模型必须从头预测完整的未来帧序列，导致视频预测质量不好。</p><p data-vmark="cc78">基于这样的背景，李飞飞团队提出了 MaskViT—— 通过掩码视觉建模对 Transformer 进行预训练，从而建立视频预测模型。</p><p style="text-align: center;" data-vmark="0663"><img src="https://img.ithome.com/newsuploadfiles/2022/6/3c5a9af8-42d2-4f2c-a277-6bd79c3179c8.png" w="1080" h="276" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="1080" height="210" referrerpolicy="no-referrer"></p><p data-vmark="2f8f">具体有两种设计决策。</p><p data-vmark="40a3">首先，为了提高记忆和训练效率，使用了两种类型的窗口注意力：空间注意力和时空注意力。其次，训练过程中掩码的 token 比例是可变的。在推理阶段，视频是通过迭代细化生成的，其中按照掩码调度函数逐步降低掩码率。</p><p style="text-align: center;" data-vmark="841a"><img src="https://img.ithome.com/newsuploadfiles/2022/6/62d19f36-6454-4c73-bf37-f7a0e5079855.png" w="1080" h="273" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="1080" height="207" referrerpolicy="no-referrer"></p><h3 data-vmark="72cc">实验结果</h3><p data-vmark="9695">研究团队在三个不同数据集，以及四个不同指标来评估了 MaskViT。结果显示，跟以往先进的方法比较，MaskViT 都表现出了更好的性能，可生成分辨率达 256 × 256 的视频。</p><p style="text-align: center;" data-vmark="0a72"><img src="https://img.ithome.com/newsuploadfiles/2022/6/7aeeae79-b0b1-435e-92f9-8ed66b4b6630.png" w="1080" h="437" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="1080" height="332" referrerpolicy="no-referrer"></p><p data-vmark="3f15">还在 BAIR 进行了消融实验。</p><p style="text-align: center;" data-vmark="648f"><img src="https://img.ithome.com/newsuploadfiles/2022/6/47c69a4a-912e-4def-8ae9-53e4f1c93d05.png" w="1080" h="407" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="1080" height="309" referrerpolicy="no-referrer"></p><p data-vmark="8b39">随后，团队还展示了真实机器人使用 MaskViT 进行实时规划的效果。</p><p style="text-align: center;" data-vmark="7b43"><img src="https://img.ithome.com/newsuploadfiles/2022/6/ad3bfd62-2181-41d2-b03e-dd7676a3ce48.gif" w="640" h="290" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="640" height="290" referrerpolicy="no-referrer"></p><p data-vmark="65b7">推理速度最高可提升 512 倍。</p><p style="text-align: center;" data-vmark="b5d6"><img src="https://img.ithome.com/newsuploadfiles/2022/6/46d35c50-f439-49b9-8bc9-07d4bd06971d.png" w="640" h="376" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="640" height="376" referrerpolicy="no-referrer"></p><p data-vmark="030d">研究人员表示，本次工作表明，可以通过最小的领域知识，利用掩码视觉建模的一般框架，赋予像智能体强大的预测模型。但同时表示，也具有一定的局限性。比如在每帧量化时会出现闪烁伪影，尤其是在 RoboNet 这种有静态背景的视频中。</p><p style="text-align: center;" data-vmark="b572"><img src="https://img.ithome.com/newsuploadfiles/2022/6/06771e58-368b-4681-a53c-7809cf03ea72.gif" w="640" h="332" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="640" height="332" referrerpolicy="no-referrer"></p><p data-vmark="9540">还有如果要扩大视频预测的规模，也仍然具有挑战性，特别是那种有大量摄像机运动的场景。未来，他们将探索把这一视频预测方法整合到更复杂的规划算法中。值得一提的是，在今年 5 月，何恺明团队曾提出过视频版 MAE，并发现最佳掩蔽率高达 90%。</p><p style="text-align: center;" data-vmark="d633"><img src="https://img.ithome.com/newsuploadfiles/2022/6/2c6edfca-6964-4b5b-ad35-e3a81c0f2e7b.png" w="1056" h="480" title="李飞飞团队将 ViT 用在机器人身上，规划推理最高提速 512 倍，还 cue 了何恺明的 MAE" width="1056" height="373" referrerpolicy="no-referrer"></p><p data-vmark="dd0e">论文链接：</p><p data-vmark="28a4"><span class="link-text-start-with-http">https://arxiv.org/abs/2206.11894</span></p><p data-vmark="cba8">项目链接：</p><p data-vmark="8748"><span class="link-text-start-with-http">https://maskedvit.github.io/</span></p><p data-vmark="92da">何恺明论文：</p><p data-vmark="0f68"><span class="link-text-start-with-http">https://arxiv.org/abs/2205.09113</span></p>
          
</div>
            