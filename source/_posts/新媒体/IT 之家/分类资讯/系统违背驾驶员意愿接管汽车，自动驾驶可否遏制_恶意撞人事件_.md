
---
title: '系统违背驾驶员意愿接管汽车，自动驾驶可否遏制_恶意撞人事件_'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/5/0a963cf9-0702-4b2b-8ad0-1c7ab69ccda8.jpg'
author: IT 之家
comments: false
date: Sun, 30 May 2021 07:35:18 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/5/0a963cf9-0702-4b2b-8ad0-1c7ab69ccda8.jpg'
---

<div>   
<p><img src="https://img.ithome.com/newsuploadfiles/2021/5/0a963cf9-0702-4b2b-8ad0-1c7ab69ccda8.jpg" w="600" h="400" title="系统违背驾驶员意愿接管汽车，自动驾驶可否遏制“恶意撞人事件”" width="600" height="400" referrerpolicy="no-referrer"></p><p>今日凌晨，继大连恶意撞人事件后，南京的“蓄意撞人新闻”再度牵动了所有人的神经。</p><p>数万年来，人 + 工具，一直是双刃剑般的组合。它们既可进行协同创造，也可实现协同破坏。两个结果，均取决于“人”的动机与“人”的操作规范。</p><p>人工智能时代，在人机协同过程中，我们依旧对“人”的影响颇为有限，但或许可以控制“工具”。</p><p>车，便是被控制的工具之一。未来的乘用车，大规模地嵌入自动驾驶，尤其是辅助驾驶系统，是必然的趋势。地平线 CEO 早前曾预言，对于未来乘用智能汽车而言，自动驾驶是通用必选项，但它并不会带来差异化价值。</p><p>“也就是说，用户会因为缺乏自动驾驶功能而不买某款车型，而不会因为自动驾驶功能而买这款车型。”</p><p>这既是个人所需，也是公共所需。那么自动驾驶，在遇到人为犯罪的驾驶场景时，能否在紧急情况下实现规避和降低损害？</p><p>专家告诉我们，从工程实现上，欲避免这类事件，或最大化减轻后果，分两种途径：</p><p>一种是实现汽车完全自动驾驶化（L4/L5），相当于把开车这件事，完全交给了无人驾驶系统，甚至没有方向盘。从源头上避免驾驶员主观恶意操作的发生，但要达到这一条件，相对较为遥远。</p><p>一种是在辅助驾驶（L3 以下）的前提下，在系统内写入极端情况的规则，一旦触发极端规则，系统便拥有最高操作权限，及时“违背”人类驾驶员的不当行为，通过汽车已有功能，阻止加速，或进行自动紧急刹车等操作。</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/5/61256e36-70a1-4123-9d34-a16140375183.jpg" w="720" h="527" title="系统违背驾驶员意愿接管汽车，自动驾驶可否遏制“恶意撞人事件”" width="720" height="527" referrerpolicy="no-referrer"></p><h2>系统在违背驾驶员意愿下接管汽车，是好事吗？</h2><p>有人指出，如果有驾驶者超速和闯红灯（会避开行人和车辆），是因为家人需要去医院急救，这个时候机器如果在人工驾驶期间，强行介入去控制车辆，影响到救急，是否有悖伦理？</p><p>确实，类似的自动驾驶伦理问题，一直广泛存在。</p><p>人类驾驶员作出在机器看来可能不当的决策，有时候往往是基于不得已的特殊情况下，瞬间发生的本能反应，以及基于过往的经验和认知做出判断。</p><p>但与此同时，人类驾驶员也将为其决策，承担社会和法律责任。</p><p>而机器在紧急情况下的驾驶决策，均需要工程师们事先给定机器一个判断逻辑和决策规则，让其遵循。</p><p>但规则能全部制定正确吗？</p><p>答案是否定的。</p><p>MIT 曾发表了一篇论文，整理了 2016 年一个叫做“道德机器”的在线测试的数据。</p><p>“道德机器”对 9 个不同的影响因素进行了测试，其中包括了：</p><p>车祸发生时撞男性，还是女性？</p><p>撞多数人，还是少数人？</p><p>年轻人，还是老年人？</p><p>守交通规则的行人，还是乱穿马路的人？</p><p>社会地位高的人，还是社会地位低的人？</p><p>……</p><p>当一个个扎心的问题摆在自动驾驶工作人员面前时，所有人陷入了沉默。</p><p>业内专家告诉我们，上述情况属于开放性的道德问题，人类自己都没有标准答案，因此也无法把这些问题的最终决策，写入系统内。</p><h2>伦理也分类别</h2><p>但有些极端情况，是可定义、可规则化，有明确答案的。</p><p>以近期的大连事件为例，刘某驾车在等候绿灯指示后，突然在 7 秒钟内将所驾车辆车速从 0 时速加速至 108 公里 / 小时（该路段限速 60 公里 / 小时），并冲闯红灯，以驾车冲撞路人的极端方式实施犯罪，造成 5 死 5 伤。</p><p>红灯期间、猛加速、冲向行人。</p><p>此行为基本满足了定性的全部条件，因此无论驾驶员遇到了何种情况，都是可以通过机器强行介入控制的。</p><p>比如当车体上的摄像头或激光雷达检测到红灯和行人，以及距离时，可及时限制驾驶员的突然加速行为。</p><p>目前常见的辅助驾驶功能，主要为自适应巡航、前碰撞预警、自动紧急刹车、车道保持辅助、换道辅助等。</p><p>配备了自动刹车功能的汽车，当驾驶员在遇到危险没有做出有效反应的情况下，系统可以自动紧急刹车。</p><p>但它并不能在特定情况下，拥有最高控制权限，完全强制接管车辆。</p><p>也就是说，若人类驾驶员即便在危险场景下，依旧执意要加速行驶，以及其他恶意操作，哪怕拥有自动紧急刹车功能，系统也毫无办法。</p><p>因此，技术人员需为辅助驾驶功能，赋予部分极端场景中，高于驾驶员的最高驾驶控制权限。</p><p>目前已有部分厂商也正在这样做。</p><h2>当今常见的主动刹车系统</h2><p>目前市场上已有的 BAS 与自动刹车系统，利用摄像头或雷达检测前方车辆，结合一定的行驶速度，分析出可能发生的碰撞时（如下图 d3 的距离），系统便警示驾驶员。</p><p>当进入 d2 距离时，自动准备足够的制动力，只要驾驶员踩下刹车，就会立刻发挥最大的制动效能。但前提是需要驾驶员踩下刹车。</p><p>当距离缩小到 d1 时，如果驾驶员并未踩刹车，自动紧急刹车系统则立即进行主动刹车。</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/5/9499d43a-30eb-429a-bd2a-c747126ea0ed.jpg" w="472" h="359" title="系统违背驾驶员意愿接管汽车，自动驾驶可否遏制“恶意撞人事件”" width="472" height="359" referrerpolicy="no-referrer"></p><p>即便如此，它只是辅助，而不是取代。</p><p>人们通常会犯一个错误，把“辅助”当做“取代”，因此形成惰性，放松警惕，以为机器能包办一切，最终酿成意外事故。</p><p>同样的问题，也存在于医疗 AI 领域。</p><p>AI 在影像科中扮演的角色，是辅助医生读片。如果医生抱有 AI 这个不成熟的助手可以承办一切的心态，从而降低自身的阅片标准，同样会带来医疗事故。</p><p>因此，要么全盘交给精度达到最高等级的机器；要么人必须与尚未成熟的机器进行强协同，抛弃依赖。</p><p>目前的 AI，显然都处于后者阶段。</p><p>自动驾驶，是一个集技术与伦理于一体的产品，更是一个富有生命力的组织形态。</p><p>技术无法凌驾于伦理之上，但可以一定程度上阻止恶意破坏伦理的人。</p><p>在伦理之内，把工具变得可控和智能，是所有科技从业者的社会使命。</p>
          
</div>
            