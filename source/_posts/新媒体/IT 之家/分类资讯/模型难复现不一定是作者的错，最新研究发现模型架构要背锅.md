
---
title: '模型难复现不一定是作者的错，最新研究发现模型架构要背锅'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2022/3/cddfc72f-66bc-489a-8dde-f5d6a41a79b9.png'
author: IT 之家
comments: false
date: Sat, 19 Mar 2022 12:15:28 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/3/cddfc72f-66bc-489a-8dde-f5d6a41a79b9.png'
---

<div>   
<p data-vmark="6575">在不同初始化条件下，同一神经网络经过两次训练可以得到相同的结果吗？CVPR 2022 的一篇研究通过将决策边界 （Decision Boundary）可视化的方法，给出了答案 —— 有的容易，有的很难。</p><p data-vmark="be7d">例如，从下面这张图来看，研究人员就发现，ViT 比 ResNet 要更难复现（两次训练过后，显然 ViT 决策边界的差异更大）：</p><p style="text-align: center;" data-vmark="3d5d"><img src="https://img.ithome.com/newsuploadfiles/2022/3/cddfc72f-66bc-489a-8dde-f5d6a41a79b9.png" w="624" h="438" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="624" height="438" referrerpolicy="no-referrer"></p><p data-vmark="d0bd">研究人员还发现，模型的可复现性和模型本身的宽度也有很大关联。同样，他们利用这种方法，对 2019 年机器学习最重要的理论之一 —— 双下降 （Double Descent）现象进行了可视化，最终也发现了一些很有意思的现象。</p><p style="text-align: center;" data-vmark="3497"><img src="https://img.ithome.com/newsuploadfiles/2022/3/5ed7c5fc-2d7f-498e-ba44-8818c0fdb9ef.png" w="1080" h="376" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="1080" height="285" referrerpolicy="no-referrer"></p><p data-vmark="e50f">来看看他们具体是怎么做的。</p><h3 data-vmark="7bfe">更宽的 CNN 模型，可复现性更高</h3><p data-vmark="1088">深度学习中的决策边界，可以用来最小化误差。简单来说，分类器会通过决策边界，把线内线外的点归为不同类。在这项研究中，作者从 CIFAR-10 训练集中选择了三幅随机图像，然后使用三次不同的随机初始化配置在 7 种不同架构上训练，绘制出各自的决策区域。</p><p style="text-align: center;" data-vmark="3c4e"><img src="https://img.ithome.com/newsuploadfiles/2022/3/9ed87382-6c91-4a21-9c18-f7d503b01c63.png" w="1080" h="462" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="1080" height="351" referrerpolicy="no-referrer"></p><p data-vmark="1e43">从中我们可以发现：左边三个和右边四个差异很大，也就是说不同架构之间的相似性很低。再进一步观察，左边的全连接网络、ViT 和 MLP Mixer 之间的决策边界图又不太一样，而右边 CNN 模型的则很相似。在 CNN 模型中，我们还可以观察到不同随机数种子之间明显的的重复性趋势，这说明不同初始化配置的模型可以产生一样的结果。</p><p data-vmark="48e5">作者设计了一种更直观的度量方法来衡量各架构的可复现性得分，结果确实验证了我们的直观感受：</p><p style="text-align: center;" data-vmark="95b9"><img src="https://img.ithome.com/newsuploadfiles/2022/3/413a4d77-60ec-4597-8daf-7647ae744883.png" w="644" h="434" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="644" height="434" referrerpolicy="no-referrer"></p><p data-vmark="e5a2">并发现更宽的 CNN 模型似乎在其决策区域具有更高的可复现性，比如 WideRN30。以及采用残差连接结构的 CNN 模型（ResNet 和 DenseNet ）的可复现性得分比无此连接的模型要略高（VGG）。此外，优化器的选择也会带来影响。在下表中，我们可以看到 SAM 比标准优化器（如 SGD 和 Adam）产生了更多可重复的决策边界。不过对于 MLP Mixer 和 ViT，SAM 的使用不能总是保证模型达到最高的测试精度。</p><p style="text-align: center;" data-vmark="58a3"><img src="https://img.ithome.com/newsuploadfiles/2022/3/fd49e918-e272-4d11-a8d3-715b16dfffad.png" w="568" h="480" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="568" height="480" referrerpolicy="no-referrer"></p><p data-vmark="05f3">有网友表示好奇，如果通过改善模型本身的设计，能改变这种现象吗？对此作者回应称，他们已经试着调整过 ViT 的学习率，但得到的结果仍然比 ResNet 差。</p><p style="text-align: center;" data-vmark="dbbe"><img src="https://img.ithome.com/newsuploadfiles/2022/3/ba3bdad8-bf11-4184-b987-b8acb77761ff.png" w="1080" h="606" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="1080" height="460" referrerpolicy="no-referrer"></p><h3 data-vmark="5b35">可视化 ResNet-18 的双下降现象</h3><p data-vmark="2e33">双下降（Double Descent）是一个有趣的概念，描述是测试 / 训练误差与模型大小的关系。在此之前，大家普遍认为参数太少的模型泛化能力差 —— 因为欠拟合；参数太多的模型泛化能力也差 —— 因为过拟合。</p><p style="text-align: center;" data-vmark="e328"><img src="https://img.ithome.com/newsuploadfiles/2022/3/b355fad7-64c5-44d3-ba50-d0cb7c849f8b.png" w="576" h="300" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="576" height="300" referrerpolicy="no-referrer"></p><p data-vmark="94ba">而它证明，两者的关系没有那么简单。具体来说：误差会先随着模型的增大而减小，然后经过模型过拟合，误差又增大，但随着模型大小或训练时间的进一步增加，误差又会再次减小。</p><p data-vmark="b9b0">作者则继续使用决策边界方法，可视化了 ResNet-18 的双下降现象。他们通过宽度参数（k：1-64）的改变来增加模型容量。训练出的两组模型，其中一组使用无噪声标签（label noise）的训练集，另一组则带有 20% 的噪声标签。最终，在第二组模型中观察到了明显的双下降现象。</p><p style="text-align: center;" data-vmark="6cac"><img src="https://img.ithome.com/newsuploadfiles/2022/3/50605a87-3b32-4644-8285-8fefaa7408a7.png" w="1080" h="739" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="1080" height="561" referrerpolicy="no-referrer"></p><p data-vmark="46ec">对此作者表示：线性模型预测的模型不稳定性也适用于神经网络，不过这种不稳定性表现为决策区域的大量碎片。</p><p data-vmark="5847">也就说，双下降现象是由噪声标签情况下决策区域的过度碎片引起的。具体来说，当 k 接近 / 达到 10 （也就是插值阈值）时，由于模型此时拟合了大部分训练数据，决策区域被分割成很多小块，变得“混乱和破碎”，并不具备可重复性；此时模型的分类功能存在明显的不稳定性。而在模型宽度很窄（k=4）和很宽（k=64）时，决策区域碎片较少，有高水平的可重复性。为了进一步证明该结果，作者又设计了一个碎片分数计算方法，最终再次验证上图的观察结果。</p><p style="text-align: center;" data-vmark="884f"><img src="https://img.ithome.com/newsuploadfiles/2022/3/ed98882a-fd80-42f6-8e61-db5f2daba49e.png" w="642" h="382" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="642" height="382" referrerpolicy="no-referrer"></p><p data-vmark="8fff">模型的可复现性得分如下：</p><p style="text-align: center;" data-vmark="fedb"><img src="https://img.ithome.com/newsuploadfiles/2022/3/7e37894e-f4a9-405c-a205-2add127df42f.png" w="630" h="294" title="模型难复现不一定是作者的错，最新研究发现模型架构要背锅" width="630" height="294" referrerpolicy="no-referrer"></p><p data-vmark="7275">同样可以看到，在参数化不足和过参数化的情况下，整个训练过程的可复现性很高，但在插值阈值处会出现“故障”。有趣的是，即使没有噪声标签，研究人员发现他们设计的量化方法也足够敏感，可以检测到可复现性的细微下降（上图蓝线部分）。</p><p data-vmark="cb15">目前代码已经开源，要不要来试试你的模型是否容易复现？</p><p data-vmark="60cd">论文地址：</p><p data-vmark="a81c"><span class="link-text-start-with-http">https://arxiv.org/abs/2203.08124</span></p><p data-vmark="52d2">GitHub 链接：</p><p data-vmark="b55c"><span class="link-text-start-with-http">https://github.com/somepago/dbVi</span></p>
          
</div>
            