
---
title: '4000 多家组织和个人发公开信：要求苹果取消_儿童安全_功能'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/8/f6b82734-ff9a-4de3-8c0c-6d58672e1fc1.jpg@s_2,w_820,h_461'
author: IT 之家
comments: false
date: Sun, 08 Aug 2021 01:13:08 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/8/f6b82734-ff9a-4de3-8c0c-6d58672e1fc1.jpg@s_2,w_820,h_461'
---

<div>   
<p>8 月 8 日消息，据外媒报道，苹果公司刚刚公布了新的“儿童安全”功能，旨在扩大对儿童的保护。</p><p>但此举遭到包括 4000 多家组织以及安全与隐私专家、密码学家、研究人员、教授、法律专家和苹果消费者的公开反对。他们于周六签署公开信，谴责苹果有计划地破坏用户隐私和端到端加密机制。</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/f6b82734-ff9a-4de3-8c0c-6d58672e1fc1.jpg@s_2,w_820,h_461" w="1200" h="675" title="4000 多家组织和个人发公开信：要求苹果取消“儿童安全”功能" srcset="https://img.ithome.com/newsuploadfiles/2021/8/f6b82734-ff9a-4de3-8c0c-6d58672e1fc1.jpg 2x" width="1200" height="461" referrerpolicy="no-referrer"></p><p>公开信全文如下：</p><p>2021 年 8 月 5 日，苹果公司宣布了新的技术措施，旨在“扩大对儿童的保护”，这些新举措几乎适用于其所有设备。虽然虐待儿童是个严重的问题，而且打击这个问题的努力几乎完全是出于善意，但苹果的提议实际上相当于引入了“后门”，有可能破坏对所有苹果产品用户的基本隐私保护。</p><p>苹果提出的方法是通过持续监控用户 <a class="s_tag" href="https://iphone.ithome.com/" target="_blank">iPhone</a>、<a class="s_tag" href="https://ipad.ithome.com/" target="_blank">iPad</a> 或 Mac 上保存或共享的照片来实现的。一个系统检测 iCloud 存储中是否会有相当数量的违规照片，并向相关机构发出警报。如果 iMessage 被用来发送或接收机器学习算法认为包含裸照的照片，另一款应用程序会通知孩子的父母。因为这两种检测都是在用户的设备上执行的，所以它们有可能绕过任何会保护用户隐私的端到端加密。</p><p>在苹果宣布这一消息后，世界各地的专家立即敲响了警钟，称苹果提出的措施可以将每部 iPhone 变成一台监控设备，不断扫描通过它的所有照片和消息，以便向执法部门报告任何令人反感的内容。这开创了一个先例，我们的个人设备成为一种激进的新入侵监控工具，几乎没有任何监督，以防止最终滥用和不合理地扩大监控范围。</p><p>电子前沿基金会 (EFF) 曾表示，苹果正在为更广泛的滥用行为敞开大门。该机构称：“我们不可能建立这样的客户端扫描系统，只用于儿童发送或接收不法图片。因此，即使是出于善意的努力来建立这样的系统，也会打破加密技术带来的关键承诺，并为更广泛的滥用打开大门。这不是滑坡效应，而是完整的系统，只是在等待外部压力做出最微小的改变。”</p><p>民主与技术中心（CDT）表示，该组织深切关注苹果的改变，这实际上给儿童和所有用户带来了新的风险，并标志着与长期存在的隐私和安全协议的重大背离。CDT 安全与监控项目联席主任格雷格・诺杰姆 (Greg Nojeim) 表示：“苹果正在用监控和审查基础设施取代其作为行业标准的端到端加密信息系统，这不仅在美国，而且在世界各地都很容易受到滥用和范围蔓延的影响。苹果应该放弃这些改变，恢复用户对苹果设备和服务上数据的安全性和完整性信心。”</p><p>安全与隐私领域的知名研究专家、瑞士洛桑 EPFL 教授卡梅拉・特隆科索博士 (Carmela Troncoso) 表示：“苹果新的扫描有关儿童受虐待材料之照片 (CSAM) 功能是以保护儿童隐私和安全名义推广的，但其实际上正朝着普遍的监控和控制迈出的坚实一步。”</p><p>另一位安全与隐私领域的知名研究专家、约翰霍普金斯大学教授马修・格林博士 (Matthew D.Green) 也说：“我们正逐渐走向这样一个未来：我们的信息必须越来越少地受到除我们自己以外的任何人的控制和审查。自上世纪 90 年代以来，我们第一次收回了对隐私的控制。然而，今天我们走上了一条不同的道路。”</p><p>开放隐私研究协会 (Open Privacy Research Society) 执行董事萨拉・杰米・刘易斯 (Sarah Jamie Lewis) 警告称：“如果苹果成功推出这项服务，你认为其他供应商需要多长时间会紧随其后？在‘围墙花园’禁止不这样做的应用程序之前？在它被载入法律之前？你认为数据库要多久才能扩大到包括‘恐怖内容’？有害但合法的“内容”呢？”</p><p>安全与隐私问题研究员纳迪姆・科贝西博士 (Nadim Kobeissi) 警告说：“苹果在沙特阿拉伯销售没有 FaceTime 的 iPhone，因为当地法规禁止加密电话。这只是苹果屈服于当地压力的众多例子中的一个。如果沙特法律要求扫描的信息不是儿童性虐待，而是同性恋或对君主制的冒犯，会发生什么？”</p><p>电子前沿基金会 (EFF) 就这个问题发表的声明支持了上述担忧，并举例说明了苹果提出的技术如何会导致全球滥用。该机构称：“以印度为例，该国最近通过的规则包括要求平台识别信息来源和屏幕前内容的危险要求。埃塞俄比亚的新法律要求在 24 小时内删除包含‘错误信息’的内容，这可能适用于信息服务。许多其他国家也通过了类似的法律。苹果的改变将允许在其端到端消息中进行这样的筛选、删除和报告，并引发滥用。”</p><p>专家们也指出了苹果提出的方法中存在的根本设计缺陷，他们声称苹果可以很容易地为每个用户使用不同的媒体指纹数据集。对一个用户来说，这可能是虐待儿童，对另一个用户来说，这可能是更广泛的类别，从而为目标用户提供了选择性的内容跟踪。</p><p>苹果为其儿童安全功能提出的技术类型取决于可扩展的基础设施，而这种基础设施既不能监控，也不受技术限制。专家们一再警告说，问题不仅仅是隐私，还有缺乏责任感，扩展的技术障碍，以及对潜在的错误和误报缺乏分析等。哈佛大学法学院网络法律诊所 (Cyberlaw Clinic) 的律师肯德拉・阿尔伯特 (Kendra Albert) 警告说，这些“儿童保护”功能会让同性恋孩子被赶出家门，遭到殴打，甚至发生更糟的情况。</p><p>我们要求：</p><p>1）苹果立即停止部署对其拟议中的内容监控技术；</p><p>2）苹果应发表声明，重申他们对端到端加密和用户隐私的承诺；</p><p>3）苹果目前的做法可能会破坏技术专家、学者和政策倡导者数十年来的努力，即强有力的隐私保护措施是大多数消费电子设备和使用案例的常态。我们要求苹果重新考虑其技术推广方法，以免毁了这项重要努力。</p>
          
</div>
            