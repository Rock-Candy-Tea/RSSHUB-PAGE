
---
title: 'OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/11/672ac36d-2e25-4322-8bab-a172fa23f275.jpg'
author: IT 之家
comments: false
date: Tue, 02 Nov 2021 09:29:23 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/11/672ac36d-2e25-4322-8bab-a172fa23f275.jpg'
---

<div>   
<p data-vmark="1097"><img src="https://img.ithome.com/newsuploadfiles/2021/11/672ac36d-2e25-4322-8bab-a172fa23f275.jpg" w="481" h="193" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="481" height="193" referrerpolicy="no-referrer"></p><p data-vmark="987a">现在小学数学题有多难？小学生拍图上传作题 App 找不到现成答案，稍微变换下题设语句，就要买会员换人工答题。</p><p data-vmark="8983">一时间小学生纷纷成了“氪金玩家”。</p><p data-vmark="fd8b">即便是题目换汤不换药，讲题 App 还是罢了工。如果有一款能听懂大白话的作题软件能有多好！</p><p data-vmark="457c">近日，OpenAI 训练了一个新系统，可解决小学数学题，称其提升了 GPT-3 的逻辑推理问题。</p><p data-vmark="82df">自去年 6 月 11 日以来，OpenAI 公布 GPT-3 语言模型，GPT-3 成为 OpenAI 的旗舰语言生成算法，参数规模达 1750 亿，在文本生成上与人类写作相媲美。</p><p data-vmark="b9cb">三个月后，OpenAI 又推出用于数学问题的 GPT-f，利用基于 Transformer 语言模型的生成能力进行自动定理证明。</p><p data-vmark="75ff">时至今日，GPT-3 的能力依据被冠以“大力出奇迹”，光凭解答小学程度的几道数学题，就能盖过对 OpenAI 的质疑声吗？</p><p data-vmark="141e"><img src="https://img.ithome.com/newsuploadfiles/2021/11/20a8a8f2-17ee-4465-9c09-ec9d635974a7.jpg" w="635" h="245" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="635" height="245" referrerpolicy="no-referrer"></p><p data-vmark="3f7d">论文地址：<span class="link-text-start-with-http">https://arxiv.org/pdf/2110.14168.pdf</span></p><p data-vmark="4a9d">数据集地址：<span class="link-text-start-with-http">https://github.com/openai/grade-school-math</span></p><p data-vmark="afa4">其中涉及一大难点：GPT-3 真的懂逻辑吗？即便是数学语言不同于大白话，但依旧涉及很多逻辑关系，一步错步步错。</p><p data-vmark="2fd5">为此，OpenAI 基于四个设计原则创建了 GSM8K 数据集供 GPT-3 反复训练，即数据集为高质量、高多样性、中等难度和自然语言的答题形式。</p><p data-vmark="6bb9">GSM8K 数据集由 8.5K 个高质量小学数学应用题组成，每个问题需要 2 到 8 步解决，涉及到加减乘除整合运算，难度近乎 9-12 岁的小学数学题。</p><p data-vmark="299e">结果发现，60 亿参数的 GPT-3 采用“新方法”，准确率直接翻倍！甚至追平了拥有 1750 亿参数，采用微调方法的 GPT-3 模型。</p><p data-vmark="a02e"><img src="https://img.ithome.com/newsuploadfiles/2021/11/c0916768-aa70-4507-93bd-1cd90bc86340.jpg@s_2,w_820,h_289" w="1080" h="381" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" srcset="https://img.ithome.com/newsuploadfiles/2021/11/c0916768-aa70-4507-93bd-1cd90bc86340.jpg 2x" width="1080" height="289" referrerpolicy="no-referrer"></p><p data-vmark="3947">新方法挑战比自己高 30 倍的大参数模型，力证参数并非越大越好，这一新方法是什么？</p><h2 data-vmark="7521">1 训练验证器：从错误中学习的模型</h2><p data-vmark="43ce">像 GPT-3 这样的大型语言模型有许多惊人的技能，包括模仿多种写作风格，自动编程、自然对话、语义搜索等。然而，它们很难完成需要精确的多步骤推理的任务，比如解决小学数学应用题。</p><p data-vmark="86b8">「小明每半小时喝一瓶水。一个普通的数独难题要花他 45 分钟。一个极难的数独需要 4 倍的时间。做一道极难的数独的时间他喝了多少瓶水？」</p><p data-vmark="7c50">在这样的数学题中，GPT-3 要匹配人类在复杂逻辑领域中的表现，一味提高参数，是解决办法的长远之策吗？</p><p data-vmark="5967">并不！OpenAI 在新方法中提到，为什么不让模型学会识别自己的错误呢？从许多候选的解决方案中选择出最佳方案！</p><p data-vmark="23d6">为此，OpenAI 训练了验证器（verifier），来评估所提出的解决方案是否正确。可比通过更新模型参数，最小化所有训练 token 的交叉熵损失的方法要多一个思路。</p><p data-vmark="5489">增加一个“验证”模块，通过反复试错，学习，再计算，原先微调无法解决的 GPT-3 逻辑推理能力，在新方法中得到进步。</p><p data-vmark="7d43">对于两种思路，OpenAI 通过新的 GSM8K 数据集来测试两种方法：</p><ul class=" list-paddingleft-2"><li><p data-vmark="f66a">高质量：GSM8K 中的问题都是人工设计的，避免了错误问题的出现。</p></li><li><p data-vmark="e834">高多样性：GSM8K 中的问题都被设计得相对独特，避免了来自相同语言模板或仅在表面细节上有差异的问题。</p></li><li><p data-vmark="ae11">中等难度：GSM8K 中的问题分布对大型 SOTA 语言模型是有挑战的，但又不是完全难以解决的。这些问题不需要超出早期代数水平的概念，而且绝大多数问题都可以在不明确定义变量的情况下得到解决。</p></li><li><p data-vmark="5d9a">自然语言解决方案：GSM8K 中的解决方案是以自然语言而不是纯数学表达式的形式编写的。模型由此生成的解决方案也可以更容易被人理解。此外，OpenAI 也期望它能阐明大型语言模型内部独白的特性。</p></li></ul><p data-vmark="2535"><img src="https://img.ithome.com/newsuploadfiles/2021/11/630befd6-dba8-4852-b534-dcbef3591969.jpg@s_2,w_820,h_439" w="842" h="451" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" srcset="https://img.ithome.com/newsuploadfiles/2021/11/630befd6-dba8-4852-b534-dcbef3591969.jpg 2x" width="842" height="439" referrerpolicy="no-referrer"></p><p data-vmark="a52a">GSM8K 中的三个问题示例，红色为计算的注释</p><p data-vmark="c7d5">在 GSM8K 数据集上，OpenAI 测试了新方法验证（verification）和基线方法微调（fine-tuning）生成的答案。</p><p data-vmark="c906">即 4 种不同的解决方案：6B 微调、6B 验证、175B 微调和 175B 验证。</p><p data-vmark="f1cd">在性能展示中，OpenAI 提供了十个数学题实例，其中一个是的解决方案如下：</p><p data-vmark="7337">小明种了 5 棵树。他每年从每棵树上收集 6 个柠檬。他十年能得到多少柠檬？</p><p data-vmark="631a"><img src="https://img.ithome.com/newsuploadfiles/2021/11/3a3336f5-82ea-4417-bfce-99c605f9210b.jpg" w="535" h="167" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="535" height="167" referrerpolicy="no-referrer"></p><p data-vmark="02e8">175B 验证正确</p><p data-vmark="5569"><img src="https://img.ithome.com/newsuploadfiles/2021/11/2f71d79a-38b3-445c-b35d-38441861939b.jpg" w="731" h="197" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="731" height="197" referrerpolicy="no-referrer"></p><p data-vmark="2066">175B 微调错误</p><p data-vmark="34c9"><img src="https://img.ithome.com/newsuploadfiles/2021/11/370f961f-cd29-4b99-8633-e31f4ae1cb96.jpg" w="709" h="165" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="709" height="165" referrerpolicy="no-referrer"></p><p data-vmark="8f1a">6B 验证正确</p><p data-vmark="5746"><img src="https://img.ithome.com/newsuploadfiles/2021/11/a51b3507-be9c-48fc-8e02-2645b16f58fa.jpg" w="566" h="164" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="566" height="164" referrerpolicy="no-referrer"></p><p data-vmark="f7da">6B 微调正确</p><p data-vmark="e3b9">很明显，验证方法（verification）比基线方法微调（fine-tuning）在回答数学应用题上有了很大的提升。</p><p data-vmark="1c36">在完整的训练集上，采用「验证」方法的 60 亿参数模型，会略微优于采用「微调」的 1750 亿参数模型！</p><p data-vmark="2d8a"><img src="https://img.ithome.com/newsuploadfiles/2021/11/8e178375-7f2d-42bc-bfa5-8a5a5d902058.jpg" w="676" h="410" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="676" height="410" referrerpolicy="no-referrer"></p><p data-vmark="e532">但大模型也不是一无是处，采用「验证」的 1750 亿参数模型还是比采用「验证」方法的 60 亿参数模型学习速度更快，只需要更少的训练问题，就能超过微调基线。</p><p data-vmark="5ee4">OpenAI 发现，只要数据集足够大，大模型就能从「验证」中获得强大的性能提升。</p><p data-vmark="46b5">但是，对于太小的数据集，验证器会通过记忆训练集中的答案而过度拟合，而不是学习基本的数学推理这种更有用的属性。</p><p data-vmark="37d3">所以，根据目前的结果进行推断，「验证」似乎可以更有效地扩展到额外的数据。</p><p data-vmark="c2d0">大模型毕竟有大模型的优势，如果之后能够用大模型 + 验证的方式，将会使得模型性能再上一个 level !</p><h2 data-vmark="7e4b">2 新方法是如何验证的？</h2><p data-vmark="2364">验证器训练时，只训练解决方案是否达到正确的最终答案，将其标记为正确或不正确。但是在实践中，一些解决方案会使用有缺陷的推理得出正确的最终答案，从而导致误报。</p><p data-vmark="dbbb"><img src="https://img.ithome.com/newsuploadfiles/2021/11/c69d4b8e-8abb-4c54-8350-5a48b7846c7c.jpg@s_2,w_820,h_359" w="905" h="396" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" srcset="https://img.ithome.com/newsuploadfiles/2021/11/c69d4b8e-8abb-4c54-8350-5a48b7846c7c.jpg 2x" width="905" height="359" referrerpolicy="no-referrer"></p><p data-vmark="ce5b">现在的验证器具体训练方法分为三步走:</p><ul class="ai-word-checked list-paddingleft-2"><li><p data-vmark="cc57">先把模型的「生成器」在训练集上进行 2 个 epoch 的微调。</p></li><li><p data-vmark="9e81">从生成器中为每个训练问题抽取 100 个解答，并将每个解答标记为正确或不正确。</p></li><li><p data-vmark="0c8f">在数据集上，验证器再训练单个 epoch。</p></li></ul><p data-vmark="1773">生成器只训练 2 个 epoch 是因为 2 个 epoch 的训练就足够学习这个领域的基本技能了。如果采用更长时间的训练，生成的解决方案会过度拟合。</p><p data-vmark="6a03">测试时，解决一个新问题，首先要生成 100 个候选解决方案，然后由验证器打分，排名最高的解决方案会被最后选中。</p><p data-vmark="b582">训练验证器既可以在全部的生成解决方案里进行单个标量预测（single scalar prediction），也可以在解决方案的每个 token 后进行单个标量预测，OpenAI 选择后者，即训练验证器在每个 token 之后进行预测。</p><p data-vmark="0ae2">如下图所示，它们分别标记为“解决方案级别”和“token 级别”。</p><p data-vmark="e0bf">在 b 图中，通过消融实验验证训练验证器中使用目标（objective）的作用，OpenAI 将使用两个目标与仅使用验证目标进行比较。</p><p data-vmark="ac7a">在 c 图中，OpenAI 对生成器和验证器的大小进行了实验，研究发现使用大的生成器、小的验证器组合性能显著优于小的生成器、大的验证器组合。</p><p data-vmark="d32d"><img src="https://img.ithome.com/newsuploadfiles/2021/11/b29395e2-e8f0-4a1e-9a43-903a46f77648.jpg" w="653" h="378" title="OpenAI 新发现：GPT-3 做小学数学题能得 55 分，验证胜过微调" width="653" height="378" referrerpolicy="no-referrer"></p><h2 data-vmark="f231">3 写在最后</h2><p data-vmark="2ec0">通过 OpenAI 所展现出的 10 个数学实例是看出，使用验证方法比单纯扩大参数要更加智能，但缺点是并不稳定。比如在另一个问题实例中，仅有 175B 验证模型输出正确结果：小明是一所私立学校的院长，他有一个班。小红是一所公立学校的院长，他有两个班，每个班的人数是小明班级人数 120 人的 1/8。问两所学校的总人数是多少?</p><p data-vmark="0393">AI 发展道阻且长，目前绝大多数的机器学习仍依赖于数据堆砌，缺乏根本性的技术突破，存在一定的发展瓶颈。Google 工程总监 Ray Kurzweil 曾表示，直到 2029 年，人类才有超过 50% 的概率打造出 AGI 系统，还有一部分专家表示至少要到 2099 年或 2200 年。</p><p data-vmark="7c4d">现下，通过在一些简单的领域试验新路径，识别和避免机器学习的错误是推动模型发展的关键方法，比如这种简单的小学数学题。最终当我们试图将模型应用到逻辑上更复杂的领域时，那些不被了解的黑箱子将变得越来越透明。</p>
          
</div>
            