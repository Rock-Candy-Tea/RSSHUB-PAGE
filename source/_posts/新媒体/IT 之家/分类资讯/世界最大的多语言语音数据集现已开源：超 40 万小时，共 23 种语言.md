
---
title: '世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/8/09cb1acd-1ebc-4e25-bf28-ca94f110fc0d.png'
author: IT 之家
comments: false
date: Fri, 06 Aug 2021 06:25:42 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/8/09cb1acd-1ebc-4e25-bf28-ca94f110fc0d.png'
---

<div>   
<p>最近，Facebook 开源了目前世界上最大的多语言语音数据集，VoxPopuli：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/09cb1acd-1ebc-4e25-bf28-ca94f110fc0d.png" w="1080" h="94" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="1080" height="71" referrerpolicy="no-referrer"></p><p>这一数据集共涵盖了 23 种语言，时长超过 40 万小时。</p><p>其中，每种语言都有 9000 到 18000 小时的无标签语音数据。</p><p>此外，还包括了共 1800 小时，16 种语言的转录语音数据，以及 17300 小时，15 种目标语言的口译语音数据。</p><p>国外网友很快为这一行为点赞：</p><blockquote><p>显然，如果数据集已经存在，那么它应该被利用，并以一种道德的方式来改善人类社会。</p></blockquote><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/d9c89c49-7eb2-4038-bce4-37b2a571da04.png" w="1080" h="237" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="1080" height="180" referrerpolicy="no-referrer"></p><p>这一数据集庞大的无标签数据量和广泛的语言覆盖率，对改进自监督模型有着很大的帮助。</p><p>而 Facebook 也希望能够帮助提高语音数据集的质量和鲁棒性，使训练语音转换神经网络更加可靠。</p><p>最终加速新的 NLP 系统的开发，使 AI 翻译的效果越来越好。</p><p>而数据集的名字，VoxPopuli 的直译“人民的心声”也表示了其原始数据的来源 ——</p><p>即源语音全都收集自 2009-2020 年欧洲议会的活动录音。</p><h2>来自 10 年欧会的语料库</h2><p>在欧洲议会的各自活动，如全体会议、委员会会议和其他活动上，发言者都会以不同的欧盟语言轮流发表演讲。</p><p>Facebook 就是从欧会官网上抓取了每个演讲的文字记录、演讲者信息、开始/结束时间戳。</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/3bf95b9a-802f-433b-85fb-6d275266f18e.png" w="1080" h="389" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="1080" height="295" referrerpolicy="no-referrer"></p><p>然后，将所有的原始演讲数据进行处理，大致分为以下 3 类：</p><p>共 40 万小时，23 种语言的无标签语音数据</p><p>每种语言都有 8 千到 2 万多的原始语音数据。</p><p>因此，Facebook 基于能量的语音激活检测（VAD）算法，将完整音频分割成 15-30 秒的短片段。</p><p>最终得到没有太多的数据不平衡，也不需要调整数据采样策略的数据集。</p><p>因此非常适合多语言模型的训练。</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/c55b4873-e7a0-4de1-96ce-6bb7de6df778.png" w="600" h="784" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="600" height="784" referrerpolicy="no-referrer"></p><p>而上表中除了无标签数据，也有转录的语音数据，这也就是第二种：</p><p>共 1800 小时，16 种语言的转录语音数据。</p><p>欧会官方的时间戳虽然可以用来在会议中定义演讲者，但常常会被截断，或混合前后演讲的片段，因此并不完全准确。</p><p>所以 Facebook 对全会话音频采用了声纹分割聚类（SD）。</p><p>这时的语音段落平均时长为 197 秒，再利用语音识别（ASR）系统，将其细分为 20 秒左右的短片段。</p><p>观察上表，可以看到最终得到的数据中，有包括各语言的持续时间、发言人数量、女性发言人百分比、标记数量等多种属性。</p><p>17300 小时的 15 种目标语言的口译语音数据：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/bd5ca3d7-075f-4e6f-846b-e44206a22a71.png" w="1080" h="484" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="1080" height="367" referrerpolicy="no-referrer"></p><p>每个原始语音都有相对应的同声传译，并互相关联。</p><p>但要使这个数据集可用，必须经过大量的预处理和过滤。</p><p>因此，Facebook 使用了语音识别（ASR）系统在句子层面上对齐源语音和目标语音。</p><h2>在域外环境的半监督学习下具有通用性</h2><p>那么这一数据集用起来到底怎么样？</p><p>首先，是使用包含了域外语言（out-of-domain out-of-language）的无监督预训练，进行少样本的语音识别：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/62a5b4cd-47d2-4dc8-b1ac-6d74d8da71ff.png" w="1080" h="460" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="1080" height="349" referrerpolicy="no-referrer"></p><p>可以从表中看到，VP-Mono5K 在 5 种 VoxPopuli 语言上，都优于 XLSR-Mono 和 XLSR-10。</p><p>而 VP-100K 则在 10 种语言中的 8 种上的都比 XLSR-10 的表现更好。</p><p>并且，虽然 XLSR-53 涵盖了 Zh 语言，但与 VP-100K（Large）在 Zh 上的表现相距甚远。</p><p>这表明 VP-100K 所学的语音表征具有高度的通用性。</p><p>然后是使用 VoxPopuli 数据集进行自我训练或弱监督的语言翻译（ST）和语音识别（ASR）：</p><p><img src="https://img.ithome.com/newsuploadfiles/2021/8/68859850-3765-48eb-926e-cbea318cbf07.png" w="1080" h="303" title="世界最大的多语言语音数据集现已开源：超 40 万小时，共 23 种语言" width="1080" height="230" referrerpolicy="no-referrer"></p><p>从表中可以看到，不管是对于域内语言还是域外语言，对 VoxPopuli 的自我训练在大多数时候都能够提高性能。</p><p>而在翻译上，也不用再增加昂贵的标签数据。</p><p>通过自我训练，就能够缩小端到端模型和级联模型之间的差距。</p><p>论文地址：</p><p>https://arxiv.org/abs/2101.00390</p><p>下载：</p><p>https://github.com/facebookresearch/voxpopuli</p><p>参考链接：</p><p>[1]https://www.reddit.com/r/MachineLearning/comments/owll7g/n_facebook_ai_releases_voxpopuli_a_largescale/</p><p>[2]https://www.marktechpost.com/2021/08/02/facebook-ai-releases-voxpopuli-a-large-scale-open-multilingual-speech-corpus-for-ai-translations-in-nlp-systems/</p>
          
</div>
            