
---
title: '_众所周知，视频不能 P_，GAN 模型：是吗？P 视频来了'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2022/1/f22e9301-cc51-4c87-b3a8-f9f2b15ea430.gif'
author: IT 之家
comments: false
date: Tue, 25 Jan 2022 09:37:52 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/1/f22e9301-cc51-4c87-b3a8-f9f2b15ea430.gif'
---

<div>   
<p data-vmark="d0b8">见过用 GAN 来 P 图，见过用 GAN P 视频吗？瞧，原本一直在面无表情地讲话的人，全程露出了微笑；原本得 4、50 岁的人，直接变 20 几岁了：</p><p data-vmark="3259"><img src="https://img.ithome.com/newsuploadfiles/2022/1/f22e9301-cc51-4c87-b3a8-f9f2b15ea430.gif" w="1079" h="199" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1079" height="151" referrerpolicy="no-referrer"></p><p data-vmark="84a1">另一边，正在微笑唱歌的“赫敏”一下子愤怒起来，还能换上一张几岁小孩的脸：</p><p data-vmark="08ae"><img src="https://img.ithome.com/newsuploadfiles/2022/1/2e698cb3-1e2c-4b4f-96eb-0ff43db29fe0.gif" w="1079" h="359" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1079" height="273" referrerpolicy="no-referrer"></p><p data-vmark="cedd">美国前总统也如此，4 种版本的面部状态信手拈来，甚至连性别都给 P 成女的了：</p><p data-vmark="e0a2"><img src="https://img.ithome.com/newsuploadfiles/2022/1/76801d95-fb16-47cc-ae07-81541838ef45.gif" w="1079" h="215" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1079" height="163" referrerpolicy="no-referrer"></p><p data-vmark="e756">不管人脸表情和状态如何变化，这些视频都没有给人任何违和感，全程如此的丝滑～哦对，除了真人，动漫视频里的脸也可以 P：</p><p data-vmark="f79f"><img src="https://img.ithome.com/newsuploadfiles/2022/1/d554de41-efb6-400b-a84b-0c2b5c0c04ef.gif" w="1079" h="348" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1079" height="264" referrerpolicy="no-referrer"></p><p data-vmark="97d6">有点厉害了。</p><h3 data-vmark="029f">基于 GAN 的视频面部编辑</h3><p data-vmark="7982">这个模型出自以色列特拉维夫大学。</p><p data-vmark="0b75"><img src="https://img.ithome.com/newsuploadfiles/2022/1/7f467ee3-2bab-4c8e-9fd1-9f5432d15e3f.png" w="1080" h="144" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1080" height="109" referrerpolicy="no-referrer"></p><p data-vmark="f095">众所周知，GAN 在其潜空间内编码丰富语义的能力，已经被广泛用于人脸编辑。不过将它用在视频中还是有点挑战性：一个是缺乏高质量数据集，一个是需要克服时间一致性 （temporal coherency）这一基本障碍。</p><p data-vmark="8236">不过研究人员认为，第二点这个障碍主要是人为的。因为原视频本具备时间一致性，编辑后的视频却变了，部分原因就是在 editing pipeline 中对一些组件（component）处理不当。而他们提出的这个视频人脸语义编辑框架，相对于当前技术水平做出了重大改进：只采用了标准的非时序 StyleGAN2，对 GAN editing pipeline 中的不同组件进行分析，确定哪些组件具备一致性，就用这些组件来操作。整个过程不涉及任何用来维持时间一致性的额外操作。具体流程一共分为六步：</p><p data-vmark="b559"><img src="https://img.ithome.com/newsuploadfiles/2022/1/bbe5297e-bded-49a8-bd9f-d2b6d4075cb8.png" w="1080" h="511" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1080" height="388" referrerpolicy="no-referrer"></p><p data-vmark="5977">1、输入视频首先被分割成帧，每帧中的人脸都被裁剪下来并对齐；</p><p data-vmark="cbe1">2、使用预训练的 e4e 编码器，将每张已裁剪的人脸反演到预训练的 StyleGAN2 的潜空间中；</p><p data-vmark="9149">3、在所有并行帧中使用 PTI（最新提出的一种视频人脸编辑方法）对生成器进行微调，纠正初始反演中的错误，恢复全局一致性；</p><p data-vmark="1524">4、所有帧通过使用固定的方向和步长，线性地操纵其轴心潜码（pivot latent codes）进行相应编辑；</p><p data-vmark="4837">5、再次微调生成器，将背景和编辑过的人脸“缝合”在一起；</p><p data-vmark="e19a">6、反转对齐步骤，并将修改后的人脸粘贴回视频中。</p><p data-vmark="e58a"><img src="https://img.ithome.com/newsuploadfiles/2022/1/d15686a6-4e44-4a55-8e01-a326c79bbbd0.png" w="978" h="618" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="978" height="518" referrerpolicy="no-referrer"></p><p data-vmark="39e9">△ 注意颈部曾产生了大量瑕疵，在最后一步完全修复好</p><h3 data-vmark="35ee">和 SOTA 模型对比</h3><p data-vmark="8fd2">这个模型效果到底有多好，来个对比就知道：</p><p data-vmark="3b76"><img src="https://img.ithome.com/newsuploadfiles/2022/1/74928704-8ead-44c5-a01c-b88a7ecb3460.gif" w="1079" h="150" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1079" height="114" referrerpolicy="no-referrer"></p><p data-vmark="f21d"><img src="https://img.ithome.com/newsuploadfiles/2022/1/6324b57b-f6a2-49e7-807b-ab1572c7db53.gif" w="1079" h="151" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1079" height="115" referrerpolicy="no-referrer"></p><p data-vmark="ef00"><img src="https://img.ithome.com/newsuploadfiles/2022/1/12de4e99-6f88-4bc5-884b-cd7caf56c3d5.gif" w="1080" h="240" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1080" height="182" referrerpolicy="no-referrer"></p><p data-vmark="7668">第一个是变年轻、第二、三个都是变老。可以明显看到目前的 SOTA 模型（Latent Transformer）和 PTI 模型中的人脸会“抽巴”，并出现一些伪影，而这个新模型就避开了这些问题。</p><p data-vmark="d72f">此外，研究人员还进行了时间一致性测试。指标包含两个：</p><p data-vmark="34be">局部时间一致性（TL-ID），通过现成的一致性检测网络来评估相邻两帧之间的一致性。TL-ID 分数越高，表明该方法产生的效果越平滑，没有明显的局部抖动。</p><p data-vmark="3f08">全局时间一致性（TG-ID），同样使用一致性检测网络来评估所有可能的帧（不一定相邻）之间的相似性。得分为 1 表示该方法成功保持了和原视频的时间一致性。</p><p data-vmark="c27f">结果如下：</p><p data-vmark="56ec"><img src="https://img.ithome.com/newsuploadfiles/2022/1/f7278471-b1cf-4121-8a63-e7c89ea8ed1a.png" w="532" h="184" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="532" height="184" referrerpolicy="no-referrer"></p><p data-vmark="6310">可以看到，这个新模型在两项指标中都略胜一筹。</p><p data-vmark="18b2">最后，代码将于 2 月 14 号发布，感兴趣的朋友可以蹲一蹲了～</p><p data-vmark="d7e4"><img src="https://img.ithome.com/newsuploadfiles/2022/1/77bbd55f-f7d1-47e2-9641-e8a5e447bcda.png" w="1080" h="446" title="“众所周知，视频不能 P”，GAN 模型：是吗？P 视频来了" width="1080" height="339" referrerpolicy="no-referrer"></p><p data-vmark="753f">论文地址：</p><p data-vmark="0565"><span class="link-text-start-with-http">https://arxiv.org/abs/2201.08361</span></p><p data-vmark="ac4c">项目主页：</p><p data-vmark="78ca"><span class="link-text-start-with-http">https://stitch-time.github.io/</span></p>
          
</div>
            