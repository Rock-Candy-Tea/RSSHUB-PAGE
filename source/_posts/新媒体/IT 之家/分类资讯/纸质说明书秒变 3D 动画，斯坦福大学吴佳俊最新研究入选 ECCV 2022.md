
---
title: '纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2022/7/b2687fb4-cad4-4b6b-8684-915a61ce503e.png'
author: IT 之家
comments: false
date: Sat, 30 Jul 2022 06:40:30 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2022/7/b2687fb4-cad4-4b6b-8684-915a61ce503e.png'
---

<div>   
<p data-vmark="5d9a">有没有空间感差的小伙伴，每次拿到乐高说明书都不知如何下手？</p><p style="text-align: center;" data-vmark="de7b"><img src="https://img.ithome.com/newsuploadfiles/2022/7/b2687fb4-cad4-4b6b-8684-915a61ce503e.png" w="230" h="220" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="230" height="220" referrerpolicy="no-referrer"></p><p data-vmark="75a6">这回，可以动的乐高说明书来了！</p><p data-vmark="a9e2">清华姚班校友、斯坦福大学助理教授吴佳俊，<span class="accentTextColor">带领团队研发了一项能把纸上的说明书转化为 3D 动画的技术，目前该论文已入选 2022 年计算机视觉顶会 ECCV。</span></p><p style="text-align: center;" data-vmark="72da"><img src="https://img.ithome.com/newsuploadfiles/2022/7/ddd5ef71-ec52-40eb-9ffe-2c00e0609c9b.gif" w="1078" h="645" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1078" height="491" referrerpolicy="no-referrer"></p><p style="text-align: center;" data-vmark="d2f8"><img src="https://img.ithome.com/newsuploadfiles/2022/7/bb35199c-9f4a-4e38-ae5c-6bc3b65a39ac.png" w="1080" h="220" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1080" height="167" referrerpolicy="no-referrer"></p><p data-vmark="3230">看完效果图，有网友直呼：这对所有年龄段的乐高爱好者都大有帮助！</p><p style="text-align: center;" data-vmark="038c"><img src="https://img.ithome.com/newsuploadfiles/2022/7/c38e7748-9d12-4216-8244-d5ded560ea9d.png" w="790" h="352" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="790" height="352" referrerpolicy="no-referrer"></p><h3 data-vmark="bc8d">3D 动画说明书</h3><p data-vmark="1167">尽管乐高的说明书都是由专业设计师编写的，但对于想象力差的人，不得不说，还是 3D 动画更香。</p><p style="text-align: center;" data-vmark="0fc9"><img src="https://img.ithome.com/newsuploadfiles/2022/7/15fd6e3f-d40c-41ca-a2d6-3cc08941f289.gif" w="1079" h="598" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1079" height="454" referrerpolicy="no-referrer"></p><p data-vmark="a138">这一步转化看上去容易，其实背后隐藏着两个技术上的难题。</p><p data-vmark="f8b6">第一个难题是如何将纸上的 2D 图像投影成 3D 动画。</p><p data-vmark="663d">研究团队要做的，是将任务分解为一系列可以顺利、高效执行的短步骤，通过建立一个模型，将说明书上的图像转换为机器可解释的算法，以简化机器学习的任务。</p><p style="text-align: center;" data-vmark="81e1"><img src="https://img.ithome.com/newsuploadfiles/2022/7/d21156b1-899e-40fe-ad5b-e7d028f27e73.png" w="1080" h="429" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1080" height="326" referrerpolicy="no-referrer"></p><p data-vmark="20aa">正如上图所示，要想把图 a 转化为图 c，需要提取说明书中的每一个零件的图像位置，以便搭建最终的成品。</p><p data-vmark="6d07">研究面对的第二个挑战是，乐高积木的形状实在是太多变了。虽然很多基础配件形状差不多，但就像图中的吉他头一样，乐高也有不少灵活又复杂的配件。而且，这些配件可能产生的不同组合也大大增加了机器解读的难度：每一个搭建步骤都会形成一个新的不可知的图像。</p><p style="text-align: center;" data-vmark="55bc"><img src="https://img.ithome.com/newsuploadfiles/2022/7/9f7061b3-1438-4744-9bf6-45b0ce8d5c63.png" w="1080" h="566" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1080" height="430" referrerpolicy="no-referrer"></p><p data-vmark="dfa0">为了解决这两个挑战，研究团队提出了一种新的基于机器学习的框架：手动执行计划网络 (manual-To-executable-Plan Network, MEPNet)。其核心思想是将基于神经网络的二维关键点检测方法与 2D-3D 匹配算法相结合，实现对不可见的 3D 对象的高精度预测。</p><p style="text-align: center;" data-vmark="0a83"><img src="https://img.ithome.com/newsuploadfiles/2022/7/de2e1347-4247-4898-98b2-92ae7ebfe8dc.png" w="1080" h="535" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1080" height="406" referrerpolicy="no-referrer"></p><p data-vmark="9d71">MEPNet 的运行有两个阶段。第一阶段要做的，是将基础形状和新零件的 3D 模型、目标形状的 2D 图像作为输入信息，为每个零件预测一组 2D 关键点、旋转角度和掩码。在第二阶段中，通过寻找基础形状和新零件之间的可能联系，再将第一阶段预测的 2D 关键点反向投影到 3D 图像中。</p><p data-vmark="331c">值得一提的是，这个方法在训练时不需要任何 ground truth 图像。</p><p data-vmark="9ac6">另外，MEPNet 的数据集表现优于其他现有方法。与基于端到端的学习方法相比，MEPNet 保持了基于机器学习的模型效率，并可以被更好地推广到生成未知的 3D 对象上。</p><p data-vmark="efb0">最值得注意的是，MEPNet 能够利用合成数据进行单独训练，从而应用到真实的生活场景中。</p><p style="text-align: center;" data-vmark="743a"><img src="https://img.ithome.com/newsuploadfiles/2022/7/28eda3eb-7696-4bfa-94c8-724ea2ef480b.png" w="1080" h="426" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="1080" height="323" referrerpolicy="no-referrer"></p><p data-vmark="5e6c">目前，所有代码和数据已开源，感兴趣的小伙伴可以关注一下。</p><h3 data-vmark="3a1e">作者介绍</h3><p data-vmark="10fb">该篇论文来自斯坦福大学吴佳俊团队。作者还包括：Ruocheng Wang、Yunzhi Zhang，麻省理工大学的 Jiayuan Mao 以及 Autodesk AI Lab 的 Chin-Yi Cheng。</p><p data-vmark="2800">吴佳俊，现任斯坦福大学助理教授，隶属于斯坦福视觉与学习实验室 (SVL) 和斯坦福人工智能实验室 (SAIL)。在麻省理工学院完成博士学位，本科毕业于清华大学姚班，曾被誉为“清华十大学神之一”。</p><p style="text-align: center;" data-vmark="d07b"><img src="https://img.ithome.com/newsuploadfiles/2022/7/737a9d44-0722-4d0b-8cce-b47504a287b9.png" w="388" h="394" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="388" height="394" referrerpolicy="no-referrer"></p><p data-vmark="6af1">论文第一作者 Ruocheng Wang，硕士毕业于斯坦福大学计算机科学专业，是吴佳俊门下的学生。本科毕业于浙江大学计算机专业，还在加州大学洛杉矶分校与 Adnan Darwiche 教授一起工作过一段时间。</p><p style="text-align: center;" data-vmark="0d5b"><img src="https://img.ithome.com/newsuploadfiles/2022/7/95d35beb-3ed0-4c1c-8520-045b3d90127e.jpg" w="400" h="400" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="400" height="400" referrerpolicy="no-referrer"></p><h3 data-vmark="a30b">One More Thing</h3><p data-vmark="c598">虽然整篇论文都在以乐高为例，但作者也在论文中提到，其实这项技术还能应用到其他类型的组装说明书上。好多“苦安装久矣”的网友就号召赶紧推出宜家版：</p><p style="text-align: center;" data-vmark="7c79"><img src="https://img.ithome.com/newsuploadfiles/2022/7/000787bc-4106-4434-9e93-3b6116cbc391.png" w="492" h="268" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="492" height="268" referrerpolicy="no-referrer"></p><p data-vmark="2c15">不过，在一片欢呼声中，也有网友提出了不同的声音：我不知道这是惊喜还是毁了我玩乐高的乐趣。</p><p style="text-align: center;" data-vmark="f160"><img src="https://img.ithome.com/newsuploadfiles/2022/7/4dcfdf86-3dd0-4658-ad06-89f21d5ead84.png" w="882" h="344" title="纸质说明书秒变 3D 动画，斯坦福大学吴佳俊最新研究入选 ECCV 2022" width="882" height="320" referrerpolicy="no-referrer"></p><p data-vmark="6271">对此，你怎么看？你是喜欢看着说明书拼乐高，还是自己发挥呢？</p><p data-vmark="17f4">参考链接：</p><p data-vmark="4599">[1]<span class="link-text-start-with-http">https://cs.stanford.edu/~rcwang/projects/lego_manual/</span></p><p data-vmark="fc44">[2]<span class="link-text-start-with-http">https://twitter.com/_akhaliq/status/1552118469214314496</span></p><p data-vmark="2bd0">[3]<span class="link-text-start-with-http">https://arxiv.org/abs/2207.12572</span></p><p data-vmark="85a1">[4]<span class="link-text-start-with-http">https://jiajunwu.com/</span></p>
          
</div>
            