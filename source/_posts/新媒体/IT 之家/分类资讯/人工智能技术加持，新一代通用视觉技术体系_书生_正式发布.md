
---
title: '人工智能技术加持，新一代通用视觉技术体系_书生_正式发布'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/11/962da873-e121-4107-af52-df8940cd2232.png'
author: IT 之家
comments: false
date: Thu, 18 Nov 2021 01:19:13 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/11/962da873-e121-4107-af52-df8940cd2232.png'
---

<div>   
<p data-vmark="f46e"><a class="s_tag" href="https://www.ithome.com/" target="_blank">IT之家</a> 11 月 18 日消息，昨日，上海人工智能实验室联合商汤科技 SenseTime、香港中文大学、上海交通大学<span class="accentTextColor">共同发布新一代通用视觉技术体系“书生”（INTERN）</span>，该体系旨在系统化解决当下人工智能视觉领域中存在的任务通用、场景泛化和数据效率等一系列瓶颈问题。</p><p data-vmark="b41d"><img src="https://img.ithome.com/newsuploadfiles/2021/11/962da873-e121-4107-af52-df8940cd2232.png" w="1080" h="493" alt="图片" title="人工智能技术加持，新一代通用视觉技术体系“书生”正式发布" width="1080" height="374" referrerpolicy="no-referrer"></p><p data-vmark="1ef9">▲ 图源：上海人工智能实验室</p><p data-vmark="49f0">目前，技术报告《INTERN: A New Learning Paradigm Towards General Vision》已在 arXiv 平台发布，基于“书生”的通用视觉开源平台 OpenGVLab 也将在明年年初正式开源，向学术界和产业界公开预训练模型及其使用范式、数据系统和评测基准等。</p><p data-vmark="166c">根据相关技术报告，一个“书生”基模型即可全面覆盖分类、目标检测、语义分割、深度估计四大视觉核心任务。</p><p data-vmark="be59">上海人工智能实验室表示，相较于当前最强开源模型（OpenAI 于 2021 年发布的 CLIP），“书生”在准确率和数据使用效率上均取得大幅提升。具体而言，基于同样的下游场景数据，“书生”在分类、目标检测、语义分割及深度估计四大任务 26 个数据集上的平均错误率分别降低了 40.2%、47.3%、34.8% 和 9.4%。</p><p data-vmark="b564">IT之家了解到，通用视觉技术体系“书生”（INTERN）由七大模块组成，包括通用视觉数据系统、通用视觉网络结构、通用视觉评测基准三个基础设施模块，以及区分上下游的四个训练阶段模块。</p>
          
</div>
            