
---
title: '用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开'
categories: 
 - 新媒体
 - IT 之家
 - 分类资讯
headimg: 'https://img.ithome.com/newsuploadfiles/2021/10/d7a028ef-de86-4cad-a325-c8c2ed69cc3d.png'
author: IT 之家
comments: false
date: Fri, 01 Oct 2021 05:37:33 GMT
thumbnail: 'https://img.ithome.com/newsuploadfiles/2021/10/d7a028ef-de86-4cad-a325-c8c2ed69cc3d.png'
---

<div>   
<p data-vmark="c725">用 AI 搞视频编解码器，现在路子有点“野”。</p><p data-vmark="1c1f">插帧、过拟合、语义感知、GAN…… 你想过这些“脑洞”或 AI 算法，也能被用到编解码器上面吗？</p><p data-vmark="1578">例如，原本的算法每帧压缩到 16.4KB 后，树林开始变得无比模糊：</p><p data-vmark="9754"><img src="https://img.ithome.com/newsuploadfiles/2021/10/d7a028ef-de86-4cad-a325-c8c2ed69cc3d.png" w="1080" h="400" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="304" referrerpolicy="no-referrer"></p><p data-vmark="97f6">但在用上 GAN 后，不仅画面更清晰，每帧图像还更小了，只需要 14.5KB 就能搞定！</p><p data-vmark="8df3"><img src="https://img.ithome.com/newsuploadfiles/2021/10/a763680e-5c1c-4464-b2e5-e19b886b2777.png" w="1080" h="382" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="290" referrerpolicy="no-referrer"></p><p data-vmark="babb">又例如，用插帧的思路结合神经编解码器，能让最新压缩算法效果更好……</p><p data-vmark="c2b2">这一系列算法的思路，背后究竟是什么原理，用 AI 搞编解码器，潜力究竟有多大？</p><p data-vmark="a469">我们采访了高通工程技术副总裁、高通 AI 研究方向负责人侯纪磊博士，了解了高通一些 AI 编解码器中的算法细节和原理。</p><h2 data-vmark="b5cf">编解码器标准逐渐“内卷”</h2><p data-vmark="37a2">当然，在了解 AI 算法的原理之前，需要先了解视频到底是怎么压缩的。</p><p data-vmark="ad3b">如果不压缩，1 秒 30 帧、8bit 单通道色深的 480p 视频，每秒就要传输 80+Mbps 数据，想在网上实时看高清视频的话，几乎是不可能的事情。</p><p data-vmark="01be">目前，主要有色度子采样、帧内预测（空间冗余）和帧间预测（时间冗余）几个维度的压缩方法。</p><p data-vmark="b36e">色度子采样，主要是基于我们眼睛对亮度比对颜色更敏感的原理，压缩图像的色彩数据，但视觉上仍然能保持与原图接近的效果。</p><p data-vmark="f25a"><img src="https://img.ithome.com/newsuploadfiles/2021/10/f2adf660-fc33-487b-b1c7-415b0797fc8b.png" w="1080" h="616" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="468" referrerpolicy="no-referrer"></p><p data-vmark="72a1">帧内预测，利用同一帧中的大片相同色块（下图地板等），预测图像内相邻像素的值，得出的结果比原始数据更容易压缩。</p><p data-vmark="5690"><img src="https://img.ithome.com/newsuploadfiles/2021/10/5d28b37b-cda7-43e3-b91b-f02e304f4832.png" w="1080" h="608" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="462" referrerpolicy="no-referrer"></p><p data-vmark="7ced">帧间预测，用来消除相邻帧之间大量重复数据（下图的背景）的方法。利用一种名叫运动补偿的方法，用运动向量（motion vector）和预测值计算两帧之间像素差：</p><p data-vmark="fd12"><img src="https://img.ithome.com/newsuploadfiles/2021/10/96a8560a-9a80-4b4b-a6cf-f53e32a9c610.png" w="1080" h="557" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="423" referrerpolicy="no-referrer"></p><p data-vmark="af18">这些视频压缩的方法，具体到视频编解码器上，又有不少压缩工作可以进行，包括分区、量化、熵编码等。</p><p data-vmark="3888">然而，据侯纪磊博士介绍，从 H.265 到 H.266，压缩性能虽然提升了 30% 左右，但这是伴随着编码复杂度提高 30 倍、解码复杂度提高 2 倍达成的。</p><p data-vmark="6e9b">这意味着编解码器标准逐渐进入了一个“内卷”的状态，提升的压缩效果，本质上是用编解码器复杂度来交换的，并不算真正完成了创新。</p><p data-vmark="fd04">因此，高通从已有压缩方法本身的原理、以及编解码器的构造入手，搞出了几种有意思的 AI 视频编解码方法。</p><h2 data-vmark="621f">3 个方向提升压缩性能</h2><p data-vmark="fbdb">具体来说，目前的 AI 研究包括帧间预测方法、降低解码复杂度和提高压缩质量三个方向。</p><p data-vmark="6eda"><strong>“预判了 B 帧的预判”</strong></p><p data-vmark="2907">从帧间预测来看，高通针对 B 帧编解码提出了一种新思路，论文已经登上 ICCV 2021。</p><p data-vmark="a0e4">I 帧：帧内编码帧（intra picture）、P 帧：前向预测编码帧（predictive-frame）、B 帧：双向预测内插编码帧（bi-directional interpolated prediction frame）</p><p data-vmark="c9e0"><img src="https://img.ithome.com/newsuploadfiles/2021/10/ce01140e-4a5e-4cab-9338-ed35fe581457.png" w="1080" h="321" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="244" referrerpolicy="no-referrer"></p><p data-vmark="0844">目前的编解码大多集中在 I 帧（帧内预测）和 P 帧上，而 B 帧则是同时利用 I 帧和 P 帧的双向运动补偿来提升压缩的性能，在 H.265 中正式支持（H.264 没有）。</p><p data-vmark="658e">虽然用上 B 帧后，视频压缩性能更好，但还是有两个问题：</p><p data-vmark="5623">一个是视频需要提前加载（必须提前编码后面的 P 帧，才能得到 B 帧）；另一个是仍然会存在冗余，如果 I 帧和 P 帧高度相关，那么再用双向运动补偿就显得很浪费。</p><p data-vmark="edaf">打个比方，如果从 I 帧→B 帧→P 帧，视频中只有一个球直线运动了一段距离，那么再用双向运动补偿的话，就会很浪费：</p><p data-vmark="069e"><img src="https://img.ithome.com/newsuploadfiles/2021/10/3de4fa65-e722-4624-97c0-63aeb0c7d40a.png" w="1080" h="159" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="121" referrerpolicy="no-referrer"></p><p data-vmark="b0c7">这种情况下，用插帧似乎更好，直接通过时间戳就能预测出物体运动的状态，编码计算量也更低。</p><p data-vmark="a2d4">但这又会出现新的问题：如果 I 帧和 P 帧之间有个非常大的突变，例如球突然在 B 帧弹起来了，这时候用插帧的效果就很差了（相当于直接忽略了 B 帧的弹跳）。</p><p data-vmark="8ffa">因此，高通选择将两者结合起来，将基于神经网络的 P 帧压缩和插帧补偿结合起来，利用 AI 预测插帧后需要进行的运动补偿：</p><p data-vmark="a0a1"><img src="https://img.ithome.com/newsuploadfiles/2021/10/c22f234f-c123-467f-86e1-3d34e92c49c2.png" w="1080" h="541" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="411" referrerpolicy="no-referrer"></p><p data-vmark="c3e2">别说，效果还确实不错，比谷歌之前在 CVPR 2020 上保持的 SOTA 纪录更好，也要好于当前基于 H.265 标准实现开源编解码器的压缩性能。</p><p data-vmark="ce94"><img src="https://img.ithome.com/newsuploadfiles/2021/10/87562cba-9cf6-4b6a-8f2b-80e254305acd.png" w="1080" h="446" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="339" referrerpolicy="no-referrer"></p><p data-vmark="f4b1">除此之外，高通也尝试了一些其他的 AI 算法。</p><p data-vmark="da04"><strong>用“过拟合”降低解码复杂度</strong></p><p data-vmark="627c">针对编解码器标准内卷的情况，高通也想到了用 AI 做自适应算法，来像“过拟合”一样根据视频比特流更新一个模型的权重增量，已经有相关论文登上 ICLR 2021。</p><p data-vmark="67fd"><img src="https://img.ithome.com/newsuploadfiles/2021/10/16154e47-5412-489c-96c8-9ba7ed903058.png" w="1080" h="346" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="263" referrerpolicy="no-referrer"></p><p data-vmark="a302">这种方法意味着针对单个模型进行“过拟合”，对比特流中的权重增量进行编码，再与原来的比特流进行一个比较。如果效果更好的话，就采用这种传输方式。</p><p data-vmark="8a86"><img src="https://img.ithome.com/newsuploadfiles/2021/10/719f617f-396e-4c64-a301-fee99b288e35.png" w="1080" h="555" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="421" referrerpolicy="no-referrer"></p><p data-vmark="083e">事实证明，在不降低压缩性能的情况下，这种方法能将解码复杂度降低 72%，同时仍然保持之前 B 帧模型达到的 SOTA 结果。</p><p data-vmark="102e">当然，除了视频压缩性能以外，单帧图像被压缩的质量也需要考虑，毕竟视觉效果也是视频压缩追求的标准之一。</p><p data-vmark="eb96"><strong>用语义感知和 GAN 提高压缩质量</strong></p><p data-vmark="ced0">用语义感知和 GAN 的思路就比较简单了。</p><p data-vmark="7865">语义感知就是让 AI 基于人的视觉来考虑，选出你在看视频时最关注的地方，并着重那部分的比特分配情况。</p><p data-vmark="f903">例如你在看网球比赛时，往往并不会关注比赛旁边的观众长什么样、风景如何，而是更关注球员本身的动作、击球方法等。</p><p data-vmark="efdd">那么，就训练 AI，将更多的比特放到目标人物身上就行，像这样：</p><p data-vmark="5d8e"><img src="https://img.ithome.com/newsuploadfiles/2021/10/2f38772b-0049-4983-8298-aad7a53cddbc.png" w="1080" h="487" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="370" referrerpolicy="no-referrer"></p><p data-vmark="a397">从结构上来讲也比较简单，也就是我们常见的语义分割 Mask（掩膜）：</p><p data-vmark="07ac"><img src="https://img.ithome.com/newsuploadfiles/2021/10/55162af1-37c0-43a6-a89b-2ce13296d4b1.png" w="1080" h="864" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="656" referrerpolicy="no-referrer"></p><p data-vmark="f360">这种方法能很好地将受关注的局部区域帧质量提升，让我们有更好的观看效果，而不是在视频被压缩时，看到的整幅图像都是“打上马赛克”的样子。</p><p data-vmark="a436"><img src="https://img.ithome.com/newsuploadfiles/2021/10/bf28e0ef-c26a-4b42-8a55-27d6ba9942b7.png" w="716" h="682" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="716" height="682" referrerpolicy="no-referrer"></p><p data-vmark="6853">据高通表示，这种语义感知的图像压缩，目前已经在扩展到视频压缩上了，同样是关注局部的方法，效果也非常不错。</p><p data-vmark="29a6">而基于 GAN 的方法，则更加致力于用更少的比特数生成视觉效果同样好的图像质量：</p><p data-vmark="053c"><img src="https://img.ithome.com/newsuploadfiles/2021/10/5413f071-5aa1-41c0-acb4-ab9d73a12dff.png" w="1080" h="433" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="329" referrerpolicy="no-referrer"></p><p data-vmark="4773">据高通表示，数据集来自 CVPR 中一个针对图像压缩的 Workshop CLIC，提供了大约 1600 张的高清图片，利用自研的模型，能在上面训练出很好的效果：</p><p data-vmark="5c28"><img src="https://img.ithome.com/newsuploadfiles/2021/10/7eecd9c9-44bc-4c44-a594-2b1c0cbc426a.png" w="1080" h="457" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="347" referrerpolicy="no-referrer"></p><p data-vmark="01f5">也就是开头的图片效果，即使在大小被压缩后，基于 GAN 的图像还是能取得更好的视觉质量：</p><p data-vmark="502c"><img src="https://img.ithome.com/newsuploadfiles/2021/10/c8186b72-d647-49ba-a277-5feca89ad845.png" w="1080" h="599" title="用 AI 打破编解码器内卷，高通最新顶会论文脑洞大开" width="1080" height="455" referrerpolicy="no-referrer"></p><p data-vmark="b990">期待这些技术能马上应用到手机等设备上，让我们看视频的时候真正变得不卡。</p><p data-vmark="0117">相关论文：</p><p data-vmark="704c">[1]https://arxiv.org/abs/2104.00531</p><p data-vmark="ea41">[2]https://arxiv.org/abs/2101.08687</p><p data-vmark="819e">参考链接：</p><p data-vmark="e49b">[1]https://www.qualcomm.com/news/onq/2021/07/14/how-ai-research-enabling-next-gen-codecs</p><p data-vmark="7162">[2]https://github.com/leandromoreira/digital_video_introduction</p>
          
</div>
            