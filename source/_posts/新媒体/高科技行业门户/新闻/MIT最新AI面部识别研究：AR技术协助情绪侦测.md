
---
title: 'MIT最新AI面部识别研究：AR技术协助情绪侦测'
categories: 
 - 新媒体
 - 高科技行业门户
 - 新闻
headimg: 'https://picsum.photos/400/300?random=3175'
author: 高科技行业门户
comments: false
date: Fri, 24 Jun 2022 05:42:00 GMT
thumbnail: 'https://picsum.photos/400/300?random=3175'
---

<div>   
<p style="text-indent: 2em; text-align: left;"><strong>“</strong><strong>自闭症成人的感知神经连接可能是“嘈杂的”（noisy）或低效的。</strong><strong>”</strong></p><p style="text-indent: 2em; text-align: left;">作者：Claire编辑：tuya出品：财经涂鸦（ID：caijingtuya）</p><p style="text-indent: 2em; text-align: left;"><span style="text-indent: 2em;">对大部分健康的人来说，识别人脸上表达的情绪很容易。微笑可能意味着幸福，而皱眉可能意味着愤怒，但自闭症患者在完成这项任务时有很大的困难。来自麻省理工学院的一支研究团队，训练出一个人工神经网络来处理面部情绪识别信息，以帮助自闭症患者更好地识别人们脸上表达的情绪。</span></p><p style="text-indent: 2em; text-align: left;">6月15日，麻省理工学院教授脑研究所教授Kohitij Kar在《神经科学杂志》（The Journal of Neuroscience）上发表了一项名为“自闭症非典型面部情绪处理的行为和神经标记的计算探索”（A computational probe into the behavioral and neural markers of atypical facial emotion processing in autism）的新研究。该研究利用<span class="hrefStyle"><a href="https://www.ofweek.com/ai/" target="_blank" title="人工智能">人工智能</a></span>在头脑中建模计算，揭示了大脑的内部工作机制。</p><p style="text-indent: 2em; text-align: left;">在过去的一项实验中，研究人员向自闭症成年人和由神经功能正常的被试者组成的对照组，展示了一系列面部图像。这些图像由软件生成，在一个从恐惧到快乐的范围内变化，参与者需要迅速判断这些面孔是否描绘了快乐。与对照组相比，<strong style="max-width: 100%; outline: 0px; letter-spacing: 0.544px; background-color: rgb(255, 255, 255); overflow-wrap: break-word !important; box-sizing: border-box !important;">患有自闭症的成年人需要看到面部表现出更高程度快乐的图像，才能识别出快乐这一特征</strong>。</p><p style="text-indent: 2em; text-align: left;">Kar受到这项实验的启发，训练了一个人工神经网络，这是一种受大脑结构启发的复杂数学函数，来完成同样的任务，即确定人脸图像是否令人高兴。Kar的研究结果表明，自闭症成人的感知神经连接可能是“嘈杂的”（noisy）或低效的。</p><p style="text-indent: 2em; text-align: left;">Kar认为这些视觉处理的计算模型在未来可能有多种用途。“我认为面部情感识别只是冰山一角。”，<strong style="max-width: 100%; outline: 0px; letter-spacing: 0.544px; background-color: rgb(255, 255, 255); overflow-wrap: break-word !important; box-sizing: border-box !important;">他认为这些视觉处理模型也可以用来选择、甚至生成诊断内容</strong>。例如，人工智能可用于生成电影和教育材料等内容，以最大限度地吸引自闭症儿童和成人。</p><p style="text-indent: 2em; text-align: left;">根据这项研究，<strong style="max-width: 100%; outline: 0px; letter-spacing: 0.544px; background-color: rgb(255, 255, 255); overflow-wrap: break-word !important; box-sizing: border-box !important;">这些计算模型有可能被用来帮助调整增强现实（AR）眼镜中的面部和其他相关像素</strong>（pixels），以改变自闭症患者看到的东西，例如通过夸大人们脸上的快乐或其他情绪的水平，以帮助自闭症患者更好地识别。</p><p style="text-indent: 2em; text-align: left;">即使是在更简单的形式中，安装了面部情绪识别软件的AR眼镜也可以检测到人们的情绪，并覆盖文本提示来帮助佩戴眼镜的自闭症患者，以便向他们描述与他们互动的人可能的情绪状态。</p><p>       <span style="color:#999999;font-family:  微软雅黑;font-size:14px;">原文标题 : MIT最新AI面部识别研究：AR技术协助情绪侦测</span></p> 
  
</div>
            