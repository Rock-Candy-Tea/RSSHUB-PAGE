
---
title: '中国厂商跨界自研芯片的困局'
categories: 
 - 新媒体
 - 高科技行业门户
 - 新闻
headimg: 'https://picsum.photos/400/300?random=7587'
author: 高科技行业门户
comments: false
date: Mon, 25 Jul 2022 03:00:00 GMT
thumbnail: 'https://picsum.photos/400/300?random=7587'
---

<div>   
<article><p style="text-indent: 2em; text-align: left;">近些年，随着数据量暴涨，以及业务形式的多样化，特别是各种创新业务模式的推出，各家互联网大厂都遇到了同样的难题：买不到适用的服务器处理器及相关芯片。最早遇到这类问题的是谷歌（Google），为了解决应用需求，该公司不得不建立了自己的芯片研发团队，专门为自家的设备定制处理器，大名鼎鼎的TPU就是这样诞生的。</p><p style="text-indent: 2em; text-align: left;">作为全球第二大互联网市场，中国也遇到了当初Google遇到的问题，无论是阿里，还是腾讯，都开启了芯片自研之路。</p><p style="text-indent: 2em; text-align: left;"><strong>如今，同样的问题落在了字节跳动身上。</strong></p><p style="text-indent: 2em; text-align: left;">本周，字节跳动确认了一则传闻：为了满足该公司旗下TikTok的应用需求，字节跳动已计划聘用专家，为其数据中心开发SoC，以处理某些特定的工作负载。字节跳动已在其网站上发布了31个与芯片相关的职位，以组成团队与芯片开发商合作。至此，字节跳动正式开启自研芯片之路。</p><p style="text-indent: 2em; text-align: left;">字节跳动副总裁杨震原表示，除了采购x86架构CPU，该公司也会与芯片供应商探索RISC架构芯片在云端的应用。字节跳动的自研芯片探索将主要围绕自身的视频推荐业务展开，为大规模推荐服务场景定制硬件优化方案，比如视频编解码，云端推理加速等，以提升效率、降低成本。</p><p style="text-indent: 2em; text-align: left;">也就是说，传统x86架构CPU已经不能满足TikTok的视频推荐业务，因为这种业务具有很强的创新性，这也是TikTok很快风靡全球的主要原因。从我们普通抖音用户的实际体验也可以感受到，不用去找，抖音会根据用户的个人喜好，主动推荐相应的短视频，以形成非常强的用户粘性。虽然传统CPU具有AI推理能力，但其在海量大数据面前，信息处理速度慢的短板暴露无遗，这就需要具备快速处理大数据，且AI智能化水平比较高的处理器，再加上TikTok的视频属性，还需要有很好的视频编解码能力。放眼当下全球芯片厂商，能够完全满足这些条件的处理器SoC，还没有看到。当然，传统芯片厂商也并非无所作为，几年前，以英伟达、赛灵思为代表的厂商就已经开始了这方面的研发工作，这些年火爆的DPU（Data Processing Unit）和智能网卡，很大程度上就是为了满足这类的大数据处理和AI智能化需求，但这些努力还在进行当中，要想完全满足各大互联网厂商的需求，还需要时间去打磨。正是在这样的背景下，字节跳动开启了自研芯片之路。</p><p style="text-indent: 2em; text-align: left;"><strong>先驱Google</strong></p><p style="text-indent: 2em; text-align: left;">前文提到，在互联网大厂中，最先遇到处理器瓶颈，并自研相关芯片的就是Google，研发的产品名为TPU（Tensor Processing Unit，张量处理器），这是一种专用<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-%E9%9B%86%E6%88%90%E7%94%B5%E8%B7%AF.HTM" target="_blank" title="集成电路">集成电路</a></span>（ASIC），是专门为Google的TensorFlow框架（一个符号数学库，用于机器学习应用程序，如神经网络）设计的，用于加速机器学习。从2015年开始，Google就已经在内部使用TPU，主要为其云基础架构服务，据悉，在Google相册中，单个TPU每天可以处理超过1亿张照片。与<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-GPU.HTM" target="_blank" title="GPU">GPU</a></span>不同，TPU主要用于进行大量的低精度计算（如8位精度），每焦耳功耗下的输入／输出操作更多。当然，除了TPU，Google也会采用传统的<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-CPU.HTM" target="_blank" title="CPU">CPU</a></span>和GPU，用于其它类型的机器学习处理。</p><p style="text-indent: 2em; text-align: left;">目前，TPU已经发展到了第四代，算力不断提升。</p><p style="text-indent: 2em; text-align: left;">在视频处理方面，Google也遇到了问题，那就是传统的<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-%E8%8B%B1%E7%89%B9%E5%B0%94.HTM" target="_blank" title="英特尔">英特尔</a></span>通用CPU数据处理能力已经难以满足YouTube上海量视频的处理要求，对此，Google专门自研了Argos视频编码器（VCU），据悉，它的视频处理能力非常高效，取代了数千万个英特尔CPU。在需要处理海量数据的时候，相对于传统CPU，专用ASIC优势非常明显，VCU就是这样的ASIC。</p><p style="text-indent: 2em; text-align: left;">在YouTube上，每分钟内，用户会以各种格式上传超过500小时的视频内容，Google需要快速将内容转码为多种分辨率（包括144p，240p，360p，480p，720p，1080p，1440p，2160p和4320p）和高效格式（例如H．264，VP9或AV1），这需要强大的编码能力。</p><p style="text-indent: 2em; text-align: left;">传统上，对于视频的转码／编码，Google有两种选择：一是英特尔的视觉计算加速器（VCA），它将三个Xeon（至强）E3 CPU、内置Iris Pro P6300 ／ P580 GT4e的集成GPU，以及硬件编码器集成在了一起；二是使用软件编码和英特尔Xeon<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-%E5%A4%84%E7%90%86%E5%99%A8.HTM" target="_blank" title="处理器">处理器</a></span>。</p><p style="text-indent: 2em; text-align: left;">Google认为，对于不断壮大的YouTube工作负载来说，以上这两种选择都不够节能，且数据中心需要占用更多空间，于是自研了VCU。</p><p style="text-indent: 2em; text-align: left;">第一代Argos VCU并没有完全取代英特尔CPU，因为服务器仍然需要运行操作系统并管理存储驱动器和网络连接。VCU类似于一个GPU，需要一个CPU配合工作。</p><p style="text-indent: 2em; text-align: left;">除了内部设计的编码／转码器外，VCU的大多数IP都是从第三方获得的，以降低开发成本。VCU将尽可能多的高性能编码／转码器集成在一个芯片上（同时保持高能效）。Google将两个VCU放在一块板上，每个双插槽英特尔Xeon服务器安装10张卡，这大大提高了每个机架的解码／转码性能。</p><p style="text-indent: 2em; text-align: left;">Google表示，与采用英特尔Skylake处理器的服务器系统相比，基于VCU的设备在性能／TCO（系统总体拥有成本）计算效率方面提高了7倍（H．264）和33倍（VP9），这里考虑到了VCU的成本和三年的运营费用。从Google给出的性能数据来看，在进行H．264编解码时，单个Argos VCU几乎不比双向英特尔Skylake服务器快，但是，由于可以将20个VCU安装到一个服务器中，其效率更高。当进行VP9编解码时，VCU比英特尔的双插槽Xeon快5倍，效率优势明显。</p><p style="text-indent: 2em; text-align: left;">之所以说了这么多Google自研芯片的内容，就是要说明：字节跳动要自研芯片，大概率是遇到了上面提到的、Google曾经遇到的这些问题。TikTok的数据中心需要支持各种业务，包括视频平台、信息和娱乐应用，需要开发视频编解码SoC来对用户上传的海量视频流进行处理，同时，为了进一步降低数据中心的功耗和存储容量，还需要更高效的AI算法及相关硬件。</p><p style="text-indent: 2em; text-align: left;"><strong>全行业跟进</strong></p><p style="text-indent: 2em; text-align: left;">海量数据＋视频流处理需求是近些年各大厂商研发新型处理器的核心动力，不止Google和字节跳动这些互联网大厂，传统处理器（CPU、GPU、FPGA等）大厂也在不遗余力地进行着研发工作，因为市场有巨大需求。</p><p style="text-indent: 2em; text-align: left;">以DPU为例，这是近些年最火爆的词语了，<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-%E8%8B%B1%E4%BC%9F%E8%BE%BE.HTM" target="_blank" title="英伟达">英伟达</a></span>是行业大佬，也有一众厂商在这一赛道上摸爬滚打。</p><p style="text-indent: 2em; text-align: left;">DPU是以数据为中心构造的专用处理器，采用软件定义技术支撑基础设施层资源虚拟化，支持存储、安全、服务质量管理等服务。2020年，英伟达发布的DPU战略中将其定位为数据中心继CPU和GPU之后的“第三颗主力芯片”，掀起了一波行业热潮。DPU面向的应用更加底层，要解决的核心问题是基础设施的降本增效，即将CPU处理效率低下、GPU处理不了的负载交由专用DPU处理，从而提升整个计算系统的效率、降低TCO。</p><p style="text-indent: 2em; text-align: left;">DPU最直接的作用是作为CPU的卸载引擎，接管网络虚拟化、硬件资源池化等基础设施层服务，释放CPU的算力到上层应用。以<span class="hrefStyle"><a href="http://ee.ofweek.com/CAT-2804-NetworkProtocol.html" target="_blank" title="网络协议">网络协议</a></span>处理为例，要线速处理10G的网络需要大约4个Xeon CPU核，也就是说，单是做网络数据包处理，就可以占去一个8核高端CPU一半的算力。如果考虑40G、100G的高速网络，性能开销就更加难以承受了。而将数据中心开销全部从CPU卸载到DPU加速卡上，可以给上层应用释放可观的算力。</p><p style="text-indent: 2em; text-align: left;">此外，DPU还可以成为新的数据网关，以提升隐私安全级别，DPU也可以成为存储的入口，将分布式存储和远程访问本地化。</p><p style="text-indent: 2em; text-align: left;">虽然DPU与前文提到的Google和字节跳动自研芯片有所差异，但它们在本质上都是相同的，都是为了解决传统CPU和GPU难以承受的海量数据处理难题。目前来看，它们与传统CPU和GPU能够实现很好的互补，在需要高性能的海量数据处理能力时，则用专用的DPU等ASIC，而平时需要灵活处理的指令则是CPU的专长。</p><p style="text-indent: 2em; text-align: left;">另外，基于FPGA的智能网卡在近些年也有快速发展，它为大型互联网企业的大数据、高带宽通信带来了更多、更好的选择，赛灵思在这方面很有一套。2018年，该公司将“数据中心优先（Datacenter First）”作为其全新发展战略。发布了Alveo系列加速卡产品，旨在大幅提升云端和本地数据中心服务器性能。2019 年4月，该公司收购Solarflare通信公司，将FPGA、MPSoC和ACAP解决方案与 Solarflare 的超低时延网络接口卡（<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-NI.HTM" target="_blank" title="NI">NI</a></span>C）技术，以及应用加速软件相结合，实现了全新的SmartNIC解决方案。这些，或许是<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-AMD.HTM" target="_blank" title="AMD">AMD</a></span>决定对其进行收购的重要原因。</p><p style="text-indent: 2em; text-align: left;"><strong>除了英伟达和赛灵思，CPU霸主英特尔也没闲着，该公司于2015年收购了Altera，在通用处理器的基础上，进一步完善硬件加速能力。</strong></p><p style="text-indent: 2em; text-align: left;">2021 年6月，该公司发布了IPU（可以视其为英特尔版本的DPU），将FPGA与Xeon D系列处理器集成，成为了DPU赛道有力的竞争者。IPU是具有强化的加速器和以太网连接的高级网络设备，它使用紧密耦合、专用的可编程内核加速和管理基础架构功能。</p><p style="text-indent: 2em; text-align: left;">另外，Marvall发布了OCTEON 10 DPU产品，不仅具备强大的转发能力，还具有突出的AI处理能力。</p><p style="text-indent: 2em; text-align: left;">当然，研发类似TPU和DPU产品的不止以上这些厂商，目前，越来越多的业内厂商在加大这方面的投入力度，以期在未来的竞争中占得先机。</p>中国厂商不甘人后<p style="text-indent: 2em; text-align: left;">在自研处理器方面，中国各大互联网企业都很积极，早在字节跳动之前，阿里、腾讯、百度都有行动。例如，阿里拥有自己的AI推理芯片和通用处理器，百度有昆仑AI处理器，腾讯有适用于各种云工作负载的处理器。</p><p style="text-indent: 2em; text-align: left;">以腾讯为例，该公司的自研芯片之路，是从拿FPGA试水开始的，2015年，腾讯团队研发的图片编码FPGA，取得了比CPU编码和软件编码更高的压缩率和更低的延时，也帮助QQ相册大幅降低了存储成本。他们看到了在 FPGA 方向探索和深入的可能性，2016 年，通过FPGA对深度学习模型CNN算法进行加速后，处理性能达到通用CPU的4倍，而单位成本仅为三分之一。</p><p style="text-indent: 2em; text-align: left;">那之后，腾讯在自研芯片方面取得了多个成果，代表作是蓬莱实验室的AI推理芯片紫霄和视频转码芯片沧海，它们有望于今年实现量产。</p><p style="text-indent: 2em; text-align: left;">2019 年，腾讯迎来云计算业务上的里程碑——云服务器规模突破了 100 万。随着服务器接入带宽不断提升，服务器用于网络处理的CPU资源也越来越多，能否以更低成本的方式来实现服务器网络处理，同时还提供更高的网络性能？答案是智能网卡。该公司制定了“先从基于FPGA自研智能网卡起步，再开展智能网卡芯片研发”的发展路线。</p><p style="text-indent: 2em; text-align: left;"><strong>2020年9月，腾讯第一代基于FPGA的自研智能网卡正式上线，命名为水杉。</strong></p><p style="text-indent: 2em; text-align: left;">水杉投入应用后，第二代智能网卡银杉的研发工作于2021年10月正式上线，这一代智能网卡的网络端口翻了一番，达到2＊100G，基于此，腾讯云推出了业界首款自研第六代100G云服务器。它的计算性能最大提升220％、存储性能最大提升100％。单节点接入网络带宽相比上一代最大提升4倍，延时下降50％。</p><p style="text-indent: 2em; text-align: left;">目前，腾讯正在研发其首款智能网卡芯片玄灵，采用7nm制程工艺，预计在2022年底流片。据悉，玄灵的性能相对商业芯片可提升4倍，通过将原来运行在主机CPU上的虚拟化、网络／存储 IO等功能卸载到芯片，可实现主机CPU的0占用。</p><p style="text-indent: 2em; text-align: left;">不止腾讯，阿里和百度都有各自的芯片研发故事，这里就不一一赘述了。</p><p style="text-indent: 2em; text-align: left;">中国大陆系统厂商（互联网和设备厂商）自研芯片，也不全是商业原因，有的是受到国际贸易限制，市场上有可用芯片，但买不到。</p><p style="text-indent: 2em; text-align: left;">无论是阿里、腾讯、百度，还是字节跳动，他们自研芯片，主要与Google类似，市场上没有满意的芯片，而<span class="hrefStyle"><a href="https://ee.ofweek.com/tag-%E5%8D%8E%E4%B8%BA.HTM" target="_blank" title="华为">华为</a></span>则有些不同，该公司2005年就开始布局自研芯片，主要考虑的是有朝一日如果受到国际贸易限制，能够有自家芯片顶上，从而掌握主动权。2019年之后，多年担心的事情还是发生了，但无奈的是，虽然华为的芯片研发能力很强，但由于中国大陆芯片制造能力有限，设计出了高端芯片，制造端受限后，造不出来，非常遗憾。</p><p style="text-indent: 2em; text-align: left;">因此，国际大厂（如Google）自研芯片，完全出于商业原因，而中国大陆系统厂商自研芯片，原因更多，苦难更深。</p></article><p>       <span style="color:#999999;font-family:  <span class='hrefStyle'><a href='https://ee.ofweek.com/tag-%E5%BE%AE%E8%BD%AF.HTM' target='_blank' title='微软'>微软</a></span>雅黑;font-size:14px;">原文标题 : 中国厂商跨界自研芯片的困局</span></p> 
  
</div>
            