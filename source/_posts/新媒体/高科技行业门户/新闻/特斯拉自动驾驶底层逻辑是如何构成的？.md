
---
title: '特斯拉自动驾驶底层逻辑是如何构成的？'
categories: 
 - 新媒体
 - 高科技行业门户
 - 新闻
headimg: 'https://mp.ofweek.com/Upload/News/Img/member36344/202107/wx_article__1f1ee2f412b604e9e078e658708187e9.jpg'
author: 高科技行业门户
comments: false
date: Thu, 26 Aug 2021 04:15:00 GMT
thumbnail: 'https://mp.ofweek.com/Upload/News/Img/member36344/202107/wx_article__1f1ee2f412b604e9e078e658708187e9.jpg'
---

<div>   
<p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202107/wx_article__1f1ee2f412b604e9e078e658708187e9.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">本文系基于公开资料撰写，仅作为信息交流之用，不构成任何投资建议。</p><p style="text-indent: 2em; text-align: left;">如果机器人有大脑，会是什么样？</p><p style="text-indent: 2em; text-align: left;">在科幻电影《机械姬》里，全球最大搜索引擎公司“蓝皮书”CEO纳森向观众展示了自己发明的机器人大脑，并留下这么一句话：“人们认为搜索引擎是人们思考的事物，但其实那是人们思考的方式。”  </p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__91fc4da4fec7b759b4e2b812b723b9af.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">该影片上映于2015年，被誉为人工智能爱好者必看的电影之一，拿下包括奥斯卡金像奖在内等多项国际电影大奖。但在众多奖项中，单项之冠是“最佳女配角”，艾丽西卡·维坎德，也正是影片中智能机器人“艾娃”的扮演者。</p><p style="text-indent: 2em; text-align: left;">“艾娃”是纳森给“她”取的名字，为制造出能独立思考的人工智能，纳森利用自家搜索引擎“蓝皮书”的算法来构建艾娃大脑的“思维”，使之学会人类思考方式。</p><p style="text-indent: 2em; text-align: left;">无独有偶，想让机器有人类思维，同样见之于<span class="hrefStyle"><a href="https://libattery.ofweek.com/KW-tesla.html" target="_blank" title="特斯拉">特斯拉</a></span>打造的自动驾驶AI上。2019特斯拉自动驾驶日上，安德鲁·卡帕西（Andrej Karpathy，特斯拉AI总负责人）曾明确地向大众传达特斯拉自动驾驶是在模仿人类驾驶，因为现行的交通系统是基于人类视觉和认知系统来设计的。</p><p style="text-indent: 2em; text-align: left;">由此，特斯拉开发出“人工神经网络”，并利用大量有效的行车数据来训练它，在这一过程中不断完善并迭代视觉算法，终于在今年年中拿掉毫米波雷达，而随着超算Dojo浮出水面，长期被诟病只能算辅助驾驶的特斯拉，离真正的自动驾驶又近一步。</p><p style="text-indent: 2em; text-align: left;">从学会开车，到比人类更懂开车、开得更好，当一名优秀的“老司机”，是特斯拉自动驾驶持续优化的底层逻辑。</p><p style="text-align:center"><strong><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__6ed612934bbefd1878f2778d0c970fa6.jpg" referrerpolicy="no-referrer"></strong></p><p style="text-indent: 2em; text-align: left;"><strong>01</strong></p><p style="text-indent: 2em; text-align: left;"><strong>“云端司机”的神经网络</strong></p><p style="text-indent: 2em; text-align: left;">纯视觉自动驾驶方案是特斯拉的独门绝技，但需建立对计算机视觉深度训练之上。</p><p style="text-indent: 2em; text-align: left;">计算机视觉是一种研究机器如何“看”的科学，当人类看到一张图片时，能清晰辨析图片里的事物，比如说美丽的风景照、或者一张小狗的照片，然而计算机看到的却是像素（pixel），像素是指由图像的小方格组成的，这些小方块都有一个明确的位置和相对应的色彩数值，计算机“记住”的就是这堆数字字符，而不是具体事物。</p><p style="text-indent: 2em; text-align: left;">如果想让计算机能像人类一样快速准确识别出图片里的事物，机器也有了人工大脑，来模拟人脑处理加工图像信息过程，分为输入层、隐藏层、输出层，里面有许多人工神经元，可视作人脑初级视觉皮层中的锥体细胞和中间神经元。</p><p style="text-indent: 2em; text-align: left;">整个训练过程亦可类比小孩看图识物，通过一次次输入、对比、纠正，完成机器图像认知。通常在训练初期，人工神经网络识别结果的准确度非常低，输出结果和实际值相似度可能只有10％；为了提高准确度，需要再将两者误差从输出层反向传播至输入层，并在反向传播中，修正神经网络隐藏层的参数值，经过上百万次的训练，误差逐渐将收敛，直至输入和输出端匹配度达到99％。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__dc58884983aa65020fb6756ebb005e72.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">上述过程是理解特斯拉自动驾驶AI的关键，只不过特斯拉开发的人工神经网络专注于驾驶领域，做一名专职云端司机。对它来说，最好的学习<span class="hrefStyle"><a href="https://libattery.ofweek.com/tag-%E9%94%82%E7%94%B5%E6%B1%A0%E6%9D%90%E6%96%99.HTM" target="_blank" title="材料">材料</a></span>就是行车数据，大量、多样化、来自真实世界的驾驶训练数据集（training dataset）是自动驾驶AI能应对各种路况、交通问题的百宝书。</p><p style="text-indent: 2em; text-align: left;">在影子模式的支持下，特斯拉全球百万车队每时每刻的行车数据都成为这位云端“老司机”提升自身驾驶能力的养分。时至今日，特斯拉Autopilot已经能瞬间完成道路上各种动静目标、道路标识、交通符号的语义识别，反应速度甚至比人脑条件反射更快。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__6a4f1265f13c5195c45172ef01998281.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">除了应对日常驾驶场景外，AI司机还需要处理一些较为少见的长尾情况（Corner cases）。在2020年Matroid机器学习大会上，卡帕西以交通指标STOP为例，讲解Autopilot应对这些长尾情况的具体方法。</p><p style="text-indent: 2em; text-align: left;">在日常驾驶过程中，车辆总会经过形形色色的STOP指标，最为正常的情况就是一个立在路旁或者路中、红底白字的STOP标识，但现实生活总会有些预料之外的情况发生，驾驶员偶尔会碰上一些奇奇怪怪、需要结合具体背景来理解意涵的指标，包括不限于以下：</p><p style="text-indent: 2em; text-align: left;">无效STOP指标，比如被某人拿在手上，却无意义；下方附带文字说明的STOP指标，比如不限制右行；STOP字母被树枝、建筑物遮挡的指标…这都是些出现频次不高却不胜枚举的情况。</p><p style="text-indent: 2em; text-align: left;">遇到上述情况，人类驾驶员可以轻松识别出绝大部分情况下的“STOP”，并很快作出行动反应。但对计算机来说，情况就变得复杂起来，毕竟它看到的不是具体的＂STOP＂，而是一堆无意义的数字代码，如果遇到现有训练数据集中没出现的情况，比如一些上述奇奇怪怪、较为少见的指标，自动驾驶神经网络就不能处理。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__42efeb8b0d0d6e1b02bbe90cea0bfca0.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">这部分少见的长尾数据通常无穷尽，但又必须在尽可能短的时间内学会应对，如果一切都让人工操作，无疑需要耗费巨大的时间成本和资源。尽管在8月20日AI大会上，卡帕西透露目前特斯拉标注团队规模已达千人级别，但在海量行车数据面前，千人还是显得杯水车薪，对此特斯拉内部开发了数据离线自动标注（Data Auto Labeling）以及自动训练框架“数据引擎（Data Engine）”。  </p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__45b1fdd0f0a9613a599ae9f5fa0635d5.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">首先，特斯拉神经网络团队在对这些长尾情况有所了解后，会先编成一个样本数据集，并为此创造一个局部小型神经网络来学习、训练（与其他神经网络并行），通过OTA方式部署到全球英语地区特斯拉车辆上。</p><p style="text-indent: 2em; text-align: left;">再利用车辆影子模式，但凡遇到实际驾驶情况和自动驾驶AI决策不一致的情况，这部分行车数据会自动上传至特斯拉后台数据引擎中，在被自动标注后，重新纳入已有的数据训练集中，继续训练原本的神经网络，直到新的数据被掌握。</p><p style="text-indent: 2em; text-align: left;">就这样，在大量训练数据的喂养下，神经网络变得“见多识广”、更加聪明，可以识别不同条件状况下的STOP标识，精确度逐渐从40％提升至99％，完成单一任务学习。</p><p style="text-indent: 2em; text-align: left;">不过，这仅仅是学习一个静态的信号，在汽车驾驶过程中会涌现无数静态和动态的信号，静态如路边大树、路障、电线杆等，动态的有行人、车辆等，而这些信号由摄像机捕捉到后交由神经网络训练、学习。目前特斯拉的自动驾驶神经网络已发展出九大主干神经（HydraNet）和48个神经网络，识别超过1000种目标。</p><p style="text-indent: 2em; text-align: left;">然而，仅仅让自动驾驶AI学会开车还不够，还得让它开得像人类老司机一般驾轻就熟、安全又平稳。</p><p style="text-indent: 2em; text-align: left;"><strong>02</strong></p><p style="text-indent: 2em; text-align: left;"><strong>摆脱拐杖，Autopilot初长成</strong></p><p style="text-indent: 2em; text-align: left;">任何一位经验老道的司机，都能在不同路况下，轻易判断出前方车辆与我们的距离，从而为保障行车安全而留出一定车距。</p><p style="text-indent: 2em; text-align: left;">但对传感器而言，要想判断物体远近必须要理解物体的深度，不然在他们眼中，距离我们10米和5米的两辆完全一样的车，就会被认为是一大一小的关系。</p><p style="text-indent: 2em; text-align: left;">对此，有些车厂选择激光雷达路线来探测深度，而特斯拉则选择了纯视觉算法，模仿人类视觉来感知深度，不过特斯拉先是打造了毫米波雷达＋视觉传感融合路线，直到今年5月，才正式官宣，拿掉毫米波雷达，上线纯视觉版本Autopilot。</p><p style="text-indent: 2em; text-align: left;">此事一出，社会各界一片哗然，很多人不能理解特斯拉为何要拿掉单价才300元、又能为行车安全增添保障的高性价比雷达。殊不知，在特斯拉早期多传感器融合路线中，毫米波雷达的存在就犹如小孩的学步车，只是帮助神经网络来学习训练深度标注（annotate）。</p><p style="text-indent: 2em; text-align: left;">在2019年自动驾驶发布会上，卡帕西是这样介绍毫米波雷达的，他说：“要想让神经网络学会预测深度，最好的方式还是通过深度标注的数据集进行训练，不过相对于人工标注深度，毫米波雷达反馈的深度数据精准度更高”，因此，引入毫米波雷达，实质是用以训练和提高神经网络对深度的预测。</p><p style="text-indent: 2em; text-align: left;">值得一提的是，在他讲解时的背景幻灯片右下角上，清晰地注明了带有毫米波雷达的自动驾驶算法是“Semi－Automonous Self Driving”，翻译过来是，半自动驾驶，明显彼时的特斯拉Autopilot只是个半成品。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__fe7db7d317eed7850706327b89206041.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">直到特斯拉视觉算法在预测物体的深度、速度、加速度的表现，达到可替代毫米波雷达的水平，特斯拉的视觉算法才算真正独立。</p><p style="text-indent: 2em; text-align: left;">在2021年6月CVPR大会上，卡帕西曾表示毫米波雷达收集数据中曾出现“间歇性翻车”、甚至误判等情况。他举了三个具体例子，前方车辆急刹车、大桥下前车行驶速度以及对路边静止卡车的判断。</p><p style="text-indent: 2em; text-align: left;">情况一：前方车辆出现急刹，毫米波雷达短时间内出现6次跟丢目标车的情况，跟丢状态下前车的位置、速度和加速度都归于零。</p><p style="text-indent: 2em; text-align: left;">情况二：在行驶的汽车从大桥下通过时，雷达把一静一动的物体都当作静止物体；此时视觉传感却计算出行驶车辆的速度和位移，导致数据融合后的曲线传递出“前车在减速并且刹车”的错误信息。</p><p style="text-indent: 2em; text-align: left;">情况三：在高速路旁停着一辆白色大卡车，纯视觉算法在距目标车180m处就发现白色卡车，并作出预报，但融合算法直到110m处才作出反馈，足足延迟5秒。</p><p style="text-indent: 2em; text-align: left;">上述案例里，纯视觉算法均输出稳定且大幅优于雷达＋视觉融合算法，精准地跟踪到前车行驶状况并作出深度、速度、加速度等数据。</p><p style="text-indent: 2em; text-align: left;">不仅如此，纯视觉算法还可以在雾、烟、尘等环境里保持对前方车辆的测速、测距工作，如此一来拿掉毫米波雷达也不奇怪了。根据特斯拉AI Day上最新发布的信息，目前特斯拉每周能够获得一万个人们恶劣环境下驾车的短视频，包括大雨、大雪、大雾、黑夜、强光等等情况，神经网络通过学习训练这些已经标注好的材料，实现在没有毫米波雷达的情况下，也可以精准感知前方车辆距离。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__8173d918ac2e8595f5943dba83f4f4cc.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">可以说，特斯拉宣布拿掉毫米波雷达的底气，是对自己纯视觉算法成熟的自信，并且在无监督自学的加持下，特斯拉纯视觉算法迭代和完善明显提速。</p><p style="text-indent: 2em; text-align: left;">今年7月10日，特斯拉纯视觉版本的FSD正式在美开启内测，2000名受邀车主通过OTA方式升级到FSD Beta V9．0版本，他们大多是特斯拉的粉丝兼中小型KOL，Youtube博主Chunk Cook（以下简称CC）就是其中之一，他还略懂工程学和航天学专业知识。</p><p style="text-indent: 2em; text-align: left;">系统更新一结束，CC开启新版FSD道路测试，并把测试视频上传至油管。视频中他来到一个车辆较多、车速较快的T路口进行转弯测试，结果显示，7次中只有1次，FSD顺利完成自动驾驶，其余都需要人工接管方向盘来完成驾驶。</p><p style="text-indent: 2em; text-align: left;">但很快，随着7月底FSD推送新版本V9．1，CC发现升级后的FSD表现出乎他的意料。他又在相同道路进行了七次自动驾驶测试，结果显示，7次中4次都较为顺利完成自动驾驶，但在转弯速度上有些“磨蹭”，没有展现老司机应有的果断，但在综合得分上，新版本Autopilot优于旧版本。</p><p style="text-indent: 2em; text-align: left;">8月16日，特斯拉FSD又升级至新版本V9．2，CC同样抢先测试并上传视频，还是一个路段，不过测试时间改为夜间，他公开表示，此次最明显的改进是Autopilot的加速表现，在转弯时能像人类驾驶员一样果断加速。</p><p style="text-indent: 2em; text-align: left;">前后一个月的时间，纯视觉Autopilot在同一条道路的表现进步迅速，身后正是人工神经网络强悍自学能力的体现。马斯克表示，FSD beta V9．3、9．4都已在筹备中，会根据车主使用情况不断进行细节优化，改善用户体验，并预备在V10版本做出现重大的变化。</p><p style="text-indent: 2em; text-align: left;"><strong>03</strong></p><p style="text-indent: 2em; text-align: left;"><strong>Dojo上马，模拟极限</strong></p><p style="text-indent: 2em; text-align: left;">需要注意的是，大家惊艳特斯拉纯视觉Autopilot各种老司机操作时，也不能忘记这些路测大部分发生在北美地区，而在非英语地区，比如人口稠密的亚洲地区，其城市道路交通复杂度与地广人稀的北美迥异，而如何让神经网络学会应对各种路况交通，更值得思考。</p><p style="text-indent: 2em; text-align: left;">收集实地数据是方法之一，但前提是你有大量车队在该地区驾驶，另一种解决方法则是对自动驾驶进行仿真测试。仿真，简单讲就是利用现实数据，将真实世界的实时动态景象，在计算机系统实现重新构建和重现。</p><p style="text-indent: 2em; text-align: left;">除了能模拟不同城市的交通路况，而且仿真测试还能模拟一些极限场景，比如各种突发交通事件或者极为罕见的交通路况。在AI DAY上，特斯拉工程师举了具体例子，包括有行人在高速路上奔跑、行人数量庞大、或者非常狭窄的驾驶道路。</p><p style="text-indent: 2em; text-align: left;">这些案例往往非常极端，在日常驾驶场景中出现的概率也微乎其微，但正因为此，通过仿真来训练神经网络才有真正价值，而只有通过训练，神经网络才能学会正确应对。</p><p style="text-indent: 2em; text-align: left;">为了能真正起到训练作用，这些仿真测试必须充分还原现实场景，包括道路上各种行人、车辆、绿化林、路障、信号灯等等，几乎包含你在路上见到的所有交通要素。目前特斯拉已创建了3．71亿张车内网络训练的图像，以及4．8亿个标签，并且数据规模还在快速扩张中。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member36344/202108/wx_article__25b85bdf1d9df4f09b99595eff5981dc.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">要知道，仿真测试可达到的逼真程度，与计算机可提供的数据处理能力成正比。特斯拉AI的仿真越强，对硬件算力、读写速度的要求越高。</p><p style="text-indent: 2em; text-align: left;">马斯克曾在2020WAIC大会上表示，当下计算机视觉已经超越人类专家水平，但要保证计算机视觉实现的关键是算力的大小，为此特斯拉则准备好了顶级超算Dojo，保证一切运算都能高效、准确完成。</p><p style="text-indent: 2em; text-align: left;">在AI day上，超算Dojo揭开了庐山真面目，内置了3000颗Dojo 1芯片，并组装成峰值算力达到1．1EFLOPS的ExaPOD，超越目前世界上最快的超算日本富岳，就成了全球第一。在发布会后，马斯克在推特上回复网友提问时表示，ExaPOD的运算能力足以模拟人脑。</p><p style="text-indent: 2em; text-align: left;">现阶段，Dojo这台性能猛兽专注于训练特斯拉自动驾驶神经网络，有了它，神经网络的学习潜力一下子变得深不可测，而至此，特斯拉也集齐自动驾驶三要素，数据、算法、算力，为推进L5级别自动驾驶做好软硬件准备。</p><p style="text-indent: 2em; text-align: left;">不过要想快进至自动驾驶终局，特斯拉还有很长的路要走，包括来自法律和道德层面的考验。</p> 
  
</div>
            