
---
title: '神经网络技术，特斯拉储备了多少牛专利？马斯克为啥爱它爱的疯狂！'
categories: 
 - 新媒体
 - 高科技行业门户
 - 新闻
headimg: 'https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__a6489e99c037b0b2cb0314c61ac2adf6.jpg'
author: 高科技行业门户
comments: false
date: Mon, 29 Aug 2022 07:11:00 GMT
thumbnail: 'https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__a6489e99c037b0b2cb0314c61ac2adf6.jpg'
---

<div>   
<p style="text-indent: 2em; text-align: left;">知情郎·眼｜</p><p style="text-indent: 2em; text-align: left;">侃透天下专利事儿</p><p style="text-indent: 2em; text-align: left;">马斯克（Elon Musk）是真爱视觉神经网络技术。</p><p style="text-indent: 2em; text-align: left;">日前，特斯拉首次披露了自研AI芯片及Dojo系统更多细节，并表示自家人型机器人Tesla Bot“擎天柱”头部将配备与自家汽车相同的智能驾驶摄像头，与汽车共用AI系统。</p><p style="text-indent: 2em; text-align: left;">换言之，特斯拉人形机器人延续了以视觉为主的传感技术路线。</p><p style="text-align:center"><img title width="100%" src="https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__a6489e99c037b0b2cb0314c61ac2adf6.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;"><strong>Elon Musk和“擎天柱”Tesla Bot</strong></p><p style="text-indent: 2em; text-align: left;">你懂的，AI牛不牛，在于对摄像头拍摄的图片信息处理速度快不快、准不准，对海量数据的运算分析处理，需要强大的算法和算力。</p><p style="text-indent: 2em; text-align: left;">这也是特斯拉自研AI芯片以及开发Dojo系统的核心动力。</p><p style="text-indent: 2em; text-align: left;">所谓 Dojo，是特斯拉自研的超级计算机，可利用海量视频数据，完成“无人监管”的标注和训练。</p><p style="text-indent: 2em; text-align: left;">在去年的AI Day上，特斯拉就已发布Dojo超级计算机，但当时其“羽翼未丰”，尚只有第一个芯片及训练块，公司仍在推动构建完整的Dojo Exapod。</p><p style="text-indent: 2em; text-align: left;">如今Dojo已成型了，特斯拉拿出来宣传了。人家一直高调宣称，理论上，Dojo ExaPod将是世界上最快的AI训练超级计算机。</p><p style="text-indent: 2em; text-align: left;">据不靠谱传闻，特斯拉擎天柱人形机器人在Dojo的训练下，每接受一亿张图片信息以及相关文字训练后，智商就能涨一岁。</p><p style="text-indent: 2em; text-align: left;">它能聪明地捕捉到每个物体的特性，并把它们合理地组织在一起，这几乎超越了人类3岁小孩的智力。</p><p style="text-indent: 2em; text-align: left;">这传闻纯属脑补，做不得信！</p><p style="text-indent: 2em; text-align: left;">另外，查了特斯拉关于神经网络的全球AI专利，不少！人家下了功夫！</p><p style="text-indent: 2em; text-align: left;"><strong>01Dojo Exapod 亮相！</strong></p><p style="text-indent: 2em; text-align: left;">在此前的硅谷芯片技术研讨会HOT CHIPS上，特斯拉硬件工程师Emil Talpes公开了特斯拉Dojo超算指令集结构细节，并展示了Dojo的数据格式、系统网络、软件系统绕行死节点能力等。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__1a205cc8c537b94bb73f972e15322b1d.jpg" referrerpolicy="no-referrer"></p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__90d73c92b1d6468c934802a9aac6f8a0.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">从工程师披露的技术细节看，每个Dojo ExaPod集成120个训练模块，内置3000个D1芯片，拥有超过100万个训练节点，算力达到1．1EFLOP＊（每秒千万亿次浮点运算）。</p><p style="text-indent: 2em; text-align: left;">微架构方面，每个Dojo节点都有一个内核，是一台具有CPU专用内存和I／O接口的成熟计算机。</p><p style="text-indent: 2em; text-align: left;">Dojo Exapod的核心，便是特斯拉自研的D1芯片。该芯片由台积电制造，采用7nm工艺，拥有500亿个晶体管，芯片面积为645mm?，小于英伟达的A100（826 mm?）和AMD Arcturus（750 mm?）。</p><p style="text-indent: 2em; text-align: left;">值得注意的是，有望在下个月现身的特斯拉人形机器人“擎天柱”大脑所使用的，便是Dojo D1超级计算芯片，每个D1芯片之间无缝连接，相邻芯片之间的延迟极低，训练模块最大程度上实现了带宽的保留。</p><p style="text-indent: 2em; text-align: left;">得益于庞大数据库的支撑、AI预测能力与算法，特斯拉认为，纯视觉方案也能较好地弥补深度传感器缺失所带来的不足。</p><p style="text-indent: 2em; text-align: left;">目前，其基于视觉的神经网络技术已在汽车FSD上获得实战验证，华安证券27日报告指出，该技术有望借助Dojo超算加速训练升级。</p><p style="text-indent: 2em; text-align: left;"><strong style="text-indent: 2em;">02为啥马斯克那么爱视觉神经网络技术</strong></p><p style="text-indent: 2em; text-align: left;">在传统驾驶模式中，人们都是依靠人眼、大脑来收集、处理信息，再根据信息来调整车辆的状态，自动驾驶其实就是依靠机器来收集信息进行决策。</p><p style="text-indent: 2em; text-align: left;">最困难的地方在于，机器能否准确收集、识别各种场景。</p><p style="text-indent: 2em; text-align: left;">那么在这种场景下，摄像头、激光雷达、毫米波雷达、超声波雷达均可以成为车企的选择。</p><p style="text-indent: 2em; text-align: left;">众所周知，自动驾驶方案有2派，纯视觉感知派和激光雷达派，闹得不可开交，针尖对麦芒。</p><p style="text-indent: 2em; text-align: left;">特斯拉典型地选择摄像头的车企，坚持用纯视觉路线。</p><p style="text-indent: 2em; text-align: left;">此前特斯拉的部分Model 3和Model Y车型配备了毫米波雷达，但不久之前也改装了纯视觉方案的摄像头来进行辅助驾驶。</p><p style="text-indent: 2em; text-align: left;">马斯克曾嘲笑，任何依靠激光雷达的企业注定没有未来。</p><p style="text-indent: 2em; text-align: left;">人家一直强调：“摄像头和神经网络是实现自动驾驶的关键。整个道路系统旨在与光学成像器（眼睛）和神经网络（大脑）配合使用。因此摄像头和神经网络才是根本解决方案。”</p><p style="text-indent: 2em; text-align: left;">作为AI派的顶梁柱，特斯拉认为单纯依靠摄像头就可以完成自动驾驶所需要的周围环境感知逻辑，典型的算法决定一切的认知逻辑。</p><p style="text-indent: 2em; text-align: left;">他们认为，智能汽车的感应系统应尽量模仿人，智能驾驶汽车可以通过计算视觉来接近人类靠2只眼（2个摄像头）处理开车的水平。</p><p style="text-indent: 2em; text-align: left;">需要注意的是，这些人的出身多与机器学习尤其是深度学习有关，他们对计算视觉的信心来自对深度学习的信心。</p><p style="text-indent: 2em; text-align: left;">换句话说，偏向算法工程师出身的他们认为深度学习是全自动驾驶技术的未来。</p><p style="text-indent: 2em; text-align: left;">另一边，激光雷达派则以激光雷达为主导，配合毫米波雷达、超声波传感器、摄像头多传感器融合完成周围环境感知，小鹏P5、蔚来ET7使用的是激光雷达方案。</p><p style="text-indent: 2em; text-align: left;">这群人就是现实派，考虑如何推叠硬件降低事故风险。</p><p style="text-indent: 2em; text-align: left;">激光雷达就是很安全的探测仪！</p><p style="text-indent: 2em; text-align: left;">它可以提供关于景深的信息，其原理是通过发射镭射光并接受反射来建立周边的三维立体图像。</p><p style="text-indent: 2em; text-align: left;">激光雷达在探测精度、范围以及稳定性上，更具有优势，可以达到厘米级。</p><p style="text-indent: 2em; text-align: left;">尤其是激光雷达负责主要的周边探测建模，毫米波雷达用来辅佐激光雷达，可以在恶劣天气下做出更好的回馈，加上摄像头提供2D的实时影像，3D建模搭配2D影像，就可以更好的用算法和数据学习能力，对周边的信息做到更精确的探测，更精确的周围信息，就更能有利的提升辅助驾驶的能力。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__4a0647ffea6d409f5fb4515adbe5bd9d.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;"><strong>03不想依赖高清地图</strong></p><p style="text-indent: 2em; text-align: left;">去年，特斯拉<span class="hrefStyle"><a href="https://www.ofweek.com/ai/" target="_blank" title="人工智能">人工智能</a></span>与自动驾驶视觉总监Andrej Karpathy曾表态为何不认可激光雷达。</p><p style="text-indent: 2em; text-align: left;">他认为，将激光雷达添加到自动驾驶堆栈会带来其自身的复杂性。</p><p style="text-indent: 2em; text-align: left;">Karpathy说，“你必须用激光雷达预先绘制环境地图，然后你必须创建一张高清地图，你必须插入所有车道及其连接方式以及所有交通信号灯，收集、构建和维护这些高清激光雷达地图是不可扩展的，让这个基础设施保持最新状态将是极其困难的。”</p><p style="text-indent: 2em; text-align: left;">Karpathy表示特斯拉在其自动驾驶堆栈中不使用激光雷达和高清地图，“发生的一切，都是第一次发生在车内，基于围绕汽车的八个摄像头的视频”。</p><p style="text-indent: 2em; text-align: left;">Karpathy具体解释了特斯拉的视觉方案运作原理。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__f801f5716682e4accef034b4984050b5.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">特斯拉汽车上安装了8个摄像头，摄像头没有深度信息，他们的目标之一就是形成矢量空间视图。</p><p style="text-indent: 2em; text-align: left;">那么要怎么知道旁边一辆车究竟在哪里又有多长呢？</p><p style="text-indent: 2em; text-align: left;">首先的一个难点是，不同视角的摄像头都只能看到周边环境的一部分，有不同的校准（calibration）、位置（location）、取景方向（view direction）等，比如以下这张图，谁能知道这个点对应于相机视图的哪个点？而我们只有知道这些信息，才能把周围物体准确放到向量空间视图（vector space view）中。</p><p style="text-indent: 2em; text-align: left;"><span style="text-indent: 2em;">因此就需要一种将多个摄像头的信息融合在一起的技术，特斯拉使用了在2017年提出，如今已经席卷<span class="hrefStyle"><a href="https://www.ofweek.com/ai/CAT-201718-nlp.html" target="_blank" title="自然语言处理">自然语言处理</a></span>和<span class="hrefStyle"><a href="https://www.ofweek.com/ai/CAT-201716-cpv.html" target="_blank" title="计算机视觉">计算机视觉</a></span>领域的Transformer神经网络（Transformer Neural Network）。</span></p><p style="text-indent: 2em; text-align: left;">然后则是加入有时间概念时间的RNN（Recurrent Neural Network，循环神经网络）以判断移动物体的速度以及对被遮挡物进行预测。</p><p style="text-indent: 2em; text-align: left;">RNN体现了“人的认知是基于过往的经验和记忆”的观点，通过记忆来处理任意时序的输入序列，从而对接下来要发生的事情进行预测。比如这里对被遮挡物预测，通过对遮挡前的特征和轨迹的记忆，使得视野被短暂遮蔽的情况下，依然可以预测遮挡视野后的物体运动轨迹，并记录已行驶过的路段的各种路标。</p><p style="text-indent: 2em; text-align: left;">而对于深度信息，在缺少了雷达信息后，则需要通过对大量的有深度标注的相机数据进行训练得到的检测算法来得到。</p><p style="text-indent: 2em; text-align: left;">这些年，特斯拉一直在迭代神经网络，利用了多头路径，其中包括摄像机校准、缓存、队列和优化以简化所有任务。</p><p style="text-indent: 2em; text-align: left;">另外，特斯拉神经网络系统技术的背后有千人的数据标记团队，可以对各类数据例如道路、环境以及行人数据进行标记，另外当下也已经拥有了自动标记技术，这样就可以自动选取有特点的样本来不断更新优化自动驾驶能力。</p><p style="text-indent: 2em; text-align: left;"><strong>04从专利看特斯拉神经网络</strong></p><p style="text-indent: 2em; text-align: left;">神经网络，炙手可热。</p><p style="text-indent: 2em; text-align: left;">再次科普下这个概念！</p><p style="text-indent: 2em; text-align: left;">人工神经网络（Artificial Neural Networks，简写为ANNs），也简称为神经网络（NNs）或称作连接模型（Connection Model），它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。</p><p style="text-align:center"><img src="https://mp.ofweek.com/Upload/News/Img/member52128/202208/wx_article__59d3c6907cfbee5a32c2d4369b762957.jpg" referrerpolicy="no-referrer"></p><p style="text-indent: 2em; text-align: left;">这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。</p><p style="text-indent: 2em; text-align: left;">神经网络利用现有的数据找出输入与输出之间得权值关系（近似），然后利用这样的权值关系进行仿真，例如输入一组数据仿真出输出结果，当然你的输入要和训练时采用的数据集在一个范畴之内。</p><p style="text-indent: 2em; text-align: left;">例如预报天气：寻找基本预测因子，如温度湿度气压等气象情况，利用历史的气象数据在神经网络进行关系训练，然后输入今天的温度湿度气压等因子，根据历史数据测算的概率情况得到今日气象预测结果进行预报，这是神经网络的典型应用。</p><p style="text-indent: 2em; text-align: left;">在德高行全球专利库中，以神经网络为关键词，检索相关特斯拉专利，Tesla 全球AI专利249件。</p><p style="text-indent: 2em; text-align: left;"><strong>国内最新公开的6个专利：</strong></p><p style="text-indent: 2em; text-align: left;">序号</p><p style="text-indent: 2em; text-align: left;">标题</p><p style="text-indent: 2em; text-align: left;">摘要</p><p style="text-indent: 2em; text-align: left;">公开号</p><p style="text-indent: 2em; text-align: left;">1</p><p style="text-indent: 2em; text-align: left;">具有指定偏差浮点操作数的矩阵乘法指令的系统和方法</p><p style="text-indent: 2em; text-align: left;">一种微处理器系统包括矩阵计算单元和控制单元。矩阵计算单元包括多个处理元件。控制单元被配置为向矩阵计算单元提供矩阵处理器指令。矩阵处理器指令指定使用第一浮点表示格式格式化的浮点操作数。矩阵计算单元累加使用浮点操作数计算的中间结果值。中间结果值采用第二浮点表示格式。</p><p style="text-indent: 2em; text-align: left;">CN113785271A</p><p style="text-indent: 2em; text-align: left;">2</p><p style="text-indent: 2em; text-align: left;">用于获取训练数据的系统和方法</p><p style="text-indent: 2em; text-align: left;">描述了用于获取训练数据的系统和方法。示例方法包括接收传感器并且将神经网络应用于传感器数据。触发分类器被应用于神经网络的中间结果，以确定针对传感器数据的分类器得分。至少部分地基于分类器得分，做出以下确定：是否要经由计算机网络传送传感器数据的至少一部分。在肯定的确定时，传感器数据被传送并且被用来生成训练数据。</p><p style="text-indent: 2em; text-align: left;">CN112771548A</p><p style="text-indent: 2em; text-align: left;">3</p><p style="text-indent: 2em; text-align: left;">用于自主驾驶的数据管线和深度学习系统</p><p style="text-indent: 2em; text-align: left;">接收使用交通工具上的传感器捕获的图像并且将其分解为多个分量图像。将多个分量图像中的每个分量图像作为不同输入提供给人工神经网络的多个层中的不同层，以确定结果。使用人工神经网络的结果，以至少部分地自主操作交通工具。</p><p style="text-indent: 2em; text-align: left;">CN112639817A</p><p style="text-indent: 2em; text-align: left;">4</p><p style="text-indent: 2em; text-align: left;">用于基于硬件的池化的系统和方法</p><p style="text-indent: 2em; text-align: left;">本文描述了系统和方法，其利用新颖的基于硬件的池化架构来处理卷积引擎的输出，卷积引擎的输出表示卷积神经网络（CNN）中的卷积层的输出通道。池化系统将输出转换为一组阵列，并且根据池化操作将为一组阵列对准以生成池化结果。在某些实施例中，这通过使用对准器来实现，该对准器例如在多个算术循环上，将输出中的数据的阵列对准到行中，并且使行相对于彼此移位。池化器将池化操作应用于来自每行的数据的子集的组合，以生成池化结果。</p><p style="text-indent: 2em; text-align: left;">CN111758107A</p><p style="text-indent: 2em; text-align: left;">5</p><p style="text-indent: 2em; text-align: left;">用于处理载具神经网络处理器中的错误的系统和方法</p><p style="text-indent: 2em; text-align: left;">一种用于处理神经网络中的错误的系统包括神经网络处理器，其用于执行与载具的使用相关联的神经网络。该神经网络处理器包括：错误检测器，被配置为检测与神经网络的执行相关联的数据错误；以及神经网络控制器，被配置为从错误检测器接收数据错误的报告。响应于接收到该报告，神经网络控制器还被配置为：在不终止神经网络的执行的情况下，发信号通知该神经网络的未决结果被污染。</p><p style="text-indent: 2em; text-align: left;">CN111212775A</p><p style="text-indent: 2em; text-align: left;">6</p><p style="text-indent: 2em; text-align: left;">加速数学引擎</p><p style="text-indent: 2em; text-align: left;">本公开的各种实施例涉及一种加速数学引擎。在某些实施例中，加速数学引擎被应用于图像处理，使得图像的卷积通过使用包括子电路的二维矩阵处理器而被加速，子电路包括ALU、输出寄存器和影子寄存器。该架构支持时钟二维架构，其中图像数据和权重以同步方式相乘，以允许大量数学运算被并行执行。</p><p style="text-indent: 2em; text-align: left;">CN111095241A</p><p style="text-indent: 2em; text-align: left;"><strong>美国最新公开的8件相关专利</strong></p><p style="text-indent: 2em; text-align: left;">序号</p><p style="text-indent: 2em; text-align: left;">标题</p><p style="text-indent: 2em; text-align: left;">摘要</p><p style="text-indent: 2em; text-align: left;">公开号</p><p style="text-indent: 2em; text-align: left;">1</p><p style="text-indent: 2em; text-align: left;">Vector computational unit（矢量计算单元）</p><p style="text-indent: 2em; text-align: left;">A microprocessor system comprises a computational array and a vector computational unit． The computational array includes a plurality of computation units． The vector computational unit is in communication with the computational array and includes a plurality of processing elements． The processing elements are configured to receive output data elements from the computational array and process in parallel the received output data elements．</p><p style="text-indent: 2em; text-align: left;">US11409692B2</p><p style="text-indent: 2em; text-align: left;">2</p><p style="text-indent: 2em; text-align: left;">Accelerated mathematical engine（加速数学引擎）</p><p style="text-indent: 2em; text-align: left;">Various embodiments of the disclosure relate to an accelerated mathematical engine． In certain embodiments，  the accelerated mathematical engine is applied to image processing such that convolution of an image is accelerated by using a two－dimensional matrix processor comprising sub－circuits that include an ALU，  output register and shadow register． This architecture supports a clocked，  two－dimensional architecture in which image data and weights are multiplied in a synchronized manner to allow a large number of mathematical operations to be performed in parallel．</p><p style="text-indent: 2em; text-align: left;">US11403069B2</p><p style="text-indent: 2em; text-align: left;">3</p><p style="text-indent: 2em; text-align: left;">PREDICTING THREE－DIMENSIONAL FEATURES FOR AUTONOMOUS DRIVING（预测自动驾驶的三维特征）</p><p style="text-indent: 2em; text-align: left;">A processor coupled to memory is configured to receive image data based on an image captured by a camera of a vehicle． The image data is used as a basis of an input to a trained machine learning model trained to predict a three－dimensional trajectory of a machine learning feature． The three－dimensional trajectory of the machine learning feature is provided for automatically controlling the vehicle．</p><p style="text-indent: 2em; text-align: left;">US20220107651A1</p><p style="text-indent: 2em; text-align: left;">4</p><p style="text-indent: 2em; text-align: left;">DATA PIPELINE AND DEEP LEARNING SYSTEM FOR AUTONOMOUS DRIVING（用于自主驾驶的数据管道和深度学习系统）</p><p style="text-indent: 2em; text-align: left;">An image captured using a sensor on a vehicle is received and decomposed into a plurality of component images． Each component image of the plurality of component images is provided as a different input to a different layer of a plurality of layers of an artificial neural network to determine a result． The result of the artificial neural network is used to at least in part autonomously operate the vehicle．</p><p style="text-indent: 2em; text-align: left;">US20220107652A1</p><p style="text-indent: 2em; text-align: left;">5</p><p style="text-indent: 2em; text-align: left;">Estimating object properties using visual image data（利用视觉图像数据估计物体属性）</p><p style="text-indent: 2em; text-align: left;">A system is comprised of one or more processors coupled to memory． The one or more processors are configured to receive image data based on an image captured using a camera of a vehicle and to utilize the image data as a basis of an input to a trained machine learning model to at least in part identify a distance of an object from the vehicle． The trained machine learning model has been trained using a training image and a correlated output of an emitting distance sensor．</p><p style="text-indent: 2em; text-align: left;">US11288524B2</p><p style="text-indent: 2em; text-align: left;">6</p><p style="text-indent: 2em; text-align: left;">SYSTEM AND METHOD FOR HANDLING ERRORS IN A VEHICLE NEURAL NETWORK PROCESSOR（用于处理车辆神经网络处理器中的误差的系统和方法）</p><p style="text-indent: 2em; text-align: left;">A system for handling errors in a neural network includes a neural network processor for executing a neural network associated with use of a vehicle． The neural network processor includes an error detector configured to detect a data error associated with execution of the neural network and a neural network controller configured to receive a report of the data error from the error detector． In response to receiving the report，  the neural network controller is further configured to signal that a pending result of the neural network is tainted without terminating execution of the neural network．</p><p style="text-indent: 2em; text-align: left;">US20220083412A1</p><p style="text-indent: 2em; text-align: left;">7</p><p style="text-indent: 2em; text-align: left;">MULTI－CHANNEL SENSOR SIMULATION FOR AUTONOMOUS CONTROL SYSTEMS（自主控制系统的多通道传感器仿真）</p><p style="text-indent: 2em; text-align: left;">An autonomous control system combines sensor data from multiple sensors to simulate sensor data from high－capacity sensors． The sensor data contains information related to physical environments surrounding vehicles for autonomous guidance． For example，  the sensor data may be in the form of images that visually capture scenes of the surrounding environment，  geo－location of the vehicles，  and the like． The autonomous control system simulates high－capacity sensor data of the physical environment from replacement sensors that may each have lower capacity than high－capacity sensors． The high－capacity sensor data may be simulated via one or more neural network models． The autonomous control system performs various detection and control algorithms on the simulated sensor data to guide the vehicle autonomously．</p><p style="text-indent: 2em; text-align: left;">US20220043449A1</p><p style="text-indent: 2em; text-align: left;">8</p><p style="text-indent: 2em; text-align: left;">Scalable matrix node engine with configurable data formats（具有可配置数据格式的可扩展矩阵节点引擎）</p><p style="text-indent: 2em; text-align: left;">A microprocessor system comprises a matrix computational unit and a control unit． The matrix computational unit includes one or more processing elements． The control unit is configured to provide a matrix processor instruction to the matrix computational unit． The matrix processor instruction specifies a floating－point operand formatted with an exponent that has been biased with a specified bias．</p><p style="text-indent: 2em; text-align: left;">US11227029B2</p><p style="text-indent: 2em; text-align: left;">【转载请注明德高行·知情郎】</p><p>       <span style="color:#999999;font-family:  微软雅黑;font-size:14px;">原文标题 : 神经网络技术，特斯拉储备了多少牛专利？马斯克为啥爱它爱的疯狂！</span></p> 
  
</div>
            