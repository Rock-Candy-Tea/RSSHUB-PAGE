
---
title: '正面刚CNN，Transformer居然连犯错都像人类'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b35f_1024.jpg'
author: ZAKER
comments: false
date: Mon, 26 Jul 2021 03:10:37 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b35f_1024.jpg'
---

<div>   
<p>这是你眼里的一只猫：</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b35f_1024.jpg" data-height="434" data-width="614" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b35f_1024.jpg" referrerpolicy="no-referrer"></div></div>这是 CNN 眼里的一只猫：<p></p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b360_1024.jpg" data-height="908" data-width="1588" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b360_1024.jpg" referrerpolicy="no-referrer"></div></div>这是<strong>ViT</strong> ( Vision Transformer ) 眼里的一只猫 :<p></p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b361_1024.jpg" data-height="225" data-width="225" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b361_1024.jpg" referrerpolicy="no-referrer"></div></div>从去年起，Transformer 忙着跨界 CV，如 ViT 在图像分类上准确率已超过 CNN，大有取代之势。<p></p><p>这背后的原因是什么？</p><p>最近普林斯顿的一项研究认为，Transformer 的运作方式<strong>更接近人类</strong>，连犯错的方式都和人类一样。</p><p>研究团队在图像分类的准确率之外，增加了对<strong>错误类型</strong>的分析。</p><p>结果发现，与 CNN 相比，ViT 更擅长判断<strong>形状</strong>。</p><p>此前在 ICLR2019 上发表的一篇论文提出，用 ImageNet 训练的 CNN 模型更倾向于通过<strong>纹理</strong>分类图像。</p><p>如下图中混合了大象皮肤纹理的猫被判断成了大象。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b362_1024.jpg" data-height="302" data-width="872" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b362_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>△</strong>来自 arXiv:1811.12231<p></p><p>虽然说这更可能和 ImageNet 的数据纹理信息更丰富有关。</p><p>但 ViT 模型，使用相同数据集训练，就倾向于通过形状分类图像，并且表现比 CNN 更好。</p><p>用形状分类物体也是人类的倾向。不信的话，试试回答下图的问题：右面的三个物体中哪个与左边的是同类？</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b363_1024.jpg" data-height="290" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b363_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>△</strong>来自 DOI: 10.1016/0749-596X ( 92 ) 90040-5<p></p><p>这意味着，使用 ViT 不仅能建立更高效的视觉神经网络，甚至对理解人类视觉的运作方式都有帮助。</p><p>这么神奇？</p><p>下面来看看 CNN 与 Transformer 与人脑的联系分别在哪里。</p><p>CNN：从猫身上获得灵感</p><p>大脑的不同区域对视觉信息有不同的处理方式，CNN 主要模仿的是 "<strong>腹侧流</strong> ( Ventral Stream ) " 在物体识别、分类上的运作方式。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b364_1024.jpg" data-height="782" data-width="1228" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b364_1024.jpg" referrerpolicy="no-referrer"></div></div>1981 年获得诺贝尔生理和医学奖，由神经科学家 Hubel 和 Wiesel 发现猫的视觉皮层中有<strong>简单细胞</strong>和<strong>复杂细胞</strong>两种。<p></p><p>每个简单细胞对一个特定角度的长条物体反应最强烈，而复杂细胞接受许多个简单细胞传出的信号，就能做到将不同角度的长条物体识别成同一个。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b365_1024.jpg" data-height="460" data-width="910" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b365_1024.jpg" referrerpolicy="no-referrer"></div></div>在 CNN 中，这两种细胞的工作被分配给了<strong>卷积层</strong>和<strong>池化层</strong>。<p></p><p>卷积层中的神经元像简单细胞一样，仅和上一层的部分区域相连接，学习局部特征。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_7" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b366_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b366_raw.gif" data-height="381" data-width="395" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b366_1024.jpg" referrerpolicy="no-referrer"></div></div>而<strong>最大池化</strong> ( Max Pooling ) 操作就是模仿复杂细胞，对简单细胞中信号最强的作出反应。<p></p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b367_1024.jpg" data-height="602" data-width="816" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b367_1024.jpg" referrerpolicy="no-referrer"></div></div>这就是 CNN 从动物视觉中学到的<strong>第一个</strong>重要特性 "<strong>局部连接</strong>"。<p></p><p>在卷积层和池化层中使用局部连接，仅在最后输出结果前加入全连接层，使 CNN 获得了 " 平移不变性 "。</p><p>也就是把图像稍微挪动位置，也可以识别成相同的特征。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b368_1024.jpg" data-height="552" data-width="1444" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b368_1024.jpg" referrerpolicy="no-referrer"></div></div>另外，与全连接的神经网络相比，局部连接的方式还大大减少了需要的参数量，降低训练成本。<p></p><p>为了进一步节省资源、提高效率，CNN 在此基础上发展出另一个特性 "<strong>权重共享</strong>"。</p><p>隐藏层中的每个神经元都使用相同的过滤器，也就是<strong>卷积核</strong>。</p><p>就像这样：</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_10" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b369_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b369_raw.gif" data-height="336" data-width="473" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b369_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>△</strong>来自 freecodecamp<p></p><p>卷积核中的相同的参数使用在每一次卷积操作中，进一步降低了需要的参数量。</p><p>不过，与生物视神经的<strong>不同之处</strong>也随之出现了。</p><p>ViT: 拥有多个注意力中心</p><p>让我们再来看看人眼的<strong>注意力机制</strong>。</p><p>人是不能同时看清视野左右两端边缘上的物体的。</p><p>当你把目光聚焦到一边时，另一边只能模糊的感觉到有无物体存在，看不清具体的形状或颜色。</p><p>不信的话现在就可以试一试。</p><p>这是因为感光细胞在视网膜上的分布并是<strong>不均匀</strong>的。</p><p>人眼的感光细胞分为视杆细胞 ( Rods ) 和视锥细胞 ( Cones ) 两种。</p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_11" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36a_1024.jpg" data-height="452" data-width="471" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36a_1024.jpg" referrerpolicy="no-referrer"></div></div>视杆细胞主要负责感知光的亮度，不能很好地分辨细节。<p></p><p>而在光亮度足够时能分辨颜色和形状的视锥细胞，集中分布在视网膜中心处。</p><p>只有在目光聚焦的位置上可以看清细节，所以我们观察时要不停地转动眼球，将目光聚焦在视野上的不同位置，这就产生了注意力机制。</p><p></p><div class="img_box" id="id_imagebox_12" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_12" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36b_1024.jpg" data-height="312" data-width="500" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36b_1024.jpg" referrerpolicy="no-referrer"></div></div>不过比人眼更先进的是，神经网络可以拥有多个注意力，被称为多头注意力 ( Multi-Head Attention ) 机制。<p></p><p>一句话是一个序列</p><p>在 NLP 任务中，Transformer 将文本作为一个序列来处理。</p><p>有了注意力机制，就可以在长序列中注意到每个词与其他词间的关系，实现上下文关联的机器翻译。</p><p></p><div class="img_box" id="id_imagebox_13" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_13" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36c_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36c_raw.gif" data-height="566" data-width="640" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36c_1024.jpg" referrerpolicy="no-referrer"></div></div>一张图也是一个序列<p></p><p>谷歌大脑团队进一步提出，图像在分解成小块之后，再配合位置编码，也可以当作一个序列来处理。</p><p></p><div class="img_box" id="id_imagebox_14" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_14" data-original="http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b36d_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b36d_raw.gif" data-height="618" data-width="900" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b36d_1024.jpg" referrerpolicy="no-referrer"></div></div>就像在 NLP 领域 Transformer 可以有效注意到一个词与上下文的关系一样，在 CV 领域也可以汇总图像的全局特征进行学习。<p></p><p>用于图像分类的<strong>ViT</strong>就此诞生，开启了 Transformer 的跨界刷屏之旅。</p><p>犯错的方式都和人一样</p><p>在普林斯顿大学对比 CNN 和 ViT 的这篇论文中，还建立了<strong>错误一致性</strong>这个指标来对各个模型进行评判。</p><p>从 WordNet 中选取了 16 个概念 ( 如飞机、熊、键盘等 ) 来衡量 CNN 和 ViT 犯错的类型。</p><p></p><div class="img_box" id="id_imagebox_15" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_15" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36e_1024.jpg" data-height="954" data-width="836" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b36e_1024.jpg" referrerpolicy="no-referrer"></div></div>从结果可以看出，ViT 和人类一样，更倾向于通过形状判断物体。<p></p><p>未来趋势</p><p>ViT 问世之初来势汹汹，以至于很多人都在问，注意力机制这是要取代卷积吗？</p><p>从最近的趋势看来，Transformer 在 CV 领域的应用，反倒是刺激了二者的<strong>结合</strong>和<strong>统一</strong>。</p><p>卷积擅长提取<strong>细节</strong>，要掌握全局信息往往需要堆叠很多个卷积层。</p><p>注意力善于把握<strong>整体</strong>，但又需要大量的数据进行训练。</p><p>如果把两者结合起来，是不是能够取长补短？</p><p>把注意力引入 CNN 的有谷歌推出的<strong>BoTNet</strong>就是简单把 ResNet 的最后瓶颈块中的 3x3 卷积替换成全局自注意力，没有别的改变，就在减少开销的情况下提高了性能。</p><p></p><div class="img_box" id="id_imagebox_16" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_16" data-original="http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b36f_1024.jpg" data-height="330" data-width="642" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b36f_1024.jpg" referrerpolicy="no-referrer"></div></div>之后麦吉尔大学和微软又把卷积引入 Transformer 架构的<strong>CvT</strong> ( Convolutional vision Transformers ) ，去除了 Transformer 中的位置编码，提升对于高分辨率视觉任务的效果。<p></p><p></p><div class="img_box" id="id_imagebox_17" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_17" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b370_1024.jpg" data-height="362" data-width="969" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b370_1024.jpg" referrerpolicy="no-referrer"></div></div>最近，谷歌大脑 Quoc Le 团队利用简单的相对注意力把两大架构自然地统一起来，提出了混合模型<strong>CoAtNet</strong>。<p></p><p>看来，强强联合果然不错。</p><p>这还没结束，除了卷积与注意力的协作以外，甚至有人从更高的层面开始尝试将二者统一。</p><p>上海交大和华为的研究，用对卷积特征的变换操作达到近似自注意力的效果，提出全新的算子<strong>X-Volution</strong>，可以在任何现代神经网络结构中使用。</p><p></p><div class="img_box" id="id_imagebox_18" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_18" data-original="http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b371_1024.jpg" data-height="488" data-width="1044" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60fe3b1d8e9f0961e953b371_1024.jpg" referrerpolicy="no-referrer"></div></div>港中文提出更是将 CNN、Transformer 以及 MLP 都统一在一起，提出了用于多头上下文聚合的通用结构<strong>Container</strong>，取得了超越三大架构及混合架构的成绩。<p></p><p></p><div class="img_box" id="id_imagebox_19" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_19" data-original="http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b372_1024.jpg" data-height="1152" data-width="1116" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60fe3b1d8e9f0961e953b372_1024.jpg" referrerpolicy="no-referrer"></div></div><p></p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            