
---
title: '谷歌请印度标注员给Reddit评论数据集打标签，错误率高达30%？'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0bf_1024.jpg'
author: ZAKER
comments: false
date: Mon, 18 Jul 2022 21:46:23 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0bf_1024.jpg'
---

<div>   
<p>机器之心报道</p><p><strong>编辑：蛋酱</strong></p><p>可以确定的是，人工标注员完全没懂 Reddit 网友的梗。</p><p>去年，谷歌发布了 GoEmotions 数据集，该数据集包含 58K 人工标注的 Reddit 评论，其中涉及 27 种情绪。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0bf_1024.jpg" data-height="370" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0bf_1024.jpg" referrerpolicy="no-referrer"></div></div>但一位名叫 Edwin Chen 的机器学习工程师却在使用该数据集的时候，偶然发现了一些令人哭笑不得的错误。<p></p><p>他们本来尝试自己在 GoEmotions 数据集上训练模型，注意到似乎存在一些深层的质量问题。于是他们<strong>随机抽取了 1000 条评论，在其中 308 条中发现了严重错误</strong>。</p><p>这里举一些有代表性的例子：</p><p>aggressively tells friend I love them —— 被标记为「愤怒」</p><p>Yay, cold McDonald's. My favorite. —— 被标记为「喜爱」</p><p>Hard to be sad these days when I got this guy with me —— 被标记为「悲伤」</p><p>Nobody has the money to. What a joke —— 被标记为「愉悦」</p><p>……</p><p>光是从抽取的评论中，他们就统计到了 25 种被错误标记的情绪。</p><p>在人工智能领域，数据标注是一项非常基础，但也非常关键的工作。好的数据对于训练模型至关重要，当数据面临如此离谱的错误时，又该怎么训练模型并评估模型的性能呢？</p><p>Edwin Chen 最后发问：「我们真的可以相信谷歌能够创造出公正的现实世界人工智能吗？」</p><p>所以，是什么导致了这些问题？</p><p>有人说：「有没有可能，他们没请人工标注员，或者请的人工标注员并未掌握流利的英语？」</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c0_1024.jpg" data-height="510" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c0_1024.jpg" referrerpolicy="no-referrer"></div></div>据了解，GoEmotions 数据集的标注还是有人工参与的，只不过这些标注员是「以英语为母语的印度人」。<p></p><p>在论文的第 3.3 节中，有这么一段话：「我们给每个样本分配了三个评估者。对于那些评估者没有达成一致的样本，我们分配了两个额外的评估者。所有评估者都是以英语为母语的印度人。」</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c1_1024.jpg" data-height="338" data-width="994" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c1_1024.jpg" referrerpolicy="no-referrer"></div></div>因为根据「Cowen et al. ( 2019b ) 这项研究的结论，印度和美国两地的英语使用者的情绪判断维度很大程度上是相同的。<p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c2_1024.jpg" data-height="174" data-width="970" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c2_1024.jpg" referrerpolicy="no-referrer"></div></div>事实是，尽管掌握了流利的英语，标注员之中的许多人可能不了解所标注文本的文化、社会背景。但这却是关键要点之一，尤其是对于 NLP 数据集，标注者必须具备充分的文化意识。<p></p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c3_1024.jpg" data-height="953" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c3_1024.jpg" referrerpolicy="no-referrer"></div></div>也就是说，鉴于很多标注员可能缺乏必要的背景知识，即使大多数的数据标注都不存在争议了（如上图），也不代表标注结果就是完全正确的。<p></p><p>造成这种问题的另一个重要原因是，数据集中的数据都没有附加的元数据 ( 比如作者或子版块名称 ) 。原论文中也提到了这一点：</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202207/62d63a238e9f0953781eb0c4_1024.jpg" data-height="534" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62d63a238e9f0953781eb0c4_1024.jpg" referrerpolicy="no-referrer"></div></div><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c5_1024.jpg" data-height="526" data-width="1078" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62d63a238e9f0953781eb0c5_1024.jpg" referrerpolicy="no-referrer"></div></div>语言不是处于真空之中的，它所在的版块等信息非常重要。谷歌在构建数据集时却忽略了这一点。<p></p><p>这不是一个孤立事件：作者还提到，假如连谷歌这种拥有大量资源的公司都难以创建准确的数据集，那么我们见过的其他数据集质量更是难以想象。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202207/62d63a238e9f0953781eb0c6_1024.jpg" data-height="618" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62d63a238e9f0953781eb0c6_1024.jpg" referrerpolicy="no-referrer"></div></div>好消息是，已经有学者关注到了这个问题。上个月，吴恩达发起了「以数据为中心的 AI」倡议，他表示，专注于提升人工智能系统的数据质量将有助于释放其全部力量。<p></p><p>如果你想部署现实中 work 的机器学习模型，是时候关注高质量数据集而不是更大的模型了。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            