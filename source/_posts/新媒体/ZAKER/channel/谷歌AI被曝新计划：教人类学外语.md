
---
title: '谷歌AI被曝新计划：教人类学外语'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://picsum.photos/400/300?random=814'
author: ZAKER
comments: false
date: Fri, 18 Jun 2021 02:21:00 GMT
thumbnail: 'https://picsum.photos/400/300?random=814'
---

<div>   
<p><strong>编译 | 心缘</strong></p><p><strong>编辑 | 漠影</strong></p><p>智东西 6 月 18 日消息，据 The Information 独家报道，谷歌的下一个人工智能行动是教外语。</p><p>谷歌首席执行官 Sundar Pichai 上个月展示了一个人工智能（AI）模型，称该模型将使人们能够与技术进行开放式对话。</p><p>但曾使用过该语言模型的现任和前任员工表示，在人与技术之间实现连贯、自由流畅和准确的对话，仍然是一个艰巨的任务。</p><p>据参与这项工作的人称，因此，谷歌正在通过谷歌搜索教外语，在对话式 AI 方面更进一步。</p><p>该项目内部被称为 Tivoli，由其谷歌研究部门发展而来，可能于今年晚些时候推出。它最初将通过文本工作，无法学习教学的确切外观和感觉。</p><p>谷歌员工还在讨论如何最终将该功能添加到语音助手和 YouTube 产品线中。例如，在 YouTube 上，它能生成语言测验，观众在观看视频后可以自己录制，AI 会对他们表现进行评估。</p><p>谷歌发言人没有对此发表评论。</p><p><b>一、教外语能让谷歌 AI 更健谈</b></p><p>知情人士称，教外语可以让谷歌的 AI 变得将更流畅、更健谈，从愚蠢的交流转变到一个实用但风险较低的案例中。使用错误的时态或短语不太可能对用户造成严重的伤害。</p><p>数十年来，AI 研究人员一直致力于促进计算机和人类之间的对话，让这种对话感觉更加真实，了解人们如何沟通的细微差别，并简化任务。</p><p>谷歌、亚马逊、苹果、微软和三星都开发了自己的虚拟语音助手，他们押注未来人们会希望通过声音来访问和控制科技产品。如今语音助手已经被嵌入手机、音箱、电视、洗衣机、汽车等各种智能设备中。</p><p>但是，除非用户特意编程快捷方式和其他序列，通常这些虚拟助理中的大多数，只能一次完成一项任务。如若不然，复杂的请求和后续问题往往会让语音助手感到困惑。他们还努力反映请求的严肃性或语气，并把握上下文。</p><p><b>二、谷歌的对话式 AI 野心与反垄断忧患</b></p><p>多年来，谷歌在 AI 领域一直处于领先地位，从谷歌大脑到 DeepMind，一直吸引顶级行业人才。LaMDA 由谷歌大脑研究部门研发，是为新搜索工具提供动力的语言模型。</p><p>但谷歌面临着来自其他科技公司的重大竞争，包括 OpenAI，这是一个由微软支持的团队，已经发布了重大突破，如 GPT-3。各种各样的公司正在使用该模型来开发对话式 AI 工具。</p><p>谷歌用户通常使用谷歌搜索来翻译语言。其中一位知情人士说，这加上谷歌在搜索方面的主导地位，引起了一些高管的担忧，即<b>外语教学功能可能会给谷歌带来新的反垄断问题</b>。</p><p>这一 AI 项目的现任和前任员工表示，他们希望通过对话 AI 为语言学习者创造更流畅的交流，使其更容易掌握新语言，从而扩大学习者的收入潜力。</p><p>Tivoli 的开发始于大约两年前，使用早期的神经对话模型 Meena，该模型后来演变为 LaMDA。谷歌将其更名的部分原因是内部担心其名字性别化程度过高，可能导致用户将其与某个人联系起来。</p><p>尽管 Pichai 在谷歌开发者会议上承认，<strong>研究仍处于早期阶段，该技术有局限性，</strong>但 LaMDA 已经可以实现相对自由流畅、连贯的对话。</p><p>在一个例子中，LaMDA 技术从纸飞机的角度来对话，回答了关于被抛向空中的感觉和从上面看世界是什么样子的问题。在另一个令人备受鼓舞的例子中，Pichai 要求视频播放器通过描述场景来快进到电影的特定部分。</p><p>" 它没有把所有事情都做对。有时它会给出荒谬的回应。"Pichai 谈道。此外，LaMDA 只接受过文本训练，而不是人们用来沟通的图像、音频和其他人们用来沟通的媒介。</p><p><b>三、AI 语言模型仍深陷伦理与偏见风波</b></p><p>研究人员认为，AI 和语言模型的进步是断断续续的，部分原因是训练大型模型所需的计算能力，以及人们在说、写和共享多媒体时如何互动的复杂性。</p><p>" 我们所做的就是交谈。" 机器学习平台 Hugging Face 的联合创始人 Clément Delangue 说，" 获得一个与普通人一样好的系统只是一个很高的标准。" 该平台帮助 AI 公司构建自然语言处理模型。</p><p>负责任 AI 的研究人员表示，进一步改善人类与数字助理等技术之间的对话也充满了道德复杂性，因为许多人可能会将数字工具在回答查询时提供的信息视为事实。</p><p>此外，模型本身的好坏取决于提供给它们的数据，这些数据通常来自互联网上的各种来源，包括论坛、新闻文章和其他网站。这意味着人类的偏见和不准确性是根深蒂固的。</p><p>例如，OpenAI 因产生偏见和冒犯性内容而受到批评。OpenAI 的一位发言人称，该公司有专门负责安全和政策的团队，并已开发了一套能改善语言模型行为和减轻有害输出的流程。</p><p>谷歌还一直在努力应对着报复员工的指控，这些员工担心谷歌没有足够认真地重视 AI 道德伦理。</p><p>自去年年底谷歌黑人 AI 研究员 Timnit Gebru 因一篇研究论文发生争议而高调解雇以来，谷歌的 AI 部门经历了一系列离职和领导层的变动。</p><p>谷歌员工及其他研究人员批评了解雇 Gebru 一事，Gebru 曾深入研究道德 AI 和技术偏见，Pichai 为该公司处理这种情况的方式道歉。</p><p><b>结语：对话式 AI 的应用存在风险</b></p><p>华盛顿大学语言学系教授 Emily M. Bender 说，消费者认为对话式 AI 总是会提供准确的答案，这存在风险。</p><p>Bender 是与 Gebru 核心论文的共同撰写者，她提到担心谷歌将 LaMDA 生成明智和连贯的语言的能力置于事实准确性之上。</p><p>" 如果聊天机器人被定义为明显虚构和有趣的东西，那么当然，这是一个有趣或不错的目标顺序。但是，如果它要涉及搜索或回答人们对信息的真实问题，那么事实必须是第一位的。"</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            