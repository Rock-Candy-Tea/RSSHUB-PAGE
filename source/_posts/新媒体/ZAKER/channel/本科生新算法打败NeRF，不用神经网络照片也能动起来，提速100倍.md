
---
title: '本科生新算法打败NeRF，不用神经网络照片也能动起来，提速100倍'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e4_1024.jpg'
author: ZAKER
comments: false
date: Thu, 23 Dec 2021 23:14:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e4_1024.jpg'
---

<div>   
<p>万万没想到，把照片<strong>变 3D</strong>这件事，离了神经网络也是这般丝滑。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e4_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e4_raw.gif" data-height="226" data-width="600" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e4_1024.jpg" referrerpolicy="no-referrer"></div></div>而在此之前，新视角合成这方面的 " 大牛 "，是近两年大火的<strong>NeRF</strong>（神经辐射场）。<p></p><p>它是一个简单的<strong>全连接神经网络</strong>，使用 2D 图像的信息作为训练数据，还原拥有体积的 3D 场景。</p><p>但最近，来自伯克利大学的研究人员提出了一个叫做<strong>Plenoxels</strong>的方法。</p><p>不需要神经网络，仅仅通过梯度下降和正则化便实现了同样的效果，而且速度还快了<strong>100 倍</strong>！</p><p>那么他们是如何做到这点的呢？</p><p><b>由 NeRF 到 Plenoxels 的进化</b></p><p>为了帮助大家理解<strong>Plenoxels</strong>，我们先来简单介绍一下<strong>NeRF</strong>模型。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_1" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e5_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e5_raw.gif" data-height="536" data-width="952" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e5_1024.jpg" referrerpolicy="no-referrer"></div></div><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993e6_1024.jpg" data-height="166" data-width="624" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993e6_1024.jpg" referrerpolicy="no-referrer"></div></div>要准备<strong>NeRF</strong>的数据，我们首先需要一部相机。<p></p><p>拍了很多张各个角度的照片后，沿相机射线将每一张 2D 图片的<strong>坐标</strong>与<strong>视图方向</strong>构成一个 5D 向量 （x, y, z, θ , φ）作为 mlp （多层全连接神经网络）的输入。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993e7_1024.jpg" data-height="207" data-width="624" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993e7_1024.jpg" referrerpolicy="no-referrer"></div></div>我们从图 ( b ) 上可以看到，射线上的点有了颜色，每点的颜色 c = （r, g, b）和密度（σ）就是输出向量。<p></p><p>接着<strong>NeRF</strong>使用体积渲染技术将得到的颜色与密度进行 3D 渲染。</p><p>由于渲染函数是可导的，我们可以最小化合成效果与实际效果的误差，从而进行神经网络参数的优化。</p><p>其中 mlp 使用的参数多可达到 5MB，实际训练起来就会发现训练时间十分漫长，通常要 1-4 天。</p><p>这个速度与<strong>Plenoxels</strong>的 11 分钟相比确实是无法接受的。</p><p>2D 图片变 3D，听起来不是个小工程，<strong>Plenoxels</strong>不用神经网络是如何实现的呢？其实并不复杂。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_4" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e8_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e8_raw.gif" data-height="536" data-width="952" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993e8_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>Plenoxels</strong>发现<strong>NeRF</strong>成功的秘诀其实是它的体积渲染方程，与其最耗时的神经网络关系不大。<p></p><p>那么你一定会好奇这个体积渲染方程究竟是何方神圣，我们就先来看一下。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993e9_1024.jpg" data-height="117" data-width="246" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993e9_1024.jpg" referrerpolicy="no-referrer"></div></div>σ i 代表不透明度，ci 代表颜色，δ i 代表距离。Ti 代表有多少光经过射线上的点 i，是通过密度和距离计算的。<p></p><p>这个体积渲染方程其实就是将射线上每个点的颜色，不透明度，光，还有距离进行了一个整合处理。</p><p>体积渲染方程介绍过了，那么不需要神经网络的<strong>Plenoxels</strong>是如何表示图片的呢？</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ea_1024.jpg" data-height="160" data-width="517" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ea_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>Plenoxels</strong>首先重建了一个稀疏的体素表格，每个被占用的体素都带有<strong>不透明度</strong>和<strong>球谐系数</strong>。<p></p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_7" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993eb_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993eb_raw.gif" data-height="531" data-width="948" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993eb_1024.jpg" referrerpolicy="no-referrer"></div></div>我们的颜色信息就存储在这些<strong>球谐系数</strong>中，每个颜色通道需要 9 个系数表示，一共有三个颜色，那么每个体素就需要 27 个<strong>球谐系数</strong>来表示它的颜色。<p></p><p>相机射线经过的每个点的颜色和不透明度，就是通过其最近处的 8 个体素的三线性插值计算的。</p><p>接着与<strong>NeRF</strong>一样，使用体积渲染技术将得到的颜色与不透明度进行 3D 渲染。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_8" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993ec_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993ec_raw.gif" data-height="531" data-width="948" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993ec_1024.jpg" referrerpolicy="no-referrer"></div></div><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993ed_1024.jpg" data-height="157" data-width="285" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993ed_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>Plenoxels</strong>通过对渲染的像素的<strong>平均平方误差</strong>（MSE）进行最小化，来优化体素的不透明度和球谐系数，并且使用<strong>TV 正则化</strong>帮助消除噪声。<p></p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ee_1024.jpg" data-height="144" data-width="352" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ee_1024.jpg" referrerpolicy="no-referrer"></div></div>我们可以看出，是否使用<strong>TV 正则化</strong>的效果区别还是很大的！<p></p><p><b>提速 100 倍，仅需 11 分钟</b></p><p>我们用最直观的方法对比一下两个模型速度上的差距。</p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_11" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ef_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ef_raw.gif" data-height="536" data-width="952" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993ef_1024.jpg" referrerpolicy="no-referrer"></div></div>看到了吗，只用几秒<strong>Plenoxels</strong>就可以达到一个比较清晰的效果，而<strong>NeRF</strong>只有一个模糊的影子。<p></p><p>同样是单个场景，<strong>NeRF</strong>使用型号为 v100 的单个 GPU 训练需要耗时 1-2 天，而<strong>Plenoxels</strong>使用单个 GPU 通常只需要 11 分钟。</p><p>这时有一个问题一定萦绕在你的脑海里，速度提升了这么多，效果真的不会受影响吗？</p><p>空口无凭，我们还是要用数据说话。</p><p></p><div class="img_box" id="id_imagebox_12" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_12" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993f0_1024.jpg" data-height="224" data-width="382" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993f0_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>PSNR</strong>（峰值信噪比）：是最普遍，最广泛使用的评鉴画质的客观量测法，PSNR 值越大，就代表失真越少。<p></p><p><strong>SSIM</strong>（结构相似性）：衡量实际图像和合成图像的相似度，当两张图像一模一样时，SSIM 的值等于 1。</p><p><strong>LPIPS</strong>（学习感知图像块相似度）：用于度量实际图像和合成图像之间的差别，值越低代表图片越相似。</p><p>可以看到<strong>Plenoxels</strong>对比其他模型的表现不说样样最好，但也绝不落后他人，关键在于它的速度整整快了<strong>两个数量级</strong>！</p><p></p><div class="img_box" id="id_imagebox_13" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_13" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993f1_1024.jpg" data-height="927" data-width="850" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993f1_1024.jpg" referrerpolicy="no-referrer"></div></div>正因为<strong>Plenoxels</strong>速度上的大幅提升，使得一些目前处于瓶颈的下游应用变得可能，例如<strong>多次反射照明</strong>（multi-bounce lighting）和<strong>大型场景的 3D 建模</strong>（3D generative models）。<p></p><p>如果能在相机和体素散列上进行有效优化，模型甚至可以让端到端三维重建成为拥有<strong>pipeline</strong>的实际应用。</p><p>相信<strong>Plenoxels</strong>的潜力不仅于此，让我们一起期待它落地后的成果吧！</p><p><b>UC 伯克利本科生一作</b></p><p>效果强劲的<strong>Plenoxels</strong>来自 UC 伯克利的学生团队，一作<strong>Alex Yu</strong>还是一名<strong>本科生</strong>。</p><p>在大学里，他不仅同时学习<strong>计算机</strong>和<strong>应用数学</strong>两门专业，还在伯克利的<strong>BAIR</strong>（ Berkeley Artificial Intelligence Research）实验室进行 3D 计算机视觉的相关研究。</p><p></p><div class="img_box" id="id_imagebox_14" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_14" data-original="http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993f2_1024.jpg" data-height="381" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61c5657b8e9f0973882993f2_1024.jpg" referrerpolicy="no-referrer"></div></div>Alex 计划在 2022 的秋季开始他的<strong>PhD</strong>旅程，让人不禁感叹 AI 界真是人才辈出。<p></p><p>在未来经过 PhD 的学习后，他又会迸发出怎样的能量呢，让我们一起拭目以待吧！</p><p><b>GitHub 代码开源</b></p><p>目前，<strong>Plenoxels</strong>项目的代已经在 GitHub 上开源。</p><p></p><div class="img_box" id="id_imagebox_15" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_15" data-original="http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993f3_1024.jpg" data-height="306" data-width="624" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61c5657b8e9f0973882993f3_1024.jpg" referrerpolicy="no-referrer"></div></div>小伙伴们要注意的是，拍摄照片的时候要尽可能环绕物体，并且尝试不同的高度哦。<p></p><p>快来试试效果如何吧！</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            