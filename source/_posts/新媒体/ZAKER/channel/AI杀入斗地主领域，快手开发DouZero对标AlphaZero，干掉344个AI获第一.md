
---
title: 'AI杀入斗地主领域，快手开发DouZero对标AlphaZero，干掉344个AI获第一'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa5a_1024.jpg'
author: ZAKER
comments: false
date: Fri, 18 Jun 2021 01:07:33 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa5a_1024.jpg'
---

<div>   
<p>AlphaGo 在围棋界大杀四方时就有人不服：有本事让 AI 斗地主试试？</p><p>试试就试试。</p><p>快手团队开发的斗地主 AI 命名为<strong>DouZero</strong>，意思是像 AlphaZero 一样<strong>从零开始</strong>训练，不需要加入任何人类知识。</p><p>只用 4 个 GPU，短短几天的训练时间，就在 Botzone 排行榜上的 344 个斗地主 AI 中<strong>排名第一</strong>。</p><p>而且还有<strong>在线试玩</strong>（链接在文章最后），手机也能运行。</p><p>在线试玩中演示的是<strong>三人斗地主</strong>，玩家可以选择扮演地主、地主的上家或下家。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa5a_1024.jpg" data-height="1157" data-width="1920" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa5a_1024.jpg" referrerpolicy="no-referrer"></div></div>选择当地主来玩玩看，可以打开显示 AI 手牌功能，更容易观察 AI 决策过程。另外可以设置 AI 考虑时间，默认是 3 秒。<p></p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5b_1024.jpg" data-height="1050" data-width="1396" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5b_1024.jpg" referrerpolicy="no-referrer"></div></div>在 AI 的回合，会显示面临的决策和每种打法的预测胜率。<p></p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa5c_1024.jpg" data-height="1033" data-width="1920" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa5c_1024.jpg" referrerpolicy="no-referrer"></div></div>有时可以看到 AI 并不是简单的选择当前胜率最高的打法，而是有更全局的考虑。<p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5d_1024.jpg" data-height="1060" data-width="1384" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5d_1024.jpg" referrerpolicy="no-referrer"></div></div>斗地主对 AI 来说，很难<p></p><p>从博弈论的角度看，斗地主是 "<strong>不完全信息博弈</strong>"。</p><p>围棋是所有棋子都摆在棋盘上，对弈双方都能看到的完全信息博弈。</p><p>而斗地主每个玩家都看不到其他人的手牌，对于 AI 来说更有挑战性。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5e_1024.jpg" data-height="305" data-width="250" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5e_1024.jpg" referrerpolicy="no-referrer"></div></div>在棋牌类游戏中，虽然斗地主的<strong>信息集</strong>的大小和数量不如麻将，但行动空间有 10^4，与德州扑克相当，而大多数强化学习模型只能处理很小的行动空间。<p></p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5f_1024.jpg" data-height="1104" data-width="1668" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa5f_1024.jpg" referrerpolicy="no-referrer"></div></div>斗地主的所有牌型总共有 27472 种可能。<p></p><p>像下图的手牌就有 391 种打法。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa61_1024.jpg" data-height="252" data-width="610" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa61_1024.jpg" referrerpolicy="no-referrer"></div></div>且斗地主的行动不容易被<strong>抽象化</strong>，使搜索的计算成本很高，像 Deep Q-Learning 和 A3C 等强化学习模型都只有<strong>不到 20%</strong>的胜率。<p></p><p>另外作为不对称游戏，几个农民要在沟通手段有限的情况下合作并与地主对抗。</p><p>像扑克游戏中最流行的 "<strong>反事实后悔最小化</strong>" ( Counterfactual Regret Minimization ) 算法，就不擅长对这种竞争和合作建模。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa62_1024.jpg" data-height="610" data-width="500" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa62_1024.jpg" referrerpolicy="no-referrer"></div></div>全局、农民和地主网络并行学习<p></p><p>首先将手牌状态编码成 4x15 的独热 ( one-hot ) 矩阵，也就是 15 种牌每种最多能拿到 4 张。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa63_1024.jpg" data-height="406" data-width="618" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa63_1024.jpg" referrerpolicy="no-referrer"></div></div>DouZero 是在 Deep Q-Learning 的基础上进行改进。<p></p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa64_1024.jpg" data-height="438" data-width="648" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202106/60cc3f048e9f0953323eaa64_1024.jpg" referrerpolicy="no-referrer"></div></div>使用 LSTM ( 长短期记忆神经网络 ) 编码历史出牌，独热矩阵编码预测的牌局和当前手牌，最终用 6 层，隐藏层维度为 512 的 MLP ( 多层感知机 ) 算出 Q 值，得出打法。<p></p><p>除了 " 学习者 " 全局网络以外，还用 3 个 " 角色 " 网络分别作为地主、地主的上家和下家进行并行学习。全局和本地网络之间通过共享缓冲区定期通信。</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa65_1024.jpg" data-height="818" data-width="1334" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa65_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>△</strong>学习者和角色的算法<p></p><p>DouZero 在 48 个内核和 4 个 1080Ti 的一台服务器上训练 10 天击败了之前的冠军，成为最强斗地主 AI。</p><p>下一步，加强 AI 间的协作</p><p>对于之后的工作，DouZero 团队提出了几个方向：</p><p>一是尝试用 ResNet 等 CNN 网络来代替 LSTM。</p><p>以及在强化学习中尝试 Off-Policy 学习，将目标策略和行为策略分开以提高训练效率。</p><p>最后还要明确的对农民间合作进行建模。好家伙，以后 AI 也会给队友倒卡布奇诺了。</p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_11" data-original="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa66_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa66_raw.gif" data-height="173" data-width="307" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202106/60cc3f048e9f0953323eaa66_1024.jpg" referrerpolicy="no-referrer"></div></div>柯洁在围棋被 AlphaGO 击败以后，2019 年参加了斗地主锦标赛获得了冠军。<p></p><p>不知道会不会有 AI" 追杀 " 过来继续挑战他。</p><p>在线试玩：</p><p>https://www.douzero.org</p><p>GitHub 项目地址：</p><p>https://github.com/kwai/DouZero</p><p>论文地址：</p><p>https://arxiv.org/pdf/2106.06135.pdf</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            