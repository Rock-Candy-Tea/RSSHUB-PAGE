
---
title: '首次超越人类！_读图会意_这件事，AI比你眼睛更毒辣'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1149_1024.jpg'
author: ZAKER
comments: false
date: Fri, 13 Aug 2021 21:06:24 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1149_1024.jpg'
---

<div>   
<p>在<strong>超越人类</strong>这件事上，AI 又拿下一分。</p><p>就在最近，国际权威机器视觉问答榜单<strong>VQA Leaderboard</strong>，更新了一项数据：</p><p>AI 在 " 读图会意 " 任务中，准确率达到了<strong>81.26%</strong>。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1149_1024.jpg" data-height="739" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1149_1024.jpg" referrerpolicy="no-referrer"></div></div>要知道，我们<strong>人类</strong>在这个任务中的基准线，也才<strong>80.83%</strong>。<p></p><p>而解锁这一成就的，是来自阿里巴巴达摩院团队的<strong>AliceMind-MMU</strong>。</p><p>而此举也就意味着，AI 于 2015 年、2018 年分别在视觉识别和文本理解超越人类之后，在多模态技术方面也取得了突破！</p><p><b>AI 比你更会看图</b></p><p>这个 AI 有多会看图？</p><p>来看下面几个例子就知道了。</p><p>当你问 AI：" 这些玩具用来做什么的？"</p><p>它就会根据小熊穿的礼服，回答道：</p><p><strong>婚礼。</strong></p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a114a_1024.jpg" data-height="820" data-width="1000" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a114a_1024.jpg" referrerpolicy="no-referrer"></div></div>给 AI 再提一个问题：" 男人的橄榄球帽代表哪只球队？"<p></p><p>它会根据帽子中的 "B" 字母回答：</p><p><strong>波士顿球队</strong>。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114b_1024.jpg" data-height="752" data-width="994" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114b_1024.jpg" referrerpolicy="no-referrer"></div></div>加大挑战难度再来一个。<p></p><p>" 图中玩具人的 IP 出自哪部电影？"</p><p>这时候，AI 就会根据图中的玩具，还有战斗场景等信息，做一个推理。</p><p>不过最后还是精准的给出了答案：</p><p><strong>星球大战</strong>。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a114c_1024.jpg" data-height="708" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a114c_1024.jpg" referrerpolicy="no-referrer"></div></div>再例如下面这些例子中，AI 都会捕捉图片中的细节信息，来精准回答提出的问题。<p></p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114d_1024.jpg" data-height="533" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114d_1024.jpg" referrerpolicy="no-referrer"></div></div>嗯，可以说是细致入微了。<p></p><p><b>怎么做到的？</b></p><p>可能上面的这些案例，对于人类来说并不是很困难。</p><p>但对于 AI 来说，可不是件容易的事情。</p><p>一个核心难点就是：</p><p>需要在单模态精准理解的基础上，整合多模态的信息进行联合推理认知，最终实现跨模态理解。</p><p>怎么破？</p><p>阿里达摩院的做法是，对 AI 视觉 - 文本推理体系进行了系统性的设计，融合了大量的创新算法。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114e_1024.jpg" data-height="619" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114e_1024.jpg" referrerpolicy="no-referrer"></div></div>具体来看，大致可以分为四个内容：<p></p><p><strong>多样性的视觉特征表示</strong>：从各方面刻画图片的局部和全局语义信息，同时使用 Region，Grid，Patch 等视觉特征表示，可以更精准地进行单模态理解；</p><p><strong>基于海量图文数据和多粒度视觉特征的多模态预训练</strong>：用于更好地进行多模态信息融合和语义映射，提出了 SemVLP、Grid-VLP、E2E-VLP 和 Fusion-VLP 等预训练模型。</p><p><strong>自适应的跨模态语义融合和对齐技术</strong>：在多模态预训练模型中加入 Learning to Attend 机制，来进行跨模态信息地高效深度融合。</p><p><strong>Mixture of Experts ( MOE）技术</strong>：进行知识驱动的多技能 AI 集成。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114f_1024.jpg" data-height="1074" data-width="1014" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a114f_1024.jpg" referrerpolicy="no-referrer"></div></div>据了解，模型中涉及技术还得到了专业的认可。<p></p><p>例如多模态预训练模型 E2E-VLP，已经被国际顶级会议 ACL2021 接受。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a1150_1024.jpg" data-height="554" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/61174aa0b15ec04c2a1a1150_1024.jpg" referrerpolicy="no-referrer"></div></div>关于 VQA<p></p><p><b></b></p><p>VQA，可以说是 AI 领域难度最高的挑战之一。</p><p>而对于单一 AI 模型来说，VQA 考卷难度堪称 " 变态 "。</p><p>在测试中，AI 需要根据给定图片及自然语言问题，生成正确的自然语言回答。</p><p>这意味着单个 AI 模型，需要融合复杂的计算机视觉及自然语言技术：</p><p>首先对所有图像信息进行扫描。</p><p>再结合对文本问题的理解，利用多模态技术学习图文的关联性、精准定位相关图像信息。</p><p>最后根据常识及推理回答问题。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1151_1024.jpg" data-height="473" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1151_1024.jpg" referrerpolicy="no-referrer"></div></div>但解决 VQA 的挑战，对研发通用人工智能具有重要意义。<p></p><p>因此，全球计算机视觉顶会 CVPR 从 2015 年起连续 6 年举办 VQA 挑战赛。</p><p>吸引了包括微软、Facebook、斯坦福大学、阿里巴巴、百度等众多顶尖机构参与。</p><p>同时，也形成了国际上规模最大、认可度最高的 VQA 数据集，其包含超 20 万张真实照片、110 万道考题。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1152_1024.jpg" data-height="711" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/61174aa0b15ec04c2a1a1152_1024.jpg" referrerpolicy="no-referrer"></div></div>据了解，今年 6 月，阿里达摩院在 VQA 2021 Challenge 的 55 支提交队伍中夺冠，成绩领先第二名约 1 个百分点、去年冠军 3.4 个百分点。<p></p><p>而仅仅在 2 个月后的今天，达摩院再次以 81.26% 的准确率创造 VQA Leaderboard 全球纪录。</p><p>达摩院对此评价道：</p><p>这一结果意味着，AI 在封闭数据集内的 VQA 表现已媲美人类。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            