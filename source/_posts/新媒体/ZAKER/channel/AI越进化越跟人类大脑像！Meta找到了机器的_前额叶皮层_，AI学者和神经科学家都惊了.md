
---
title: 'AI越进化越跟人类大脑像！Meta找到了机器的_前额叶皮层_，AI学者和神经科学家都惊了'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c123_1024.jpg'
author: ZAKER
comments: false
date: Mon, 20 Jun 2022 00:10:22 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c123_1024.jpg'
---

<div>   
<p>说出来你可能不信，有一只 AI 刚刚被证明，处理语音的方式跟<strong>大脑</strong>谜之相似。</p><p>甚至在<strong>结构</strong>上都能相互对应——</p><p>科学家们在 AI 身上直接定位出了 " 视觉皮层 "。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c123_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c123_raw.gif" data-height="287" data-width="480" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c123_1024.jpg" referrerpolicy="no-referrer"></div></div>这项来自<strong>Meta AI</strong>等机构的研究一经 po 出，立马在社交媒体上炸开了锅。一大波神经科学家和 AI 研究者前往围观。<p></p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c124_1024.jpg" data-height="529" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c124_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>LeCun</strong>称赞这是 " 出色的工作 "：自监督 Transformer 分层活动与人类听觉皮层活动之间，确实密切相关。<p></p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c125_1024.jpg" data-height="678" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c125_1024.jpg" referrerpolicy="no-referrer"></div></div>还有网友趁机调侃：Sorry 马库斯，但 AGI 真的快要来了。<p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c126_1024.jpg" data-height="444" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c126_1024.jpg" referrerpolicy="no-referrer"></div></div>不过，研究也引发了一些学者的好奇。<p></p><p>例如麦吉尔大学神经科学博士 Patrick Mineault 提出疑问：</p><p>我们发表在 NeurIPS 的一篇论文中，也尝试过将 fMRI 数据和模型联系起来，但当时并不觉得这俩有啥关系。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c127_1024.jpg" data-height="289" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c127_1024.jpg" referrerpolicy="no-referrer"></div></div>所以，这到底是一项怎样的研究，它又是如何得出 " 这只 AI 干起活来像大脑 " 的结论的？<p></p><p><b>AI 学会像人脑一样工作</b></p><p>简单来说，在这项研究中，研究人员聚焦语音处理问题，将自监督模型<strong>Wav2Vec 2.0</strong>同<strong>412 名</strong>志愿者的大脑活动进行了比较。</p><p>这 412 名志愿者中，有 351 人说英语，28 人说法语，33 人说中文。研究人员给他们听了大约 1 个小时的有声书，并在此过程中用 fMRI 对他们的大脑活动进行了记录。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c128_1024.jpg" data-height="675" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c128_1024.jpg" referrerpolicy="no-referrer"></div></div>模型这边，研究人员则用超过 600 小时的无标签语音来训练 Wav2Vec 2.0。<p></p><p>对应志愿者的母语，模型也分为英语、法语、中文三款，另外还有一款是用非语音声学场景数据集训练的。</p><p>而后这些模型也听了听志愿者同款有声书。研究人员从中提取出了模型的激活。</p><p>相关性的评价标准，遵照这个公式：</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c129_1024.jpg" data-height="90" data-width="976" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c129_1024.jpg" referrerpolicy="no-referrer"></div></div>其中，X 为模型激活，Y 为人类大脑活动，W 为标准编码模型。<p></p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12a_1024.jpg" data-height="358" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12a_1024.jpg" referrerpolicy="no-referrer"></div></div>从结果来看，<strong>自监督学习确实让 Wav2Vec 2.0 产生了类似大脑的语音表征</strong>。<p></p><p>从上图中可以看到，在初级和次级听觉皮层，AI 明显预测到了几乎所有皮层区域的大脑活动。</p><p>研究人员还进一步发现了 AI 的 " 听觉皮层 "、" 前额叶皮层 " 到底长在哪一层。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12b_1024.jpg" data-height="777" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12b_1024.jpg" referrerpolicy="no-referrer"></div></div>图中显示，听觉皮层与 Transformer 的第一层（蓝色）最吻合，而前额叶皮层则与 Transformer 的最深一层（红色）最吻合。<p></p><p>此外，研究人员量化分析了人类感知母语和非母语音素的能力差异，并与 Wav2Vec 2.0 模型进行对比。</p><p>他们发现，AI 也像人类一样，对 "<strong>母语</strong>" 有更强的辨别能力，比如，法语模型就比英语模型更容易感知来自法语的刺激。</p><p>上述结果证明了，<strong>600 小时</strong>的自监督学习，就足以让 Wav2Vec 2.0 学习到语言的特定表征——这与婴儿在学说话的过程中接触到的 " 数据量 " 相当。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12c_1024.jpg" data-height="577" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12c_1024.jpg" referrerpolicy="no-referrer"></div></div>要知道，之前 DeepSpeech2 论文认为，至少需要<strong>10000 小时</strong>的语音数据（还得是标记的那种），才能构建一套不错的语音转文字（STT）系统。<p></p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12d_1024.jpg" data-height="328" data-width="372" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12d_1024.jpg" referrerpolicy="no-referrer"></div></div><b>再次引发神经科学和 AI 界讨论</b><p></p><p>对于这项研究，有学者认为，它确实做出了一些新突破。</p><p>例如，来自谷歌大脑的 Jesse Engel 称，这项研究将可视化滤波器提升到了一个新的层次。</p><p>现在，不仅能看到它们在 " 像素空间 " 里长啥样，连它们在 " 类脑空间 " 中的模样也能模拟出来了：</p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_11" data-original="http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c12e_1024.jpg" data-height="247" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c12e_1024.jpg" referrerpolicy="no-referrer"></div></div>又例如，前 MILA 和谷歌研究员 Joseph Viviano 认为，这个研究还证明了 fMRI 中的静息态（resting-state）成像数据是有意义的。<p></p><p></p><div class="img_box" id="id_imagebox_12" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_12" data-original="http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12f_1024.jpg" data-height="960" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b01d538e9f093a2628c12f_1024.jpg" referrerpolicy="no-referrer"></div></div>但在一片讨论中，也出现了一些质疑的声音。<p></p><p>例如，神经科学博士 Patrick Mineault 除了指出自己做过相似研究但没得出结论外，也给出了自己的一些质疑。</p><p></p><div class="img_box" id="id_imagebox_13" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_13" data-original="http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c130_1024.jpg" data-height="625" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c130_1024.jpg" referrerpolicy="no-referrer"></div></div>他认为，这篇研究并没有真正证明它测量的是 " 语音处理 " 的过程。<p></p><p>相比于人说话的速度，fMRI 测量信号的速度其实非常慢，因此贸然得出 "Wav2vec 2.0 学习到了大脑的行为 " 的结论是不科学的。</p><p>当然，Patrick Mineault 表示自己并非否认研究的观点，他自己也是 " 作者的粉丝之一 "，但这项研究应该给出一些更有说服力的数据。</p><p><strong></strong>此外也有网友认为，Wav2vec 和人类大脑的输入也不尽相同，一个是经过处理后的波形，但另一个则是原始波形。</p><p></p><div class="img_box" id="id_imagebox_14" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_14" data-original="http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c131_1024.jpg" data-height="261" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c131_1024.jpg" referrerpolicy="no-referrer"></div></div>对此，作者之一、Meta AI 研究员 Jean-R é mi King 总结：<p></p><p>模拟人类水平的智能，确实还有很长的路要走。但至少现在来看，我们或许走在了一条正确的道路上。</p><p></p><div class="img_box" id="id_imagebox_15" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_15" data-original="http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c132_1024.jpg" data-height="306" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62b01d538e9f093a2628c132_1024.jpg" referrerpolicy="no-referrer"></div></div>你认为呢？<p></p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            