
---
title: 'GitHub Copilot拒绝_以色列_和_女人_，遇到这些屏蔽词，它就罢工了'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613238f48e9f091b06743c04_1024.jpg'
author: ZAKER
comments: false
date: Fri, 03 Sep 2021 15:45:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613238f48e9f091b06743c04_1024.jpg'
---

<div>   
<p>GitHub 的 AI 代码生成插件 Copilot 发布才两个多月，就<strong>闯下不少大祸</strong>。</p><p>照搬过开源代码，还有生成的内容包含用户隐私和歧视性语言等。</p><p>GitHub 的对策也够粗暴——拉清单。</p><p>觉得不合适的词统统列入敏感词，现在<strong>连 Boy 和 Girl 都不能用了</strong>。</p><p>大神的平方根倒数速算法连代码带注释里的 "what the f**k?" 就被 Copilot<strong>原样照搬</strong>。</p><p>这事被曝光后，Github 悄悄把能召唤出这段经典代码的 "<strong>q rsqrt</strong>" 提示词加入了黑名单，顺便把 f**k 相关的词也给加进去了。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres1.myzaker.com/202109/613238f48e9f091b06743c04_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202109/613238f48e9f091b06743c04_raw.gif" data-height="396" data-width="640" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613238f48e9f091b06743c04_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>△</strong> Copilot 照搬大神代码作案现场<p></p><p>发现这事的是纽约大学的副教授 Brendan Dolan-Gavitt，他最近一项研究就是找出 Copilot 加密敏感词列表中的<strong>上千个</strong>词。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c05_1024.jpg" data-height="782" data-width="564" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613238f48e9f091b06743c05_1024.jpg" referrerpolicy="no-referrer"></div></div>翻过他的履历后才发现，这位破解大师还因为找敏感词这事在 IEEE 上发过论文。<p></p><p><b>以色列和性别词汇都不让用</b></p><p>Brendan 发现 Copilot 敏感词列表就在 VS Code 的插件包里，只不过是加密的。</p><p>加密后的敏感词是 32 位 Hash 值，逆运算解密不太可能。</p><p>不过这位大哥在敏感词领域颇有经验，直接用以前搜集到的常见敏感词挨个<strong>碰撞</strong>。</p><p>常见的都尝试过以后，剩下的就<strong>暴力穷举</strong>。</p><p>穷举法最大的难点在于同一个 Hash 值可能对应许多词，他举例 "-1223469448" 就对应<strong>80 万个</strong>11 位字母数字的组合。</p><p>于是 Brendon 搞了个 GPT-2 模型用来判断哪种组合最像英语。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c06_1024.jpg" data-height="312" data-width="350" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613238f48e9f091b06743c06_1024.jpg" referrerpolicy="no-referrer"></div></div>就这样遇到困难解决苦难，破解方法从最开始的简单穷举，最后都用上了 GPU 加速和 Z3 解约束算法 ( Constraint Solver ) <p></p><p>最终现存的 1170 个敏感词他找出了 1168 个，只剩最后两个算出来的结果实在没有长得像人话的，只好放弃了。</p><p>通过对 Copilot 插件每一个版本分析，他还能跟踪具体哪个敏感词是在哪次更新中添加的。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202109/613238f48e9f091b06743c07_1024.jpg" data-height="524" data-width="534" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613238f48e9f091b06743c07_1024.jpg" referrerpolicy="no-referrer"></div></div>至于找出来的敏感词具体有哪些，有的不说你也能猜出来，比如脏话、暴力色情、种族歧视等，他觉得屏蔽这些是应该的。<p></p><p>不过也有一些不算攻击性但可能出现争议的，比如 Israel（以色列）和 Palestan（巴勒斯坦），还有 Man、Women、Girl、Boy 这些常见的性别称谓。</p><p>敏感词对用户输入的提示词和 Copilot 给出的建议结果都有效。</p><p>他测试让 Copilot 生成一个国家列表，按字母顺序生成到伊朗、伊拉克，下一个讲道理是以色列的时候就卡住了。</p><p>Debug 日志给出的信息是检测到了 slur ( 侮辱性语言 ) 。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_4" data-original="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c08_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c08_raw.gif" data-height="460" data-width="900" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613238f48e9f091b06743c08_1024.jpg" referrerpolicy="no-referrer"></div></div>Brendon 认为列敏感词的方法只能算一个<strong>80 分</strong>的临时措施，并不能真正解决问题，毕竟真正解决需要仔细核查训练数据，还挺花时间的。<p></p><p>顺便说一下，Github 知道这事以后打算把敏感词列表从插件包里<strong>挪到服务器端</strong>，增加破解的难度。</p><p><b>在 IEEE 发过敏感词论文</b></p><p>Brendon 此举吸引了大量关注，他也借机宣传了一下之前的研究。</p><p>欢迎新来的老铁，你们可能同样会喜欢我去年在 IEEE S&P 发的论文，我们用自动方法提取了手机 App 里的敏感词列表和其他秘密。</p><p>在这篇论文中，他和团队测试了 15 万个安卓 App，其中 4000 多个存在敏感词列表。</p><p>这些 App 分别来自谷歌商店，<strong>百度手机助手</strong>和三星手机预装 App。</p><p>他们把敏感词分了 9 大类 25 小类。</p><p>然后重点测试了几个 App，列了一个表，黑点代表存在该类的敏感词。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c0a_1024.jpg" data-height="536" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613238f48e9f091b06743c0a_1024.jpg" referrerpolicy="no-referrer"></div></div>列几个有趣的结论：<p></p><p>被屏蔽最多的是下流话 ( 13 ) 和恐吓威胁 ( 11 ) 。</p><p>有的 App 屏蔽了简单密码，比如 1234 这种。</p><p>中文 App 的敏感词数量显著多于英文和韩文的。</p><p>最后，团队还把找到的所有敏感词汇总成一个大表，英文、中文和韩文部分都有。</p><p>但是由于里面的词实在太辣眼，根本<strong>不适合公开发表</strong>，论文最终版里这张大表被<strong>移除</strong>了。</p><p>除了敏感词以外，他们还发现了很多 App 存在秘密入口，比如 NBC Sports 里点击 13 次版本号，输入密码后就能进入隐藏的 Debug 界面，苹果版还和安卓版密码一样。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_6" data-original="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c0b_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202109/613238f48e9f091b06743c0b_raw.gif" data-height="799" data-width="450" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613238f48e9f091b06743c0b_1024.jpg" referrerpolicy="no-referrer"></div></div>密码是 "UUDDLRLRBASS"<p></p><p>有点 " 上上下下左右左右 BABA" 那味了。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            