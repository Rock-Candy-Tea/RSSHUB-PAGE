
---
title: '苹果遭火速打脸：照片扫描AI被逆向工程，英特尔工程师发现漏洞'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/611df841b15ec00da85ce7dd_1024.jpg'
author: ZAKER
comments: false
date: Wed, 18 Aug 2021 23:08:10 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/611df841b15ec00da85ce7dd_1024.jpg'
---

<div>   
<p>没想到苹果被打脸来得如此之快。</p><p>月初，苹果表示将在 iOS 15、macOS 12 中加入对用户照片的检测，目的是遏制儿童色情与虐童照片的传播。</p><p>苹果还一再强调这项技术的安全性和准确性。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202108/611df841b15ec00da85ce7dd_1024.jpg" data-height="538" data-width="780" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202108/611df841b15ec00da85ce7dd_1024.jpg" referrerpolicy="no-referrer"></div></div>现在，不到半个月的时间，苹果的这项技术已经被一位名为 Asuhariet Ygvar 程序员 " 破解 " 了。<p></p><p>他成功将这个尚未正式发布的 AI 模型逆向工程，并在 GitHub 上提供转化成 Python 的教程。</p><p>几个小时后，另一位来自英特尔的工程师就发现了该模型的一个 bug。</p><p>这让苹果十分尴尬。</p><p>Ygvar 发现，其实早在<strong>iOS 11.3</strong>、<strong>macOS 11.4</strong>开始，就已经在系统中加入了照片检测模型 NeuralHash，只不过尚未启用。</p><p>因此任何可以下载到苹果系统固件的人，都可以轻松将 NeuralHash 模型提取出来。</p><p><b>如何提取 NeuralHash 模型</b></p><p>对于 macOS 用户或者已经越狱的 iOS 用户来说，找到 NeuralHash 模型文件非常方便，就在以下路径中：</p><p>/System/Library/Frameworks/Vision.framework/Resources/ （macOS）</p><p>/System/Library/Frameworks/Vision.framework/ （iOS）</p><p>你会发现 neuralhash 开头的 4 个文件：</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202108/611df841b15ec00da85ce7de_1024.jpg" data-height="164" data-width="634" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/611df841b15ec00da85ce7de_1024.jpg" referrerpolicy="no-referrer"></div></div>至于未越狱的用户，可以下载 ipsw 格式刷机文件，找到其中最大的 dmg 文件，从这个镜像中找到模型。<p></p><p>由于步骤较多，在此不再赘述，具体操作看参照文末 GitHub 文档操作。</p><p><b>如何逆向工程</b></p><p>在这 4 个文件中，net 和 shape 结尾的文件都是 json 格式，使用苹果开源技术 LZFSE 压缩；weights 保存的是权重。</p><p>解压前首先需安装 LZFSE 解压工具：</p><p>brew install lzfse</p><p>将 net 和 shape 解压，和权重文件放在一个文件夹中：</p><p>dd if=NeuralHashv3b-current.espresso.net bs=4 skip=7 | lzfse -decode -o model.espresso.net</p><p>dd if=NeuralHashv3b-current.espresso.shape bs=4 skip=7 | lzfse -decode -o model.espresso.shape</p><p>cp NeuralHashv3b-current.espresso.weights model.espresso.weights</p><p>为了把模型转换为 ONNX 格式，还要安装以下依赖项：</p><p>pip install onnx coremltools</p><p>转换模型时，Ygvar 使用了腾讯优图实验室的 TNN，这是一款可以转换多种 AI 模型的开源工具，可以将苹果的 Core ML 转为 ONNX 格式。</p><p>cd ..</p><p>git clone https://github.com/AsuharietYgvar/TNN.git</p><p>cd TNN</p><p>python3 tools/onnx2tnn/onnx-coreml/coreml2onnx.py ../NeuralHash</p><p>模型转化为 ONNX 格式后，就可以算出任何图片的 96bit 神经哈希值。</p><p>ab14febaa837b6c1484c35e6</p><p><b>NeuralHash 如何工作</b></p><p>说到这里，苹果的 NeuralHash 具体是如何生成图片哈希值的？</p><p>NeuralHash 是一种基于神经网络的图像<strong>感知哈希</strong>（perceptual hashing）方法，具体步骤如下：</p><p>将图像转换为 RGB；</p><p>将图像大小调整为 360x360；</p><p>将 RGB 值归一化到 [ -1, 1 ] 范围；</p><p>用 NeuralHash 模型进行推理；</p><p>将运算得到 128 个浮点数的向量与 96x128 矩阵相乘；</p><p>对生成的 96 个浮点向量使用单位阶跃函数；</p><p>将 1.0 和 0.0 的向量转换为位，生成 96 位二进制数据。</p><p>这项技术保证图像被压缩或者大小被调整的情况下，哈希值依旧不变。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202108/610cd3138e9f090a0412cfd1_1024.jpg" data-height="409" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/610cd3138e9f090a0412cfd1_1024.jpg" referrerpolicy="no-referrer"></div></div><b><strong>△</strong> 经过黑白处理的图片和原图片具有相同哈希值几小时后就被找到 bug</b><p></p><p>但是 Ygvar 发现，虽然 NeuralHash 可以承受图像大小调整和压缩，但如果图像遭裁剪或旋转，哈希值则会发生改变。</p><p>这也意味着，不法分子可以通过后两种编辑图片的方法，逃过图片审核。</p><p>在 Ygvar 发布逆向工程的模型几个小时后，另一位高手就发现了 NeuralHash 的一个 bug。</p><p>英特尔工程师 Cory Cornelius 发现其中存在<strong>哈希值冲突</strong>漏洞，请看下面两张图：</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202108/611df841b15ec00da85ce7df_1024.jpg" data-height="544" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/611df841b15ec00da85ce7df_1024.jpg" referrerpolicy="no-referrer"></div></div>只能说二者毫不相干，但是用 NeuralHash 模型计算一下却发现，二者的哈希值完全一样。<p></p><p>$ python3 nnhash.py NeuralHash/model.onnx neuralhash_128x96_seed1.dat beagle360.png</p><p>59a34eabe31910abfb06f308</p><p>$ python3 nnhash.py NeuralHash/model.onnx neuralhash_128x96_seed1.dat collision.png</p><p>59a34eabe31910abfb06f308</p><p>其实早在 11 天前，另一位名叫 unrealwill 的 GitHub 用户就上传了<strong>哈希值冲突</strong>攻击的代码，用来生成和原图哈希值一样的图片。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202108/611df841b15ec00da85ce7e0_1024.jpg" data-height="556" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202108/611df841b15ec00da85ce7e0_1024.jpg" referrerpolicy="no-referrer"></div></div>外媒 TechCrunch 针对这个漏洞询问了苹果。苹果还表示，现在被逆向工程的 NeuralHash 是早期版本，而不是即将推出的完整版本。<p></p><p>但苹果回避了哈希值冲突问题，强调有人工审核防止该功能被滥用。</p><p>破解 NeuralHash 的 Ygvar 表示，他的目的是希望帮助我们更好地了解该算法，在所有 iOS 设备上启用之前发现潜在的问题。</p><p>不知下个月的 iOS 15 正式版是否真有重大改进。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            