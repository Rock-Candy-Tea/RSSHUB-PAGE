
---
title: '从1小时到3.5分钟，Meta新算法一部手机搞定3D人脸数据采集，可用于VR的那种'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce88_1024.jpg'
author: ZAKER
comments: false
date: Tue, 05 Jul 2022 23:08:54 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce88_1024.jpg'
---

<div>   
<p>搞定这样的人脸 3D 建模需要几步？</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce88_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce88_raw.gif" data-height="279" data-width="200" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce88_1024.jpg" referrerpolicy="no-referrer"></div></div>在数据采集的阶段，答案是：一部手机 + 3.5 分钟。<p></p><p>没错，仅凭这 3.5 分钟的数据，就足以生成<strong>高保真</strong>、<strong>可驱动</strong>的真实 3D 人脸头像。</p><p>这项研究来自 Meta Reality Labs ——就是扎克伯格元宇宙计划里的那个核心部门。论文已经被 SIGGRAPH 2022 接收。</p><p>作者提到，这一方法适用于 VR 应用。</p><p>也就是说，在 VR 的世界里，以后你可能就不必顶着一张卡通脸登场了。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce89_1024.jpg" data-height="525" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce89_1024.jpg" referrerpolicy="no-referrer"></div></div>而是可以方便地与胖友们 " 真身 " 相见。<p></p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_2" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8a_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8a_raw.gif" data-height="293" data-width="300" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8a_1024.jpg" referrerpolicy="no-referrer"></div></div><b>方法原理</b><p></p><p>实现这一结果的方法框架如下图所示：</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8b_1024.jpg" data-height="375" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8b_1024.jpg" referrerpolicy="no-referrer"></div></div>具体而言，分为三个部分。<p></p><p><strong>首先，是要用大型多视角人脸数据集训练一个超网络</strong>，这个超网络可以通过神经网络解码器产生专属于个人的头像参数。</p><p>数据集中的人脸由多视角捕捉系统采集，包括 255 位不同年龄、性别和种族参与者的面部图像数据。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8c_1024.jpg" data-height="544" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8c_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>△</strong>左为图像捕获设备；右为采集到的人脸<p></p><p>这个捕获 3D 人脸的巨型装置是 Meta 在 2019 年研发的，其中配备 171 个高分辨率摄像头，每秒能记录 180GB 数据。采集时间在 1 个小时左右。</p><p>值得一提的是，在这个超网络中，解码器的基本组成模块是带有 bias map 的卷积上采样层。</p><p>这些 bias map 会被用来生成体积单元，进而通过射线追踪来渲染头像。</p><p>另外，该解码器结构能够将视线与其他面部活动区分开，这在 VR 应用中意味着能够更直接地利用眼动跟踪系统。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8d_1024.jpg" data-height="576" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8d_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>其次，是轻量级人脸表情捕捉</strong>。<p></p><p>在这项研究中，采集人脸只需要用到一部带有深度摄像头的智能手机。</p><p>实验中，研究人员采用的是 iPhone 12。</p><p>采集过程就像这样：</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_6" data-original="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8e_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8e_raw.gif" data-height="251" data-width="179" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce8e_1024.jpg" referrerpolicy="no-referrer"></div></div>采集到的数据要进行如下处理：<p></p><p>获取每一帧人脸图像中的几何形状和纹理；</p><p>对输入的 RGB 图像进行人脸标志检测和人像分割；</p><p>对模板网格进行拟合和变形，以匹配检测到的人脸标志物、分割轮廓和深度图；</p><p>对每一帧图像的纹理进行解包，而后汇总得到完整的人脸纹理。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8f_1024.jpg" data-height="834" data-width="904" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce8f_1024.jpg" referrerpolicy="no-referrer"></div></div>在进一步完善模型的过程中，还需要采集 65 种特定的表情：<p></p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_8" data-original="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce90_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce90_raw.gif" data-height="404" data-width="720" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce90_1024.jpg" referrerpolicy="no-referrer"></div></div>最后，该方法输出的 3D 人脸头像不仅能与用户外观高度匹配，通过全局表情空间，还能对其进行进一步的驱动、控制。<p></p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_9" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce91_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce91_raw.gif" data-height="303" data-width="540" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce91_1024.jpg" referrerpolicy="no-referrer"></div></div>研究人员表示，整个采集过程大概要花费<strong>3.5 分钟</strong>。<p></p><p>不过需要说明的是，建模的过程不是实时的，数据处理还要花费数小时的时间。</p><p><b>实验结果</b></p><p>说了这么多，效果如何，我们还是来看实验结果。</p><p>与 Pinscreen 提出的 " 一张照片构建 3D 数字化身 "（CVPR 2021）的方法相比，该方法能生成更具真实感的人脸模型。</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce92_1024.jpg" data-height="500" data-width="830" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202207/62c5264f8e9f0927ac77ce92_1024.jpg" referrerpolicy="no-referrer"></div></div>而与海德堡大学、慕尼黑工业大学、马普所等研究机构在<strong>Neural Head Avatars from Monocular RGB Videos</strong>一文中提出的方法相比，该方法能生成保真度更高的结果。<p></p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_11" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce93_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce93_raw.gif" data-height="404" data-width="720" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce93_1024.jpg" referrerpolicy="no-referrer"></div></div>不过，作者也指出了该方法的局限性：hold 不太住长发和眼镜，容易产生伪影。另外，该方法对于光照条件也有一定要求。<p></p><p></p><div class="img_box" id="id_imagebox_12" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_12" data-original="http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce94_1024.jpg" data-height="972" data-width="886" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202207/62c5264f8e9f0927ac77ce94_1024.jpg" referrerpolicy="no-referrer"></div></div><p></p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            