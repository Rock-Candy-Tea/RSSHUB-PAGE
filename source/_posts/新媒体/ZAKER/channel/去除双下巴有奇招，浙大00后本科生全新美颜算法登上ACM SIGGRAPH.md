
---
title: '去除双下巴有奇招，浙大00后本科生全新美颜算法登上ACM SIGGRAPH'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7111_1024.jpg'
author: ZAKER
comments: false
date: Tue, 27 Jul 2021 06:18:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7111_1024.jpg'
---

<div>   
<p>机器之心专栏</p><p><strong>机器之心编辑部</strong></p><p>浙江大学计算机辅助设计与图形学国家重点实验室和浙江大学 - 腾讯游戏智能图形创新技术联合实验室的研究者们提出了训练 StyleGAN 隐空间中精细的分离边界的方法，仅用一个向量就能在保持其它面部特征不变的情况下进行语义特征编辑。该方法在去除双下巴等应用中效果显著。</p><p>随着社交网络、直播以及短视频的流行，为了给别人留下更好的印象，人脸编辑「美颜」的应用范围越来越广泛，不断发展的科学技术使人脸编辑产生了非常多的研究分支。其中，生成对抗网络（GAN）的隐空间一直是个热点问题，现在越来越多的工作把注意力放在隐码的操控和隐空间中的语义解耦上。StyleGAN 是一种可生成高质量人脸图像的生成对抗网络，其隐空间具有非常好的线性特性。利用 StyleGAN 的这一特征可以实现高质量、应用场景广泛的人脸编辑。但是，如何在改变特定特征的同时保持其它无关特征不变，即进行特征的解耦，仍然是一个难题。</p><p>为解决这一问题，<strong>浙江大学计算机辅助设计与图形学国家重点实验室和浙江大学 - 腾讯游戏智能图形创新技术联合实验室可研究者们提出了训练 StyleGAN 隐空间中精细的分离边界的方法，仅用一个向量就能在保持其它面部特征不变的情况下进行语义特征编辑</strong>。</p><p>以去除双下巴为例，该方法效果显著：</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7111_1024.jpg" data-height="423" data-width="1269" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7111_1024.jpg" referrerpolicy="no-referrer"></div></div>图 1：具有双下巴的肖像图像 ( 第一排 ) ，去除双下巴后的新肖像 ( 第二排 ) 。<p></p><p>该研究的论文《Coarse-to-Fine: Facial Structure Editing of Portrait Images via Latent Space Classifications》已被计算机图形学顶级国际学术会议 ACM SIGGRAPH 2021 接收。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7112_1024.jpg" data-height="560" data-width="892" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7112_1024.jpg" referrerpolicy="no-referrer"></div></div>论文地址：http://www.cad.zju.edu.cn/home/jin/sig2021/sig2021.htm<p></p><p><strong>研究方向</strong></p><p><strong> </strong></p><p>在 CV 领域里，生成对抗网络的隐空间一直是个热点问题，现在越来越多的工作把注意力放在隐码的操控上。InterFaceGAN 探究了生成对抗网络的隐空间是怎么进行编码的，并且提出了使用一个分离边界对语义属性进行编辑的方法；In-domain GAN 能够将输入的图像反转到生成对抗网络的隐空间中，并且作为正则器对隐码进行微调，并提出一种语义扩散的方法。</p><p>鉴于隐空间对于 StyleGAN 研究的重要性，越来越多的工作开始关注如何高效、高质量地将图像反转回 StyleGAN 的隐空间中，并得到相应的隐码；在此基础上，基于 StyleGAN 的投影器可以将图像直接反转回隐空间，从而进行图像到图像的转换，实现人脸姿态改变、人脸之间的线性插值等等功能，Image2StyleGAN 能够将图像反转回隐空间并且进行语义编辑。</p><p>将隐码和 3D 模型结合也可以参数化调整人脸特征，GIF 在一种生成 3D 人脸模型（FLAME）上应用 StyleGAN，从而对生成的图像进行显式控制；StyleRig 则基于 StyleGAN 和 3DMM 进行面部绑定控制，参数化调整人脸。</p><p><strong>研究思想</strong></p><p>新研究的核心思想是训练 StyleGAN 隐空间中精细的分离边界。分离边界是由 InterFaceGAN 提出的一种隐空间中的超平面，但是 InterFaceGAN 训练出的分离边界无法分离无关特征。本文提出精心设计的训练流程，生成成对的仅有特定特征改变的隐码（在去除双下巴的例子中，这些隐码除了有无双下巴外，其它特征基本保持一致），从这些成对隐码中训练精细的分离边界，从而实现面部结构编辑。</p><p>该研究首先训练一个双下巴分类器，根据双下巴的有无，对 StyleGAN 的隐空间中的隐码进行评分，随后使用随机采样的隐码及其对应的下巴评分进行训练，得到一个粗糙的分离边界，用来合成没有双下巴的中间肖像。在这过程中，其它面部特征，如人脸形状和姿势，在被粗糙的分离边界编辑后不能很好地保存。</p><p>为了解决这一问题，该研究引入了一种语义扩散方法，利用能将双下巴特征从其它特征中分离出来的颈部掩膜，将中间人像的新下巴的语义扩散到原始图像中，从而得到没有双下巴且保持了面部特征的肖像图像及其对应的隐码。最后，该研究利用成对的有双下巴和没有双下巴的隐码训练出一个精细的双下巴分离边界。</p><p>在测试阶段，利用精细的双下巴分离边界编辑输入的隐码，并且用图像形变算法优化输入和输出的图像在人脸边缘处细微的错位（misalignment），得到最终结果。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres1.myzaker.com/202107/60ff77688e9f094a5c3e7113_1024.jpg" data-height="818" data-width="1269" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60ff77688e9f094a5c3e7113_1024.jpg" referrerpolicy="no-referrer"></div></div>图 2：该研究的流程图，详情请参见论文原文。<p></p><p><strong>结果展示</strong></p><p>该研究在大量的肖像图像上测试了方法的性能，这些肖像图像有不同的性别、姿势、脸部形状、肤色。图 3 展示了由该研究提出的方法自动生成的结果。</p><p>以去除双下巴为例，该方法可成功地去除输入肖像图像的双下巴，同时很好地保持其它特征不变。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7114_1024.jpg" data-height="1481" data-width="1269" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202107/60ff77688e9f094a5c3e7114_1024.jpg" referrerpolicy="no-referrer"></div></div>图 3：该研究的结果。前四行为参数连续调整的结果，后四行的每对图像中，左图为原图，右 ‍ 图为 ‍ 得到的结果。<p></p><p>与当前最优的面部编辑方法（SOTA）相比，该研究产生了更稳定和合理的结果，保持了面部特征的不变性，并且符合人脸结构。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202107/60ff77688e9f094a5c3e7115_1024.jpg" data-height="961" data-width="1269" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202107/60ff77688e9f094a5c3e7115_1024.jpg" referrerpolicy="no-referrer"></div></div>图 4：方法对比。第一行为输入肖像图像，第二行为 MaskGAN 的结果，第三行为 SC-FEGAN 的结果，第四行为 Generative Inpainting 方法的结果，最后一行为我们方法的结果。<p></p><p>研究人员希望该研究能够为人脸编辑带来新的思路，同时希望给 StyleGAN 的隐空间研究带来启发。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            