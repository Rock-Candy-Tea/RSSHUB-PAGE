
---
title: '让对方把头侧扭90°，这一动作可辨别Deepfake伪造人脸'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b079_1024.jpg'
author: ZAKER
comments: false
date: Sun, 14 Aug 2022 06:40:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b079_1024.jpg'
---

<div>   
<p>选自 metaphysic.ai</p><p><strong>作者：Martin Anderson</strong></p><p><strong>机器之心编辑部</strong></p><p>看似「天衣无缝」的伪造技术，也是有漏洞的。</p><p>视频伪造是 Deepfake 技术最为主要的代表，其制作假视频的技术也被称为人工智能换脸（AI face swap ) 。一直以来，研究者发现 DeepFake 存在着这样一个漏洞：当伪造人脸头部转到 90 度时（侧脸 90 度），对方就能识别视频中的人脸是不是伪造的。</p><p>这是怎么回事呢？在最近的一项测试中，技术专家兼评论员 Bob Doyle 允许研究人员进行一些关于人脸伪造的测试，期间研究人员采用 DeepFaceLive 来改变他的外貌。DeepFaceLive 是流行的 DeepFaceLab 软件的一个直播版本，能够帮助用户实时创建不同的视频身份。</p><p>测试中，在人脸转到 90 度以前，其余角度我们很难发现这张脸是伪造的。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b079_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b079_raw.gif" data-height="650" data-width="908" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b079_1024.jpg" referrerpolicy="no-referrer"></div></div>为什么人脸转到 90 度时会出现漏洞？原来这些深度伪造模型都没有经过高质量的人脸轮廓数据训练，因而不能转换面部的不同边界，或者执行必要的修复。<p></p><p>‍</p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07a_1024.jpg" data-height="582" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07a_1024.jpg" referrerpolicy="no-referrer"></div></div><p></p><p>不过，借助这一漏洞，我们可以判断视频会议中与自己交谈的人是真实的还是伪造的。</p><p><strong>横向限制</strong></p><p>这一漏洞是怎么造成的呢？</p><p>在 Deepfake 技术中，用于估计面部姿态的标准软件如「Facial Alignment Network」，在有些情况下不能无法可靠地工作。事实上，大多数基于 2D 的人脸对齐算法在从正面人脸映射到侧面人脸中，仅仅对齐了 50-60% 特征点。</p><p>我们以论文《Joint Multi-view Face Alignment in the Wild》来说，其展示了多视点人脸对齐，正面对齐包含 68 个特征点，而侧脸对齐只有 39 个。典型的 2D 人脸对齐算法使侧轮廓视图隐藏了 50% 的特征点，这会妨碍模型的识别、训练以及后续人脸合成。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07b_1024.jpg" data-height="716" data-width="1000" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07b_1024.jpg" referrerpolicy="no-referrer"></div></div>意识到这个缺陷后，许多病毒式 Deepfake 都会有针对性地进行规避。一些人做出了一些努力，比如 YouTube 上就有人做过实验，他们通过大量的后期处理，将 Jerry Seinfeld 的脸替换到《低俗小说》 ( 1994 ) 中的紧张场景中，获得了很棒的侧视图。<p></p><p>当然，完成如此逼真的换脸还需要大量的训练。本次用到了《宋飞传》里的镜头，时长达 66 小时，其中大部分镜头是 Jerry Seinfeld 的。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07c_1024.jpg" data-height="433" data-width="996" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07c_1024.jpg" referrerpolicy="no-referrer"></div></div>影视演员可以获得大量人脸视频，但对于我们普通人来说，侧面 90 度的照片却很少，可能是侧面照不能表达太多东西，而更多角度的照片可以提供更丰富的内容。<p></p><p>由于可用数据缺乏，很难获得一系列普通人的图像。因此，Deepfake 这一缺点提供了一种潜在的方法，可以在实时视频通话中发现「伪造」的人脸。如果你怀疑和你说话的人可能是一个「深度伪造的人脸」，你可以让他们侧身一到两秒钟，看看对方有没有破绽露出。</p><p>今年 5 月，AI 安全公司 Sensity 发布了一份报告和一段视频，展示了一个类似 DeepFaceLive 的系统，该系统通过伪造身份成功地骗过活体检测器。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07d_1024.jpg" data-height="702" data-width="900" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07d_1024.jpg" referrerpolicy="no-referrer"></div></div>Sensity 视频截图展示了 deepfake 对活体检测器的攻击。图源：theverge<p></p><p>Sensity CEO 兼首席科学家 Giorgio Patrini 表示，他们在实验和测试中没有进行 90 度人脸检测，并表示将人脸的侧视图用作身份验证的一种形式时，确实可以提供一些保护来防止 deepfake 技术。正如前面所指出的，缺乏广泛可用的侧视图数据，使得 deepfake 检测器的训练非常具有挑战性。</p><p>意识到训练数据的缺陷，论文《Dual-Generator Face Reenactment》的附加材料中提供了一些包含 90 度的人脸照片。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07e_1024.jpg" data-height="667" data-width="810" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/62f9084d8e9f095eba66b07e_1024.jpg" referrerpolicy="no-referrer"></div></div>自该现象出现以来，研究界一直在深入研究和开发 deepfake 检测技术，但在一定程度上相关技术还是受到了阻碍。<p></p><p>尽管如此，研究人员还是提出了一些解决方案来保证视频通话中的安全。这些解决方案包括测量监视器照明、评估面部区域的不一致等方法。</p><p>Deepfake 换脸能够以假乱真，但鉴别算法总能找到破绽，以控制假视频的传播。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            