
---
title: 'DeepMind打造AI游戏王！挑战各种最强棋牌AI，战斗力惊人'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d5_1024.jpg'
author: ZAKER
comments: false
date: Thu, 09 Dec 2021 05:18:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d5_1024.jpg'
---

<div>   
<p><strong>编译 | ZeR0</strong></p><p><strong>编辑 | 漠影</strong></p><p>智东西 12 月 9 日消息，谷歌母公司 Alphabet 旗下顶尖 AI 实验室 DeepMind 曾因其 AI 系统 AlphaGo 击败顶尖人类围棋选手、AlphaStar 赢得星际争霸 2 而爆红全球。本周，它又披露新的游戏 AI 系统。</p><p>与此前开发的游戏系统不同，DeepMind 的 AI 新作<strong>Player of Games 是</strong><strong>第一个在完全信息游戏</strong><strong>以及不完全信息游戏</strong><strong>中都能实现强大性能的 AI 算法。</strong>完全信息游戏如中国围棋、象棋等棋盘游戏，不完全信息游戏如扑克等。</p><p>这是向能够在任意环境中学习的真正通用 AI 算法迈出的重要一步。</p><p>Player of Game 在象棋、围棋这两种完全信息游戏和德州扑克、苏格兰场这两种不完全信息游戏中与顶尖 AI 智能体对战。</p><p>从实验结果来看，DeepMind 称 Player of Games 在完全信息游戏中的表现已经达到了 " 人类顶级业余选手 " 水平，但如果给予相同资源，该算法的表现可能会明显弱于 AlphaZero 等专用游戏算法。</p><p>在两类不完全信息游戏中，Player of Games 均击败了最先进的 AI 智能体。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d5_1024.jpg" data-height="533" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d5_1024.jpg" referrerpolicy="no-referrer"></div></div>论文链接：<a href="http://iphone.myzaker.com/zaker/link.php?pk=61b1bb868e9f096d75586c47&b=aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzIxMTIuMDMxNzgucGRm&bcode=38cc74fa&target=_new" target="_blank">https://arxiv.org/pdf/2112.03178.pdf</a><p></p><p><b>一、深蓝、AlphaGo 等 AI 系统仅擅长玩一种游戏</b></p><p>计算机程序挑战人类游戏选手由来已久。</p><p>20 世纪 50 年代，IBM 科学家亚瑟 · 塞缪尔（Arthur L. Samuel）开发了一个跳棋程序，通过自对弈来持续改进其功能，这项研究给很多人带来启发，并普及了 " 机器学习 " 这个术语。</p><p>此后游戏 AI 系统一路发展。1992 年，IBM 开发的 TD-Gammon 通过自对弈在西洋双陆棋中实现大师级水平；1997 年，IBM 深蓝 DeepBlue 在国际象棋竞赛中战胜当时的世界棋王卡斯帕罗夫；2016 年，DeepMind 研发的 AI 系统 AlphaGo 在围棋比赛中击败世界围棋冠军李世石 ……</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d6_1024.jpg" data-height="523" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d6_1024.jpg" referrerpolicy="no-referrer"></div></div>▲ IBM 深蓝系统 vs 世界棋王卡斯帕罗夫<p></p><p>这些 AI 系统有一个共同之处，都是专注于一款游戏。比如塞缪尔的程序、AlphaGo 不会下国际象棋，IBM 的深蓝也不会下围棋。</p><p>随后，AlphaGo 的继任者 AlphaZero 做到了举一反三。它证明了通过简化 AlphaGo 的方法，用最少的人类知识，一个单一的算法可以掌握三种不同的完全信息游戏。不过 AlphaZero 还是不会玩扑克，也不清楚能否玩好不完全信息游戏。</p><p>实现超级扑克 AI 的方法有很大的不同，扑克游戏依赖于博弈论的推理，来保证个人信息的有效隐藏。其他许多大型游戏 AI 的训练都受到了博弈论推理和搜索的启发，包括 Hanabi 纸牌游戏 AI、The Resistance 棋盘游戏 AI、Bridge 桥牌游戏 AI、AlphaStar 星际争霸 II 游戏 AI 等。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768d7_1024.jpg" data-height="500" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768d7_1024.jpg" referrerpolicy="no-referrer"></div></div>▲ 2019 年 1 月，AlphaStar 对战星际争霸 II 职业选手<p></p><p>这里的每个进展仍然是基于一款游戏，并使用了一些特定领域的知识和结构来实现强大的性能。</p><p>DeepMind 研发的 AlphaZero 等系统擅长国际象棋等完全信息游戏，而加拿大阿尔伯特大学研发的 DeepStack、卡耐基梅隆大学研发的 Libratus 等算法在扑克等不完全信息游戏中表现出色。</p><p>对此，DeepMind 研发了一种新的算法 Player of Games（PoG），它使用了较少的领域知识，通过用自对弈（self-play）、搜索和博弈论推理来实现强大的性能。</p><p><b>二、更通用的算法 PoG：棋盘、扑克游戏都擅长</b></p><p>无论是解决交通拥堵问题的道路规划，还是合同谈判、与顾客沟通等互动任务，都要考虑和平衡人们的偏好，这与游戏策略非常相似。AI 系统可能通过协调、合作和群体或组织之间的互动而获益。像 Player of Games 这样的系统，能推断其他人的目标和动机，使其与他人成功合作。</p><p>要玩好完全的信息游戏，需要相当多的预见性和计划。玩家必须处理他们在棋盘上看到的东西，并决定他们的对手可能会做什么，同时努力实现最终的胜利目标。不完全信息游戏则要求玩家考虑隐藏的信息，并思考下一步应该如何行动才能获胜，包括可能的虚张声势或组队对抗对手。</p><p>DeepMind 称，<b>Player of Games 是首个 " 通用且健全的搜索算法 "，在完全和不完全的信息游戏中都实现了强大的性能。</b></p><p>Player of Games（PoG）主要由两部分组成：1）一种新的生长树反事实遗憾最小化（GT-CFR）；2）一种通过游戏结果和递归子搜索来训练价值 - 策略网络的合理自对弈。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768d8_1024.jpg" data-height="325" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768d8_1024.jpg" referrerpolicy="no-referrer"></div></div>▲ Player of Games 训练过程：Actor 通过自对弈收集数据，Trainer 在分布式网络上单独运行<p></p><p>在完全信息游戏中，AlphaZero 比 Player of Games 更强大，但在不完全的信息游戏中，AlphaZero 就没那么游刃有余了。</p><p>Player of Games 有很强通用性，不过不是什么游戏都能玩。参与研究的 DeepMind 高级研究科学家马丁 · 施密德（Martin Schmid）说，AI 系统需考虑每个玩家在游戏情境中的所有可能视角。</p><p>虽然在完全信息游戏中只有一个视角，但在不完全信息游戏中可能有许多这样的视角，比如在扑克游戏中，视角大约有 2000 个。</p><p>此外，与 DeepMind 继 AlphaZero 之后研发的更高阶 MuZero 算法不同，Player of Games 也需要了解游戏规则，而 MuZero 无需被告知规则即可飞速掌握完全信息游戏的规则。</p><p>在其研究中，DeepMind 评估了 Player of Games 使用谷歌 TPUv4 加速芯片组进行训练，在国际象棋、围棋、德州扑克和策略推理桌游《苏格兰场》（Scotland Yard）上的表现。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d9_1024.jpg" data-height="489" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768d9_1024.jpg" referrerpolicy="no-referrer"></div></div>▲苏格兰场的抽象图，Player of Games 能够持续获胜<p></p><p>在围棋比赛中，AlphaZero 和 Player of Games 进行了 200 场比赛，各执黑棋 100 次、白棋 100 次。在国际象棋比赛中，DeepMind 让 Player of Games 和 GnuGo、Pachi、Stockfish 以及 AlphaZero 等顶级系统进行了对决。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768da_1024.jpg" data-height="290" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768da_1024.jpg" referrerpolicy="no-referrer"></div></div>▲不同智能体的相对 Elo 表，每个智能体与其他智能体进行 200 场比赛<p></p><p>在国际象棋和围棋中，Player of Games 被证明在部分配置中比 Stockfish 和 Pachi 更强，它在与最强的 AlphaZero 的比赛中赢得了 0.5% 的胜利。</p><p>尽管在与 AlphaZero 的比赛中惨败，但 DeepMind 相信 Player of Games 的表现已经达到了 " 人类顶级业余选手 " 的水平，甚至可能达到了专业水平。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768db_1024.jpg" data-height="282" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768db_1024.jpg" referrerpolicy="no-referrer"></div></div>Player of Games 在德州扑克比赛中与公开可用的 Slumbot 对战。该算法还与 Joseph Antonius Maria Nijssen 开发的 PimBot 进行了苏格兰场的比赛。<p></p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768dc_1024.jpg" data-height="396" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202112/61b1aa36b15ec0438d5768dc_1024.jpg" referrerpolicy="no-referrer"></div></div>▲不同智能体在德州扑克、苏格兰场游戏中的比赛结果<p></p><p>结果显示，Player of Games 是一个更好的德州扑克和苏格兰场玩家。与 Slumbot 对战时，该算法平均每 hand 赢得 700 万个大盲注（mbb/hand），mbb/hand 是每 1000 hand 赢得大盲注的平均数量。</p><p>同时在苏格兰场，DeepMind 称，尽管 PimBot 有更多机会搜索获胜的招数，但 Player of Games 还是 " 显著 " 击败了它。</p><p><b>三、研究关键挑战：训练成本太高</b></p><p>施密德相信 Player of Games 是向真正通用的游戏系统迈出的一大步。</p><p>实验的总体趋势是，随着计算资源增加，Player of Games 算法以保证产生更好的最小化 - 最优策略的逼近，施密德预计这种方法在可预见的未来将扩大规模。</p><p>" 人们会认为，受益于 AlphaZero 的应用程序可能也会受益于游戏玩家。" 他谈道，" 让这些算法更加通用是一项令人兴奋的研究。"</p><p>当然，倾向于大量计算的方法会让拥有较少资源的初创公司、学术机构等组织处于劣势。在语言领域尤其如此，像 OpenAI 的 GPT-3 这样的大型模型已取得领先性能，但其通常需要数百万美元的资源需求，这远超大多数研究小组的预算。</p><p>即便是在 DeepMind 这样财力雄厚的公司，成本有时也会超过人们所能接受的水平。</p><p>对于 AlphaStar，公司的研究人员有意没有尝试多种构建关键组件的方法，因为高管们认为训练成本太高。根据 DeepMind 披露的业绩文件，它在去年才首次盈利，年收入达到 8.26 亿英镑（折合约 69 亿人民币），获得 4380 万英镑（折合约 3.67 亿人民币）的利润。从 2016 年 ~2019 年，DeepMind 共计亏损 13.55 亿英镑（折合约 113 亿人民币）。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768dd_1024.jpg" data-height="450" data-width="800" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202112/61b1aa36b15ec0438d5768dd_1024.jpg" referrerpolicy="no-referrer"></div></div>据估计，AlphaZero 的训练成本高达数千万美元。DeepMind 没有透露 Player of Games 的研究预算，但考虑到每个游戏的训练步骤从数十万到数百万不等，这个预算不太可能低。<p></p><p><b>结语：游戏 AI 正助力突破认知及推理挑战</b></p><p>目前游戏 AI 还缺乏明显的商业应用，而 DeepMind 的一贯理念是借其去探索突破认知和推理能力所面临的独特挑战。近几十年来，游戏催生了自主学习的 AI，这为计算机视觉、自动驾驶汽车和自然语言处理提供了动力。</p><p>随着研究从游戏转向其他更商业化的领域，如应用推荐、数据中心冷却优化、天气预报、材料建模、数学、医疗保健和原子能计算等等，游戏 AI 研究对搜索、学习和博弈推理的价值愈发凸显。</p><p>" 一个有趣的问题是，这种水平的游戏是否可以用较少的计算资源实现。" 这个在 Player of Games 论文最后中被提及的问题，还没有明确的答案。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            