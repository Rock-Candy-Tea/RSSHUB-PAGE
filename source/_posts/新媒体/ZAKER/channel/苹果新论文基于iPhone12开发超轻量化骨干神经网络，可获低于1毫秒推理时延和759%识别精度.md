
---
title: '苹果新论文基于iPhone12开发超轻量化骨干神经网络，可获低于1毫秒推理时延和75.9%识别精度'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e96_1024.jpg'
author: ZAKER
comments: false
date: Thu, 23 Jun 2022 03:23:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e96_1024.jpg'
---

<div>   
<p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e96_1024.jpg" data-height="586" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e96_1024.jpg" referrerpolicy="no-referrer"></div></div>随着智能手机性能的提升，在手机端部署高效率、轻量化的深度学习模型具备越来越高的实用价值。近日，苹果研究团队基于 iPhone 12 手机平台，开发了一种名为 "MobileOne" 的轻量化神经网络架构，并在 ImageNet 数据集上获得低于 1 毫秒的推理时延，及 75.9% 的识别精度。<p></p><p>通常，人们在高识别精度和低时延两者之间进行取舍。因此设计同时满足高识别精度和低时延的神经网络模型充满了挑战。苹果团队在广泛研究了多种 " 手机友好型 " 神经网络模型后发现，提升模型推理效率的两大关键瓶颈，" 是激活函数的选择和模型结构块的设计 "。</p><p>为了缓解这些问题，该研究团队开发了一种轻量化神经网络架构 "MobileOne"，将其部署在 iPhone 12 手机平台上，并用 ImageNet 数据集进行测试，获得了低于 1 毫秒的推理时延以及 75.9% 的识别精度。</p><p>相关论文以《一种改良的毫秒推理轻量化模型主干架构》（<a class="weapp_text_link js_weapp_entry" href="http://iphone.myzaker.com/zaker/link.php?pk=62b429978e9f0948db77efd3&b=aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TXpBM05USXlPRFV6TkE9PSZtaWQ9MjY0OTY2MzQyMyZpZHg9MyZzbj1hM2U3NjA5MDdiZmYxNGIwYjk1M2FlYTBhNDNlZmY5MCZjaGtzbT04NzY5YjNhNmIwMWUzYWIwYTU0NWM1MWJhNGM1NmE4MTQzYTQ2NWFiOGVhYTUzNTM5MjdkZjEzMGFjODJmZWExZmM1ZTQ4Y2NmYzVjJnNjZW5lPTI3&bcode=ccdd3283&target=_new" data-miniprogram-appid="wxe91e9a12af9c82c3" data-miniprogram-path="pages/paper-old-detail/paper-detail?pid=2901" data-miniprogram-nickname=" 络绎论文 " data-miniprogram-type="text" data-miniprogram-servicetype target="_blank">An Improved One millisecond Mobile Backbone</a>）为题，于 2022 年 6 月 8 日提交至预印本期刊 arXiv [ 1 ] 。</p><p><strong>洞悉已有模型</strong></p><p><strong><strong><strong></strong></strong></strong>对于手机端高效神经网络架构的研究，大多聚焦于每秒浮点运算次数（Floating-point operations per second，FLOPS）或者模型参数的数量，而这两者与模型的推理效率之间并不一定明显相关。比如，每秒浮点运算量的统计通常不考虑计算并行度或内存访问行为，而某些神经网络中的无参数操作（如跳跃连接等）则会产生大量的内存访问开销。</p><p>苹果团队首先研究了一些在移动端比较流行的轻量化神经网络模型，包括 MobileViT、MobileNet、EfficientNet、和 SqueezeNet 等。较早期的 SqueezeNet 和较新的 MobileViT，其实现轻量化的方式主要是在模型的参数数量方面进行了优化；而对于每秒浮点运算量的优化，流行模型有 EfficientNet、MobileNet、ShuffleNet、GhostNet 和 MixNet 等。</p><p>较少有方法像 MobileNet-V3 和 ShuffleNet-V2 等一样，直接针对模型推理时延进行优化。学术界已有证据显示，推理时延与模型参数数量和每秒浮点运算量的相关性未必非常明显。因此，苹果团队的工作重点是在不降低甚至提升模型识别精度的条件下，减轻神经网络在手机设备上的时延。该团队认为，阻碍提升模型推理效率的两大关键瓶颈，是激活函数的选择和模型结构块的设计。</p><p>该团队研究了模型推理时延与浮点运算量及参数个数的相关性。他们开发了一个 iOS APP，能在 iPhone 12 上测量各种模型时延。研究人员发现，推理时延与每秒浮点运算量适度相关，而与模型的参数数量弱相关。</p><p>下图还可以看出，相比于其他的轻量化模型，MobileOne 模型在同等延迟下，每秒浮点运算量更多（左侧），而且模型参数数量更多（右侧），因此模型的识别精度也较高。此外，该团队还发现，不同激活函数也会对模型推理带来毫秒甚至百毫秒量级的时延，最终他们选择了时延最低的 ReLu 激活函数。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e97_1024.jpg" data-height="501" data-width="1110" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e97_1024.jpg" referrerpolicy="no-referrer"></div></div>（来源：arXiv）<p></p><p><strong>开发新颖架构</strong></p><p><strong><strong><strong></strong></strong></strong><strong></strong>" 重参数化 " 是一种模型压缩技术，可以理解为用一个简单的网络结构去等效替代一个较复杂的结构，其优点是可以降低模型计算开销。而 MobileOne 模型在已有的 MobileNet-V1 架构基础上，在结构块中引入了一些简单的可重参数化的分支。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e98_1024.jpg" data-height="713" data-width="790" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e98_1024.jpg" referrerpolicy="no-referrer"></div></div>图丨 MobileOne 模型的基本结构：左侧是训练用网络结构块，右侧是推理用结构块，即对训练时模型结构的重参数化（来源：arXiv）<p></p><p>MobileOne 模型及其变体的架构细节如下图所示。其中，所有模型的输入图像分辨率为 224 × 224，卷积的通道数和结构块的个数分别由两个超参数（α，k）控制，论文中一共涉及了 S0-S4 五种变体。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e99_1024.jpg" data-height="274" data-width="1214" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e99_1024.jpg" referrerpolicy="no-referrer"></div></div>（来源：arXiv）<p></p><p><strong>测试<strong>模型性能</strong></strong></p><p><strong><strong><strong></strong></strong></strong>苹果团队首先利用 ImageNet 数据集（该图片数据集包含 1000 种目标类别，128 万张图片用于训练，5 万张图片用于测试）对 MobileOne 模型的目标分类识别能力进行评估。如下图所示，左侧表示 transformer 类模型的测试结果，表明即便是参数数量最少的 MobileViT 变体，在移动设备上的时延也高于 4 毫秒（蓝框标出）。</p><p>下图中右侧同样用蓝框圈出了 MobileOne 类模型，红框是模型的识别精度（所谓的 Top-1 即模型输出 1000 个类别对应的概率后，取概率最大的识别结果所得到的识别精度）。可以看出，尽管 MobileFormer 达到了 79.3% 的识别精度和 70.76 毫秒的时延 [ 2 ] ，MobileOne-S4 识别精度仍然略高（79.4%），且时延仅为 1.86 毫秒，比前者快了 38 倍。</p><p>MobileOne-S3 的识别精度比 EfficientNet-B0 高 1% 而且时延降低 11%。整体来看， MobileOne 类模型平均识别精度更高且时延更低，其在 iPhone 12 上的表现，比很多流行的神经网络模型更具优越性。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e9a_1024.jpg" data-height="448" data-width="1262" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e9a_1024.jpg" referrerpolicy="no-referrer"></div></div>（来源：arXiv）<p></p><p>苹果团队在论文中进一步证实，该 MobileOne 模型架构可以推广到多种任务类型，不仅图像分类、还可用于目标检测和语义分割等任务中。</p><p>为展示 MobileOne 的多功能性，该团队在 MS-COCO 数据集上的进行了目标检测性能的测试。他们将 MobileOne 用作单阶段目标检测器 SSD 的骨干特征提取器，然后利用 mmdetection 库，基于 MS-COCO 数据集对模型进行了 200 个轮次的训练。</p><p>下图左侧部分显示的是在目标检测边框交并比阈值取不同值（0.5 到 0.95，步长 0.05）的条件下，各种模型在验证集上的平均识别精度。最佳变体 MobileOne-S4（红框）比 MNASNet 和 MobileViT 的最佳版本（两个蓝框）分别高了 27.8% 和 6.1%。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e9b_1024.jpg" data-height="439" data-width="895" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62b2e2758e9f090aa54f5e9b_1024.jpg" referrerpolicy="no-referrer"></div></div>（来源：arXiv）<p></p><p>此外，该团队还在 Pascal VOC 和 ADE 20 数据集上测试了模型的语义分割性能，用 MobileOne 作为 Deeplab-V3 语义模型的主干特征提取结构，按照 MobileViT 的训练过程，在增强的 Pascal VOC 和 ADE 20k 数据集上训练了 50 轮。上图右侧部分显示了模型的平均交并比，不论是 VOC 数据集还是 ADE20K，在时延较低的情况下，MobileOne 模型的整体平均性能仍然较高。</p><p>概括来说，此次苹果团队开发出了名为 "MobileOne" 的移动端轻量化神经网络架构，相比其他当前流行的众多轻量模型，MobileOne 具有较低时延、较高识别精度的优势。尽管其识别性能与 ConvNeXt 和 Swin Transformer 等大型网络相比仍有较大差距，但是在手机平台等移动端具有一定应用前景，为未来神经网络在手机端的高效使用提供了借鉴思路。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            