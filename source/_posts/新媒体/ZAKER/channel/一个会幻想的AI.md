
---
title: '一个会幻想的AI'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b218d_1024.jpg'
author: ZAKER
comments: false
date: Thu, 09 Jun 2022 05:35:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b218d_1024.jpg'
---

<div>   
<p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b218d_1024.jpg" data-height="1473" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b218d_1024.jpg" referrerpolicy="no-referrer"></div></div>在我们还是小婴儿的时候，都会通过咿呀学语和模仿的方式来学习语言。谁也不是一开始就会阅读文本的，因为那需要对世界有基本的认知和理解，以及解释并推断描述和关系的高级能力。相反，<strong>人类通过与环境的互动，基于物理和社会世界的背景来确定词汇并感知它们的含义，缓缓开启了我们的语言之旅</strong>。最终，我们可以构建出完整的句子，甚至传达极其复杂的想法。<p></p><p>类似的是，当人们开始学习一门外语和翻译时，也会<strong>调动其他感官信息</strong>，比如经典的识字卡可以将不熟悉的新单词与图像配对，帮助我们掌握和记忆。随后，经过一次又一次的练习，我们就可以在没有这些提示的情况下准确地理解、翻译从未见过的新句子，甚至长文。在这样一个过程中，根据原文想象出一幅场景，往往也颇有助益。</p><p>有意思的是，这其实就是一组研究团队开发的机器学习新模型的基础。这个模型被称为<strong>VALHALLA</strong>，<strong>其中一个经过训练的神经网络读到一种语言的源语句，可以 " 幻想 " 出它的图像，然后用语句加图像的组合将它翻译成目标语言</strong>。</p><p>团队发现，他们这种机器翻译的方法比纯文本翻译更准确。此外，它还为长句、" 小众 " 语言的翻译以及一些特殊的限制情况提供了额外的帮助。</p><p>从训练开始：学习 " 幻想 "</p><p><strong>自然语言处理</strong>（NLP）是如今人工智能最热门的领域之一。其中一项核心任务就是极其实用的<strong>机器翻译</strong>，现在每天都有数百万人在使用这一功能。</p><p>随着近期深度学习的重大进步，在如何使用非文本信息，比如图像、音频或其他基础信息，来解决涉及语言的实际任务方面也出现了一些相当有趣的发展。</p><p>我们人类身处一个情境化的现实世界，当我们的大脑在执行语言处理任务时，也会利用到那些非文本信息。而目前最先进的 NLP 技术只利用文本数据。</p><p>团队由此推测，在推理中，将幻想图像和文本的配对可以模拟这种过程，就应该可以提高 AI 性能。</p><p>当我们学一门新语言或者进行翻译时，我们通常会在自己尝试之前得到一些例子和练习。机器翻译系统同样如此。这就是 AI 非常关键的<strong>训练</strong>过程。团队的想法是，能否利用 " 视觉幻想 "，也就是想象视觉场景的能力，来改进机器翻译系统，而不是在推理过程中使用外部图像作为输入。这也更贴近我们应对现实世界的场景。</p><p>为了做到这一点，团队设计出了一个<strong>带有两个转换器的编码器 - 解码器结构</strong>，这是一种适合序列相关数据（比如语言）的神经网络模型，它可以关注一句话的关键词和语义。一个转换器负责产生视觉幻想，另一个则使用第一个转换器的输出进行多模态翻译。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b218f_1024.jpg" data-height="426" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b218f_1024.jpg" referrerpolicy="no-referrer"></div></div>VALHALLA 的训练流水线概念。（图／Li, Y. et al.）<p></p><p><strong>训练过程包含两个翻译流</strong>，一个是源语句和与之配对的真实图像，另一个是同一个源语句通过视觉幻想形成文本 - 图像配对。首先，真实图像和语句被词例化成转换器可以处理的表示，或者可以简单地理解成 " 切割 " 成更小的小块。然后，源语句再次被词例化，但这次是通过视觉幻想转换器，输出一个幻想结果，也就是这个语句的离散图像表示。</p><p>研究人员采用了<strong>自回归</strong>来比较现实和幻想表达的一致性，举个简单的例子，比如面对同义词的情况，提到的动物蝙蝠（bat）不能被幻想成棒球棒（bat）。随后，幻想转换器利用它们之间的差异来优化预测和视觉输出，从而确保上下文是连贯一致的。</p><p>然后，这两组词例同时通过多模态翻译转换器，每一组都包含句子表示和幻想或真实的图像。词例化的文本翻译输出会被比较，它们需要非常相似，也和另一种语言的目标句子相似。这其中的任何差异都会被反馈给翻译转换器，用来进一步优化。</p><p>测试：目标文本的可视化</p><p>在得当的训练下，AI 可以建立起属于自己的 " 知识体系 "，并可以将这些所学应用到具体场景中，根据前所未见的新数据迅速给出答案，也就是所谓<strong>推理</strong>的能力。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b2190_1024.jpg" data-height="906" data-width="1022" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1f1b08e9f0912b95b2190_1024.jpg" referrerpolicy="no-referrer"></div></div>VALHALLA 在没有视觉输入情况下的推理过程。（图／Li, Y. et al.）<p></p><p>为了测试他们的方法，团队将 VALHALLA 与其他最先进的多模态和纯文本翻译方法进行比较。他们使用了公共基准数据集，其中包含带有源语句的真实图像，以及一个用于翻译纯文本新闻文章的数据集。</p><p>研究人员测量了它在<strong>13 项任务中的表现</strong>，包括了资源丰富的语言翻译（比如英语、德语和法语），" 小众 " 语言或者叫资源不足的语言翻译（比如英语翻译成罗马尼亚语），以及非英语的翻译（比如西班牙语译为法语）。</p><p>团队还测试了不同的转换器模型大小的效果，准确性随语句长度的变化，以及在有限的文本背景下的翻译，在这种特殊情况下，一部分文本被隐藏了起来。</p><p>他们观察到，<strong>与纯文本翻译方法相比，模型有明显的改进，数据效率提高了</strong>，而且较小的模型比较大的基础模型表现更好。随着语句变长，VALHALLA 比其他方法的性能有所提高。在部分句子被隐藏的测试中，VALHALLA 甚至可以恢复并翻译原文。团队对此感到非常惊讶。</p><p>更令人惊喜的是，VALHALLA 还表现出了一些出乎意料的特点，比如面对 " 小众 " 语言的翻译任务，AI 的提高反而更为显著。这说明，<strong>以图像为基础的方法在这种情况下更有助益</strong>。</p><p>同时，<strong>这种性能上的提升，甚至在那些不容易与图像联系起来的文本类型上也出现了</strong>。简单来说，如果这种方法有助于翻译相当具象化的句子，比如 " 房子前停着一辆红汽车 "，那似乎很合理。然而，即使在纯文本的新闻文章领域，这种方法也能在纯文本系统的基础上有所提高。</p><p>" 黑箱 " 技术</p><p>虽然 VALHALLA 目前表现良好，但研究人员指出，它确实也有局限性，比如需要用图像来注释语句，这就会让模型的获取成本变得更高。此外，研究人员同样意识到，<strong>像 VALHALLA 这样的技术仍是一个 " 黑箱 "</strong>，它假设幻想图像提供了有用的信息。因此团队还计划更详细地调查模型学习的内容和方式，从而验证这种方法。</p><p>未来，团队希望探索其他改善翻译的手段。<strong>除了图像，还有其他很多类型的多模态信息，包括语音、视频，甚至触摸或其他感官模式</strong>。类似的多模态基础，有可能使世界上许多 " 小众 " 语言的机器翻译受益。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            