
---
title: 'Stable Diffusion火到被艺术家集体举报，网友科普背后机制被LeCun点赞'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce0_1024.jpg'
author: ZAKER
comments: false
date: Tue, 30 Aug 2022 23:01:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce0_1024.jpg'
---

<div>   
<p>免费开源的 Stable Diffusion 太火了！</p><p>有人拿它来做视频短片，几分钟内穿越时间看遍地球万物的演变。</p><p>还有人拿它来制作守望先锋里的英雄。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce0_1024.jpg" data-height="900" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce0_1024.jpg" referrerpolicy="no-referrer"></div></div>甚至因为使用过于泛滥，牵涉到艺术版权的问题，一群艺术家们还吵了起来，并把一个非官方账号举报到封号。<p></p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce1_1024.jpg" data-height="712" data-width="930" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce1_1024.jpg" referrerpolicy="no-referrer"></div></div>这背后究竟是如何运作的，才能形成如此惊人的反响？<p></p><p>这几天，有位小哥分享了 Stable Diffusion 工作机制的线程，还被 LeCun 点了赞。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce2_1024.jpg" data-height="1084" data-width="962" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce2_1024.jpg" referrerpolicy="no-referrer"></div></div>来看看究竟说了啥。<p></p><p><b>又是扩散模型</b></p><p>首先，从名字<strong>Stable Diffusion</strong>就可以看出，这个主要采用的扩散模型（Diffusion Model）。</p><p>简单来说，扩散模型就是去噪自编码器的连续应用，逐步生成图像的过程。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce3_1024.jpg" data-height="309" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce3_1024.jpg" referrerpolicy="no-referrer"></div></div>一般所言的扩散，是反复在图像中添加小的、随机的噪声。而扩散模型则与这个过程相反——将噪声生成高清图像。训练的神经网络通常为 U-net。<p></p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce4_1024.jpg" data-height="659" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce4_1024.jpg" referrerpolicy="no-referrer"></div></div>不过因为模型是直接在像素空间运行，导致扩散模型的训练、计算成本十分昂贵。<p></p><p>基于这样的背景下，Stable Diffusion 主要分两步进行。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce5_1024.jpg" data-height="342" data-width="662" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce5_1024.jpg" referrerpolicy="no-referrer"></div></div>首先，使用编码器将图像 x 压缩为较低维的潜在空间表示 z（x）。<p></p><p>其中上下文（Context）y，即输入的文本提示，用来指导 x 的去噪。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce6_1024.jpg" data-height="572" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce6_1024.jpg" referrerpolicy="no-referrer"></div></div>它与时间步长 t 一起，以简单连接和交叉两种方式，注入到潜在空间表示中去。<p></p><p>随后在 z（x）基础上进行扩散与去噪。换言之， 就是模型并不直接在图像上进行计算，从而减少了训练时间、效果更好。</p><p>值得一提的是，Stable DIffusion 的上下文机制非常灵活，y 不光可以是图像标签，就是蒙版图像、场景分割、空间布局，也能够相应完成。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce7_1024.jpg" data-height="1308" data-width="822" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce7_1024.jpg" referrerpolicy="no-referrer"></div></div><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce8_1024.jpg" data-height="763" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/630ef8008e9f094ab6086ce8_1024.jpg" referrerpolicy="no-referrer"></div></div><b>霸占 GitHub 热榜第一</b><p></p><p>这个平台一开源，就始终霸占 GitHub 热榜第一，目前已累计 2.9k 星。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce9_1024.jpg" data-height="147" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086ce9_1024.jpg" referrerpolicy="no-referrer"></div></div>它是由慕尼黑大学机器视觉与学习研究小组和 Runway 的研究人员，基于 CVPR2022 的一篇论文《High-Resolution Image Synthesis with Latent Diffusion Models》，并与其他社区团队合作开发的一款开源模型。<p></p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086cea_1024.jpg" data-height="254" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/630ef8008e9f094ab6086cea_1024.jpg" referrerpolicy="no-referrer"></div></div>据官方介绍，它能在几秒内在消费级 CPU 上运行创作，也无需进行任何预处理和后处理。<p></p><p>核心数据集是 LAION-5B 的一个子集，它是专为基于 CLIP 的新模型而创建。</p><p>同时，它也是首个在 4000 个 A100 Ezra-1 AI 超大集群上进行训练的文本转图像模型。</p><p>不管怎么说，在文本生成图像这一趴，又多了一位实力强劲的明星了。（狗头）</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            