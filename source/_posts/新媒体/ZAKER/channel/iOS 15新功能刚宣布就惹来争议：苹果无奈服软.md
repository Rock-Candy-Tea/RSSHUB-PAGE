
---
title: 'iOS 15新功能刚宣布就惹来争议：苹果无奈服软'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/6132e12e8e9f0955d12514d8_1024.jpg'
author: ZAKER
comments: false
date: Fri, 03 Sep 2021 21:08:02 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/6132e12e8e9f0955d12514d8_1024.jpg'
---

<div>   
<p>在遭到众多用户的反对后，苹果服软了。</p><p>据外媒报道，近日，<strong>苹果打算在 iOS 15 中加入一项新功能，用于扫描 iCloud 帐户中图像遭到众多用户的质疑后，宣布将推迟该功能的上线。</strong></p><p>周五，苹果公司发表一份声明指出，上个月，发布了一种能检测设备内儿童的不雅照片，包括虐童、有色制品等内容的本地算法，以限制相关内容的传播。</p><p>在收到客户、宣传团体、研究人员和其他方面的反馈后，<strong>决定在未来几个月内花更多时间收集意见，并在发布这些至关重要的儿童安全功能之前进一步升级改造。</strong></p><p>上个月，苹果在宣布其能够检查用户设备中是否存在非法的儿童照片功能后，立即引发了争议。<strong>众多用户担心，此举将侵犯自己的隐私权。</strong></p><p>不过，苹果方面则认为，其算法并不会侵犯用户隐私，因为苹果在这个全程中，都不会知道用户相册中图片的具体信息，只是本地算法在通过比对后，会告诉苹果这部手机中可能有相关内容。</p><p>并且该检测算法全程都会在手机本地完成。例如，用户需要在其照片库中满足约 30 个儿童性虐待材料（CSAM）内容的匹配，苹果才会被提醒相关账户的违禁情况。待人工确认图像后，必要时才会将违禁信息传递给执法部门。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202109/6132e12e8e9f0955d12514d8_1024.jpg" data-height="399" data-width="600" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/6132e12e8e9f0955d12514d8_1024.jpg" referrerpolicy="no-referrer"></div></div><p></p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            