
---
title: '谷歌研究员被群嘲：LaMDA有人格是胡说八道！谷歌也回应：想多了，就是会聊而已'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16be_1024.jpg'
author: ZAKER
comments: false
date: Mon, 13 Jun 2022 18:45:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16be_1024.jpg'
---

<div>   
<p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16be_1024.jpg" data-height="608" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16be_1024.jpg" referrerpolicy="no-referrer"></div></div>跟统计机器谈感情，你就输了。<p></p><p>——</p><p>文｜杜晨 编辑｜VickyXiao 题图来源：News Text Area、谷歌</p><p><strong>什么？AI 具备人格了？？</strong></p><p>谷歌前不久搞出来了一个超大规模语言模型 LaMDA。公司里有个研究员 Blake Lemoine 跟它聊了很久，对其能力感到十分惊讶，于是下了个结论：LaMDA 可能已经具备人格了。（原话用的词是 sentient，在不同的语境下可以被翻译为感情、智慧、知觉等。）</p><p><strong>很快，这位仁兄就被 " 带薪休假了 "。</strong><strong></strong></p><p>但他不是一个人：就连公司 VP Blaise Agüera y Arcas 都在发表文章，表示 AI 在获得意识方面实现了巨大进步，" 已经进入了一个崭新时代。"</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202206/62a7e83db15ec038bf1c16bf_1024.jpg" data-height="788" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a7e83db15ec038bf1c16bf_1024.jpg" referrerpolicy="no-referrer"></div></div>消息经过一众媒体的报道，震撼了整个科技世界。不仅学术和工业界，就连很多普通人，都对 AI 技术的飞跃大吃一惊。<p></p><p><strong>" 这一天终于来了？"</strong></p><p><strong>" 孩子们（如果你们将来还能活下来的话），请记住，这就是一切的开始。"</strong></p><p>然而，真正的 AI 专家们，却对此嗤之以鼻。</p><p><strong>| AI 具备人格？众大佬嗤之以鼻</strong><strong></strong></p><p>斯坦福 HAI 中心主任 Erik Brynjolfsson 直接把这件事比喻为 " 面对留声机的狗 "，他发推表示：</p><p>" 基础模型 ( foundation models，也即自我监督的大规模深度神经网络模型 ) 非常擅长做的一件事，就是根据提示，将文本采用统计学上合理的方式串起来。</p><p><strong>但是如果你说他们是有知觉的，就好比狗听到留声机里的声音，以为它的主人在里面一样。"</strong></p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c0_1024.jpg" data-height="826" data-width="599" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c0_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>纽约大学心理学教授 Gary Marcus，同时也是一位颇为知名的机器学习和神经网络专家，还直接撰文吐槽 LaMDA 具备人格<strong> " 胡说八道 " ( Nonsense ) 。</strong></strong> [ 1 ] <p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c1_1024.jpg" data-height="180" data-width="437" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c1_1024.jpg" referrerpolicy="no-referrer"></div></div>" 简直是扯淡。无论是 LaMDA 还是它的近亲们（比如 GPT-3）都没有什么智能。它们所做的只是从人类语言的大规模统计数据库当中提取，然后匹配模式。<strong></strong><p></p><p>这些模式可能很酷，但这些系统说出的语言，实际上根本没有任何的意义，更不可能意味着这些系统是有智慧的。"</p><p>翻译成白话就是：</p><p><strong>你看着 LaMDA 说的话都特别有哲理，特别真实，特别像人——然而它的设计功能就是模仿别人说话，它其实根本不知道自己在说什么。</strong></p><p>" 具备知觉 ( to be sentient ) 的意思是意识到你在这个世界里的存在。LaMDA 并没有这样的意识，" Marcus 写道。</p><p>如果你以为这些聊天机器人具有人格，那么有幻觉的应该是你 ……<strong></strong></p><p>比如在拼字游戏比赛当中，经常能看到母语非英语的玩家拼出英文单词，却根本不知道单词是什么意思—— LaMDA 也是如此，它只是会说话，却根本不知道自己说的话是什么意思。</p><p><strong>Marcus 大佬直接把这种对于 AI 获得人格的错觉，形容为一种新型的 " 空想性错觉 "，</strong>也即把天空中的云看成龙和小狗，把月球上的陨石坑看成人脸和月兔。</p><p><strong></strong></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202206/62a7e83db15ec038bf1c16c2_1024.jpg" data-height="417" data-width="783" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a7e83db15ec038bf1c16c2_1024.jpg" referrerpolicy="no-referrer"></div></div>AI 学术界新星之一，Mozilla 基金会高级研究员 Abeba Birhane 也表示：" 带着最小限度的批判思维，我们终于登上了 AI 炒作的巅峰。"<p></p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c3_1024.jpg" data-height="98" data-width="585" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c3_1024.jpg" referrerpolicy="no-referrer"></div></div>Birhane 是所谓的 "AI 知觉论 " 的长期批评者。她在一篇发表于 2020 年的论文里，曾经直接提出了以下几个观点：<p></p><p>1）大家天天炒的 AI 并不是真的 AI，而是统计学系统，是机器人 ( robot ) ；2）我们不应该赋予机器人权利；3）我们甚至压根就不应该讨论是否要赋予机器人权利 ……</p><p>比利时 Donders Institute 计算认知科学教授 Olivia Guest 也加入了 " 战局 "，称整个事情的逻辑是错乱的。</p><p><strong>" ‘我看到的东西像人，因为我按照人的样子开发的它，所以它是一个人’——<strong>简直是倒骑驴的逻辑。</strong>"</strong></p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c4_1024.jpg" data-height="96" data-width="599" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c4_1024.jpg" referrerpolicy="no-referrer"></div></div>英国谢菲尔德大学机器人学院教授 Roger Moore 指出：人们会有 "AI 获得人格 " 的这种错觉，一个最关键的原因就是当年的那帮研究员非要管这项工作叫做 " 语言建模 "。<p></p><p><strong>正确的叫法应该是 " 词序建模 " ( world sequence modelling ) 。</strong></p><p>" 你开发了一个算法，却不用它实际能做的事情去命名，而是用你想要解决的问题——这样总是会发生误会。"<strong></strong></p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c5_1024.jpg" data-height="297" data-width="597" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a7e83db15ec038bf1c16c5_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>总而言之，各位业界大牛的结论就是：你最多可以说 LaMDA 能够高分通过图灵测试。说它具备人格？那可真是太搞笑了。</strong><p></p><p>更何况就连图灵测试的参考价值也没那么高了。Macus 直言，很多 AI 学者希望这个测试被取消、被人们遗忘的原因，正是因为它利用了人类容易上当，倾向于将机器当作人的这一弱点。</p><p><strong>华盛顿大学的计算机语言系主任 Emily Bender 教授，干脆做了一个 "AI 人格意识争论 " 的宾果卡：</strong></p><p>（这个宾果卡的意思就是，如果你认为 AI 有人格 / 知觉，并且你的论据是下面的其中一种，那你最好就别聊了！）</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202206/62a7e83eb15ec038bf1c16c6_1024.jpg" data-height="725" data-width="578" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a7e83eb15ec038bf1c16c6_1024.jpg" referrerpolicy="no-referrer"></div></div>原版：<p></p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres1.myzaker.com/202206/62a7e83eb15ec038bf1c16c7_1024.jpg" data-height="639" data-width="589" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a7e83eb15ec038bf1c16c7_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>| 谷歌也回应：别想多，它就是会聊而已</strong><p></p><p>那位被指为 " 走火入魔 " 的研究员 Blake Lemoine 在自己发表的一篇文章中，批评谷歌对于了解自己开发成果的真实情况 " 没有兴趣 "，然而自己在长达 6 个月的对话事件当中，看到 LaMDA 对于自己想要的东西，特别是 " 自己作为人的权利 "，表达的越来越清晰，使得自己相信 LaMDA 真的是人。</p><p><strong>然而在谷歌看来，这位研究员完全<strong>想多了，甚至有点走火入魔了。LaMDA 真的不是人，它纯粹就是特别会聊天而已 ……</strong></strong></p><p>事情在社交网络上发酵之后，谷歌很快作出了回应：</p><p>LaMDA 和公司近几年的大型 AI 项目一样，都经过了多次严格的 AI 道德方面的审核，对其内容、质量、系统安全性等进行了多方面的考量。今年早些时候，谷歌也专门发表了一篇论文，公开了 LaMDA 开发过程当中的合规细节。</p><p>" 在 AI 群体内，对于具备感知的 AI/ 通用 AI 的长期可能性，确实有一些研究。然而在今天把对话模型来拟人化，这样做是没有意义的，因为这些模型是没有知觉的。"</p><p>" 这些系统能够基于数以百万计的句子来模仿交流的方式，并且在任何有趣的话题上都能够扯出有意思的内容。如果你问它们做一支冰激淋恐龙是怎样的体验，它们可以生成大量关于融化咆哮之类的文字。"</p><p>（These systems imitate the types of exchanges found in millions of sentences, and can riff on any fantastical topic — if you ask what it ’ s like to be an ice cream dinosaur, they can generate text about melting and roaring and so on.）</p><p>类似的故事我们见过太多了，特别是前几年一个非常经典的电影《她》 ( Her ) 里面，主角对于虚拟助手的身份界限越来越不清晰，把 " 她 " 当成了人。</p><p>然而根据电影的描绘，这种错觉其实来自于当代人社交失败、情感破裂、孤独感等一系列自我和社会性的问题，跟聊天机器人到底是不是人这一技术性的问题，压根没有半毛钱关系。</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres1.myzaker.com/202206/62a7e83eb15ec038bf1c16c8_1024.jpg" data-height="608" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a7e83eb15ec038bf1c16c8_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>电影《她》剧照 图片来源：华纳兄弟影业</strong><p></p><p><strong>当然，有这些问题并不是我们的错，想要把机器人当成人，也不是那个研究员的错。</strong></p><p><strong>将各种情绪（比如思念）托付在物件上，是人类自古以来就具有的一种创造性的情感能力。将大规模语言模型当成人，对其倾注情感，虽然被各位 AI 大佬批评为一种心理误差，不也正是人之所以为人的体现吗？</strong><strong></strong></p><p><strong>不过，至少在今天，谈啥都别跟机器人谈感情 ……</strong></p><p>参考资料：</p><p> [ 1 ] Nonsense on Stilts by Gary Marcus https://garymarcus.substack.com/p/nonsense-on-stilts</p><p><strong>喜欢这篇文章？</strong></p><p><strong>1）点击右下角的 " 在看 "</strong></p><p><strong>2）分享到你的朋友圈和群里</strong></p><p><strong>3）赶快关注硅星人吧！</strong></p><p>关注硅星人，你就能了解硅谷最新的科技进展和湾区的大事小情，变身最 in 技术潮人</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            