
---
title: 'Gary Marcus公开喊话Hinton、马斯克：深度学习就是撞墙了，我赌十万美金'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3c_1024.jpg'
author: ZAKER
comments: false
date: Thu, 09 Jun 2022 02:08:24 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3c_1024.jpg'
---

<div>   
<p>机器之心报道</p><p><strong>编辑：蛋酱、小舟</strong></p><p>2029 年实现 AGI ? Gary Marcus：不可能，我赌十万美金。</p><p>「如果有人说（深度学习）撞墙了，那么他们只需列出一张清单，列出深度学习无法做到的事情。5 年后，我们就能证明深度学习做到了。」</p><p>6 月 1 日，深居简出的 Geoffrey Hinton 老爷子做客 UC 伯克利教授 Pieter Abbeel 的播客节目，俩人进行了长达 90 分钟的对谈，从 Masked auto-encoders、AlexNet 聊到脉冲神经网络等等。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3c_1024.jpg" data-height="563" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3c_1024.jpg" referrerpolicy="no-referrer"></div></div>在节目里，Hinton 明确对「深度学习撞墙了」这个观点发起质疑。<p></p><p>「深度学习撞墙了」这个说法，来自知名 AI 学者 Gary Marcus 三月份的一篇文章。准确地说，他认为「纯粹的端到端深度学习」差不多走到尽头了，整个 AI 领域必须要寻找新出路。</p><p>出路在哪儿？按照 Gary Marcus 的想法，符号处理将大有前途。不过这个观点一向没有受到社区重视，之前 Hinton 甚至说过：「在符号处理方法上的任何投资都是一个巨大的错误。」</p><p>Hinton 在播客里的公开「反驳」显然引起了 Gary Marcus 的注意。</p><p>就在十几个小时前，Gary Marcus 在推特上发出了一封给 Geoffrey Hinton 的公开信：</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3d_1024.jpg" data-height="1545" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3d_1024.jpg" referrerpolicy="no-referrer"></div></div>信里是这么说的：「我注意到，Geoffrey Hinton 正在寻找一些挑战性的目标。在 Ernie Davis 的帮助下，我确实已经写下了这样一个清单，上周我还向马斯克发出了一个 100000 美元的赌约。」<p></p><p>这里又有马斯克什么事？原因还要从 5 月底的一条推特说起。</p><p><strong>与马斯克的十万美金赌约</strong></p><p>一直以来，人们所理解的 AGI 是太空漫游（HAL）和钢铁侠（JARVIS）等电影中描述的那种 AI。与当前为特定任务训练的 AI 不同，AGI 更像人脑，可以学习如何完成任务。</p><p>大多数专家认为 AGI 需要几十年才能实现，而有些人甚至认为这个目标永远不可能实现。在对该领域专家的调查中，预估到 2099 年将有 50% 的机会实现 AGI。</p><p>相比之下，马斯克显得更加乐观，甚至在推特上公开表达：「2029 年是关键的一年，如果那时我们还没有实现 AGI，我会感到惊讶。希望火星上的人们也是如此。」</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3e_1024.jpg" data-height="379" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3e_1024.jpg" referrerpolicy="no-referrer"></div></div>表示并不认同的 Gary Marcus 很快反问：「你愿意赌多少钱？」<p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3f_1024.jpg" data-height="501" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c3f_1024.jpg" referrerpolicy="no-referrer"></div></div>虽然马斯克并没有回复这条提问，但 Gary Marcus 继续表示，可以在 Long Bets 组局，金额是十万美元。<p></p><p>在 Gary Marcus 看来，马斯克的相关观点不大靠谱：「比如你在 2015 年说过，实现完全自动驾驶的汽车还需要两年时间，从那以后，你几乎每年都说一遍同样的话，可现在完全自动驾驶仍未实现。」</p><p>他还在博客中写下了五个检验 AGI 是否实现的标准，作为打赌的内容：</p><p>2029 年，AI 无法看懂电影然后准确告诉你正在发生的事情（人物是谁、他们的冲突和动机是什么等）；</p><p>2029 年，AI 无法阅读小说并可靠地回答有关情节、人物、冲突、动机等的问题；</p><p>2029 年，AI 无法在任何厨房中担任称职的厨师；</p><p>2029 年，AI 无法通过自然语言规范或与非专家用户的交互可靠地构建超过 10000 行的无错误代码（将现有库中的代码粘合在一起不算数）；</p><p>2029 年，AI 无法从以自然语言编写的数学文献中任意取证，并将其转换为适合符号验证的符号形式。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c40_1024.jpg" data-height="1104" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c40_1024.jpg" referrerpolicy="no-referrer"></div></div>「这是我的建议，如果你（或任何其他人）在 2029 年设法完成至少三个，就算你赢了。Deal？十万美元如何？」<p></p><p>在更多人的追捧下，这个赌约的金额已经上升到了 50 万美元。不过，截至目前，马斯克再无回复。</p><p><strong>Gary Marcus：AGI 并不像你想象的「近在眼前」</strong></p><p>6 月 6 日，Gary Marcus 在《科学美国人》发表文章，重申了自己的观点：AGI 并非近在眼前。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c41_1024.jpg" data-height="473" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c41_1024.jpg" referrerpolicy="no-referrer"></div></div>对于普通人来说，人工智能领域似乎正在取得巨大进步。在媒体的报道中：OpenAI 的 DALL-E 2 似乎可以将任何文本转换成图像，GPT-3 无所不知，DeepMind 5 月发布的 Gato 系统在每一项任务上都性能良好 ......DeepMind 的一位高级管理人员甚至吹嘘已开始寻求通用人工智能 ( AGI ) 、AI 具有与人类一样的智能水平 ......<p></p><p>别被骗了。机器有一天可能会和人一样聪明，甚至可能更聪明，但远不是现在。要创造真正理解和推理现实世界的机器，还有大量的工作要做。我们现在真正需要的是更少的吹捧姿态和更多的基础研究。</p><p>可以肯定的是，人工智能确实在某些方面取得了进步——合成图像看起来越来越逼真，语音识别可以在嘈杂环境中工作——但我们距离通用的人类水平 AI 还有很长的路要走，例如人工智能现在还不能理解文章和视频的真正含义，也不能处理意外障碍和中断。我们仍然面临 AI 多年来一直存在的挑战——让人工智能变得可靠。</p><p>以 Gato 为例，给定任务：为投手投掷棒球的图像加上标题，系统返回三个不同的答案：「一名棒球运动员在棒球场上投球」、「一名男子向棒球场上的投手投掷棒球」和「一名棒球运动员在击球，一名接球手在一场棒球比赛」。第一个答案是正确的，而其他两个答案似乎包含图像中看不到的其他球员。这说明 Gato 系统并不知道图像中的实际内容，而是了解大致相似图像的典型内容。任何棒球迷都能看出这是刚刚投球的投手——虽然我们预计附近有接球手和击球手，但他们显然没有出现在图像中。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c42_1024.jpg" data-height="863" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c42_1024.jpg" referrerpolicy="no-referrer"></div></div>同样，DALL-E 2 会混淆这两种位置关系：「蓝色立方体顶部的红色立方体」和「红色立方体顶部的蓝色立方体」。类似地，5 月谷歌发布的 Imagen 模型无法区分「宇航员骑马」和「马骑宇航员」。<p></p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c43_1024.jpg" data-height="1229" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202206/62a1b7d5b15ec05a5b2f9c43_1024.jpg" referrerpolicy="no-referrer"></div></div>当 DALL-E 这样的系统出错时，你可能还觉得有些滑稽，但有一些 AI 系统如果出错，就会产生非常严重的问题。例如，一辆自动驾驶的特斯拉最近直接向路中间拿着停车标志的工人开去，人类司机干预后才能减速。该自动驾驶系统可以单独识别人类和停车标志，但遇到两者的不寻常组合时就未能减速。<p></p><p>所以，很不幸，AI 系统仍然不可靠，并且难以迅速适应新环境。</p><p>Gato 在 DeepMind 报告的所有任务上都表现出色，但很少能像其他当代系统一样。GPT-3 经常写出流利的散文，但仍然难以掌握基本的算术，而且它对现实的了解太少，很容易产生「一些专家认为吃袜子有助于大脑改变状态」之类令人匪夷所思的句子。</p><p>这背后存在的问题是，人工智能领域最大的研究团队不再是学术机构，而是大型科技企业。与大学不同，企业没有公平竞争的动力。他们的新论文没有经过学术审查就通过新闻发布，引导媒体报道，并回避同行评审。我们所获得的信息只是企业本身想让我们知道的事情。</p><p>在软件行业，有一个专门的词代表这种商业策略「demoware」，指软件的设计很适合展示，但不一定适合现实世界。</p><p>而这样营销的 AI 产品，要么无法顺利发布，要么在现实中一塌糊涂。</p><p>深度学习提高了机器识别数据模式的能力，但它存在三大缺陷：学习的模式是肤浅的，而不是概念性的；产生的结果难以解释；很难泛化。正如哈佛计算机科学家 Les Valiant 所指出的：「未来的核心挑战是统一 AI 学习和推理的形式。」</p><p>目前，企业追求的是超越基准，而不是创造新的想法，他们用已有的技术勉强进行小幅改进，而不是停下来思考更基本的问题。</p><p>我们需要有更多的人询问「如何构建可以同时学习和推理的系统」等基本问题，而不是追求华丽的产品展示。</p><p>这场关于 AGI 的争辩远未到达终点，也有其他研究者陆续加入。研究者 Scott Alexander 就在博客中指出，Gary Marcus 是个传奇，过去几年里写的东西或多或少不完全准确，但仍然有其价值。</p><p>比如 Gary Marcus 此前曾经批判过 GPT-2 的一些问题，八个月后，GPT-3 诞生时，这些问题都得以解决。但 Gary Marcus 并没有对 GPT-3 留情，甚至写了一篇文章：「OpenAI 的语言生成器不知道它在说什么。」</p><p>本质上说，一个观点目前而言是对的：「Gary Marcus 以嘲笑大型语言模型为噱头，但之后这些模型会变得越来越好，如果这个趋势持续下去，AGI 很快就会实现。」</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            