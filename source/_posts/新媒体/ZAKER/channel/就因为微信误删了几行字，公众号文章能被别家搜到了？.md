
---
title: '就因为微信误删了几行字，公众号文章能被别家搜到了？'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c408_1024.jpg'
author: ZAKER
comments: false
date: Sun, 24 Oct 2021 18:08:11 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c408_1024.jpg'
---

<div>   
<p>前天世超看到一个帖子说， 在 Google 和 Bing 能搜到微信公众号的文章了。</p><p>呸，怎么可能。</p><p>世超一边不信，一边赶紧拿 Google 测试了一下，发现差评的文章确实有被收录进去。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c408_1024.jpg" data-height="835" data-width="736" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c408_1024.jpg" referrerpolicy="no-referrer"></div></div>嚯，要这样下去，在百度里搜微信文章是不是也快了？<p></p><p>想必除了世超，很多网友应该都挺期待这件事的。毕竟有时候搜资料，在百度和微信之间切来切去还挺麻烦的。</p><p>谁想到世超还没乐呵够，腾讯马上就辟谣了：</p><p><strong>是公众号的 robots 协议出现漏洞，让搜索平台的爬虫爬到了，现在已经修复了。</strong></p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202110/61757c258e9f09787038c409_1024.jpg" data-height="491" data-width="600" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202110/61757c258e9f09787038c409_1024.jpg" referrerpolicy="no-referrer"></div></div>嗐，搞半天白高兴一场。<p></p><p>不过，今天世超还是想就这个 robots 协议和大家探讨一下。</p><p><strong>因为说起来你可能不信，我们在百度里前搜不到公众号文章，后搜不到淘宝商品，都是因为 robots 协议。</strong></p><p>robots 协议其实很简单，就是一个放在网站根目录的文本，它写明了搜索引擎<strong>可以 / 不可以</strong>收录哪些信息。</p><p>微信公众号的 robots 协议 ▼</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c40a_1024.jpg" data-height="165" data-width="264" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c40a_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>有人可能会说，原来就是这几行字害得互联网不能互联了？</strong><p></p><p>不不，这锅 robots 协议可不背。</p><p>robots 协议原本只是帮助搜索引擎更高效地收录信息，只不过现在人们用着用着逐渐变了味。</p><p>这事还得从上世纪 90 年代初期说起。</p><p>在搜索引擎诞生之前，人们要查资料，只能一个个进入相关网页，效率非常低下。</p><p>后来有了搜索引擎，搜索引擎通过释放网络爬虫（ 也可以叫蜘蛛 ），抓取各个网页里的信息，并把这些信息收录起来供大家查询，这才极大提高了人们的效率。</p><p>但是，那会爬虫就跟小黑胖一样，抓取信息来完全不挑食。</p><p>不管是没用的垃圾信息，还是网站重要的内部数据，不分青红皂白地一顿乱抓，全都要。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c40b_1024.jpg" data-height="343" data-width="465" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c40b_1024.jpg" referrerpolicy="no-referrer"></div></div>这种粗暴的抓法不仅降低了用户搜到有用信息的效率，还会让网页的重要数据泄露，服务器过载无法运行。<p></p><p>所以在 1994 年初，荷兰有位网络工程师提出了 robots 协议。</p><p>就好比宾馆房间门上挂着的 " 请勿打扰 "，" 欢迎打扫 " 牌子，告诉阿姨哪些房间是可以打扫的。</p><p><strong>每个网站的<strong>根目录下</strong>也摆着一份 robots 协议，协议里告诉爬虫：哪些东西你可以抓，哪些东西你不能抓。</strong></p><p>虽说这个 robots 协议目前还没被任何国际组织采纳，没有制约性，只能算个君子协议：你不听，就不是个正人君子。</p><p>但它毕竟为了帮助搜索爬虫更有效地抓取对用户有用的信息，更好促进信息共享。</p><p>所以在国外不管是早期的 altavista 还是后来的 Google 、必应，大家也都遵守着这一套协议。</p><p>同样 2012 年 11 月中国互联网协会发布了《 互联网搜索引擎服务自律公约 》，也规定了：</p><p>搜索引擎要遵守网站的 robots 协议，但前提是<strong>这</strong><strong>个</strong> <strong>robots 协议是合理的。</strong></p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202110/61757c258e9f09787038c40c_1024.jpg" data-height="122" data-width="722" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202110/61757c258e9f09787038c40c_1024.jpg" referrerpolicy="no-referrer"></div></div>这个公约对 12 家发起单位生效，成员包括百度、腾讯、奇虎 360、搜狗、网易、新浪等。<p></p><p>图源百度百科 ▼</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202110/61757c258e9f09787038c40d_1024.jpg" data-height="375" data-width="578" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202110/61757c258e9f09787038c40d_1024.jpg" referrerpolicy="no-referrer"></div></div>如今绝大多数搜索引擎的爬虫在访问网站时，第一件事就先读下网站的 robots 协议。<p></p><p>在了解哪些信息是可以抓取之后，才会行动。</p><p>比如淘宝的 robots 协议，虽然只有简单的 4 行字，但写明了：<strong>百度爬虫</strong><strong>（ Baiduspider ）</strong><strong>不允许</strong><strong>（ Disallow ）</strong><strong>抓取任何内容</strong><strong>（ / ）</strong><strong>。</strong></p><p><strong></strong></p><p>百度爬虫过来看到协议后，就算心里难受，也只能啥也不碰马上离开。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres1.myzaker.com/202110/61757c258e9f09787038c40e_1024.jpg" data-height="173" data-width="337" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202110/61757c258e9f09787038c40e_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>那可能有人说，这既然是君子协议，会不会有人不当 " 君子 " 呢？</strong><p></p><p><strong></strong></p><p>当然有，robots 协议只相当于一个告知书，爬虫（ 背后的人 ）可以不听你的。</p><p>和大家说两个违背 robots 协议的例子。</p><p>第一个例子是 BE 和 eBay 的纠纷。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202110/61757c258e9f09787038c40f_1024.jpg" data-height="521" data-width="765" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202110/61757c258e9f09787038c40f_1024.jpg" referrerpolicy="no-referrer"></div></div>BE 是一个提供拍卖信息的聚合网站。它利用爬虫抓取 eBay 等拍卖网站的商品信息，然后放在自己网站上赚取流量。<p></p><p>尽管 eBay 早已写好了 robots 协议，告诉 BE 爬虫不准抓取任何内容。</p><p>但 BE 认为这类拍卖信息都是大众上传的，eBay 设置 robots 协议不让自己抓取，不合理啊。</p><p>后来法院经过多方调查取证，认为 ebay 网站上内容属于私有财产，它用 robots 协议保护私有财产是合理的。</p><p>最后认定 BE 侵权。</p><p>想必大家能看出来，法院判定结果并不是单纯看有没有违背 robots 协议，最主要还得看这个<strong> robots 协议合不合理。</strong></p><p><strong></strong></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><strong><img class="lazy opacity_0 " id="img_8" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c410_1024.jpg" data-height="263" data-width="258" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c410_1024.jpg" referrerpolicy="no-referrer"></strong></div></div>同样，还有个例子也证明了这点。<p></p><p>大部分人都知道 3Q 大战，但可能没听过 360 和百度的 " 3B 大战 "。</p><p>2012 年 8 月 360 搜索刚上线，它抓取了百度旗下的内容（ 百度知道，贴吧 ）并以快照的形式提供给用户。</p><p>但是，百度的 robots 协议写明了只有部分搜索引擎可以抓取，当中没包括 360 搜索。</p><p>也就是说 360 违背了百度 robots 协议。</p><p>图源百度百科 ▼</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c411_1024.jpg" data-height="349" data-width="621" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c411_1024.jpg" referrerpolicy="no-referrer"></div></div>后来百度想了一个法子，只要在 360 搜索中搜到百度相关网站，点击后就会跳转到百度搜索引擎网站。<p></p><p>再到后来他们闹上了法庭。</p><p>这件事去年才算正式结案，判决书大概有一万多字吧，可把世超看了好一会。</p><p>不管是 360 把百度快照提供给用户，还是百度的跳转措施，这些操作法院都进行了相应的判决，但是跟我们文章没太大关系。</p><p>世超只在这里说下：<strong>对于 360 搜索违背百度 robots 协议的抓取行为，是怎么判定的。</strong></p><p>首先 360 在 2012 年 8 月违背 robots 协议是有不合理在先，但是同年 11 月发布了《 自律条约 》。</p><p>条约可是规定了<strong> robots 协议限制搜索引擎</strong><strong>得有正当理由</strong>：比如为了保护敏感信息、公众利益或者维持网站正常运行。</p><p>但百度限制 360 搜索抓取的内容，既不是重要敏感信息，被抓取了也不会让百度不能运行了或者损害了公共利益。。</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c412_1024.jpg" data-height="303" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c412_1024.jpg" referrerpolicy="no-referrer"></div></div>这就可以判定百度没有正当理由拒绝 360 抓取， <strong>360 的抓取行为也并非不正当竞争行为。</strong><p></p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_11" data-original="http://zkres2.myzaker.com/202110/61757c258e9f09787038c413_1024.jpg" data-height="238" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202110/61757c258e9f09787038c413_1024.jpg" referrerpolicy="no-referrer"></div></div><strong></strong>所以啊，<strong>不是写了 robots 协议就一定在理，你这个协议首先得合理才行。</strong><p></p><p><strong></strong></p><p><strong>但关键是，这个合理的界限有时候不是很好定。。</strong></p><p>比如现在不少互联网公司用 robots 协议阻止搜索引擎收录，限制了信息分享。</p><p>你说他们是在合理设置 robots 也没错，毕竟是为了保护自己的数据权益。</p><p>但这是不是和互联网的初衷背道而驰了呢。。</p><p>就拿世超自己经历来讲。</p><p>之前写个反诈骗的文章，百度查了大半天资料不够，差点放弃。后来在微信里搜，才在一家公众号文章上找到相关资料。最后要找视频作为动图素材，我又跑去短视频平台。。</p><p>要知道曾几何时，我们明明可以很轻易的查询到信息，现在因为各大网站的 robots 协议变成了如此困难。。</p><p>更讽刺的是， robots 协议原本做出来只是为了提高爬虫效率，更好地促进信息流动的。。<strong></strong></p><p>这是不是有点变味了。。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            