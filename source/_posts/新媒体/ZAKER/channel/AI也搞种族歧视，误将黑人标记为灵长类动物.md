
---
title: 'AI也搞种族歧视，误将黑人标记为灵长类动物'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/6135c0088e9f092b4f3fe0b6_1024.jpg'
author: ZAKER
comments: false
date: Mon, 06 Sep 2021 06:22:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/6135c0088e9f092b4f3fe0b6_1024.jpg'
---

<div>   
<p>整理 | 祝涛</p><p>出品 | CSDN（ID：CSDNnews）</p><p>Facebook 的人工智能在一段有关黑人的视频上误贴 " 灵长类 " 标签，于是 Facebook 在近日道歉，称这是一个 " 不可接受的错误 "，该公司正在调查以防止类似事件再次发生。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202109/6135c0088e9f092b4f3fe0b6_1024.jpg" data-height="660" data-width="1024" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/6135c0088e9f092b4f3fe0b6_1024.jpg" referrerpolicy="no-referrer"></div></div>据《纽约时报》报道，Facebook 用户称其最近观看了一个来自英国小报的黑人视频，然而却收到了一个自动提示，询问他们是否愿意继续观看关于灵长类动物的视频。该公司立即调查并禁用推送该消息的 AI 功能。<p></p><p>这段视频拍摄于 2020 年 6 月 27 日，来源于《每日邮报》（The Daily Mail），内容涉及黑人男子与白人平民以及警察发生争执的片段，与灵长类动物没有任何关系。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202109/6135c0088e9f092b4f3fe0b7_1024.jpg" data-height="997" data-width="600" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/6135c0088e9f092b4f3fe0b7_1024.jpg" referrerpolicy="no-referrer"></div></div>曾在 Facebook 担任内容设计经理的 Darci Groves 说，一个朋友最近给她发了一张自动提醒的截图。然后，她把这篇文章发布到一个 Facebook 员工的产品反馈论坛上。作为回应，该公司的视频服务 Facebook Watch 的一名产品经理称这是 " 不可接受的 "。周五，Facebook 为其所谓的 " 不可接受的错误 " 道歉，并表示正在调查推荐功能，以 " 防类似事件再次发生 "。" 正如我们所说，虽然我们对人工智能进行了改进，但我们知道它并不完美，我们还需要一直改善。我们向任何看到这些无礼推荐消息的人道歉。"<p></p><p>这一事件只是人工智能工具显示性别或种族偏见的最新例子。谷歌、亚马逊和其他科技公司多年来一直因其人工智能系统存在偏见而受到审查，尤其是种族问题。研究表明，面部识别技术对有色人种有偏见，识别有色人种更困难，导致黑人在使用电脑的过程中受到歧视甚至因电脑错误被捕。</p><p>2015 年，谷歌照片错误地将黑人的照片贴上了 " 大猩猩 " 的标签，对此谷歌表示 " 非常抱歉 "，并将立即解决这个问题。两年多后，有媒体发现，谷歌的解决方案是审查搜索中的 " 大猩猩 " 一词，同时屏蔽 " 黑猩猩 " 和 " 猴子 " 等词汇。去年，脸书表示正在研究其使用人工智能 ( 包括 Instagram ) 的算法是否存在种族偏见。</p><p>今年 4 月，美国联邦贸易委员会 ( US Federal Trade Commission ) 警告称，显示出 " 令人不安的 " 种族和性别偏见的人工智能工具，如果被用于信贷、住房或就业决策，可能将违反消费者保护法。</p><p>参考链接：</p><p>https://www.theverge.com/2021/9/4/22657026/facebook-mislabeling-video-black-men-primates-algorithm</p><p>https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            