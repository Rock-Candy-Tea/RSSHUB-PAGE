
---
title: '错把黑人视频打上_灵长类动物_标签，Facebook的AI太离谱！官方已向公众致歉'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613599d08e9f09518009f42e_1024.jpg'
author: ZAKER
comments: false
date: Mon, 06 Sep 2021 00:07:59 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613599d08e9f09518009f42e_1024.jpg'
---

<div>   
<p>观看一个以黑人为主角的视频，结果平台给出的相关推荐是：</p><p>是否继续观看有关<strong>灵长类动物</strong>的视频？</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202109/613599d08e9f09518009f42e_1024.jpg" data-height="398" data-width="360" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613599d08e9f09518009f42e_1024.jpg" referrerpolicy="no-referrer"></div></div>这是最近一些 Facebook 用户在观看一则黑人视频时，遇到的真实情况。<p></p><p>视频的内容其实是几个平民和警察发生争执，和 " 猴子或灵长类动物 " 毫无关系。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202109/613599d08e9f09518009f42f_1024.jpg" data-height="1870" data-width="1125" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613599d08e9f09518009f42f_1024.jpg" referrerpolicy="no-referrer"></div></div>这在网上引起了轩然大波。<p></p><p>对此 Facebook 紧急致歉，称其是 " 不能容忍的错误 "。</p><p>目前，他们正在研究这一推荐功能以 " 防止这种情况再次发生 "。</p><p>" 我们的 AI 并不完美 "</p><p>这件事情起源于《每日邮报》2020 年 6 月 27 日发布的一个视频。</p><p>视频中有白人、黑人和警察，他们之间发生了一些争执，视频的主要人物是<strong>黑人</strong>。</p><p>最近，有 Facebook 用户观看这则视频时发现，平台给出的推荐提示居然是：</p><p>这让人感到有些错愕。</p><p>按照生物学定义划分，人类的确属于灵长目。</p><p>但结合一些社会情况，不少种族主义者将黑人贬低为 " 猴子 "、" 猩猩 "，意图刻意将他们与 " 人 " 区分开。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres1.myzaker.com/202109/613599d08e9f09518009f430_1024.jpg" data-height="124" data-width="1280" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613599d08e9f09518009f430_1024.jpg" referrerpolicy="no-referrer"></div></div>这样的社会背景，让人不免猜测 Facebook 给这段视频打上 " 灵长类动物 " 标签到底是怎么一回事。<p></p><p>于是有人把这个视频的情况告诉了前 Facebook 内容设计经理 Darci Groves ，看到这个情况后，Groves 感到非常的震惊。</p><p>随即，她把这一情况发到了一个面向 Facebook 员工的产品反馈论坛中。</p><p>之后，这事引起了 Facebook 官方的注意。</p><p>Facebook Watch 产品经理表示，这种情况是<strong>不能被容忍的</strong>，公司已经在调查问题的根本原因。</p><p>Facebook 发言人 Dani Lever 则在一份声明中表示，：</p><p>虽然我们在不断提升 AI 的水平，但是我们知道它并不完美，还有更多可以优化的地方。</p><p>我们向所有看到这则冒犯性推荐的人道歉。</p><p>AI 种族歧视，不是第一次了</p><p>Facebook 这次的 " 错误标签 "，再一次把 AI 推上了舆论的风口浪尖。</p><p>这几年，不少科技巨头的 AI 都出现了存在种族偏见的负面新闻。</p><p>2015 年，谷歌相册就曾把黑人照片打上黑猩猩的标签引起不少争议。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202109/613599d08e9f09518009f431_1024.jpg" data-height="978" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613599d08e9f09518009f431_1024.jpg" referrerpolicy="no-referrer"></div></div>当时，谷歌对此 " 深表歉意 "。<p></p><p>不过在 2018 年，《连线》杂志发现，谷歌并没有真的改正错误，只是……为图像分类算法去掉了 " 大猩猩 gorilla" 这个类别。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202109/613599d08e9f09518009f432_1024.jpg" data-height="440" data-width="440" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613599d08e9f09518009f432_1024.jpg" referrerpolicy="no-referrer"></div></div>去年被 CVPR 2020 收录的<strong>PLUSE 方法</strong>，也被人发现存在明显的种族偏见。<p></p><p>它是一个可以把打码的人脸修复如初的 AI，结果还原的人脸，全部是<strong>白人脸</strong>。</p><p>比如奥巴马这张复原图，可以说和他本人是毫无关系。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202109/613599d08e9f09518009f433_1024.jpg" data-height="720" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613599d08e9f09518009f433_1024.jpg" referrerpolicy="no-referrer"></div></div>对亚洲脸庞的复原效果也非常不好。<p></p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres1.myzaker.com/202109/613599d08e9f09518009f434_1024.jpg" data-height="680" data-width="1072" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613599d08e9f09518009f434_1024.jpg" referrerpolicy="no-referrer"></div></div>类似的例子在 AI 算法中，真的不少见。<p></p><p>由此，AI 的伦理问题也一直备受人们关注。</p><p>在把人和大猩猩弄混这事上，人类不会犯这种低级错误。为什么 AI 会呢？</p><p>有人认为这是一个复杂的计算机视觉问题。</p><p>找出图像之间相似是很容易的，但是找出为什么相似却不相关，这是个很难的问题。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202109/613599d08e9f09518009f435_1024.jpg" data-height="192" data-width="1470" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613599d08e9f09518009f435_1024.jpg" referrerpolicy="no-referrer"></div></div>也有人就指出这是因为 AI 做的工作更多是统计推理，它本身不会思考。<p></p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres2.myzaker.com/202109/613599d08e9f09518009f436_1024.jpg" data-height="124" data-width="1280" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202109/613599d08e9f09518009f436_1024.jpg" referrerpolicy="no-referrer"></div></div>所以，就要关注<strong>训练集</strong>。<p></p><p>有人就表示，他曾与一家大公司合作时发现，不少 AI 训练集中都存在偏见。</p><p>但是对于这一现象，不少团队都没有想消除歧视的想法。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres1.myzaker.com/202109/613599d08e9f09518009f437_1024.jpg" data-height="184" data-width="1258" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202109/613599d08e9f09518009f437_1024.jpg" referrerpolicy="no-referrer"></div></div>此外，也存在训练集中包含黑人面孔太少的可能，这导致算法在识别黑人面孔时会表现不好。<p></p><p>当然也不排除程序员本身存在种族偏见，所以在打标签时就已经存在偏见。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            