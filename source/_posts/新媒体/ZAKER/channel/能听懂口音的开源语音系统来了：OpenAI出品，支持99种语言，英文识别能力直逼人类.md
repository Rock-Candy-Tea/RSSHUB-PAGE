
---
title: '能听懂口音的开源语音系统来了：OpenAI出品，支持99种语言，英文识别能力直逼人类'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad862541c_1024.jpg'
author: ZAKER
comments: false
date: Sat, 24 Sep 2022 23:13:49 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad862541c_1024.jpg'
---

<div>   
<p><strong>逼近人类水平</strong>的语音识别系统来了？</p><p>没错，OpenAI 新开源了一个名为<strong>「Whisper」</strong>的新语音识别系统，据称在英文语音识别方面拥有接近人类水平的鲁棒性和准确性！</p><p>不仅如此，对于<strong>不同口音</strong>、<strong>专业术语</strong>的识别效果也是杠杠的！</p><p>一经发布就在推特上收获<strong>4800+ 点赞</strong>，<strong>1000+ 转发</strong>。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres1.myzaker.com/202209/632f4619b15ec04ad862541c_1024.jpg" data-height="1094" data-width="874" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad862541c_1024.jpg" referrerpolicy="no-referrer"></div></div>网友们纷纷对它意料之外的强大功能表示惊讶。<p></p><p>不仅是英文，有人用法国诗人波德莱尔的《恶之花》进行了语音测试，得到的文本<strong>几乎与原文一致</strong>。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad862541d_1024.jpg" data-height="358" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad862541d_1024.jpg" referrerpolicy="no-referrer"></div></div>OpenAI 联合创始人 & 首席科学家 Ilya Sutskever 就表示：<p></p><p>终于有一个靠谱的语音识别系统能听懂我的口音了。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres1.myzaker.com/202209/632f4619b15ec04ad862541e_1024.jpg" data-height="196" data-width="784" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad862541e_1024.jpg" referrerpolicy="no-referrer"></div></div>前任特斯拉人工智能总监 Andrej Karpathy 甚至转发评论：OpenAI 正处于最好的状态中。<p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad862541f_1024.jpg" data-height="162" data-width="418" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad862541f_1024.jpg" referrerpolicy="no-referrer"></div></div>话不多说，让我们看看这个被 " 好评如潮 " 的语音系统究竟是怎么回事。<p></p><p><b>逼近人类水平的语音识别系统</b></p><p>首先，Whisper 最大特点是它使用的<strong>超大规模训练集</strong>：</p><p>它使用从网络上收集的<strong>68 万小时</strong>的多语言、多任务监督数据进行训练。</p><p>这导致数据集的内容非常多元化，涵盖了许多不同环境、不同录音设备下、不同语言的音频。</p><p>具体而言，65% ( 438218 小时 ) 是英语音频和匹配的英语文本，大约 18% ( 125739 小时 ) 是非英语音频和英语文本，而最后 17% ( 117113 小时 ) 则是非英语音频和相应的文本。</p><p>其中，非英语部分共包含<strong>98 种</strong>不同语言。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625420_1024.jpg" data-height="984" data-width="994" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625420_1024.jpg" referrerpolicy="no-referrer"></div></div>不过，虽然音频质量的多样性可以帮助提高训练模型的鲁棒性，但转录文本质量的多样性并不是同样有益的。<p></p><p>初步检查显示，原始数据集中有大量不合格的、现有自动语音识别 ( ASR ) 系统生成的转录文本。</p><p>而以往的研究表明，在人工和机器混合生成的数据集上进行训练，会显著损害翻译系统的性能。</p><p>为了解决这个问题，研究团队开发了几种自动过滤方法来识别和删除低质量的数据源。</p><p>但值得一提的是，没有说话内容的片段会被留下，作为语音活动检测的训练数据。</p><p>其次，Whisper 体系结构是一种简单的端到端方法，具体来说就是 Transformer 的编码器 - 解码器格式。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625421_1024.jpg" data-height="756" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625421_1024.jpg" referrerpolicy="no-referrer"></div></div>输入音频被分成 30 秒的片段，再转换成 log-Mel 谱图，然后传入编码器。<p></p><p>解码器被训练来预测相应的文本标题，并混合特殊标记，指示单一模型执行诸如语言识别、多语言语音转录和英语语音翻译等任务。</p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625422_1024.jpg" data-height="190" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625422_1024.jpg" referrerpolicy="no-referrer"></div></div>除此之外，研究人员还为 Whisper 设置了<strong>5 种不同的型号</strong>，以下是各模型大致的内存需求和相对速度，使用者可以自行选择。<p></p><p>但需要注意的是，只有 "large" 型号支持多语言，前 4 个模型都只支持英语。</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625423_1024.jpg" data-height="313" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625423_1024.jpg" referrerpolicy="no-referrer"></div></div>不过不需要担心，与其他模型相比，英文语音识别正是 Whisper 的核心竞争力。<p></p><p>实验结果证明，Whisper 在 Librispeech test-clean 测试的错误率达到 2.7%。</p><p>虽然这一数值与 Wav2vec 2.0 一样，但在零样本性能上，Whisper 明显更稳健，<strong>平均误差减少了 55%</strong>。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202209/632f4619b15ec04ad8625424_1024.jpg" data-height="592" data-width="680" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad8625424_1024.jpg" referrerpolicy="no-referrer"></div></div>甚至零样本 Whisper 模型还<strong>缩小了与人类鲁棒性之间的差距</strong>。<p></p><p>可以看出，与人类 Alec 相比，LibriSpeech 模型的错误率大约是人类的两倍，而 Whisper 模型的鲁棒性边界则包括 Alec95% 的置信区间。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres1.myzaker.com/202209/632f4619b15ec04ad8625425_1024.jpg" data-height="670" data-width="696" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad8625425_1024.jpg" referrerpolicy="no-referrer"></div></div><b>研究团队</b><p></p><p>Whisper 的研究团队来自 OpenAI，共同一作有两位：Alec Radford、Jong Wook Kim。</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres1.myzaker.com/202209/632f4619b15ec04ad8625426_1024.jpg" data-height="211" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202209/632f4619b15ec04ad8625426_1024.jpg" referrerpolicy="no-referrer"></div></div>Alec Radford，OpenAI 的机器学习研究员，也是 indico.io 的联合创始人。<p></p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_11" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625427_1024.jpg" data-height="250" data-width="250" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625427_1024.jpg" referrerpolicy="no-referrer"></div></div>Jong Wook Kim，在纽约大学获得了音乐技术专业的博士学位，研究方向包括多模态深度学习和音乐理解，目前是 OpenAI 的研究人员。<p></p><p></p><div class="img_box" id="id_imagebox_12" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_12" data-original="http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625428_1024.jpg" data-height="341" data-width="341" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202209/632f4619b15ec04ad8625428_1024.jpg" referrerpolicy="no-referrer"></div></div>值得一提的是，研究团队指出，虽然目前 Whisper 还没有实时功能，但它的运行速度和内存大小表明，在这一基础上搭建实时语音识别和翻译功能是可行的。<p></p><p>他们希望 Whisper 的高精度和易用性，将允许开发人员将语音接口添加到更广泛的应用程序中。</p><p><strong></strong></p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            