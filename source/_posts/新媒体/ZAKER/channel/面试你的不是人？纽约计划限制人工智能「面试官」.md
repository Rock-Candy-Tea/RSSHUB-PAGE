
---
title: '面试你的不是人？纽约计划限制人工智能「面试官」'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201691_1024.jpg'
author: ZAKER
comments: false
date: Tue, 23 Nov 2021 18:45:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201691_1024.jpg'
---

<div>   
<p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_0" data-original="http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201691_1024.jpg" data-height="675" data-width="1200" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201691_1024.jpg" referrerpolicy="no-referrer"></div></div>「我们无法提供有关您面试结果的具体反馈。」<p></p><p>在美国，越来越多的雇主利用人工智能（AI）加快招聘流程。但求职者很少知道 AI 招聘工具为何拒绝他们的简历，或者如何分析他们的视频面试。当他们落选时，往往只能收到这样一封冷冰冰的邮件，不知道自己到底为什么落选。</p><p>▲ 图片来自：unsplash</p><p>这不免令人不安，AI 在我们的职业生涯中究竟起到怎样的决定权？</p><p>11 月初，纽约市议会以 38 票对 4 票通过了一项法案：如果 AI 招聘系统没有通过年度审计，将被禁止使用。年度审计将检查 AI 招聘系统有没有种族或性别歧视，允许求职者选择人工审查等替代方案，AI 开发人员还需披露更多过去不透明的细节。</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres1.myzaker.com/202111/619cdc4cb15ec00ff6201692_1024.jpg" data-height="342" data-width="1042" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202111/619cdc4cb15ec00ff6201692_1024.jpg" referrerpolicy="no-referrer"></div></div>有趣的是，负责年度审计的是 AI 开发人员，但会被处罚的是雇主，如果他们使用了未通过年度审计的 AI 招聘系统，每项违规行为最高处罚 1500 美元。<p></p><p>支持者认为，该法案将为复杂的算法打开一扇窗户。算法往往根据求职者的说话或写作方式对技能和个性进行排名，但机器能否准确公正地判断性格特征和情绪信号值得怀疑，这一过程未来会更加透明。</p><p>至少，知道「因为算法有偏见而被拒绝」就是有意义的，牛津大学技术法教授 Sandra Wachter 曾经表示：</p><p>反歧视法主要是由投诉驱动的，如果他们不知道发生在自己身上的事情，就没有人可以抱怨被剥夺了工作机会。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201693_1024.jpg" data-height="708" data-width="1645" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201693_1024.jpg" referrerpolicy="no-referrer"></div></div>初创公司 Pymetrics 也非常支持这一法案，他们提倡借助 AI 通过游戏等方法面试，并认为其符合公平要求。与此同时，过时的 AI 面试方案将被扫进垃圾堆。AI 招聘系统提供商 HireVue 在今年初已开始逐步淘汰其面部扫描工具，这项工具被学术界称为「伪科学」，让人想起有关种族主义的颅相学理论。<p></p><p>对法案的反对意见，大多是出于「这远远不够」。民主与技术中心主席 Alexandra Givens 指出，提案实际上只是要求雇主满足美国民权法的现有要求——禁止因种族、民族或性别而产生不同影响的招聘行为，但忽略了针对残疾或年龄的偏见。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202111/619cdc4cb15ec00ff6201694_1024.jpg" data-height="3840" data-width="5760" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202111/619cdc4cb15ec00ff6201694_1024.jpg" referrerpolicy="no-referrer"></div></div>而一些人工智能专家和数字权利活动家担心，法案只是让 AI 开发人员自证他们遵守了基本要求，也只是为联邦监管机构和立法者设定薄弱标准，具体如何「审计偏见」非常模糊。<p></p><p>值得注意的是，偏见在面试中并不少见，主要问题出在喂养算法的样本，但它们往往被置于「黑箱」之中，普通求职者很难发觉。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201695_1024.jpg" data-height="420" data-width="630" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202111/619cdc4cb15ec00ff6201695_1024.jpg" referrerpolicy="no-referrer"></div></div>几年前，亚马逊停用了简历扫描工具，因为它偏向让男性担任技术岗位。部分原因在于，它将求职者的条件与公司内部的男性技术劳动力进行比较；同理，如果算法从种族和性别差异已经普遍存在的行业中获取养料，那么它只是在巩固偏见。<p></p><p>这种偏见并不只是招聘中。今年 4 月，南加州大学一项新的研究表明，Facebook 正在以可能违反《反歧视法》的方式展示广告，男性更有可能看到披萨送货司机招聘广告，而女性更有可能看到购物广告。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202111/619cdc4cb15ec00ff6201696_1024.jpg" data-height="3888" data-width="5184" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202111/619cdc4cb15ec00ff6201696_1024.jpg" referrerpolicy="no-referrer"></div></div>本质上，AI 歧视就是被人类社会培养的，个人的偏见行为甚至是下意识的，我们自己不一定察觉。如果将一家偏见较少的公司与偏见严重的公司比较，一般就是两种原因——前者在有意消除偏见方面做得更好，后者更擅长收集并不合理的现状并使它们永久化。<p></p><p>所以，中性意见认为纽约市提案最好的部分是它的披露要求，让人们知道自己正在被 AI 评估、如何被 AI 评估以及他们的数据去向是哪里。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            