
---
title: '苹果把NeRF玩出新高度：只需单个10s视频，就能重构人物动作和场景'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156141_1024.jpg'
author: ZAKER
comments: false
date: Sun, 21 Aug 2022 18:19:26 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156141_1024.jpg'
---

<div>   
<p>有了这个发明，以后演员拍戏再也不用抠图了？</p><p>答：可以直接一键合成。（手动狗头）</p><p>让我们赶紧来看看，这个由苹果最新研发的<strong>NeuMan</strong>框架：</p><p>只需输入一段 10s 左右的人物视频，就能合成该人物在新场景下做着各种新动作的影像。</p><p>前空翻？so easy！</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156141_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156141_raw.gif" data-height="216" data-width="618" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156141_1024.jpg" referrerpolicy="no-referrer"></div></div>跳舞那也是不在话下。<p></p><p>这妖娆的舞姿，看来 NeuMan 心里也有一个舞魂～</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_1" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156142_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156142_raw.gif" data-height="504" data-width="940" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156142_1024.jpg" referrerpolicy="no-referrer"></div></div>有网友看完就表示：喔～简直是电影界未来的发展方向。<p></p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156143_1024.jpg" data-height="170" data-width="876" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156143_1024.jpg" referrerpolicy="no-referrer"></div></div>目前，有关 NeuMan 的研究论文已被 ECCV ’ 22 收录，并且已在 GitHub 上开源。<p></p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156144_1024.jpg" data-height="271" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156144_1024.jpg" referrerpolicy="no-referrer"></div></div><b>全新场景渲染</b><p></p><p>在介绍 NeuMan 的原理之前，让我们再来欣赏几个酷炫的例子～</p><p>如下图所示，左上角是输入的训练视频，左下角是新的背景，右边则是合成后小哥在新背景下跳跃的效果。</p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_4" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156145_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156145_raw.gif" data-height="216" data-width="610" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156145_1024.jpg" referrerpolicy="no-referrer"></div></div>不仅是跳跃这种常规操作，广播体操也完全没问题。<p></p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_5" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156146_1024.jpg" data-gif-url="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156146_raw.gif" data-height="582" data-width="1079" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156146_1024.jpg" referrerpolicy="no-referrer"></div></div>更厉害的是，NeuMan 还可以将上面例子中的两个人合成到一起。<p></p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_6" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156147_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156147_raw.gif" data-height="584" data-width="1024" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156147_1024.jpg" referrerpolicy="no-referrer"></div></div>再加上一个人，立马变成魔性的广场舞视频。<p></p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_7" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156148_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156148_raw.gif" data-height="341" data-width="632" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156148_1024.jpg" referrerpolicy="no-referrer"></div></div>这微笑的小表情，真的很难解释不是本人亲自跳的（手动狗头）。<p></p><p>那么话说回来，这个神奇的 NeuMan 背后的原理是什么呢？</p><p><b>基于 NeRF 的新突破</b></p><p>事实上，自从伯克利和谷歌联合打造的 NeRF（Neural Radiance Fields 神经辐射场）横空出世，各种重建三维场景的研究层出不穷。</p><p>NeuMan 原理也是基于此，简单来说，就是用单个视频训练一个<strong>人物 NeRF 模型</strong>和一个<strong>场景 NeRF 模型</strong>，然后再合成在一起生成新的场景。</p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156149_1024.jpg" data-height="345" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef156149_1024.jpg" referrerpolicy="no-referrer"></div></div>首先，在训练场景 NeRF 模型时，我们先从输入的视频中提取相机姿态、稀疏场景模型和多视角 - 立体深度图。<p></p><p>对于原视频中被人体遮挡的部分，则使用 Mask R-CNN 进行图像实体分割，将人体掩模膨胀 4 倍，以确保人体被完全遮蔽。此时，就能做到仅在背景上训练场景 NeRF 模型。</p><p>至于人体 NeRF 模型训练，研究人员引入了一种端到端的 SMPL 优化（end-to-end SMPL optimization）和纠错神经网络（error-correction network）。</p><p>SMPL（Skinned Multi-Person Linear Model）是一种基于顶点的人体三维模型，能够精确地表示人体的不同形状和姿态。</p><p>如下图所示，使用端到端的 SMPL 优化的人体模型，能够更好地表现人体的典型体积。</p><p></p><div class="img_box" id="id_imagebox_9" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_9" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614a_1024.jpg" data-height="452" data-width="944" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614a_1024.jpg" referrerpolicy="no-referrer"></div></div>纠错神经网络则是用来弥补 SMPL 模型无法表达的细节。值得一提的是，它只在训练过程中使用，在进行全新场景渲染时会被放弃，以免造成过度拟合。<p></p><p>接下来，在两个模型对齐的阶段，研究人员先使用 COLMAP 解决任意尺度下的对齐问题。然后通过假设人类始终与地面有至少一个接触点，来进一步估计该场景的比例。</p><p></p><div class="img_box" id="id_imagebox_10" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_10" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614b_1024.jpg" data-height="446" data-width="946" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614b_1024.jpg" referrerpolicy="no-referrer"></div></div>最后，再应用 SMPL 网格和场景的点云叠加，就形成了新图像的渲染效果。<p></p><p></p><div class="img_box" id="id_imagebox_11" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_11" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614c_1024.jpg" data-height="329" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614c_1024.jpg" referrerpolicy="no-referrer"></div></div>最终成品显示，该场景 NeRF 模型方面模型能够有效地去除场景中的人类，并在有限的场景覆盖下生成高质量的新背景渲染图像。<p></p><p></p><div class="img_box" id="id_imagebox_12" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_12" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef15614d_1024.jpg" data-height="470" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef15614d_1024.jpg" referrerpolicy="no-referrer"></div></div>人物 NeRF 模型方面也能很好的捕捉人体的细节，包括袖子、衣领甚至衣服拉链，甚至在渲染新动作时，能执行难度极大的侧翻动作。<p></p><p></p><div class="img_box" id="id_imagebox_13" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_13" data-original="http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614e_1024.jpg" data-height="650" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202208/6301ced38e9f0926ef15614e_1024.jpg" referrerpolicy="no-referrer"></div></div>值得一提的是，不同于现行的其他 NeRF 模型对训练视频要求很高，比如需要多个机位拍摄、曝光要保持不变、背景要干净等等，NeuMan 的最大亮点是仅通过用户随意上传的<strong>单个视频</strong>就能达到同款效果。<p></p><p></p><div class="img_box" id="id_imagebox_14" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_14" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef15614f_1024.jpg" data-height="325" data-width="1080" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef15614f_1024.jpg" referrerpolicy="no-referrer"></div></div>并且，在分别输入六组不同的视频后，数据显示，与此前方法相比，NeuMan 的方法生成的视频渲染质量最佳。<p></p><p></p><div class="img_box" id="id_imagebox_15" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_15" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156150_1024.jpg" data-height="446" data-width="964" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156150_1024.jpg" referrerpolicy="no-referrer"></div></div>不过，研究团队也承认，NeuMan 的设计目前还存在一些缺陷。<p></p><p>例如，由于人在活动时手势的变化细微又多变，因此生成视频中对手部细节的把握还不是很准确。</p><p>另外，在 NeRF 模型渲染时，由于系统假设人类始终与地面有至少一个接触点，因此 NeuMan 不能适用于人与地面接触为零的视频，比如人做后空翻的视频。</p><p>要想解决这个问题，需要更智能的几何推理知识，这也是未来研究的一个发展方向。</p><p><b>研究团队</b></p><p>这项研究由苹果机器学习研究中心和英属哥伦比亚大学合作完成。</p><p>第一作者 Wei Jiang，是英属哥伦比亚大学计算机科学专业的一名四年级博士生，目前在苹果机器学习研究中心实习。</p><p>主要研究方向是新视角合成、视觉定位和三维视觉。</p><p></p><div class="img_box" id="id_imagebox_16" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_16" data-original="http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156151_1024.jpg" data-height="256" data-width="241" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202208/6301ced38e9f0926ef156151_1024.jpg" referrerpolicy="no-referrer"></div></div>他还是英属哥伦比亚大学计算机视觉实验室的一员，导师是 Kwang Moo Yi 教授。<p></p><p>硕士毕业于波士顿大学计算机科学专业，本科毕业于浙江工业大学软件工程专业。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            