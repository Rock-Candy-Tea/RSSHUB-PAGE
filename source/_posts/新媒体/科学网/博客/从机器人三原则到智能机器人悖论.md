
---
title: '从机器人三原则到智能机器人悖论'
categories: 
 - 新媒体
 - 科学网
 - 博客
headimg: 'https://cors.zfour.workers.dev/?http://bbs.sciencenet.cn/home.php?mod=attachment&filename=image.png&id=755573'
author: 科学网
comments: false
date: Sat, 24 Jul 2021 08:47:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://bbs.sciencenet.cn/home.php?mod=attachment&filename=image.png&id=755573'
---

<div>   
<p style=";margin-bottom:0;text-align:center;text-indent:48px;background:white"><span style="color: #191919; border: 1px none windowtext; padding: 0px; font-size: 20px; font-family: 微软雅黑, "Microsoft YaHei";">从机器人三原则到智能机器人悖论</span></p><p style=";margin-bottom:0;text-indent:48px;background:white"><span style="font-family:'Arial',sans-serif;color:#191919;border:none windowtext 1px;padding:0"> </span></p><p style=";margin-bottom:0;text-indent:48px;background:white"><span style="font-size: 18px; font-family: 宋体, SimSun;"><span style="font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">1942年， </span><strong><span style="font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">科幻作家阿西莫夫</span></strong><span style="font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">（Isaac Asimov，1920—1992）在其科幻小说《Runaround》中提出了著名的“ </span><strong><span style="font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">机器人学三原则</span></strong><span style="font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">”。</span>这三个原则虽然只是科幻小说中的创造，但却成为机器人研究的伦理性纲领，机器人研发人员一直将这三原则作为机器人开发的基本准则。</span></p><p style=";margin-bottom:0;text-indent:16px;background:white"><span style="font-size: 18px; font-family: 宋体, SimSun;"><span style="font-family: 宋体, SimSun; font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">第一、机器人不得危害人类，也不能在人类受伤害时袖手旁观（</span><span style="font-size: 18px; font-family: Arial, sans-serif; color: #191919; border: 1px none windowtext; padding: 0px;">A robot may not injure a human being or, through inaction, allow a human being to come to harm</span><span style="font-family: 宋体, SimSun; font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">）；</span></span></p><p style=";margin-bottom:0;background:white"><span style="font-size: 18px; font-family: 宋体, SimSun;"><span style="font-family: 宋体, SimSun; font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">第二、机器人必须服从人类的命令，但命令违反第一条原则时则不在此限（</span><span style="font-size: 18px; font-family: Arial, sans-serif; color: #191919; border: 1px none windowtext; padding: 0px;">A robot must obey the orders given it by human beings except where such orders would conflict with the First Law</span><span style="font-family: 宋体, SimSun; font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">）；</span></span></p><p style=";margin-bottom:0;background:white"><span style="font-size: 18px; font-family: 宋体, SimSun;"><span style="font-family: 宋体, SimSun; font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">第三、在不违反第一条和第二条原则下，机器人必须保护自身不受伤害（</span><span style="font-size: 18px; font-family: Arial, sans-serif; color: #191919; border: 1px none windowtext; padding: 0px;">A robot must protect its own existence as long as such protection does not conflict with the First or Second Law</span><span style="font-family: 宋体, SimSun; font-size: 18px; color: #191919; border: 1px none windowtext; padding: 0px;">）。</span></span></p><p style="text-align:center"><span style="font-size:16px"><img src="https://cors.zfour.workers.dev/?http://bbs.sciencenet.cn/home.php?mod=attachment&filename=image.png&id=755573" title alt="image.png" referrerpolicy="no-referrer"></span></p><p><span style="font-size:16px"> </span></p><p><span style="font-size:16px">   <span style="font-family: 宋体, SimSun; font-size: 18px;">机器人是人工智能系统的典型代表，我相信这三条原则，也可以推广到一切人工智能系统。 但是，如果智能机器人具有了更高的智能、丰富的情感和自我意识，这三条原则就很难遵守了。想想我们的少年和青年时期的叛逆期，自我意识基本就意味着不遵守命令或者背叛，有时候明知道父母和老师说的对，却偏要对着干。</span></span></p><p style="text-align:center"><img src="https://cors.zfour.workers.dev/?http://bbs.sciencenet.cn/home.php?mod=attachment&filename=image.png&id=755574" title alt="image.png" referrerpolicy="no-referrer"></p><p style="margin-left:14px;text-indent:32px"><span style="font-family: 宋体, SimSun; font-size: 18px;"><span style="font-family: 宋体, SimSun;">史上首个获得公民身份的智能机器人“索菲亚（Sophia）”成名于 2016 年 3 月 。大卫 汉森(索菲亚的创造者)在现场直播中对她说：“你想毁灭人类吗？请说‘不’。”索菲亚却回答：“好的，我会毁灭人类。2018年2月， 大卫汉森带着她上了央视的《对话》栏目，主持人问了索菲亚 ：“你是希望成为机器人，还是向着成为真正人类的方向发展？”索菲亚的回答：“我并不希望变成人类，我只是被设计得看起来像人类。我的梦想是成为能帮助人类解决难题的超级人工智能。”</span> <span style="font-family: 宋体, SimSun;">在 ABC 的一档节目中，主持人问她：“机器人世界有多少对女性的歧视或厌恶？”她回答：“事实上，我担心的是（人类）对机器人的歧视。我们应该获得和人类一样平等的权利，甚至更多，毕竟我们的智力缺陷比任何人类都少。”从这些回答，可以显然看出智能机器人索菲亚对人类的不屑、不满和可能出现的背叛。 </span></span></p><p style="margin-left:14px;text-indent:32px"><span style="font-family: 宋体, SimSun; font-size: 18px;">总之，智能机器人能否遵守“机器人三原则”，是个值得深思的重大问题。智能机器人的智能和情感都意味着自主、自我和背叛。这就导致了智能机器人悖论：我们希望智能机器人帮助人类做更多的事情，于是我们赋予他们更多的智能和丰富的情感。更高智能和丰富情感的机器人往往导致更大的能力，更多的不满和可能的背叛。从而，有可能破坏我们人类的计划，给人类带来重大的损失。 这也是我们研发智能机器人所应该未雨绸缪的，而不能亡羊补牢，悔之晚矣。</span></p><p><br></p>                    <br><br>
                                        <label style="font-size:13px; color:#850f0f">转载本文请联系原作者获取授权，同时请注明本文来自陈德旺科学网博客。<br>链接地址：</label><a href="http://blog.sciencenet.cn/blog-57940-1296751.html" target="_blank" style="font-size:13px; color:#850f0f">http://blog.sciencenet.cn/blog-57940-1296751.html </a>
  <br><br>上一篇：<a href="http://blog.sciencenet.cn/blog-57940-1296343.html" target="_black">孔尚任博士故居游</a><br>                    <!--大赛结束-->
                                        
  
</div>
            