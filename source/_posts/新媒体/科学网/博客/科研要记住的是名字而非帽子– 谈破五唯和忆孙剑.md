
---
title: '科研要记住的是名字而非帽子– 谈破五唯和忆孙剑'
categories: 
 - 新媒体
 - 科学网
 - 博客
headimg: 'https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103159ijhd7e67ycc06mgz.png'
author: 科学网
comments: false
date: Sun, 26 Jun 2022 10:05:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103159ijhd7e67ycc06mgz.png'
---

<div>   
<p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 88px"><br></p><p style=";font-size: medium;font-family: 宋体;white-space: normal">         这学期本科课上《数字图像处理》，人数远上于预期，只有6个学生，感觉挺郁闷的，也不知道上学期哪做错了。好在我的研究生课《高级机器学习》70多人，多少平衡了点。另外，今年的课只线下上了三节，就全程线上了。这也让我平衡了点，因为几个人、几十人，在线上上课的感觉，我觉得区别不大。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">不过既然是上课，就得认真上，与人多人少无关。一如既往，我在本科课上穿插了很多图像处理相关的、新的理念方法，也会给大家讲点返璞归真、大道至简的案例。比如上到第五章图像还原时，我会提下计算机视觉顶级会议2009年拿到最佳论文的那篇，去雾模型，因为它也是通过建模方式来还原去雾前的图像，属于图像还原范畴。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">虽然是最佳论文，但看它的思路，其实如果认真听过图像处理课并不难理解。它的两个关键步，一是局部找颜色通道的最小值，一是再从局部图像块上找最小值。两个合并起来，称为黑通道先验。为什么要在颜色通道找最小值呢？如果学过彩色图像处理这一章，就知道，饱和度的概念，和这个是一致的。饱和度越高，颜色越鲜明，它渗杂雾的可能性就越小，它被阴影遮住的可能性也越小。所以，认真学好图像处理，你会更好地理解作者提出这一去雾模型的动机。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><img src="https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103159ijhd7e67ycc06mgz.png" title alt="截屏2022-06-26 上午10.11.57.png" referrerpolicy="no-referrer"></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">图1: 黑通道先验[1]</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><br></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">但是光有这个概念还不行，细节决定成败。只做了这一步的结果，并不能帮助模型获得像素级的处理结果。所以，作者又增加了一个matting（注：最近从贾佳亚的“忆孙剑”一文得知，孙剑03年就已经开始研究Matting技术，并在Siggraph上与贾佳亚合作发表了相关论文）。这是来自图形学领域的概念，在当时也是广受关注的，因为它能帮助PS在剪人脸时把头发丝都不差毫厘地从照片中分离出来。这一技巧也适用于去雾模型。将黑通道先验与去雾模型结合后，便有了让人眼前一亮的去雾结果。拿到当年CVPR的最佳论文，也理所当然了。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><img src="https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103238p7hh9bk7nksy9sof.png" title alt="截屏2022-06-26 上午10.12.28.png" referrerpolicy="no-referrer"></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><br></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">图2: Matting思想[2]</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><img src="https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103313vlplr1r0wk099kr6.png" title alt="截屏2022-06-26 上午10.13.21.png" referrerpolicy="no-referrer"></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">图3: 去雾效果[3]</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">在讲图像压缩一章时，我会跟大家分析如何能够把编码做得更短，压缩程度更大。一般来说，信息越集中，越有利压缩。所以，在不考虑图像像素间关系时，信道上又无误差传输时，接近香农第一采样定律的块随机变量编码方式是最优的。但图像像素间往往是相关的，此时如果通过相减方式来获得残差，则可以把编码长度进一步压缩。这一点，可以通过像素的分布和像素残差分布，直观看出来，后者的分布更为集中。说到这里，我又会跳到CVPR16的最佳论文，残差神经网络。我跟同学们说，抛开层次的深度不说，想想，为什么要用残差来进行训练呢？不就是因为它的分布更为集中，在模型寻优中更容易找到最优解吗？那为什么要用跳连接呢？这是为了不损失掉原有的信息。可是直觉归直觉，要真正做好，还是细节决定的。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><img src="https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103408wc8jcqf8q6c4h7f6.png" title alt="截屏2022-06-26 上午10.25.36.png" referrerpolicy="no-referrer"></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">图4: 残差网的局部模块[2]</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><img src="https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/103436xlal3yllwl4vyjlv.png" title alt="截屏2022-06-26 上午10.18.21.png" referrerpolicy="no-referrer"></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">图5: 图像与图像预测误差的分布和熵值大小（引自图像处理课件）</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px"><br></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">讲完这些，我跟同学们说了更有意思的事，就是两篇论文的作者。第一篇，何凯明、汤晓鸥、孙剑，实际上也是人工智能界少有的三位著名学者。何凯明是2003年的广东高考状元。汤晓鸥和孙剑都曾是微软亚洲研究院的同事，后来汤于2014年创立了商汤科技，孙则于2016年加入旷视科技。在国内人工智能企业里，形成了所谓“南商汤、北旷视”的局面，颇像我当年看过的香港电视剧《再向虎山行》里的口头禅“南沧海、北铁山、一岳擎天绝世间”。而第二篇论文的作者，则仍然以何凯明和孙剑为主。而且，这篇文章提出的残差网，在近十年来，一直为大多数深度学习研究者当成骨干网在使用着，可见其性能是多么让人信服。两位作者的名字，也一并为大家记住了。提到何凯明、提到孙剑，大家都能说出他们的贡献是什么。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">实际上，对个人来说，这是科研的最高境界。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">我以前说科研，一般喜欢说王国维的三重境界：一境，“昨夜西风凋碧树。独上高楼，望尽天涯路”；二境，“衣带渐宽终不悔，为伊消得人憔悴”；三境，“众里寻他千百度，蓦然回首，蓦然回首，那人却在灯火阑珊处”。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 28px">这三境，都是在科研探索道路上走上成功需要的。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 32px">但对个人来说，我认为让大家记住名字更重要，尤其是在破五唯的时代，即需要破除“唯论文、唯帽子、唯职称、唯学历、唯奖项”的时代。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 32px">确实，论文本质上是用来交流学术进展的，对学生来说，也是验证自己科研能力的佐证，是读研期间必不可少的环节。但也不应该沉迷于其中，为了论文的数量而做低质量的成果叠加和重复性的微小变动。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 32px">帽子应该只作为个人科研能力达到一定程度后的锦上添花，而不应让其变成人生追求、科研院校追求的终极目标，否则有可能会造成学术圈的不良竞争、导致科研能力的整体下滑。其它“唯”类似。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 32px">唯有名字，是人出生就有了，一般也不会轻易改。一旦因为科研成果卓越，而被人记住名字了，这是一辈子的殊荣，不会因帽子多少而被忘记，也不会被人只记得帽子却忘了名字。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 32px">但要做到这一点，却又比论文、帽子要难，因为只有有非常有代表性的成果出现时，才可能让人记住名字。但也唯有这样，也许才能真正推动我国的科研水平整体向前更快的发展。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal;text-indent: 32px">所以，做科研，当如孙剑一样，能因为突出的科研成果而让人记住名字。但我也强烈建议，在身体健康方面，一定要注意平衡，细水长流。不要像孙剑一样，提前消耗掉自己宝贵的生命，让我国痛失了一位人工智能界的杰出人才。</p><p style=";font-size: medium;font-family: 宋体;white-space: normal"> </p><p style=";font-size: medium;font-family: 宋体;white-space: normal">张军平</p><p style=";font-size: medium;font-family: 宋体;white-space: normal">2022年6月26日</p><p style=";font-size: medium;font-family: 宋体;white-space: normal"><br></p><p style=";font-size: medium;font-family: 宋体;white-space: normal">参考文献：</p><ol class=" list-paddingleft-2" style="white-space: normal; padding: 0px 0px 0px 1.5em; outline: 0px; max-width: 100%; caret-color: rgb(34, 34, 34); color: rgb(34, 34, 34); font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; font-size: 17px; letter-spacing: 0.5440000295639038px; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"><li><p style="margin: 0px 0cm; padding: 0px; outline: 0px; max-width: 100%; clear: both; min-height: 1em; font-family: 宋体; caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0); letter-spacing: normal; box-sizing: border-box !important; word-wrap: break-word !important;"><span style="margin: 0px; padding: 0px; outline: 0px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;">Kaiming He, Jian Sun, Xiaoou Tang. Single Image Haze Removal Using Dark Channel Prior. CVPR 09, 最佳论文</span></p></li><li><p style="margin-top: 0px; margin-bottom: 0px; padding: 0px; outline: 0px; max-width: 100%; clear: both; min-height: 1em; box-sizing: border-box !important; word-wrap: break-word !important;"><span style="margin: 0px; padding: 0px; outline: 0px; max-width: 100%; font-family: NimbusRomNo9L; box-sizing: border-box !important; word-wrap: break-word !important;">Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. Deep Residual Learning for Image Recognition. CVPR 16, 最佳论文</span></p></li></ol><p style=";font-size: medium;font-family: 宋体;white-space: normal"> </p><p style=";font-size: medium;font-family: 宋体;white-space: normal;line-height: 28px"><span style="font-size: 15px">附挽联一首：</span></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;line-height: 28px"><span style="font-size: 15px">上联：ResNet网，faster-RCNN网，</span><span style="letter-spacing: 2px"> shuffle网，安息在网</span></p><p style=";font-size: medium;font-family: 宋体;white-space: normal;line-height: 28px"><span style="font-size: 15px;letter-spacing: 2px">下联：创旷视，领CV视，</span>改AI视，英名存视</p><p><span style="font-size: 15px;font-family: 宋体;letter-spacing: 2px"><span style="outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important">横批：视界流芳<br></span>           </span><span style="font-size: 15px;font-family: 'Helvetica Neue'"><span style="outline: 0px;max-width: 100%;box-sizing: border-box;visibility: visible"><span style="outline: 0px;max-width: 100%;visibility: visible;box-sizing: border-box !important">---</span><span style="font-size: 15px;font-family: 宋体">中国自动化学会混合智能专委会副主任张军平</span></span></span></p><p><span style="font-size: 15px;font-family: 'Helvetica Neue'"><span style="outline: 0px;max-width: 100%;box-sizing: border-box;visibility: visible"><span style="font-size: 15px;font-family: 宋体"><br></span></span></span></p><p><span style="font-size: 15px;font-family: 'Helvetica Neue'"><span style="outline: 0px;max-width: 100%;box-sizing: border-box;visibility: visible"><span style="font-size: 15px;font-family: 宋体"><img src="https://cors.zfour.workers.dev/?http://image.sciencenet.cn/home/202206/26/100515jj04go7fnqqqgfdg.jpg" title alt="DSC014051.JPG" referrerpolicy="no-referrer"></span></span></span></p><p><span style="font-size: 15px;font-family: 'Helvetica Neue'"><span style="outline: 0px;max-width: 100%;box-sizing: border-box;visibility: visible"><span style="font-size: 15px;font-family: 宋体"></span></span></span></p><p style=";font-size: medium;font-family: 宋体;white-space: normal"><span style="font-size: 15px;letter-spacing: 2px">图6：2017年混合智能专委会成立大会合影留念</span>（主任：薛建儒（前排左三）、副主任：孙长银（前排左二）、孙剑（前排右三）、张军平（前排右四）、陈德旺（后排左一）、李灵犀（前排右一）、秘书长：曲延云（后排右二）；副秘书长：李策（后排左二）、王晓（后排右二））</p><p><span style="font-size: 15px;font-family: 'Helvetica Neue'"><span style="outline: 0px;max-width: 100%;box-sizing: border-box;visibility: visible"><span style="font-size: 15px;font-family: 宋体"></span></span></span><br></p><p><br></p>                    <br><br>
                                        <label style="font-size:13px; color:#850f0f">转载本文请联系原作者获取授权，同时请注明本文来自张军平科学网博客。<br>链接地址：</label><a href="https://blog.sciencenet.cn/blog-3389532-1344599.html" target="_blank" style="font-size:13px; color:#850f0f">https://blog.sciencenet.cn/blog-3389532-1344599.html </a>
  <br><br>上一篇：<a href="http://blog.sciencenet.cn/blog-3389532-1343695.html" target="_black">《高质量读研》出版感言</a><br>                    <!--大赛结束-->
                                        
  
</div>
            