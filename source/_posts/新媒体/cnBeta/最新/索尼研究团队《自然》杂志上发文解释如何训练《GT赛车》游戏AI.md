
---
title: '索尼研究团队《自然》杂志上发文解释如何训练《GT赛车》游戏AI'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2022/0210/1c148ee85e1b2fb.jpg'
author: cnBeta
comments: false
date: Thu, 10 Feb 2022 03:30:39 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2022/0210/1c148ee85e1b2fb.jpg'
---

<div>   
过去两年时间里，<strong>索尼一直在通过由 1000 台 PlayStation 4 游戏机组建的虚拟训练场，对名为“GT Sophy”的人工智能开展培训。</strong>在去年 7 月的一场单车比赛中，其已能够超越真人玩家。然后 10 月份的时候，它甚至在虚拟赛车比赛中将人类挑落马下。<br>
<p><img src="https://static.cnbetacdn.com/article/2022/0210/1c148ee85e1b2fb.jpg" alt="1.jpg" referrerpolicy="no-referrer"></p><p style="text-align: center;">游戏截图</p><p>测试项目选择了 Polyphony Digital 开发的《GT 赛车》（Gran Turismo Sport），这是一款画面真实、热度相当之高的 PlayStation 独占游戏。</p><p>而在最新实验中，索尼希望证明人工 AI 可在国际象棋 / 围棋之外的赛事中也碾压真人选手，即使这些游戏被长期认为是由人类主导的。</p><p>有趣的是，AI 还曾在经典的雅达利视频游戏和《星际争霸》即时战略（RTS）游戏中击败了人类选手。</p><p><img src="https://static.cnbetacdn.com/article/2022/0210/ca71b3fb8cd93e0.png" referrerpolicy="no-referrer"></p><p>当今的人工智能，通常特指基于神经网络技术的计算机编程过程。该技术旨在模仿人脑的工作方式，而索尼的最新研究成果，已发表在周三出版的《<a href="https://www.nature.com/articles/s41586-021-04357-7" target="_self">自然</a>》杂志上。</p><p>对于《GT 赛车》之类的视频游戏来说，其最大的特色，就是提供了开放式的战术选择、以及模拟的物理规则。然而一位真人挑战者表示，GT Sophy 选择了新颖的路线来追赶他们。</p><p style="text-align: center;"><iframe src="//tv.sohu.com/s/sohuplayer/iplay.html?bid=324889829&autoplay=false&disablePlaylist=true" width="640" height="480" frameborder="0"></iframe></p><p style="text-align: center;">Sony AI x Polyphony Digital Race Together - K.Yoshida Message（<a href="https://tv.sohu.com/v/dXMvODIyMjQwNTMvMzI0ODg5ODI5LnNodG1s.html" target="_self">via</a>）</p><p>在 SONY AI 油管频道分享的一段视频中，曾于 FIA《Gran Turismo 2020》世界总决赛中赢得三项挑战的 Takuma Miyazono 指出：</p><p>“人工智能在以一种我们永远想不到的方式去驾驶，但在回看的时候，它又显得相当合理”。</p><p style="text-align: center;"><iframe src="//tv.sohu.com/s/sohuplayer/iplay.html?bid=324892377&autoplay=false&disablePlaylist=true" width="640" height="480" frameborder="0"></iframe></p><p style="text-align: center;">The Making of Gran Turismo Sophy - SONY AI（<a href="https://tv.sohu.com/v/dXMvODIyMjQwNTMvMzI0ODkyMzc3LnNodG1s.html" target="_self">via</a>）</p><p>据悉，GT Sophy 使用了一套被称作“深度强化学习”（deep reinforcement learning）的技术路线。</p><blockquote><p>起初这套完全未经训练的系统并不知道它该干什么，但通过遵循人工设计的奖励机制，它最终掌握了比赛规则、然后一遍又一遍地掌控了比赛。</p><p>期间的难点，在于如何弄清赛车比赛中中的不成文规则，包括如何避免碰撞、以及适时地切断竞争对手的路线。</p></blockquote><p>索尼 AI 总监 Peter Wurman 补充道：</p><blockquote><p>我们普遍低估了彰显正确体育精神的难度，要做到这一点，我们必须不在竞争压力下面露难色、过于胆怯或咄咄逼人。</p></blockquote><p>最后，为了运行这套模拟，索尼使用了 1000 台 PlayStation 4 游戏主机，并将之连接到了一台采用传统处理器的计算机上。</p>   
</div>
            