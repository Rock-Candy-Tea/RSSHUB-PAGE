
---
title: '民权组织呼吁云视频服务提供商Zoom放弃打造情绪分析软件的计划'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2022/0512/89db248df1a0ab4.jpg'
author: cnBeta
comments: false
date: Thu, 12 May 2022 03:21:47 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2022/0512/89db248df1a0ab4.jpg'
---

<div>   
美国公民自由联盟（ACLU）在致云视频会议服务提供商 Zoom 的一封公开信中表示：<strong>利用基于人工智能（AI）的算法来监测与会者情绪的做法，涉嫌侵犯了用户隐私及其公民权益。</strong>有鉴于此，民权组织呼吁 Zoom 放弃打造“情绪分析软件”的探索计划。<br>
<p><a href="https://static.cnbetacdn.com/article/2022/0512/89db248df1a0ab4.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0512/89db248df1a0ab4.jpg" referrerpolicy="no-referrer"></a></p><p>据悉，该软件计划使用 AI 技术来分析视频会议参与者的情绪状况。</p><p>而在周三致 Zoom 公司创始人 Eric Yuan 的公开信中，包括 ACLU 和数字权利非盈利组织在内的近 30 个倡议团体，纷纷抨击此类技术不科学、具有操纵性、且存在助长歧视等问题。</p><blockquote><p>信中写道 —— Zoom 自诩关心其用户的安全与福祉，但这项涉嫌冒犯隐私与人权的侵入性技术，却又让该公司自扇耳光。</p><p>此外收集此类‘深度个人数据’，或使得客户公司成为‘窥探政府当局和恶意黑客攻击的目标’。</p></blockquote><p>即便如此，Zoom 产品、数据与 AI 负责人 Josh Dulberger 在接受 Protocol 采访时辩称 ——虽然这些信息属于可用信号，但它们并不在其中起到决定性的作用。</p><p>显然，Dulberger 设想利用该技术 —— 比如通过检测与会者情绪在何时出现下降 —— 以便销售代表能够更好地了解视频会议的进展情况。</p><blockquote><p>但据民权倡导组织所述，情绪追踪软件存在本质上的偏见，因为它假设所有人都会露出同样的面部表情、声音模式、以及肢体语言。</p><p>更糟糕的是，若技术被滥用，员工、学生或其它 Zoom 用户或因‘错误的情绪表达’而受到上级部门的不当惩戒。</p><p>此外对于某些族群和残障人士来说，若放任这种基于硬性编码的刻板印象被部署到数以百万计的设备上，后果更是不堪设想。</p></blockquote><p>综上所述，民权倡导团体呼吁 Zoom 在 5 月 20 日前做出不在其产品中部署情绪追踪 AI 的承诺。遗憾的是，截止发稿时，该公司并没有立即回应外媒的置评请求。</p>   
</div>
            