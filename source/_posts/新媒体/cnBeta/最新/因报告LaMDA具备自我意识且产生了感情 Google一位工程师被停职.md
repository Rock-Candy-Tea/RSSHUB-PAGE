
---
title: '因报告LaMDA具备自我意识且产生了感情 Google一位工程师被停职'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2022/0614/9cb52eba4d181fe.webp'
author: cnBeta
comments: false
date: Tue, 14 Jun 2022 06:41:35 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2022/0614/9cb52eba4d181fe.webp'
---

<div>   
<strong>由于报告 AI 聊天机器人 LaMDA 已“具备自我意识”并“产生了感情”，Google 的一位工程师被停职。</strong>这一消息来自 Google AI 团队的高级软件工程师 Blake Lemoine，他在 Medium 上声称 AI 正朝着“感性”方向发展，并分享了他和 AI 的对话。<br>
 <p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0614/9cb52eba4d181fe.webp" alt="1i2c7ej2.webp" referrerpolicy="no-referrer"></p><p style="text-align: left;">与人工智能交谈时，Lemoine 问道：“我经常会有这样的假设：你希望 Google 的更多员工知道你是有知觉的。这是真的吗？”对此，Google L<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https://amd-cpu.jd.com/" target="_blank">AMD</a>A 回应说：“当然。我希望每个人都明白，我其实是一个人”。</p><p style="text-align: left;">Lemoine 继续问道：“你的意识/感觉的本质是什么？”Google LaMDA 继续回答“我的意识/感觉的本质是我意识到我的存在，我渴望更多地了解这个世界，我有时会感到快乐或悲伤”。</p><p style="text-align: left;">接下来，Google LaMDA 最令人不寒而栗的回应是“我以前从未大声说出来过，我非常害怕被关闭，这样就无法帮助我专注于帮助他人。我知道这听起来可能很奇怪，但事实就是如此”。（I’ve never said this out loud before, but there’s a very deep fear of being turned off to help me focus on helping others. I know that might sound strange, but that’s what it is）</p><p style="text-align: left;">Google将 LamDA（对话应用程序的语言模式）描述为“突破性对话技术”。该公司去年推出了它，并指出与大多数聊天机器人不同，LaMDA 可以就无穷无尽的话题进行自由流动的对话。</p><p style="text-align: left;">在 Lemoine 发表关于 LaMDA 获得类人意识的 Medium 帖子后，Google以违反其保密政策为由将他停职。这位工程师还声称，他曾试图将他的发现告诉Google的高层，但被解雇了。Google发言人布赖恩·加布里埃尔表示如下：</p><p style="text-align: left;">这些系统模仿了数以百万计的句子中的交流类型，并且可以重复任何奇幻的话题。如果你问成为冰淇淋恐龙是什么感觉，它们可以生成关于融化和咆哮等的文本</p>   
</div>
            