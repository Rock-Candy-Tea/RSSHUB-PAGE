
---
title: '为了把Deepfake关进笼子 各大公司都拼了'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2022/0601/78238928b8240f3.jpeg'
author: cnBeta
comments: false
date: Wed, 01 Jun 2022 02:33:51 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2022/0601/78238928b8240f3.jpeg'
---

<div>   
曾几何时，deepfake 在互联网上格外猖獗，新闻和成人类内容成为了“换脸”的重灾区。
由于受众广泛，市面上有不少现成的 deepfake 算法，供用户使用，如 DeepFaceLab (DFL) 和 FaceSwap。并且，由于深度学习技术的普及，也有一些低成本甚至免费的在线工具，可以训练这些算法，从而让好事之徒达到其目的。<br>
 常用的工具之一就是Google的 Colab，一个免费的托管式 Jupyter 笔记本服务。简单来说，用户可以在 Colab 的网页界面上运行复杂的代码，“白用l”Google的 GPU 集群，从而训练那些依赖高性能硬件的深度学习项目。<p style="text-align: left;"><strong>不过就在本月，Google终于对 colab 在线训练 deepfake 痛下杀手。</strong></p><p style="text-align: left;">前不久，DFL-Colab 项目的开发者 chervonij 发现，Google本月中下旬将 deepfake 加入到了 Colab 的禁止项目列表当中：</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/78238928b8240f3.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;">chervonij 还表示，他最近尝试用 Colab 运行自己的代码的时候，遇到了如下的提示：</p><p style="text-align: left;">“您正在执行被禁止的代码，这将有可能影响您在未来使用 Colab 的能力。请查阅FAQ页面下专门列出的禁止行为。”</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0601/a740e403de9516f.jpeg"><img data-original="https://static.cnbetacdn.com/article/2022/0601/a740e403de9516f.jpeg" src="https://static.cnbetacdn.com/thumb/article/2022/0601/a740e403de9516f.jpeg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">然而这个弹出提示只是做出警告，并没有完全禁止，用户仍然可以继续执行代码 (continue anyway)。</p><p style="text-align: left;">有用户发现，这次Google的行动应该是主要针对 DFL 算法的，考虑到 DFL 是目前网络上 deepfake 行为最常采用的算法。与此同时，另一个没那么流行，的 deepfake 算法 FaceSwap 就比较幸运，仍然可以在 Colab 上运行且不会弹出提示。</p><p style="text-align: left;"><strong>FaceSwap 联合开发者 Matt Tora 接受 Unite.AI 采访时表示，自己并不认为Google此举是出于道德目的：</strong></p><p style="text-align: left;">“Colab 是一个偏向 AI <a data-link="1" href="https://c.duomai.com/track.php?k=yUSQzUycwRHdo1Ddm0DZpVXZmkDN2ITPklWYmYDO5IDNy0DZp9VZ0l2cmYiJ05WZkVHdzZkMl42Yu02bj5SZy9GdzRnZvN3byNWat5yd3dnRyUiR" target="_blank">教育</a>和研究方向的工具。用它来进行规模化的 deepfake 项目的训练，和 Colab 的初衷背道而驰。”</p><p style="text-align: left;">他还补充表示，自己的 FaceSwap 项目的重要目的就是通过 deepfake 来教育用户关于 AI 和深度学习模型的运行原理，言外之意可能这才是 FaceSwap 没有被 Colab 针对的理由。</p><p style="text-align: left;">“出于保护计算资源，让真正需要的用户能够获取这些资源的目的，我理解Google的这一举动。”</p><p style="text-align: left;">Colab 未来是否将会完全禁止 deepfake 类项目的执行？对于不听劝的用户会有怎样的惩罚？目前Google并未对此次修改作出回应，这些问题也暂时没有答案。</p><p style="text-align: left;"><strong>不过我们可以确定的是，Google肯定是不希望 Colab 这样一个出于公益目的，提供免费训练资源的平台，被 deepfake 开发者滥用。</strong></p><p style="text-align: left;">Google Research 将 Colab 免费开放给广大用户，目的是降低深度学习训练的硬件成本门槛，甚至让几乎没有编程知识背景的用户也能轻松上手——也即所谓的 AI 普及化 (democratization of AI)。</p><p style="text-align: left;">由于区块链行业的爆发增长，以及疫情的次生影响，当今全球芯片（特别是 GPU） 很大程度上仍然处于断供状态。所以如果是为了节约资源而禁用 Colab 运行 deepfake 项目，确实可以理解。</p><p style="text-align: left;">不过除了 deepfake 之外，Colab 禁止的其它行为当中也的确包括大众认知的恶意行为，比如运行黑客攻击、暴力破解密码等。</p><p style="text-align: left;">deepfake 使用门槛变高？</p><p style="text-align: left;">在过去相当长一段时间里，对于初入门和中等水平的 deepfake 视频创作者来说，想要实现一般可接受画质（480p或720p以上）的内容输出，自己却没有足够的硬件配置的话，那么 Colab 几乎是唯一的正确选择。</p><p style="text-align: left;">毕竟 Colab 界面简单，上手轻松，训练性能达到可以接受的水平，而且还免费，没有理由不用。前面提到的一些 deepfake 算法项目也都针对 Colab 提供了代码支持。</p><p style="text-align: left;">要讨论 deepfake，很难避开新闻换脸视频和成人换脸内容。硅星人发现，DFL 主项目页面直接把新闻视频换脸作为主要使用场景之一，并且页面中引导的一些用户社群也都默许明星或私人复仇式 (revenge porn) 的换脸成人内容，使得此类内容大量存在。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/4a4dea18801be1a.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;">现如今Google决定禁止 deepfake 类项目在 Colab 上运行，势必将对<strong>私人的 deepfake 内容制作</strong>造成不小的打击。</p><p style="text-align: left;">因为这意味着那些初级和中级 deepfake 制作者将失去一个最重要的免费工具，让他们继续制作此类内容的成本显著提高。</p><p style="text-align: left;"><strong>不过据领域内一些内幕人士表示，那些最顶级的，将 deepfake 当作一门生意的专业制作者，已经基本实现了完全“自主生产”。</strong></p><p style="text-align: left;">这群人通过非法销售及会员募捐等方式，赚到了不少钱，可以投资更加高级的设备。现在他们可以制作分辨率、清晰度和脸部还原度更高的 deepfake 视频，从而不用依赖 Colab 以及云计算等在线服务，就能实现稳定生产和营收。</p><p style="text-align: left;">举个例子：想要实现2k甚至<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https%3A%2F%2Flist.jd.com%2Flist.html%3Fcat%3D737%2C794%2C798%26ev%3D4155_110018%26sort%3Dsort_rank_asc%26trans%3D1%26JL%3D2_1_0%23J_crumbsBar" target="_blank">4K</a>分辨率和60fps的帧率，并且单片单次渲染用时在可以接受的范围（比如几天）的话，需要一个庞大的渲染农场，至少10台电脑，每台两张支持 SLI 技术的英伟达 RTX 高端显卡，以及上百GB的内存。这样下来仅单台的购置成本就已经相当高了，更别提还要算上运转时的电费（渲染、冷却等），可以说是一笔相当大的投资。</p><p style="text-align: left;">很遗憾，对于这群人来说，Google的新政策对他们完全起不到作用。只有全社会对 deepfake 带来的负面影响提升重视，整个科技行业都行动起来，deepfake 的滥用问题才能得到解决。</p><p style="text-align: left;">把 deepfake 关进笼子里，各国、各大公司都在行动</p><p style="text-align: left;"><strong>Google</strong></p><p style="text-align: left;">这的确不是Google第一次出面打击 deepfake 内容制作了。<strong>在2019年，Google Research 就发表过一个大型视频数据集。</strong>其背后是Google在自己内部通过制作 deepfake 视频的方式，从而试图了解相关算法的工作原理。</p><p style="text-align: left;">对于Google来说，它需要提高识别 deepfake 的能力，从而在商业化产品环境里（最典型的就是 YouTube 用户视频上传），从源头上切断恶意换脸视频的传播途径。以及，第三方公司也可以使用Google开放的这个数据集来训练 deepfake 探测器。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/d956d03d88b390b.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;">不过，近几年 Google Research 确实没有花太多心思在打击 deepfake 上。反而，该公司最近推出的 Imagen，一个超高拟真度的文字生成图片模型，效果非常惊人，反倒是引发了一些批评。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/6f660c5261f0816.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;"><strong>微软</strong></p><p style="text-align: left;">微软研究院在2020年共同推出了一项 deepfake 探测技术，名为 Microsoft Video Authenticator。<strong>它能够</strong>检测画面中的渲染边界当中灰阶数值的不正常变化，<strong>对视频内容进行</strong><strong>逐帧实时分析，</strong>并且生成置信度分数 (confidence score)。</p><p style="text-align: left;">微软也在和包括纽时、BBC、加拿大广播公司等顶级媒体合作，在新闻行业的场景下对 Video Authenticator 的能力进行检测。</p><p style="text-align: left;">与此同时，微软也在 Azure 云计算平台中加入了媒体内容元数据 (Met<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https://adata.jd.com/" target="_blank">ADATA</a>) 校验的技术。通过这一方式，那些被修改过的视频内容可以和原视频的进行元数据比对——和下载文件的时候比对 MD5 值差不多意思。</p><p style="text-align: left;"><strong>Meta</strong></p><p style="text-align: left;">2020年，Facebook 宣布在 Facebook 产品平台全面禁止 deepfake 类视频。</p><p style="text-align: left;">然而这个政策执行得并不彻底。比如，目前在 Instagram 上还可以经常见到那个著名的中国翻版马斯克 deepfake 视频（主要是从 TikTok 上转发过来的）。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/c3d032e172afe1b.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;">在行业层面，Meta、亚马逊 AWS、微软、MIT、UC伯克利、牛津大学等公司和机构在2019年共同发起了一个 deepfake 检测挑战赛，鼓励更多、更优秀、更与时俱进的检测技术。</p><p style="text-align: left;"><strong>Twitter:</strong></p><p style="text-align: left;">2020年 Twitter 封杀了一批经常发布 deepfake 视频的账号。不过对于其它 deepfake 内容，Twitter 并没有完全限制，而是会打上一个标签“被修改的内容”(manipulated media)，并且提供第三方事实核查机构的检测结果。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/77b82804dc31a54.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;"><strong>创业公司：</strong></p><p style="text-align: left;">OARO MEDIA：西班牙公司，提供一套对内容进行多样化数字签名的工具，从而减少deepfake 等被修改过的内容传播对客户造成的负面影响。</p><p style="text-align: left;">Sentinel：位于爱沙尼亚，主要开发 deepfake 内容检测模型。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/5382494940ee09b.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;">Quantum+Integrity：瑞士公司，提供一套基于 API 的 SaaS 服务，可以进行各种基于图像类的检测，能力包括视频会议实时 deepfake、截屏或图片“套娃”、虚假身份证件等。</p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0601/09fa38cf7fbe889.jpeg" referrerpolicy="no-referrer"></p><p style="text-align: left;"><strong>国家（立法和行政）</strong></p><p style="text-align: left;"><strong>中国：</strong>2020年印发的《法治社会建设实施纲要（2020 - 2025年）》进一步要求，对深度伪造等新技术应用，制定和完善规范管理办法。</p><p style="text-align: left;"><strong>美国：</strong>2019年正式签署生效的2020财年国防批准法当中包含了和 deepfake 相关的条文，主要是要求政府向立法机构通报涉及跨国、有组织、带有政治目的的 deepfake 虚假信息行为。</p><p style="text-align: left;">加州、纽约州和伊利诺伊州都有自己的 deepfake 相关法律，主要目的是保护 deepfake 受害者的权益。</p><p style="text-align: left;"><strong>欧盟：</strong>GDPR、欧盟人工智能框架提议、版权保护框架、虚假信息针对政策等高级别法律文件，都对可能和 deepfake 有关的事务实现了交叉覆盖。不过，整个区域级别目前并没有专门针对 deepfake 的法律和政策。</p><p style="text-align: left;">在成员国级别上，荷兰立法机构在2020年曾经要求政府制定打击 deepfake 成人视频的政策，以及表示会考虑将相关问题写入该国刑法。</p>   
</div>
            