
---
title: '_视频_OpenAI展示DALL-E 2：AI图像生成器支持编辑图像了'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2022/0407/6b985bfb9e51318.webp'
author: cnBeta
comments: false
date: Thu, 07 Apr 2022 02:11:51 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2022/0407/6b985bfb9e51318.webp'
---

<div>   
人工智能研究小组 OpenAI 创建了一个新版本的 DALL-E，可以根据用户的自然语言描述来生成图片。<strong>DALL-E 2 是初代系统的高分辨率和低延迟版本，除了根据用户描述生成图片之外，还引入了编辑现有图像等新功能。</strong><br>
 <p>与之前的 OpenAI 工作一样，该工具并没有直接向公众发布。但研究人员可以在网上注册预览该系统，OpenAI 希望以后能将其用于第三方应用程序中。</p><p><iframe src="//player.bilibili.com/player.html?bvid=BV1zr4y1p7mQ&page=1" width="750" height="480" frameborder="0"></iframe></p><p>初代 DALL-E 是艺术家“Salvador Dalí”和机器人“WALL-E”的谐音，于 2021 年 1 月首次亮相。这是对人工智能视觉表现概念能力的一个有限但迷人的测试，从穿法兰绒衬衫的模特的平凡描述到"乌龟做的长颈鹿"或萝卜遛狗的插图。</p><p style="text-align: center;"><img src="https://static.cnbetacdn.com/article/2022/0407/6b985bfb9e51318.webp" style referrerpolicy="no-referrer"></p><p style="text-align: center;">使用“Teddy bears mixing sparkling chemicals as mad scientists, steampunk.”描述 DALL-E 2 生成的图像</p><p>。当时，OpenAI说它将继续在该系统的基础上发展，同时研究潜在的危险，如图像生成中的偏见或错误信息的产生。它正试图利用技术保障措施和新的内容政策来解决这些问题，同时也在减少其计算负荷，</p><p>DALL-E 2的新功能之一是绘画，在更细的层面上应用DALL-E的文本到图像的能力。用户可以从现有的图片开始，选择一个区域，并告诉模型来编辑它。例如，你可以把客厅墙上的一幅画挡住，然后用另一幅画代替，或者在<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https%3A%2F%2Flist.jd.com%2Flist.html%3Fcat%3D737%2C752%2C761" target="_blank">咖啡</a>桌上增加一个花瓶。</p><p style="text-align: center;"><img src="https://static.cnbetacdn.com/article/2022/0407/4bcdb9ebb64d996.webp" style referrerpolicy="no-referrer"></p><p style="text-align: center;">使用“Shiba Inu dog wearing a beret and black turtleneck”描述 DALL-E 2 生成的图像</p><p>模型可以填充（或删除）物体，同时考虑到细节，如房间里的阴影方向。另一个功能，变化，有点像一个图片搜索工具，用于搜索不存在的图片。用户可以上传一张起始图片，然后创建一系列与之相似的变化。他们还可以混合两张图片，生成具有两者元素的图片。生成的图片是1024 x 1,024像素，比原始模型提供的256 x 256像素有了飞跃。</p><p style="text-align: center;"><img src="https://static.cnbetacdn.com/article/2022/0407/6f706d54cc9e247.webp" style referrerpolicy="no-referrer"></p><p style="text-align: center;">使用“An existing image of a room with a flamingo added in one corner.”描述 DALL-E 2 生成的图像</p><p>DALL-E 2 建立在 CLIP（计算机视觉系统）的基础上。OpenAI 研究科学家 Prafulla Dhariwal 说：“DALL-E 1 只是从语言中提取了我们的 GPT-3 方法，并将其应用于制作图像：我们将图像压缩成一系列单词，我们只是学习预测接下来的内容”。</p><p style="text-align: center;"><img src="https://static.cnbetacdn.com/article/2022/0407/971c262ace31dfb.webp" style referrerpolicy="no-referrer"></p><p style="text-align: center;">使用“a bowl of soup that looks like a monster, knitted out of wool.”描述 DALL-E 2 生成的图像</p><p>但是单词匹配并不一定能捕捉到人类认为最重要的品质，而且预测过程限制了图像的真实性。CLIP被设计用来观察图像，并以人类的方式总结它们的内容，OpenAI对这一过程进行了迭代，创造了"unCLIP"--一个从描述开始并向图像前进的倒置版本。</p><p>DALL-E 2使用一种叫做“diffusion”的过程生成图像，Dhariwal 将其描述为从“一袋点”（bag of dots）开始，然后用越来越多的细节填入一个图案。</p>   
</div>
            