
---
title: '苹果发布《扩展儿童保护》快速问答文档 化解CSAM相关疑虑'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2021/0807/046d322363f3200.jpg'
author: cnBeta
comments: false
date: Mon, 09 Aug 2021 10:11:56 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2021/0807/046d322363f3200.jpg'
---

<div>   
<strong>针对 CSAM 系统引发的一系列争议，苹果已经在一份题为《扩展儿童保护》的常见问题解答（FAQ）中给出了回复。</strong>这家库比蒂诺科技巨头宣称，相关回答旨在减轻广大用户对 iCloud 图像检测和消息扫描功能的隐私与通讯安全顾虑。<br>
 <p><a href="https://static.cnbetacdn.com/article/2021/0807/046d322363f3200.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2021/0807/046d322363f3200.jpg" referrerpolicy="no-referrer"></a></p><p>苹果写道：</p><blockquote><p>自 CSAM 宣布以来，包括隐私倡导和儿童安全组织在内的许多利益相关者，都明确表达了对这套新解决方案的支持。</p><p>与此同时，也有一些人提出了相关问题。而这份文件的出现，就是为了解决这些问题，并提升此过程中的清晰度与透明度。</p></blockquote><p>显然，苹果认为一些讨论模糊了两项功能之间的区别，于是在文档中煞费苦心地将它们区分开来。</p><blockquote><p>比如消息服务中的通信安全，仅适用于在家庭共享中设置了儿童账户的消息应用中收发的图像。</p><p>而针对 iCloud 上的 CSAM 检测，也只影响选择通过 iCloud 来存储相册的用户。任何其它设备上的数据，都不在此列。</p></blockquote><p>简而言之，这两项功能并不相同，也不基于相同的技术实现方案。</p><blockquote><p>消息应用中的通信安全，旨在为家长和孩子们提供额外的防护工具，以确保未成年人免受消息应用程序中收发的色情图片的影响。</p><p>其仅适用于‘消息’应用程序中，基于‘家庭共享’设置的儿童账户的图像收发。该功能会分析设备上的图像，因而不会改变消息服务的隐私承诺。</p><p>当儿童账户发送或接收到色情图片时，照片将被模糊化处理。此举可确保儿童不受违规信息影响，且家长也能够在收到警告提示后亡羊补牢。</p></blockquote><p>至于 iCloud 中的 CSAM 检测功能，其旨在让 iCloud 相册远离此类资料。</p><blockquote><p>据悉，在包括美国在内的大多数市场区域，持有 CSAM 类图像文件都属于非法行为。</p><p>而除了与已知儿童受虐材料相匹配的照片之外，苹果不会知晓任何照片信息。</p><p>此功能仅影响选择使用 iCloud 相册来存储照片的用户，而不会影响未选择 iCloud 的用户。至于其它设备上的任何数据，CSAM 也不涉及。</p></blockquote><p><img src="https://static.cnbetacdn.com/article/2021/0809/32df35f0f48f132.png" referrerpolicy="no-referrer"></p><p style="text-align: center;">FAQ 文档的其余部分，还罗列了三个部分。</p><p><strong>首先是“消息的通信安全”：</strong></p><blockquote><p>● 谁可在消息应用中获得安全的通信体验？</p><p>● 是否意味着要与苹果或执法部门分享信息？</p><p>● 否会破坏消息应用的端到端加密？</p><p>● 是否会导致在家庭中受虐的儿童难以寻得救助？</p><p>● 父母会在没有警告和选择的情况下收到通知吗？</p></blockquote><p><strong>其次是“关于 CSAM 检测”：</strong></p><blockquote><p>● 是否意味着苹果将扫描我 <a data-link="1" href="https://apple.pvxt.net/c/1251234/435400/7639?u=https%3A%2F%2Fwww.apple.com%2Fcn%2Fiphone%2F" target="_blank">iPhone</a> 上存储的所有照片？</p><p>● 是否会将 CSAM 图像下载到用户的本地设备进行比对？</p><p>● 为何苹果选择在这个时候推行？</p></blockquote><p><strong>然后是“对 iCloud 照片展开 CSAM 检测的安全性”：</strong></p><blockquote><p>‌● iCloud 照片‌中的 CSAM 检测系统，可否用来检测 CSAM 以外的资料？</p><p>● 政府能否强制苹果将非 CSAM 图像添加到哈希比对列表中？</p><p>● 是否可将非 CSAM 映像‘注入’到系统中，以标记除 CSAM 之外的账户内容？</p><p>● 是否存在将无辜者错误标记、并上报给执法部门的可能？</p></blockquote><p>感兴趣的朋友，可移步至苹果官网查看（<a href="https://www.apple.com/child-safety/pdf/Expanded_Protections_for_Children_Frequently_Asked_Questions.pdf" target="_self">PDF</a> 传送门）。</p><div class="article-relation"><p><strong>相关文章:</strong></p><p><a href="https://www.cnbeta.com/articles/tech/1163245.htm" target="_blank">拒绝后门：公开信呼吁苹果停止实施CSAM虐童图像检测系统</a></p></div>   
</div>
            