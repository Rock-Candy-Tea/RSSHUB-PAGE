
---
title: 'TikTok第三方内容审核员称公司在培训期间向其展示儿童性虐待材料'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2022/0311/e66c58f65c5e9a2.webp'
author: cnBeta
comments: false
date: Sat, 06 Aug 2022 00:20:48 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2022/0311/e66c58f65c5e9a2.webp'
---

<div>   
《福布斯》的一份报告<strong>对TikTok的审核团队如何处理儿童性虐待材料(CSAM)提出了质疑--称其为非法照片和视频提供了广泛而不安全的访问权限。</strong><br>
 <p style="text-align:center"><a href="https://static.cnbetacdn.com/article/2022/0311/e66c58f65c5e9a2.webp" target="_blank"><img src="https://static.cnbetacdn.com/article/2022/0311/e66c58f65c5e9a2.webp" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">一家名为Teleperformance的第三方审核机构的员工称，该机构与TikTok及其他公司合作，要求他们审查一份被称为DRR或TikTok审核标准的每日必读的令人不安的电子表格。据称，该电子表格包含违反TikTok准则的内容，包括“数百张”儿童裸体或受虐待的图片。这些员工说，TikTok和Teleperformance的数百人可以从办公室内外获取这些内容--这为更广泛的泄漏打开了大门。</p><p style="text-align: left;">Teleperformance向《福布斯》否认向员工展示了性虐待的内容，TikTok说其培训材料有“严格的访问控制，不包括CSAM的视觉例子”，尽管它没有确认所有第三方供应商都符合这一标准。</p><p style="text-align: left;">员工们讲述了一个不同的故事，正如《福布斯》所描述的，这是一个法律上很危险的故事。内容审核员经常被迫处理发布在许多社交媒体平台上的CSAM。但虐待儿童的图像在美国是非法的，必须小心处理。公司应该向美国国家失踪和被剥削儿童中心（NCMEC）报告这些内容，然后将其保存90天，但尽量减少看到这些内容的人数。</p><p style="text-align: left;">这里的指控远远超出了这个限制。它们表明，Teleperformance公司向员工展示了图片和视频，作为在TikTok上标记内容的例子，同时对这些内容的访问权进行了快速和宽松的处理。一名员工说，她联系了联邦调查局，询问这种做法是否构成了传播CSAM的犯罪行为，尽管不清楚是否已经立案。</p>   
</div>
            