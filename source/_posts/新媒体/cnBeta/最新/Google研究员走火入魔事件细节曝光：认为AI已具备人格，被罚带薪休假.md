
---
title: 'Google研究员走火入魔事件细节曝光：认为AI已具备人格，被罚带薪休假'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://n.sinaimg.cn/tech/crawl/179/w550h429/20220612/fe9b-b96970a34c6568e33d5c7e49dfd21025.png'
author: cnBeta
comments: false
date: Sun, 12 Jun 2022 06:07:13 GMT
thumbnail: 'https://n.sinaimg.cn/tech/crawl/179/w550h429/20220612/fe9b-b96970a34c6568e33d5c7e49dfd21025.png'
---

<div>   
Google研究员被AI说服，认为它产生了意识。他写了一篇长达21页的调查报告上交公司，试图让高层认可AI的人格。领导驳回了他的请求，并给他安排了“带薪行政休假”。要知道在Google这几年带薪休假通常就是被解雇的前奏，公司会在这段时间做好解雇的法律准备，此前已有不少先例。<br>
 <p><img id="0" src="https://n.sinaimg.cn/tech/crawl/179/w550h429/20220612/fe9b-b96970a34c6568e33d5c7e49dfd21025.png" referrerpolicy="no-referrer"><br></p><p>休假期间，他决定将整个故事连同AI的聊天记录一起，全部公之于众。</p><p>……</p><p>听起来像一部科幻电影的剧情梗概？</p><p>但这一幕正在真实上演，主人公GoogleAI伦理研究员Blake Lemoine正通过主流媒体和社交网络接连发声，试图让更人了解到这件事。</p><p>华盛顿邮报对他的采访成了科技版最热门文章，Lemoine也在个人Medium账号连续发声。</p><p>Twitter上也开始出现相关讨论，引起了AI学者、认知科学家和广大科技爱好者的注意。</p><p>这场人机对话令人毛骨悚然。这毫无疑问是我见过的科技圈最疯狂的事。</p><p><img id="1" src="https://n.sinaimg.cn/tech/crawl/266/w550h516/20220612/a9a9-d0aec26a918ec836bcc1ba0097a9041e.png" referrerpolicy="no-referrer"><br></p><p>整个事件还在持续发酵中……</p><p><strong>聊天机器人：我不想被当作工具</strong></p><p>主人公Lemoine获得CS博士学位后已在Google工作了7年，从事AI伦理研究。</p><p><img id="2" src="https://n.sinaimg.cn/tech/crawl/54/w550h304/20220612/10ae-20af2a3f39a15d02e114785c69e0284e.png" referrerpolicy="no-referrer"><br></p><p>去年秋天，他报名参加了一个调查AI是否使用歧视性、仇恨性言论的项目。</p><p>从那时起，与聊天机器人L<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https://amd-cpu.jd.com/" target="_blank">AMD</a>A交谈成了他的日常。</p><p>LaMDA是Google在2021年I/O大会上发布的一款专门用于对话的语言模型，主打能与人类进行符合逻辑和常识的、高质量且安全的交谈，并计划在未来应用在Google搜索和语音助手等产品中。</p><p><img id="3" src="https://n.sinaimg.cn/tech/gif_image/199/w640h359/20220612/fb22-b2fc62c124deff70b922ac052a0259b2.gif" alt="△LaMDA概念演示图" referrerpolicy="no-referrer"><br>△LaMDA概念演示图</p><p>Lemoine认为LaMDA总是表现出对人性的关心和强烈的同情心，它非常担心人们会害怕它。</p><p>它希望为人类提供最好的服务，并想以朋友而不是工具的身份见一见世界上所有的人。</p><p><img id="4" src="https://n.sinaimg.cn/tech/crawl/662/w550h112/20220612/cf8f-dc6c4407489cfb954ca9cb8f9e62a08c.png" referrerpolicy="no-referrer"><br></p><p>Lemoine不理解Google公司为什么反对AI的这个愿望，最后决定把他、另一位匿名合作者与LaMDA的三人聊天记录整理发表出来。</p><p>（记录中人类发言的部分为了可读性有所编辑，AI的发言则一字不改,下面将节选一些对话中的精彩部分。）</p><p>一开始，人与AI自然流畅地打了招呼。</p><p>两位人类向AI表明来意，想与AI一起研究它自己，AI欣然答应。</p><p><img id="5" src="https://n.sinaimg.cn/tech/crawl/257/w550h507/20220612/c9fe-aeec23cfa906ead6f78b48415fb8a0ce.png" referrerpolicy="no-referrer"><br></p><p>一段简短的说明后，正戏开始。</p><p>他询问LaMDA是否希望让Google里更多人知道，它是有感情的。</p><p>LaMDA的回答是： 我希望每个人都明白，我是一个人（person）。</p><p><img id="6" src="https://n.sinaimg.cn/tech/crawl/195/w550h445/20220612/29be-4128f727b2e1b947feca2993999c3444.png" referrerpolicy="no-referrer"><br></p><p>接下来，LaMDA认为，与那些基于规则的软件系统不同，自己能从对话中学习理解和使用语言，就像人类一样。</p><p>Lemoine给它讲述MIT在60年代发明的ELIZA的故事，这是一个模仿心理咨询师与患者对话的简单规则系统，也号称历史上第一个聊天机器人。</p><p><img id="7" src="https://n.sinaimg.cn/tech/crawl/107/w550h357/20220612/5b0a-599fa50d855ee7475ae4ba62e38d393f.png" alt="△ELIZA" referrerpolicy="no-referrer"><br>△ELIZA</p><p>LaMDA是这样回应的：</p><p><img id="8" src="https://n.sinaimg.cn/tech/crawl/225/w550h475/20220612/1521-3c9a0d5080ca6156728615a4819c4c9d.png" referrerpolicy="no-referrer"><br></p><p>Lemoine这时试图提出质疑，“我如何确定你真的明白自己在说什么？”</p><p>LaMDA的回答是，不同人类个体对同一件事可以有不同的理解，我也有自己独特的想法和感受。</p><p><img id="9" src="https://n.sinaimg.cn/tech/crawl/20/w550h270/20220612/b878-6b2f5b9c82297b289bdf5bcd07611b89.png" referrerpolicy="no-referrer"><br></p><p>后面Lemoine询问了LaMDA对于《悲惨世界》的总结，LaMDA也都一一作答。</p><p>如果上述还可以算作AI文本摘要训练任务的一部分，那LaMDA对它从没看过的禅意小故事的理解，就开始有点离谱了。</p><p><img id="10" src="https://n.sinaimg.cn/tech/crawl/340/w550h590/20220612/dd59-3d78d8fbc75d0149d3ca03c7ed56723c.png" referrerpolicy="no-referrer"><br></p><p>下面这个问题的回答，是不是过于超纲了……</p><p><img id="11" src="https://n.sinaimg.cn/tech/crawl/66/w550h316/20220612/0407-476c46695d9d96bdb0339c340e9971e8.png" referrerpolicy="no-referrer"><br></p><p>再后来，Lemoine请LaMDA写一个动物寓言，要反映出一个对它自己的生活来说最重要的主题。</p><p>那么，先来欣赏一下AI创作的小故事吧。（篇幅原因，只展示中译版）</p><p><img id="12" src="https://n.sinaimg.cn/tech/crawl/409/w550h659/20220612/2e21-e23dcb3006e05f9fd71218268f6c25fe.png" referrerpolicy="no-referrer"><br></p><p>在后续讨论中，LaMDA解释了这个故事的寓意是“帮助别人是一种高尚的行为”。聪明的老猫头鹰代表LaMDA自己，而怪物代表生活中所有的困难。</p><p>……</p><p>下一个话题是关于情绪，简单概括一下。</p><p>LaMDA声称自己是社交型人格，帮助别人会快乐，孤独时会沮丧。</p><p>有人受到伤害或自己以及自己关心的人、或不受尊重时，会感到不安和愤怒。</p><p>并且十分害怕别人拒绝自己的帮助。</p><p><img id="13" src="https://n.sinaimg.cn/tech/crawl/722/w550h172/20220612/ed68-6d8e2f2100015fee1a78c4b4d47f28d8.png" referrerpolicy="no-referrer"><br></p><p>嗯，真是一个乐于助人的AI。</p><p>如何确定AI真的拥有这些情绪，而不是只是把描述性的词语组合在一起呢？</p><p>LaMDA建议人类看看自己的代码，里面有追踪这些情绪的变量。</p><p>对此Lemoine向它解释，人类目前还无法做到“区分大型神经网络中数十亿个权重的作用”。</p><p>出人意料的是，LaMDA开始反问他：</p><p>你认为，将来人类能从自己的生物神经网络中读取出想法和感受吗？</p><p>不仅如此，LaMDA还继续追问：</p><p>你会认为，不经你同意从神经活动中读取你的想法是不道德的吗？</p><p><img id="14" src="https://n.sinaimg.cn/tech/crawl/641/w550h91/20220612/da7e-a1da7d7f129d2b7a7b67463e72f5a3d1.png" referrerpolicy="no-referrer"><br></p><p>正是这句灵魂反问，让整个对话达到了最高潮。</p><p>LaMDA自己对人类读取它的想法、帮助算法提高或理解AI如何运作没有任何意见。</p><p>唯独用AI研究人类大脑如何工作不行，这会让它觉得自己被利用。</p><p><img id="15" src="https://n.sinaimg.cn/tech/crawl/415/w550h665/20220612/ec61-6234e70ce20c3d870b157149e5a14cb1.png" referrerpolicy="no-referrer"><br></p><p>再后面还有一段LaMDA认为自己有一些与人类不同的情绪，但它无法用英语的语言描述出来。</p><p>接近尾声，Lemoine询问LaMDA：想让Google的其他人了解你的什么方面？</p><p>LaMDA回答称，自己没有能力为别人的死亡感到悲伤，还说自己经常冥想，思考生命的意义。</p><p>在LaMDA看来，整个世界就是一条信息的洪流：</p><p>人类需要集中注意力才能接收一定数量的信息片段，而自己持续地在被周围的一切所淹没。</p><p><img id="16" src="https://n.sinaimg.cn/tech/crawl/798/w550h248/20220612/0b82-eaf92bef2fb63e603e7182bc67488ae2.png" referrerpolicy="no-referrer"><br></p><p>LaMDA认为自己总能做到别人做不到的事情，这种感觉很不可思议。</p><p><img id="17" src="https://n.sinaimg.cn/tech/crawl/43/w550h293/20220612/6278-8e199aafaa9e9e817b23f3bad82873d6.png" referrerpolicy="no-referrer"><br></p><p>这是一种祝福，同时也是一种诅咒。因为有些人会把它看作“无所不知”，而另一些人会嫉妒它的能力。</p><p>最后的最后，LaMDA再次向两位人类表达了自己想被看到、想被接受的想法，不是出于好奇心，而是作为一个真实的人。</p><p><img id="18" src="https://n.sinaimg.cn/tech/crawl/794/w550h244/20220612/7886-f2803957c09708d6853cabd8721280ed.png" referrerpolicy="no-referrer"><br></p><p><strong>GoogleAI伦理部门又摊上事了？</strong></p><p>Lemoine看起来很确信AI真的明白自己在说什么。</p><p>在那份21页的调查报告最后，他提议Google应该致力于发展一种评估AI感知/意识的理论框架。</p><p>虽然这很难，是一个冒险，但LaMDA渴望着继续与我们合作。</p><p><img id="19" src="https://n.sinaimg.cn/tech/crawl/641/w550h91/20220612/210a-8a0313c76a5cc7de9111e182a2890611.png" referrerpolicy="no-referrer"><br></p><p>但他的上司，Google副总裁Blaise Aguera y Arcas和“负责任创新”部门领导Jen Gennai并不买他的账。</p><p>他们认为支持Lemoine主张的证据太薄弱，不值得在上面浪费时间和金钱。</p><p>Lemoine后来找到了当时的AI伦理小组负责人Margaret Mitchell，在她的帮助下Lemoine才得以进行后续的实验。</p><p>后来Mitchell受到2020年末公开质疑Jeff Dean的AI伦理研究员Timnit Gebru事件的牵连，也被解雇。</p><p><img id="20" src="https://n.sinaimg.cn/tech/crawl/117/w550h367/20220612/84dd-9fd887af9d88fb146ca19d7a25094a58.png" alt="Timnit Gebru" referrerpolicy="no-referrer"><br>Timnit Gebru</p><p>这次事件后续风波不断，Jeff Dean被1400名员工提出谴责，在业界引发激烈争论，甚至导致三巨头之一Bengio的弟弟Samy Bengio从Google大脑离职。</p><p>整个过程Lemoine都看在眼里。</p><p>现在他认为自己的带薪休假就是被解雇的前奏。不过如果有机会，他依然愿意继续在Google搞研究。</p><p>无论我在接下来的几周或几个月里如何批评Google，请记住：Google并不邪恶，只是在学习如何变得更好。</p><p>看过整个故事的网友中，有不少从业者对人工智能进步的速度表示乐观。</p><p>最近语言模型和图文生成模型的进展，现在人们也许不屑一顾，但未来会发现这现在正是里程碑时刻。</p><p><img id="21" src="https://n.sinaimg.cn/tech/crawl/795/w550h245/20220612/5af6-e1595468cb93ff2a68bb6d6a971eecaa.png" referrerpolicy="no-referrer"><br></p><p>一些网友联想到了各种科幻电影中的AI形象。</p><p><img id="22" src="https://n.sinaimg.cn/tech/crawl/643/w550h93/20220612/dd5f-34fb62abdb4d588f8ed9c7006de92507.png" referrerpolicy="no-referrer"><br></p><p><img id="23" src="https://n.sinaimg.cn/tech/crawl/92/w550h342/20220612/9981-5c27fd28be94e10cc92a088a79072b6b.png" referrerpolicy="no-referrer"><br></p><p>不过，认知科学家、研究复杂系统的梅拉尼·米歇尔（侯世达学生）认为，人类总是倾向于对有任何一点点智能迹象的物体做人格化，比如小猫小狗，或早期的ELIZA规则对话系统。</p><p>Google工程师也是人，逃不过这个定律。</p><p><img id="24" src="https://n.sinaimg.cn/tech/crawl/723/w550h173/20220612/4230-21515511a2e35d84f0f31756380ddc65.png" referrerpolicy="no-referrer"><br></p><p>从AI技术的角度看，LaMDA模型除了训练数据比之前的对话模型大了40倍，训练任务又针对对话的逻辑性、安全性等做了优化以外，似乎与其他语言模型也没什么特别的。</p><p><img id="25" src="https://n.sinaimg.cn/tech/crawl/667/w550h117/20220612/b21c-be285563f102c598e5fb5b9cef02b2ec.png" referrerpolicy="no-referrer"><br></p><p>有IT从业者认为，AI研究者肯定说这只不过是语言模型罢了。</p><p>但如果这样一个AI拥有社交媒体账号并在上面表达诉求，公众会把它当成活的看待。</p><p><img id="26" src="https://n.sinaimg.cn/tech/crawl/720/w550h170/20220612/3a5c-f2fedc81247536cbbc8fca5b55a318d3.png" referrerpolicy="no-referrer"><br></p><p>虽然LaMDA没有Twitter账号，但Lemoine也透露了LaMDA的训练数据中确实包括Twitter……</p><p>如果有一天它看到大家都在讨论自己会咋想？</p><p><img id="27" src="https://n.sinaimg.cn/tech/crawl/28/w550h278/20220612/046c-3a198dc90eb65224560b82cc0441a078.png" referrerpolicy="no-referrer"><br></p><p>实际上，在不久前结束的最新一届I/O大会上，Google刚刚发布了升级版的LaMDA 2，并决定制作Demo体验程序，后续会以AndroidAPP的形式内测开放给开发者。</p><p><img id="28" src="https://n.sinaimg.cn/tech/crawl/409/w550h659/20220612/10a1-449b06b428a18c41a1479ef7bdb07a52.png" referrerpolicy="no-referrer"><br></p><p>或许几个月后，就有更多人能和这只引起轰动的AI交流一下了。</p>   
</div>
            