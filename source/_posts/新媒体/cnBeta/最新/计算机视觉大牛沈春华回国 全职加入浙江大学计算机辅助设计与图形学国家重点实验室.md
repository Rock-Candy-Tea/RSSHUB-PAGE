
---
title: '计算机视觉大牛沈春华回国 全职加入浙江大学计算机辅助设计与图形学国家重点实验室'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2021/1220/2130646cbff5622.png'
author: cnBeta
comments: false
date: Mon, 20 Dec 2021 05:43:00 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2021/1220/2130646cbff5622.png'
---

<div>   
原澳大利亚阿德莱德大学教授、计算机视觉大牛沈春华已回国，并全职加入浙江大学。据主页介绍，沈春华于今年12月入职浙江大学，并兼任莫纳什大学信息技术学院的数据科学与AI无偿兼职教授。他本科毕业于南京大学，并拥有南京大学信号处理系和澳大利亚国立大学应用统计学系的两个硕士学位，于2005年获得阿德莱德大学计算机视觉博士学位。<br>
 <p><img src="https://static.cnbetacdn.com/article/2021/1220/2130646cbff5622.png" referrerpolicy="no-referrer"><br></p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/6765524210b561b.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/6765524210b561b.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/6765524210b561b.png" referrerpolicy="no-referrer"></a><br></p><p>博士毕业后，他在NICTA和澳大利亚国立大学工作，并于2011年加入阿德莱德大学担任教职。</p><p>去年10月，沈春华入选了澳大利亚终身成就榜。澳大利亚终身成就榜根据每位研究人员每年的 H 指数，在衡量生产力和影响力的基础上，选出澳大利亚的大学和研究机构在八个主要学科领域中的每一个领域的五名顶尖研究人员。当年入选的还包括悉尼大学教授、<a data-link="1" href="https://c.duomai.com/track.php?k=nJ9QWa1VmJxYTPklWYmYDO5IDNy0DZp9VZ0l2cmYiJt92YuQmauc3d3ZkMlYkMlE0MlMHc0RHa9Q" target="_blank">京东</a>探索研究院院长陶大程，阿德莱德大学教授Peng Shi，斯威本科技大学教授韩清龙等。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/12b7a67c231b229.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/12b7a67c231b229.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/12b7a67c231b229.png" referrerpolicy="no-referrer"></a><br></p><p>据主页介绍，沈春华如今加入的是浙江大学计算机辅助设计与图形学国家重点实验室。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/dc118beb084af04.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/dc118beb084af04.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/dc118beb084af04.png" referrerpolicy="no-referrer"></a><br></p><p>计算机辅助设计与图形学国家重点实验室依托浙江大学。由校内计算机系、数学系和机械系三系共建。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/bb5fcfe3e76ca9b.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/bb5fcfe3e76ca9b.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/bb5fcfe3e76ca9b.png" referrerpolicy="no-referrer"></a><br></p><p>实验室主要专注计算机辅助设计（CAD）、计算机图形学、媒体计算和可视分析、虚拟现实等领域，目前已发表国内外重要刊物论文300多篇。</p><p>该实验室来头不小，不仅有多名院士、长江学者加持，郭百宁、鲍虎军、周昆、陈宝权、胡事民等计算机图形学大牛亦构成了其高层次、高水平的科研队伍的基石。</p><p>能加入此等实验室，沈春华当然也有足够实力背书。据Google Scholar显示，沈春华论文总引用数已超33000，其中引用量最高的三篇是：</p><ul class=" list-paddingleft-2"><li><section>Refinenet: Multi-path refinement networks for high-resolution semantic segmentation</section></li><li><section>Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections</section></li><li><section>FCOS: Fully Convolutional One-Stage Object Detection</section></li></ul><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/c5180448cce5a5d.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/c5180448cce5a5d.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/c5180448cce5a5d.png" referrerpolicy="no-referrer"></a><br></p><p><strong>Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections</strong></p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/0765141cdd5204d.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/0765141cdd5204d.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/0765141cdd5204d.png" referrerpolicy="no-referrer"></a><br></p><p>论文地址：<a href="https://arxiv.org/pdf/1603.09056.pdf" _src="https://arxiv.org/pdf/1603.09056.pdf" target="_blank">https://arxiv.org/pdf/1603.09056.pdf</a><br></p><p>在这篇论文中，研究团队提出了一个非常深的全卷积编码解码框架，用于图像恢复，例如去噪和超分辨率。该网络由多层卷积和反卷积算子组成，学习从损坏图像到原始图像的端到端映射。</p><p>该研究将卷积层和反卷积层与跳过层连接对称地连接起来，从而模型可以训练收敛得更快，并获得更高质量的局部最优解。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/4a355c31bcd08ff.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/4a355c31bcd08ff.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/4a355c31bcd08ff.png" referrerpolicy="no-referrer"></a><br></p><ul class=" list-paddingleft-2"><li></li></ul><p><strong>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</strong></p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/8c57d108c9f332f.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/8c57d108c9f332f.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/8c57d108c9f332f.png" referrerpolicy="no-referrer"></a><br></p><p>论文地址：https://arxiv.org/pdf/1611.06612.pdf</p><p>RefineNet的提出针对的是，深度 CNN 中的池化或卷积跨步（striding）等重复子采样操作会导致初始图像分辨率显著降低的现象。</p><p>RefineNet是一种通用的多路径细化网络，它明确利用下采样过程中的所有可用信息，以使用远程残差连接进行高分辨率预测。通过这种方式，可以使用来自早期卷积的细粒度特征直接细化捕获高级语义特征的更深层。</p><p>RefineNet 的各个组件采用遵循身份映射思维方式的残差连接，从而实现有效的端到端训练。此外，还引入了链式残差池，它以有效的方式捕获丰富的背景上下文。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/218e6d5f4128595.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/218e6d5f4128595.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/218e6d5f4128595.png" referrerpolicy="no-referrer"></a><br></p><ul class=" list-paddingleft-2"><li></li></ul><p><strong>FCOS: Fully Convolutional One-Stage Object Detection</strong></p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/8ca2812afc37ae3.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/8ca2812afc37ae3.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/8ca2812afc37ae3.png" referrerpolicy="no-referrer"></a><br></p><p>论文地址：<a href="https://arxiv.org/pdf/1904.01355.pdf" _src="https://arxiv.org/pdf/1904.01355.pdf" target="_blank">https://arxiv.org/pdf/1904.01355.pdf</a><br></p><p>这篇论文提出了一种完全卷积的单级目标检测器 (FCOS)，以类似于语义分割的每像素预测方式解决目标检测问题。</p><p>几乎所有最先进的物体检测器，如 RetinaNet、<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https://list.jd.com/list.html?cat=670,677,11303" target="_blank">SSD</a>、YOLOv3 和 Faster R-CNN 都依赖于预定义的锚框。相比之下，FCOS 没有锚框，也没有proposal。</p><p>通过消除预定义的锚框集合，FCOS 完全避免了与锚框相关的复杂计算，例如在训练过程中计算重叠。</p><p>FCOS的提出表明，为了提高检测精度，采用更简单和灵活的检测框架或许更有效。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/26d8902f355fbe7.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/26d8902f355fbe7.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/26d8902f355fbe7.png" referrerpolicy="no-referrer"></a><br></p><p>丰硕的科研成果背后，是他自身深厚的学术素养以及人才培养能力。沈春华培养了众多优秀的博士生，其中包括了近年获得Google奖研金的刘伊凡、王鑫龙、Zhi Tian等等，他们毕业后都在知名高校和互联网企业任职，可谓人才济济。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2021/1220/42f11df0ab8ae15.png"><img data-original="https://static.cnbetacdn.com/article/2021/1220/42f11df0ab8ae15.png" src="https://static.cnbetacdn.com/thumb/article/2021/1220/42f11df0ab8ae15.png" referrerpolicy="no-referrer"></a><br></p>   
</div>
            