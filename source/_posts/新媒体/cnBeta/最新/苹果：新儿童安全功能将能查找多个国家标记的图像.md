
---
title: '苹果：新儿童安全功能将能查找多个国家标记的图像'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2021/0815/6d56b4aa0ab134e.jpg'
author: cnBeta
comments: false
date: Sun, 15 Aug 2021 01:09:37 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2021/0815/6d56b4aa0ab134e.jpg'
---

<div>   
最近，苹果公推出了一项新的儿童安全功能，它可以代表政府扫描用户iCloud照片中跟儿童性虐待相关的图片。然而，这一决定却遭到了隐私倡导者的严厉批评。现在，针对这些批评，路透社报道称，这家科技巨头已经澄清，它将使用该功能扫描“被多个国家的资讯交换中心所标记”的图像。<br>
 <p style="text-align:center"><a href="https://static.cnbetacdn.com/article/2021/0815/6d56b4aa0ab134e.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2021/0815/6d56b4aa0ab134e.jpg" alt="1620085457_1580301538_apple.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">自动扫描系统只有在图像超过30张的初始阈值时才会提醒苹果以便由人工审查人员处理这个问题。</p><p style="text-align: left;">该公司表示，这一数字最终将在未来一段时间内减少。它还明确表示，它的图像标识符列表是通用的，对于它所应用的任何设备都是相同的。</p><p style="text-align: left;">苹果进一步说明，它的部署会产生一个加密的设备上儿童性虐待材料(CSAM)的哈希数据库，它们来自不少于两个或更多的组织并在独立的国家政府的赞助下运转。</p><p style="text-align: left;">这家科技巨头没有说明这一影响是否对其立场有任何影响，但它表示，对于最初的声明存在困惑且该项目仍在开发中。</p>   
</div>
            