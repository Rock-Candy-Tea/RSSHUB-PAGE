
---
title: 'NVIDIA的最新技术使人工智能的声音更具表现力和真实感'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2021/0831/64695f88cb9c5f0.webp'
author: cnBeta
comments: false
date: Tue, 31 Aug 2021 13:23:05 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2021/0831/64695f88cb9c5f0.webp'
---

<div>   
亚马逊的Alexa、Google助手和其他人工智能助手的声音远远领先于老式的GPS设备，但它们仍然缺乏节奏、音调和听上去让人感觉真实的品质，NVIDIA公司在Interspeech 2021会议上宣布，该公司已经公布了新的技术和工具，可以通过让你用自己的声音训练AI系统来捕捉这些自然的语音品质。<br>
 <p><img src="https://static.cnbetacdn.com/article/2021/0831/64695f88cb9c5f0.webp" title alt="Rafael_002.webp" referrerpolicy="no-referrer"></p><p>为了改进其人工智能语音合成，NVIDIA的文本-语音研究团队开发了一个名为RAD-TTS的模型，这是NAB广播大会上开发最逼真化身的比赛的获胜作品。该系统允许个人用自己的声音训练文字转语音模型，包括节奏、音调、音色等等。</p><p>RAD-TTS的另一个特点是语音转换，它可以让用户用另一个人的声音来传递一个说话者的话语。该界面可以对合成的声音的音调、持续时间和能量进行精细的、帧级的控制。</p><p>利用这项技术，NVIDIA的研究人员为自己的《我是人工智能》系列视频创造了更多听起来像对话的语音解说，使用的是合成的声音而不是人的声音。其目的是让解说词与视频的语气和风格相匹配，这是迄今为止许多人工智能解说视频中没有做到的。结果仍然有点像机器人，但比我听过的任何人工智能解说都好。</p><p style="text-align: center;"><iframe src="//tv.sohu.com/s/sohuplayer/iplay.html?bid=284341439&autoplay=false&disablePlaylist=true" width="640" height="480" frameborder="0"></iframe></p><p>"有了这个界面，我们的视频制作人可以录下自己阅读视频脚本的过程，然后用人工智能模型将他的语音转换为女解说员的声音。"NVIDIA公司写道："利用这一基线旁白，制作人可以像配音演员一样指挥人工智能--调整合成的语音以强调特定的词语，并修改旁白的节奏以更好地表达视频的基调。"</p><p>NVIDIA公司正在分发这项研究的一部分--当然是为了在NVIDIAGPU上有效运行而进行的优化--通过用于GPU加速的对话式人工智能的NVIDIA NeMo Python工具包（可在该公司的容器和其他软件的NGC中心获得），向任何想要尝试的人开放源代码。其中几个模型是在NVIDIA DGX系统上用数万小时的音频数据训练出来的。开发人员可以针对他们的使用情况对任何模型进行微调，利用NVIDIA Tensor Core GPU上的混合精度计算加快训练速度。</p>   
</div>
            