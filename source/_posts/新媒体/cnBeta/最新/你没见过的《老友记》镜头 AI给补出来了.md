
---
title: '你没见过的《老友记》镜头 AI给补出来了'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://x0.ifengimg.com/ucms/2022_32/5E001EBCCFA87A695C1B6C396052CE8FA32BCA4C_size9491_w640_h360.gif'
author: cnBeta
comments: false
date: Tue, 02 Aug 2022 07:48:46 GMT
thumbnail: 'https://x0.ifengimg.com/ucms/2022_32/5E001EBCCFA87A695C1B6C396052CE8FA32BCA4C_size9491_w640_h360.gif'
---

<div>   
诶？这是《老友记》流出未公开镜头了？还是“子弹时间”特效那种？只见人物定格的一瞬，机位丝滑运动，一个多角度全方位的厨房出现在了眼前，仿佛我人就站在现场啊。<br>
 <p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/5E001EBCCFA87A695C1B6C396052CE8FA32BCA4C_size9491_w640_h360.gif" src="https://x0.ifengimg.com/ucms/2022_32/5E001EBCCFA87A695C1B6C396052CE8FA32BCA4C_size9491_w640_h360.gif" referrerpolicy="no-referrer"></p><p style="text-align: left;">要知道，在正片里其实只有这两幅画面：</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/9D59A4C87EC5AAD20D80518648017B1A2150D8D9_size542_w1080_h605.png" src="https://d.ifengimg.com/w1080_h605_q90/x0.ifengimg.com/ucms/2022_32/9D59A4C87EC5AAD20D80518648017B1A2150D8D9_size542_w1080_h605.png" referrerpolicy="no-referrer"></p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0802/8c3ccc792e7366d.jpg"><img data-original="https://static.cnbetacdn.com/article/2022/0802/8c3ccc792e7366d.jpg" src="https://static.cnbetacdn.com/thumb/article/2022/0802/8c3ccc792e7366d.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">没错，又是AI在搞“魔法”。</p><p style="text-align: left;">在看了《老友记》之后，AI能直接还原出宛如真实现场的3D场景，补足两个切换画面之间人物在不同角度时的姿态。</p><p style="text-align: left;"><strong>没拍过</strong>的角度画面，它都能重建出来。</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/F16580A0AB7C4571D5EB2802BB236006AB8FA1B4_size9727_w640_h360.gif" src="https://x0.ifengimg.com/ucms/2022_32/F16580A0AB7C4571D5EB2802BB236006AB8FA1B4_size9727_w640_h360.gif" referrerpolicy="no-referrer"></p><p style="text-align: left;">还能把一个近景镜头，变成大远景。</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/D7000622A96DF27008D73438A09066CA8B19FEDA_size4274_w640_h360.gif" src="https://x0.ifengimg.com/ucms/2022_32/D7000622A96DF27008D73438A09066CA8B19FEDA_size4274_w640_h360.gif" referrerpolicy="no-referrer"></p><p style="text-align: left;">乍一眼看去，真的很难分辨出生成效果其实是完全捏造的。</p><p style="text-align: left;">“以后<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https%3A%2F%2Flist.jd.com%2Flist.html%3Fcat%3D737%2C794%2C798%26ev%3D4155_76344%26sort%3Dsort_rank_asc%26trans%3D1%26JL%3D2_1_0%23J_crumbsBar" target="_blank">电视</a>剧补拍镜头都省了？”</p><p style="text-align: left;">这就是由UC伯克利大学研究人员提出的重建3D人物和环境的新方法。</p><p style="text-align: left;">网友看后脑洞大开：</p><p style="text-align: left;">可能不出10年，你就能把自己的VR形象放到自己喜欢的节目里了。</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/5F13AC136B3843682E73615A0C8E97EE17936D64_size150_w1080_h319.png" src="https://d.ifengimg.com/w1080_h319_q90/x0.ifengimg.com/ucms/2022_32/5F13AC136B3843682E73615A0C8E97EE17936D64_size150_w1080_h319.png" referrerpolicy="no-referrer"></p><p style="text-align: left;">目前，该方法已被ECCV 2022接收。</p><p style="text-align: left;">专门针对电视剧场景重建</p><p style="text-align: left;">研究人员表示，这次提出的新方法就是专门针对电视剧场景的。</p><p style="text-align: left;">除了《老友记》外，他们还3D重建了《生活大爆炸》等7个电视剧的场景。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0802/323274c2fa8ac34.jpg"><img data-original="https://static.cnbetacdn.com/article/2022/0802/323274c2fa8ac34.jpg" src="https://static.cnbetacdn.com/thumb/article/2022/0802/323274c2fa8ac34.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">要知道，使用单个视频来重建3D场景的难度其实还很高，但是电视剧中往往是同一场景拍下了多个画面，这为AI学习提供了非常丰富的图像资料。</p><p style="text-align: left;">本文方法能够在整季剧集中自动运行，计算出各个镜头的摄像机位置信息、静态三维场景结构和人物身体信息，然后将他们整合计算成一个3D场景来。</p><p style="text-align: left;">具体来看，该方法主要分为处理场景信息人物信息两方面。</p><p style="text-align: left;">场景上，基于不同画面，该方法通过SfM（Structure-from-Motion）来估计出拍摄时摄像机的位置。</p><p style="text-align: left;">这种方法是指在只有单个摄像机的情况下，通过分析摄像机移动时拍到的场景来确定3D场景信息。</p><p style="text-align: left;">然后通过分析摄像机与人物之间的位置关系，以此确定出人物所在的区域，然后将两个不同角度的画面整合分析，进行三角定位，以此确定人物的真正位置。</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/EED5354AB13D34EEF13EE8BCC0FD6AC39B424826_size9691_w640_h360.gif" src="https://x0.ifengimg.com/ucms/2022_32/EED5354AB13D34EEF13EE8BCC0FD6AC39B424826_size9691_w640_h360.gif" referrerpolicy="no-referrer"></p><p style="text-align: left;">之后，利用<strong>NeRF</strong>来重建出细致的3D场景信息。</p><p style="text-align: left;">神经渲染辐射场可以将场景的体积表示优化为向量函数，该函数由位置和视图方向组成的连续5D坐标定义。</p><p style="text-align: left;">也就是沿着相机射线采样5D坐标，以此合成图像。</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/49FC8D906205168277D01D43507F7921BE8E54E9_size82_w1044_h282.png" src="https://d.ifengimg.com/w1044_h282_q90/x0.ifengimg.com/ucms/2022_32/49FC8D906205168277D01D43507F7921BE8E54E9_size82_w1044_h282.png" referrerpolicy="no-referrer"></p><p style="text-align: left;">接下来，就是处理场景中人物信息方面。</p><p style="text-align: left;">针对多镜头情况下，在确定好人物所在位置后，使用NeRF就能直接重建出人体3D信息。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0802/17456430940575b.jpg"><img data-original="https://static.cnbetacdn.com/article/2022/0802/17456430940575b.jpg" src="https://static.cnbetacdn.com/thumb/article/2022/0802/17456430940575b.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">而如果是单镜头情况，就需要利用上下帧画面中人体姿势的变化、摄像机位置和环境结构信息来进行重建。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0802/94879578693ac25.jpg"><img data-original="https://static.cnbetacdn.com/article/2022/0802/94879578693ac25.jpg" src="https://static.cnbetacdn.com/thumb/article/2022/0802/94879578693ac25.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0802/1215c98708d5bca.png" referrerpolicy="no-referrer"></p><p style="text-align:center"><img src="https://static.cnbetacdn.com/article/2022/0802/7646fc53a82c3f6.jpg" referrerpolicy="no-referrer"></p><p style="text-align: left;">从实验结果中可以看到，该方法最终可以综合得到的3D信息，重新渲染出一个新的画面。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0802/1eab5775f996b6b.jpg"><img data-original="https://static.cnbetacdn.com/article/2022/0802/1eab5775f996b6b.jpg" src="https://static.cnbetacdn.com/thumb/article/2022/0802/1eab5775f996b6b.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">在消融实验中，如果没有确定摄像机、人物的特征信息，最终得到的结果也都不尽如人意。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0802/2326f4cbdf1b382.jpg"><img data-original="https://static.cnbetacdn.com/article/2022/0802/2326f4cbdf1b382.jpg" src="https://static.cnbetacdn.com/thumb/article/2022/0802/2326f4cbdf1b382.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">并且，研究人员还对得到的场景进行了数据分析，包括相机距离、人物位置分布。</p><p style="text-align: left;">还提供了编辑选项，可以删除或插入选定对象。</p><p style="text-align:center"><img lazyload="https://x0.ifengimg.com/ucms/2022_32/E58FE2DAF0AF45C21B0E604A5B95102D43ECD1A0_size811_w1080_h625.png" src="https://d.ifengimg.com/w1080_h625_q90/x0.ifengimg.com/ucms/2022_32/E58FE2DAF0AF45C21B0E604A5B95102D43ECD1A0_size811_w1080_h625.png" referrerpolicy="no-referrer"></p><p style="text-align: left;">目前，该团队已将代码和论文数据开源。</p><p style="text-align: left;">研究团队来自UC伯克利大学人工智能研究实验室。</p><p style="text-align: left;">作者表示，本文方法在电影、体育节目等领域同样适用。</p>   
</div>
            