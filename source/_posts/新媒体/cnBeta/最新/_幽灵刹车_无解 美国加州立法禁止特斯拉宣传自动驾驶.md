
---
title: '_幽灵刹车_无解 美国加州立法禁止特斯拉宣传自动驾驶'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://n.sinaimg.cn/finance/transform/324/w630h494/20220916/2532-b3b5b5deb3ddaab5331bd67c39752ab5.jpg'
author: cnBeta
comments: false
date: Fri, 16 Sep 2022 10:54:17 GMT
thumbnail: 'https://n.sinaimg.cn/finance/transform/324/w630h494/20220916/2532-b3b5b5deb3ddaab5331bd67c39752ab5.jpg'
---

<div>   
“特斯拉还没有生产出任何接近全自动驾驶汽车的产品。”美国车主布里格斯·马茨科日前将特斯拉告上法庭，他认为特斯拉误导性的夸大了自动辅助驾驶（Autopilot）和完全自动驾驶（Full Self Driving，简称FSD）能力。<br>
<p></p><p>马茨科花费5000美元升级了增强版Autopilot功能，但他的2018款Model X在实际驾驶中问题不断，实际就像是“未经培训的测试工程师”。</p><p>马茨科在向旧金山联邦法院提起的诉讼中指出，特斯拉CEO马斯克在宣传时错误描述Autopilot的技术，并一次又一次的作出无法兑现的承诺，让消费者相信特斯拉拥有更强的自动驾驶技术。</p><p>其实，关于特斯拉涉嫌虚假宣传的诉讼并不少。就在上个月，Model 3车主托莱多也在加州法院起诉特斯拉，表示自己驾驶的特斯拉会在根本不存在的障碍物的情况下突然刹车（“幽灵刹车”），并称这是“可怕的噩梦”。</p><p style="text-align: center;"><img src="https://n.sinaimg.cn/finance/transform/324/w630h494/20220916/2532-b3b5b5deb3ddaab5331bd67c39752ab5.jpg" alt="美国国家公路交通安全管理局（NHTSA）诉讼截图" data-link referrerpolicy="no-referrer"><br>美国国家公路交通安全管理局（NHTSA）诉讼截图</p><p>托莱多同样认为特斯拉明知道Autopilot可能存在功能缺陷，但还是推向市场，宣称具备自动驾驶的能力是不负责任的表现。</p><p>不只是普通消费者，美国政府机构的忍耐也接近极限。加州机动车辆管理局（DMV）和美国国家公路交通安全管理局（NHTSA）分别将特斯拉告上法庭，表示特斯拉存在虚假宣传。加州参议院也已通过法案，禁止在智能驾驶的广告里包含“自动驾驶”等词汇。</p><p>值得注意的是，官司缠身的特斯拉并未做出回应，而是在9月5日将FSD的售价从1.2万美元上调至1.5万美元，这是年内第二次涨价。FSD的售价也从2500美元上涨至1.5万美元，7年时间价格翻6倍。</p><p>回到问题本身，特斯拉为何幽灵刹车频发，FSD和Autopilot是否存在虚假宣传？数次跳票的自动驾驶汽车，马斯克年底推出的承诺是否又是一张空头支票？</p><p><strong><span style>7成事故和特斯拉有关</span></strong></p><p>特斯拉Autopilot和FSD宣传和实际使用不符，消费者和政府机构坐不住了。</p><p>如果考虑到特斯拉自动驾驶软件订阅数量的高速增长，意味类似马茨科和托莱多的案例涉及更多消费者。根据特斯拉早前公布的数据显示，2020年特斯拉FSD软件在Model S/X车型的选装率超过60%，在Model Y车型的选装率超过40%，2021年，自动驾驶软件订购及其他业务实现营收38.02亿美元，同比增加65%，占总营收的7.06%。</p><p>《华盛顿邮报》今年2月的报道称，在过去的9个月中，关于特斯拉“幽灵刹车”累计投诉已达354起，特别是近三个月，相关投诉量迅速增长，已达到107起。</p><p>投诉内容显示，用户在开启特斯拉的自动驾驶辅助系统时，车辆高速行驶途中，在没有任何警告的情况下突然刹车。</p><p>NHTSA认为，这种行驶途中的不必要的刹车，极大提升车辆发生事故的潜在可能性。</p><p>根据NHTSA公布的数据显示，在涉及驾驶辅助技术的事故中，有约7成涉及特斯拉的产品。其中，特斯拉造成严重伤害的事故占60%，致死事故占比达到85%。</p><p>NHTSA要求对特斯拉展开新一轮的安全性调查。</p><p>而DMV今年7月向法院提起诉讼，指控特斯拉对自动驾驶技术的能力进行虚假宣传，“在宣传车辆配备或可能配备高级驾驶辅助系统（ADAS）功能时，特斯拉传播了不真实或误导性的声明，而且没有事实依据。”</p><p>特斯拉在其网站上的营销文案中称，特斯拉驾驶辅助技术能够“在不需要驾驶席上的人采取行动的情况下”行驶。DMV认为，尽管特斯拉声明辅助驾驶“需要驾驶员的积极监督”，但这些广告宣传依然具有误导性，夸大了自动驾驶和全自动驾驶技术的功能。</p><p>幽灵刹车未解决的前提下，特斯拉仍存在虚假宣传的嫌疑。</p><p>频繁在政府监管红线徘徊的特斯拉最终被套上枷锁。9月2日，美国加州参议院通过一项新法案，禁止特斯拉在智能驾驶的广告里包含“自动驾驶”等词汇。</p><p><strong><span style>为何幽灵刹车频发？</span></strong></p><p>幽灵刹车的根源是纯视觉感知系统的缺陷。</p><p>特斯拉前AI项目负责人安德烈·卡帕西曾公开描述过“幽灵刹车”的典型案例，并称这是“臭名昭著”的。当车辆即将驶入桥下的时候，毫米波雷达已经检测到了“桥”这个静态物体的存在，但是因为没有足够的分辨率，毫米波雷达分不清楚这个物体是桥梁还是汽车。</p><p>这时，需要视觉感知（摄像头）介入，告诉车辆系统这个静态的物体到底是什么。但是，由于感知系统关联了毫米波雷达，摄像头在对前方物体各项参数的测量中都没有发挥足够的精度。如果此时前方恰好有一辆缓慢减速的汽车（但不足以造成刹车），系统就会将视觉系统报告的“减速车辆”和雷达报告的“静态物体”相关联，从而造成幽灵刹车。</p><p style="text-align: center;"><img src="https://n.sinaimg.cn/finance/transform/181/w630h351/20220916/08f9-7d6c0c91aad590455fbb6ca6a49867fe.jpg" alt="卡帕西谈神经网络以及幽灵刹车" data-link referrerpolicy="no-referrer"><br>卡帕西谈神经网络以及幽灵刹车</p><p>简单来说，卡帕西认为，特斯拉幽灵刹车的源头是毫米波雷达和摄像头对物体识别产生冲突，导致系统发出错误指令。</p><p>对此，特斯拉将“锅”甩给毫米波雷达。今年5月，特斯拉在发布FSD Beta v9版本时，同步取消了北美地区全系产品搭载的毫米波雷达，转向纯视觉路线，使用“Tesla Vision”视觉系统，通过不同位置布局的摄像头实现三维图像感知。</p><p>事与愿违，特斯拉切换纯视觉路线后，幽灵刹车的现象不减反增。根据部分车主描述，可能只是路上飘过的塑料袋或者前车行驶中的阴影，自己驾驶车辆都会幽灵刹车。</p><p>上述现象表明摄像头使用场景存在限制。和人眼类似，摄像头受天气、强弱光影响较大，但在智能化程度上远不及人眼。据峰瑞资本合伙人杨永成介绍，车载自动驾驶摄像头基本都是固定焦距、固定FOV、固定光圈、固定位置安装的，完全不具备人眼的自动化和灵活性。</p><p>杨永成表示，车头前方就配有远、中、近距离的视觉成像模式，除了成本方面考量，要实现人眼通用化设计，必然使用大量电机、机械运动、控制部件。而汽车使用场景复杂，包括高低温、震动、运动等，要求摄像头无故障运行时间长。</p><p>这也是为何车辆在感知系统中，会在主传感器摄像头之后加上辅助系统毫米波雷达。毫米波本质上是电磁波，可直接测距和测速，其主流频段集中在24GHz（用于15-30米中短距离感知）和77GHz（用于100-200米长距离感知）。</p><p>不过，特斯拉如今的自断双臂的做法，在纯视觉感知算法未迭代到理想状态下，显然有些仓促。就像特斯拉2016年和Mobileye的分手，在很长一段时间内，特斯拉Autopilot和ADAS饱受诟病，迭代后的体验不升反降。</p><p><strong><span style>幽灵刹车何时能解决?</span></strong></p><p>一向乐观的马斯克在面对幽灵刹车问题时，也变得谨慎起来。</p><p>日前，马斯克在推特上表示，FSD最新测试版本已推出，但用户应该对该系统更谨慎。</p><p>根据特斯拉FSD Beta 10.9更新日志，特斯拉“通过改进对能见度尽头的物体的速度估计，减少了交叉物体的错误减速”，“通过更好地建模合并点和位于可见性边缘的重影对象，改进合并控制的平滑度”。</p><p>至于何时能解决幽灵刹车的问题，甚至马斯克本人也不能确定。</p><p>关于FSD的迭代，马斯克表示，他在《总体规划第二部分》已提到，特斯拉大概需要60亿英里的自主里程，才能使自动驾驶系统获得全球监管机构的批准。</p><p>截止今年二季度，特斯拉FSD测试版车队有效行驶里程为3500万英里。简单换算，已完成马斯克目标值的0.58%。</p><p>马斯克的逻辑通过大量边际案例，通过特斯拉深度神经网络实现机器学习。通过神经网络对原始图像进行处理，将目标物体的边界“抠”出来，最后对数据进行比对和纠正，完成机器的图像的识别。这个过程就像教小朋友识图，告诉机器该物体是人、车还是路牌等信息（专业术语为监督学习，Supervised Learning）。</p><p>同时，为了加速机器的“文化水平”，特斯拉还推出“影子模式”，让车辆的自动驾驶系统出于开启状态，传感器探测车辆行驶道路周围的数据。驾驶操作仍由人来完成，机器不参与驾驶。但在人的驾驶过程中，机器会学习人的驾驶操作，从而达到对自动驾驶系统的优化。</p><p>边际案例基于大量道路数据抓取，其实，其实，道路上行驶的每一辆特斯拉都可以看作是其测试车辆，车辆配有的摄像头不断抓取道路信息，再回传至中心服务器。</p><p>不过，特斯拉现阶段面临更严重的一个问题——中国对特斯拉使用场景的限制。出于数据安全性考量，不少事业单位和特殊路段已明令禁止特斯拉的驶入和通过，意味着特斯拉在面对中国特有场景（匝道、城市外卖车、快递三轮车）时，能否有效识别需打个问号。</p>   
</div>
            