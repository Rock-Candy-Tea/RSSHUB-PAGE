
---
title: '麻省理工学院AI图像生成系统让《DALL-E 2》等模型散发出创意'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2022/0925/7279e0ae92e4be6.jpg'
author: cnBeta
comments: false
date: Sun, 25 Sep 2022 07:15:40 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2022/0925/7279e0ae92e4be6.jpg'
---

<div>   
随着DALL-E的问世，互联网迎来了一个集体感觉良好的时刻。这个基于人工智能的图像生成器的灵感来自于艺术家萨尔瓦多-DALL-E和动画电影中可爱的机器人瓦力，它使用自然语言来生成你心中想要的任何神秘而美丽的图像。看到打出的输入信息，如"拿着冰激凌甜筒的微笑地鼠"，机器的灵感瞬间涌现出来，这种生动的人工智能生成的图像显然得到了世界的共鸣。<br>
 <p><a href="https://static.cnbetacdn.com/article/2022/0925/7279e0ae92e4be6.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0925/7279e0ae92e4be6.jpg" title alt="DALL-E-2-Astronaut-Image.jpg" referrerpolicy="no-referrer"></a></p><p>DALL-E 2使用了一种叫做扩散模型的概念，它试图将整个文本编码为一个描述来生成一个图像。然而，一旦文本有了更多的细节，单一的描述就很难捕捉到它的全部。此外，虽然它们高度灵活，但扩散模型有时很难理解某些概念的构成，例如混淆不同对象之间的属性或关系。</p><p style="text-align: center;"><a href="https://static.cnbetacdn.com/article/2022/0925/a22074ee2a48767.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0925/a22074ee2a48767.jpg" title alt="Train-on-a-Bridge-Generated-Images.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: center;">这个生成的图像阵列，显示了"桥上的火车"和"桥下的河流"，是使用麻省理工学院研究人员开发的新方法生成的。</p><p>为了生成具有更好理解力的更复杂的图像，来自麻省理工学院计算机科学和人工智能实验室（CSAIL）的科学家们从不同的角度对典型的模型进行了结构化设计：他们将一系列的模型加在一起，按照输入文本或标签的要求，合作生成捕捉多个不同方面的理想图像。要创建一个有两个组成部分的图像，比如说，由两句描述组成的图像，每个模型将处理图像的一个特定组成部分。</p><p>图像生成背后看似神奇的模型通过建议一系列的迭代完善步骤来达到所需的图像。它从一张"糟糕"的图片开始，然后逐渐细化，直到成为选定的图像。通过将多个模型组合在一起，它们在每个步骤中共同完善外观，所以结果是一个展现每个模型所有属性的图像。通过让多个模型合作，你可以在生成的图像中得到更多的创造性组合。</p><p style="text-align: center;"><a href="https://static.cnbetacdn.com/article/2022/0925/3187278065ae51c.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0925/3187278065ae51c.jpg" title alt="River-Leading-Into-Mountains-Generated-Images.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: center;">这个生成的图像阵列，显示了"一条通向山脉的河流"和"边上的红树"</p><p>以一辆红色卡车和一座绿色房子为例。当这些句子变得非常复杂时，模型会混淆红色卡车和绿色房子的概念。像《DALL-E 2》这样的典型生成器可能会把这些颜色调换一下，做成绿色卡车和红色房子。该团队的方法可以处理这种类型的属性与物体的绑定，特别是当有多组东西时，它可以更准确地处理每个物体。</p><p>"该模型可以有效地对物体位置和关系描述进行建模，这对现有的图像生成模型来说是一个挑战。例如，把一个物体和一个立方体放在某个位置，把一个球体放在另一个位置。DALL-E 2善于生成自然图像，但有时难以理解物体关系，"麻省理工学院CSAIL博士生和共同主要作者Li Shuang说。"除了艺术和创意，也许我们可以把我们的模型用于教学。如果你想告诉孩子把一个立方体放在一个球体的上面，如果我们用语言这么说，他们可能很难理解。但我们的模型可以生成图像并向他们展示。"</p><p><strong>让DALL-E感到自豪</strong></p><p>可组合扩散--该团队的模型--将扩散模型与组合运算符一起使用，无需进一步的训练就能组合出文字描述。该团队的方法比原始扩散模型更准确地捕捉文本细节，后者直接将文字编码为一个长句。例如，给定"粉红色的天空"和"地平线上的一座蓝色的山"和"山前的樱花"，该团队的模型能够准确地生成该图像，而原始的扩散模型使天空变成蓝色，山前的一切变成粉红色。</p><p style="text-align: center;"><a href="https://static.cnbetacdn.com/article/2022/0925/105948f36b829c7.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0925/105948f36b829c7.jpg" title alt="AI-Generated-Images-Dog-Sky.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: center;">研究人员能够用"一只狗"和"天空"的文字创造出一些令人惊讶的、超现实的图像。左边出现的是一只狗和云，下面标有"狗"和"天空"，右边出现的是两张像云一样的狗的图像，下面标有"狗和天空"。</p><p>"我们的模型是可组合的，这意味着你可以学习模型的不同部分，一次一个。你可以先学习另一个物体上面的一个物体，然后学习另一个物体右边的一个物体，再学习另一个物体左边的东西，"共同主要作者、麻省理工学院CSAIL博士生Du Yilun说。"由于我们可以将这些东西组合在一起，你可以想象我们的系统使我们能够逐步学习语言、关系或知识，我们认为这是未来工作的一个相当有趣的方向。"</p><p>虽然这种方法在生成复杂、逼真的图像方面表现出了优势，但它仍然面临着挑战，因为该模型是在比《DALL-E 2》这样的数据集小得多的基础上训练的。</p><p>现在，可压缩扩散可以在生成模型的基础上工作，如DALL-E 2，研究人员准备探索持续学习作为潜在的下一步。鉴于通常会有更多的东西被添加到物体关系中，他们想看看扩散模型是否可以开始"学习"，而不会忘记以前学过的知识--达到模型可以用以前和新的知识生成图像的程度。</p><p style="text-align: center;"><a href="https://static.cnbetacdn.com/article/2022/0925/12f97f12b8f18e9.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0925/12f97f12b8f18e9.jpg" title alt="MIT-Composable-Diffusion-Generated-Images.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: center;">这幅照片插图是用麻省理工学院的一个名为"可组合扩散"的系统生成的图像制作的，并在Photoshop中排列。像"扩散模型"和"网络"这样的短语被用来生成粉红色的点和几何角度的图像。短语"一匹马和一片黄花地"被包含在图像的顶部。左边是生成的马和黄土地的图像，右边是黄花地里的马的组合图像。资料来源：Jose-Luis Olivares, MIT和研究人员</p><p>"这项研究提出了一种在文本-图像生成中合成概念的新方法，不是通过串联它们来形成提示，而是通过计算与每个概念有关的分数，并使用连接和否定运算符来合成它们，"Mark Chen说。他是DALL-E 2的共同创造者，也是OpenAI的研究科学家。"这是一个很好的想法，它利用了扩散模型的基于能量的解释，因此，围绕着使用基于能量的模型的组合性的旧想法可以被应用。该方法还能够利用无分类器的指导，令人惊讶的是，它在各种构成性基准上的表现优于GLIDE基线，并能在质量上产生非常不同的图像生成类型。"</p><p>"人类可以以无数种方式组成包括不同元素的场景，但这项任务对计算机来说是具有挑战性的，"Adobe Systems的研究科学家Bryan Russel说。"这项工作提出了一个优雅的表述，它明确地组成了一组扩散模型，以生成一个给定的复杂自然语言提示的图像。"</p>   
</div>
            