
---
title: '苹果将部署照片识别算法以检测照片库中的儿童虐待图像'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2021/0805/143791717f22cbc.webp'
author: cnBeta
comments: false
date: Thu, 05 Aug 2021 09:42:39 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2021/0805/143791717f22cbc.webp'
---

<div>   
<strong>苹果公司将宣布新的照片识别功能，该功能将使用散列算法，将用户照片库中的照片内容与已知的虐待儿童材料（如儿童色情制品）进行匹配。苹果的系统将发生在客户端，也就是用户的设备上。</strong>iPhone将下载一组代表非法内容的指纹，然后对照该列表检查用户相机胶卷中的每张0照片，如果发现匹配内容会自动向机主发起提示。<br>
<p><img src="https://static.cnbetacdn.com/article/2021/0805/143791717f22cbc.webp" title alt="iPhone-app-privacy.webp" referrerpolicy="no-referrer"></p><p>苹果公司此前曾表示，它在照片上传到iCloud时采用了散列技术，这个新系统将在用户的设备上的客户端完成。苹果还没有正式宣布这项新举措，持续打磨细节很重要。</p><p>这种系统类似于苹果照片中已经存在的物体和场景识别的机器学习功能。然而，密码学和安全专家Matthew Green指出，这种推广的影响是复杂的。哈希算法并非万无一失，可能会出现误报。如果苹果公司允许政府控制指纹内容数据库，那么他们也许可以利用该系统来检测明显非法的儿童内容以外的图片，比如压制政治议题。</p><p>然而，无论如何，所有上传到iCloud照片的备份和同步的照片都不是端到端的加密存储。照片以加密的形式存储在苹果的服务器群中，但解密的密钥也是由苹果公司拥有。这意味着执法机构可以传唤苹果，并看到用户上传的所有照片。(这并不罕见，所有第三方照片服务都是这样工作的)</p><p>未来，苹果有可能推出类似的系统，在客户端扫描内容，然后以端到端加密的方式存储在服务器上。许多国家的政府都在争取从iMessage和WhatsApp等E2E私人信息应用中建立这样的系统，因为他们担心越来越多地转向加密通信会使执法部门更难发现和起诉虐待儿童的案件。</p>   
</div>
            