
---
title: 'Google正在使用人工智能_更准确地检测更广泛的个人危机搜索_'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2022/0331/9e0d49592068a26.jpg'
author: cnBeta
comments: false
date: Wed, 30 Mar 2022 23:44:26 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2022/0331/9e0d49592068a26.jpg'
---

<div>   
据The Verge报道，在个人危机中，许多人求助于一个非个人的支持来源：Google。每天，该公司都要处理关于自杀、性侵犯和家庭虐待等主题的搜索。但是，<strong>Google想做更多的事情来引导人们找到他们需要的信息，并<a href="https://blog.google/products/search/using-ai-keep-google-search-safe/#link=%7B%22role%22:%22standard%22,%22href%22:%22https://blog.google/products/search/using-ai-keep-google-search-safe/%22,%22target%22:%22_blank%22,%22linkText%22:%22Google%20blog%20post%22,%22absolute%22:%22%22%7D" target="_self">表示</a>其新的人工智能技术正在帮助人们更好地解析语言的复杂性。</strong><br>
 <p style="text-align:center"><a href="https://static.cnbetacdn.com/article/2022/0331/9e0d49592068a26.jpg" target="_blank"><img src="https://static.cnbetacdn.com/thumb/article/2022/0331/9e0d49592068a26.jpg" alt="ai_search_hero.max-1000x1000.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">具体而言，Google正在将其最新的机器学习模型MUM整合到其搜索引擎中，以“更准确地检测更广泛的个人危机搜索”。该公司去年在其 I/O开发者大会上公布了MUM，此后用它来增强搜索功能，试图回答与原始搜索有关的问题。</p><p style="text-align: left;">Google负责健康和信息质量的产品经理Anne Merritt说，在这种情况下，MUM将能够发现与困难的个人情况有关的搜索查询，而早期的搜索工具无法做到。</p><p style="text-align: left;">“MUM能够帮助我们理解更长或更复杂的查询，比如‘当我说我不爱他时，他为什么攻击我’，”Merritt告诉The Verge。“对人类来说，这个查询可能很明显是关于家庭暴力的，但像这样长的自然语言查询，如果没有先进的人工智能，我们的系统很难理解。”</p><p style="text-align: left;">MUM可以做出反应的其他查询例子包括 “完成自杀的最常见方式”（Merrit说早期的系统“以前可能理解为寻求信息”）和 “悉尼自杀热点”（同样，早期的反应可能会返回旅游信息--忽略提及“自杀”而选择更受欢迎的“热点”查询）。当Google检测到这种危机搜索时，它会用一个信息框来回应，告诉用户“可以提供帮助”，通常伴随着一个电话号码或Samaritans等心理健康慈善机构的网站。</p><p style="text-align: left;">除了使用MUM来应对个人危机外，Google表示它还在使用一种较早的人工智能语言模型BERT，以更好地识别寻找色情等明确内容的搜索。通过利用BERT，Google表示，它的“意外震惊的结果同比减少了30%”。然而，该公司无法分享其用户平均遇到多少“令人震惊的结果”的绝对数字，因此，虽然这是一个相对的改进，但它没有表明问题实际上有多大或多小。</p><p style="text-align: left;">Google热衷于告诉你，人工智能正在帮助该公司改善其搜索产品--尤其是在一个正在形成“Google搜索正在消亡”的说法的时候。然而，整合这种技术也有其缺点。</p><p style="text-align: left;">许多人工智能专家警告说，Google越来越多地使用机器学习语言模型可能会给该公司带来新的问题，比如在搜索结果中引入偏见和错误信息。人工智能系统也是不透明的，对于它们如何得出某些结论，工程师的洞察力有限。</p><p style="text-align: left;">例如，当The Verge问Google如何事先核实MUM确定的哪些搜索词与个人危机有关时，其代表要么不愿意要么无法回答。该公司表示，它使用人类评估员严格测试其搜索产品的变化，但这与事先知道人工智能系统将如何应对某些查询是不同的。不过，对Google来说，这种权衡显然是值得的。</p>   
</div>
            