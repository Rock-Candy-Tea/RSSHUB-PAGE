
---
title: '美国一位特斯拉Model Y车主在体验FSD测试版系统时发生事故'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/article/2020/1006/feab64051c9c887.jpg'
author: cnBeta
comments: false
date: Sat, 13 Nov 2021 04:25:40 GMT
thumbnail: 'https://static.cnbetacdn.com/article/2020/1006/feab64051c9c887.jpg'
---

<div>   
近日，美国国家公路交通安全管理局（NHTSA）收到了一份与特斯拉“全自动驾驶”（FSD）测试功能有关的事故报告。<strong>可知 11 月 3 号的时候，一辆处于 FSD 测试模式的特斯拉 Model Y 车型，于洛杉矶东南部城市 Brea 发生了一起交通事故。</strong>虽然车子受损严重，但庆幸的是无人在事故期间受伤。<br>
 <p><img src="https://static.cnbetacdn.com/article/2020/1006/feab64051c9c887.jpg" referrerpolicy="no-referrer"></p><p style="text-align: center;">（图自：Tesla 官网）</p><p>作为特斯拉打造新版驾驶辅助系统过程中发生的一起早期事故，相关报道也引发了外界的高度关注。</p><p>NHTSA 对特斯拉 Autopilot 系统展开了多重细致的调查，但事故报告似乎由 Model Y 车主本人撰写，且 NHTSA 发言人没有立即回应外媒的置评请求。</p><blockquote><p>● 事故发生时，这辆 Model Y 处于 FSD Beta 测试模式。但在该左转时，车子意外驶向了错误的车道，导致其被另一辆车撞到。</p><p>● Model Y 在转弯到一半时发出了警报，车主试图转动方向盘以避免驶入错误车道，但系统还是强行控制车子犯下了错误。</p><p>● 这起事故造成的不安全操控，让所有交通参与者都陷入了风险之中，且 Model Y 单侧遭遇了严重的碰撞损伤。</p></blockquote><p><a href="https://www.theverge.com/2021/11/12/22778135/tesla-full-self-driving-beta-crash-fsd-california" target="_self">TheVerge</a> 编辑 Andrew J. Hawkins 指出，此前特斯拉决定让未经培训的车主在公共道路上测试其“FSD”驾驶辅助软件。尽管引发了大量的批评和审查，但该公司还是决定强行推进。</p><p>从推出至今，该公司已推出并撤回了几版本该更早推出的系统软件更新，但期间显然还有不少软件错误未得到及时修复。</p><p>在互联网上，我们见到过许多特斯拉车主高调分享的 FSD 测试版体验视频片段。</p><p>一些剪辑显示驾驶辅助系统能够自信地处理复杂的驾驶场景，但也有许多剪辑描绘了汽车漂移到错误的车道、或犯下其它严重的错误。</p><p><strong>总结：</strong></p><p>（1）现阶段的 Autopilot 不该被直译理解为 L5 级别的“自动驾驶”，而是 L2 级别的“自动辅助驾驶”。</p><p>（2）现阶段的“Full Self-Driving”也不该被直译理解为“全自动驾驶”，车主仍需注意随时接管车辆的控制。</p>   
</div>
            