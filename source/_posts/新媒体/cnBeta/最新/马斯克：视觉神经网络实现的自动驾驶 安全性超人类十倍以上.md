
---
title: '马斯克：视觉神经网络实现的自动驾驶 安全性超人类十倍以上'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2021/0917/e0e5b022d2ea82a.jpg'
author: cnBeta
comments: false
date: Fri, 17 Sep 2021 05:55:55 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2021/0917/e0e5b022d2ea82a.jpg'
---

<div>   
9月17日上午，在海南省海口市召开的2021世界新能源汽车大会上，<strong>特斯拉首席执行官埃隆·马斯克通过视频发言时表示，未来的自动驾驶可以通过视觉神经网络实现，并且相比普通人驾驶有十倍以上的安全性。</strong><br>
 <p style="text-align: left;">记者| 邵文</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2021/0917/e0e5b022d2ea82a.jpg"><img data-original="https://static.cnbetacdn.com/article/2021/0917/e0e5b022d2ea82a.jpg" src="https://static.cnbetacdn.com/thumb/article/2021/0917/e0e5b022d2ea82a.jpg" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">近日，特斯拉向其抢先体验车队推出FSD（Full-self Driving，完全自动驾驶）Beta V10软件。这是在特斯拉AI Day上发布最新应用在自动驾驶上的视觉神经网络之后，技术上做了重要改进的的纯视觉自动驾驶方案新版本。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2021/0917/42ca17ce47d3a7f.png"><img data-original="https://static.cnbetacdn.com/article/2021/0917/42ca17ce47d3a7f.png" src="https://static.cnbetacdn.com/thumb/article/2021/0917/42ca17ce47d3a7f.png" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">特斯拉CEO伊隆·马斯克称，有望在9月25日左右向所有特斯拉车主开放使用。</p><p style="text-align: left;">FSD Beta 10的软件版本号为2021.24.15。在该版本软件的支持下，特斯拉汽车能够在高速公路和城市街道上虚拟驾驶，但它仍然被视为L2级驾驶员辅助驾驶，因为它需要驾驶员仍然对车辆负责，将手放在方向盘上，并随时准备好控制。</p><p style="text-align: left;">在Youtube（译为“油管”，是目前全球最大的视频搜索和分享平台）上参与测试的用户发布的针对性测试和路测结果来看，目前还有很多情景下会出现问题，一个最明显的提升表现在驾驶中可视化用户界面，越来越多的道路标识和交通标识物的识别走向细分化，但依然有部分道路标志还不能准确识别。</p><p style="text-align: left;">在近期的特斯拉人工智能日上，特斯拉AI负责人Andrej Karpathy和自动驾驶硬件高级总监Ganesh Venkataramanan介绍了纯视觉自动驾驶系统与FSD软件的最新成果，此前5月份，马斯克曾发文表示，特斯拉最新版本的FSD将取消毫米波雷达，采用纯视觉感知方案。</p><p style="text-align: left;">在自动驾驶感知领域，有两个明显区别的路径——纯视觉派和激光雷达派，纯视觉派认为单纯依靠摄像头就可以完成自动驾驶所需要的周围环境感知，特斯拉、极氪、百度都使用的是纯视觉感知方案。激光雷达派则以激光雷达为主导，配合毫米波雷达、超声波传感器、摄像头多传感器融合完成周围环境感知，商汤AR小巴、小鹏P5、蔚来ET7使用的是激光雷达方案。</p><p style="text-align: left;">商汤智能驾驶研发总监李怡康在接受澎湃新闻采访时表示，“无论是纯视觉方案还是多传感器融合的方案最终都是有可能实现L4或L5级别的自动驾驶的，区别在于，引入激光雷达实际上是把问题变简单了，因为我们引入了很多额外的信息，而且这些信息跟视觉很互补，有些信息，比如深度，它可以估算地很准确。假如最后两条路径都能实现L5级自动驾驶，那我相信多传感器融合这条路线可能会更快一些。当然，感知只是决定自动驾驶是否实现的因素之一。”</p><p style="text-align: left;"><strong>特斯拉“纯视觉派”技术路线：视觉神经网络</strong></p><p style="text-align: left;">特斯拉人工智能与自动驾驶视觉总监Andrej Karpathy认为，将激光雷达添加到自动驾驶堆栈会带来其自身的复杂性。在CVPR 2021自动驾驶研讨会上，Karpathy，“你必须用激光雷达预先绘制环境地图，然后你必须创建一张高清地图，你必须插入所有车道及其连接方式以及所有交通信号灯，收集、构建和维护这些高清激光雷达地图是不可扩展的，让这个基础设施保持最新状态将是极其困难的。”</p><p style="text-align: left;">Karpathy表示特斯拉在其自动驾驶堆栈中不使用激光雷达和高清地图，“发生的一切，都是第一次发生在车内，基于围绕汽车的八个摄像头的视频”。</p><p style="text-align: left;">特斯拉汽车上安装了8个摄像头，摄像头没有深度信息，他们的目标之一就是形成矢量空间视图。那么要怎么知道旁边一辆车究竟在哪里又有多长呢？</p><p style="text-align: left;">首先的一个难点是，不同视角的摄像头都只能看到周边环境的一部分，有不同的校准（calibration）、位置（location）、取景方向（view direction）等，比如以下这张图，谁能知道这个点对应于相机视图的哪个点？而我们只有知道这些信息，才能把周围物体准确放到向量空间视图（vector space view）中。</p><p style="text-align:center"><a target="_blank" href="https://static.cnbetacdn.com/article/2021/0917/2f1a996d5789f15.png"><img data-original="https://static.cnbetacdn.com/article/2021/0917/2f1a996d5789f15.png" src="https://static.cnbetacdn.com/thumb/article/2021/0917/2f1a996d5789f15.png" referrerpolicy="no-referrer"></a></p><p style="text-align: left;">因此就需要一种将多个摄像头的信息融合在一起的技术，特斯拉使用了在2017年提出，如今已经席卷自然语言处理和计算机视觉领域的Transformer神经网络（Transformer Neural Network）。</p><p style="text-align: left;">然后则是加入有时间概念时间的RNN（Recurrent Neural Network，循环神经网络）以判断移动物体的速度以及对被遮挡物进行预测。RNN体现了“人的认知是基于过往的经验和记忆”的观点，通过记忆来处理任意时序的输入序列，从而对接下来要发生的事情进行预测。比如这里对被遮挡物预测，通过对遮挡前的特征和轨迹的记忆，使得视野被短暂遮蔽的情况下，依然可以预测遮挡视野后的物体运动轨迹，并记录已行驶过的路段的各种路标。</p><p style="text-align: left;">而对于深度信息，在缺少了雷达信息后，则需要通过对大量的有深度标注的相机数据进行训练得到的检测算法来得到。</p><p style="text-align: left;"><strong>激光雷达多传感器融合方案</strong></p><p style="text-align: left;">激光雷达多传感器方案是以激光雷达为主导，毫米波雷达、超声波传感器及摄像头作为辅助。通过激光雷达发射激光束，测量激光在发射及收回过程其中的时间差、相位差，从而确定车与物体之间的相对距离，实现环境实时感知及避障功能。摄像头的价格在几十美元左右，而激光雷达则要昂贵的多，这或许也是很多纯视觉流派厂商一个没有说的难言之隐。</p><p style="text-align: left;">商汤智能驾驶研发总监李怡康向澎湃新闻介绍，“我们会做很多种传感器的评测，去找到最适合我们设计需求的传感器方案，然后通过自动化的算法将这些传感器摆放到最合适的地方，从而实现最优的环境信息获取。传感器之间是不在一个坐标系下的，我们通过自动化标定算法将不同传感器的特性及相关关系非常准确地找出来，然后设计融合感知模型，并用大量的感知数据去训练它，最终实现多传感器融合感知。”</p><p style="text-align: left;">自动驾驶底层逻辑是感知、决策、执行三个步骤的结合，对周围环境的周密感知是所有决策的基础，也是自动驾驶汽车的安全保障。在了解周围环境中物体的位置、速度和方向、路面的性质、路缘石的位置、信号（交通、道路标志）等之后，自动驾驶系统则要开始做计划和控制：首先是其他移动物体在接下来的短时间会做什么，然后是根据整体计划（比如规划的通向目的地路线）计划自己要做什么，最后就是告诉汽车要做什么。</p>   
</div>
            