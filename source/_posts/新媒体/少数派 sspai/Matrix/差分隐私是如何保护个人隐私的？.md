
---
title: '差分隐私是如何保护个人隐私的？'
categories: 
 - 新媒体
 - 少数派 sspai
 - Matrix
headimg: 'https://cdn.sspai.com/2021/08/11/57265faf30b01b00e1f6a5b0f3532d6f.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1'
author: 少数派 sspai
comments: false
date: Thu, 12 Aug 2021 06:07:58 GMT
thumbnail: 'https://cdn.sspai.com/2021/08/11/57265faf30b01b00e1f6a5b0f3532d6f.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1'
---

<div>   
<div class="articleWidth-content" data-v-3e67f99b><div class="content wangEditor-txt minHeight" data-v-3e67f99b><p>隐私，是互联网时代无法绕开的一个话题。科技公司对隐私的态度不尽相同，既出现过李彦宏关于「中国人愿意用隐私换取便利」的言论，也有过苹果以用户隐私为由而拒绝为 FBI 解锁手机的故事。但不论如何，随着各国政府关于信息隐私相关法律陆续出台，隐私问题的监管力度和重要程度在全球总体呈现出上升的趋势。</p><p>在这样的大背景下，手机厂商开始不断探索各种保护用户隐私的技术。我们今天要讲的<strong>差分隐私</strong>就是近年兴起、较为热门的技术。</p><p>所谓差分隐私，是指在共享数据时，仅提供可以描述数据库的一些<strong>统计特征</strong>、而不提供具体到个人的信息。</p><p>尽管这种方法在上世纪七十年代就被初步提出、本世纪前十年已在普查等领域得到应用，但在移动科技领域还是由苹果率先大规模应用的。在 2016 年 6 月召开的 WWDC 上，苹果宣布采用差分隐私，使得软件提供商能够在不掌握个人用户隐私数据的情况下，学习用户行为。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/08/11/57265faf30b01b00e1f6a5b0f3532d6f.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/11/57265faf30b01b00e1f6a5b0f3532d6f.png" referrerpolicy="no-referrer"><figcaption>WWDC 2016（来源：Apple）</figcaption></figure><p>苹果带头先行先试后，其他厂商也陆续跟进。以国内为例，小米在 MIUI 12.5 中、魅族在 Flyme 9 中都加入了差分隐私，使得软件只能获得模糊定位而非精准定位。</p><figure class="image ss-img-wrapper image_resized" style="width:559px;"><img src="https://cdn.sspai.com/2021/08/12/59cae4721cd8833c4003c354e8434083.jpg?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/59cae4721cd8833c4003c354e8434083.jpg" referrerpolicy="no-referrer"><figcaption>MIUI 12.5 发布会（来源：小米）</figcaption></figure><figure class="image ss-img-wrapper image_resized" style="width:561px;"><img src="https://cdn.sspai.com/2021/08/12/b2c5ce48ab76c54e616eb1ae3ac13598.jpg?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/b2c5ce48ab76c54e616eb1ae3ac13598.jpg" referrerpolicy="no-referrer"><figcaption>Flyme 9 发布会（来源：魅族）</figcaption></figure><h2>差分隐私受重视的背景</h2><p>在具体了解差分隐私的原理之前，一个值得讨论的问题是，为何要差分隐私？答案并非隐私保护这么简单。事实上，对于隐私的诉求一直存在，为何到了近年变得尤其热门、又为何是差分隐私这项技术脱颖而出呢？我认为，这主要是受两个因素的影响：法律法规要求日趋严格和传统保护方法弊端凸显。</p><h3>法律法规要求日趋严格</h3><p>近年来，许多国家和地区都颁布了用于保护个人隐私信息的法律法规。在欧洲，2016 年发布、2018 年开始强制执行的《通用数据保护条例》（General Data Protection Regulation， GDPR）涵盖范围广、保护要求严格，甫一推行就引发了科技公司的密切关注。在美国，尽管联邦层面没有专门用于隐私保护的法律，但健康、教育、金融等领域新近颁布的专门法规中都出现了保护个人信息的条文。2018 年，严格程度不逊于 GDPR 的《加州消费者隐私法案》 （California Consumer Privacy Act, CCPA）出台，尽管只是州法，但由于加州在科技领域的特殊地位，其影响范围同样是全球性的。</p><p>在我国，近年陆续颁布或修订的《民法典》《网络安全法》均为个人信息保护作了专门规定，《消费者权益保护法》《执业医师法》等部门法则从消费、医疗等具体维度反映了对个人信息的保护。 同时，尚处草案阶段的《个人信息保护法》也标志着我国对互联网时代个人信息保护的重视达到了一个新的高度。</p><p>在这样的背景下，重视消费者隐私的保护与合法合规使用，是科技公司必然的选择。</p><p>不仅如此，尽管各国法规的具体条款各异，但它们对于「个人信息」的定义却有很大重合度，基本都以「可识别性」为主要判定标准。例如，《民法典》规定「个人信息是以电子或者其他方式记录的能够单独或者与其他信息结合<strong>识别特定自然人</strong>的各种信息」，而 GDPR 也规定「『个人数据』是指与<strong>已识别或可识别</strong>的自然人（『数据主体』）相关的任何信息。」因此，能够避免识别特定个体的差分隐私，对于厂家就格外有吸引力了。 </p><h3>传统保护方法弊端凸显</h3><p>不过，法律只规定了要达到保护隐私的结果，至于实现这个结果的手段，则是厂商自主决定的范畴。显然，差分隐私并不是唯一可以用于保护隐私的手段。计算机界的大牛 Donald Ervin Knuth 曾说，「过早优化是万恶之源」（Premature optimization is the root of all evil）。既然已经有了匿名化、权限限制等传统手段，为什么要专门再引入一个差分隐私呢？</p><p>要回答这个问题，我们不妨来看看这些传统的隐私保护方法究竟效果如何。</p><h4>匿名化（Anonymization）与链接攻击（Linkage Attack）</h4><p>要实现隐私保护，一个最简单直接的思路就是<strong>匿名化</strong>。换言之，将用户的真实姓名，电话，身份证，或者用户 ID 进行匿名处理，变成无法反向计算的一串字符，只保留那些对于分析有意义的数据。</p><p>这看起来也十分有效：没办法看出谁是谁了，不就实现了隐私保护吗？</p><p>非也。知名流播服务商 Netflix 当初也是这么想的，然而其导致的隐私泄露使他们付出了 900 万美元的代价。</p><p>这就要提到机器学习与数据挖掘领域一个绕不开的事件。2006 年 10 月，Netflix 举办了一项大奖赛（Netflix Prize Competition）。比赛中，Netflix 提供了一个数据集，包含了从 1988 年到 2005 年间，超过 48 万个随机选择的匿名用户对于一万七千多部电影的评分。数据集中包括的具体数据有：用户 ID（随机分配，无法推出真实 ID）、电影信息（ID、年份、标题、用户对电影的评分等。</p><p>Netflix 希望参赛队提出一种算法，使得在相同的训练集上，新算法预测用户喜好的性能比现有算法的性能高出 10%，并宣布对效果最好的队伍给予 50000 美元的奖励。这场比赛持续了 5 年之久，引发了各国参赛队伍激烈的竞争。</p><figure class="image ss-img-wrapper image_resized" style="width:575px;"><img src="https://cdn.sspai.com/2021/08/12/4b457a3d1fee73fb4348898e72916b13.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/4b457a3d1fee73fb4348898e72916b13.png" referrerpolicy="no-referrer"></figure><p>由于比赛中提供的是真实业务数据，不可避免地会涉及个人信息保护的问题。表面上看，出现个人信息泄露的风险并不高，因为 Netflix 已经对提供的数据做了随机化处理。</p><p>然而，2008 年，来自德州大学奥斯汀分校的两名研究人员 Arvind Narayanan 和 Vitaly Shmatikov 发表了名为《<a href="https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf">Robust De-anonymization of Large Sparse Datasets</a>》的论文，详细描述了如何对 Netflix 提供的数据进行隐私攻击。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/08/12/690216ba4fc8c3488f6e10f7ce630b4b.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/690216ba4fc8c3488f6e10f7ce630b4b.png" referrerpolicy="no-referrer"></figure><p>简而言之，他们采用了<strong>链接攻击</strong>的方法：使用其他公开数据库的信息（如 IMDB）与 Netflix 提供的信息（如喜欢的电影、评分）进行比对，这样，就能够在一定程度上推断某一 Netflix 匿名用户在 IMDB 上的身份。Netflix 的这一疏忽使得用户对其提起集体诉讼，最终不得不支付 900 万美元的和解费才让事件告一段落。</p><h4>集合查询（Aggregation Queries） 与差分攻击（Differencing Attack） </h4><p>现在我们知道匿名化无法保护有效保护用户隐私，那换个方法。我们给数据库加个<strong>「集合查询」</strong>的限制，禁止查询单条信息、只准查询根据整体数据计算出的结果，这样不就能保护「每个人」的隐私了吗？很可惜，依旧不能。</p><p>假设，三个人在称体重，结果分别是 50、60、70 公斤。系统允许我们使用集合查询的方法，可以查询非单人的数据平均值。那么，我们可以使用差分攻击，先查三个人的，然后再查某两个人的，这样剩下的那个人的数据通过简单的数学计算就能被识破。另外，如果有一个第三方，知道其中两个人的数据，那他就能轻易推出第三个人的数据。这个例子看上去人畜无害，但如果换成患乙肝的人数，就会造成巨大的隐私风险。因为一个人患病与否是法律规定的个人隐私。</p><h4>不公开数据</h4><p>如果不再对外提供数据，将权限限制在公司内部，是否能完全保护个人隐私呢？并不能。你的员工可能是你信息泄露的重大隐患，因为他们能够访问你拥有的所有数据。如果你炒掉了所有员工，打算只让自己一个人分析数据，而且已知你是一个正直的人，事情又会如何发展呢？这样的确能较大程度确保个人隐私，但并不现实。至此，我相信大家已经发现了，<strong>数据的泄露风险和数据的可用性永远是一对不可调和的矛盾。</strong></p><p>事实上，数据的公开在某种程度上是不可避免的。企业获取数据是为了使用数据，提高企业的业务能力和盈利能力。如果只有一个人，数据处理的效率会大大降低，可谓是因噎废食。现实中，公司为了改善经营管理，会对自己所拥有的数据进行分析，或者交给其他商业分析公司进行商业咨询。国家部门也需要依法公开国家和地区的统计数据。</p><p>但保护个人隐私，并不等同于不分享数据。因为法律上的个人隐私仅仅代表了个人数据，而非集体数据（如平均数，个数）。但正如刚才提到的，即使是集体数据的披露，也有可能导致个人数据的泄露。</p><p>退一万步讲，即使公司不向外分享数据，公司中的个人也可能以权谋私，泄露公司系统中的信息，进行非法的勾当、牟利。这种种风险都指向了一个问题：我们如何在保证个人数据不泄露的情况下对数据进行有效利用？究竟有没有方法能够让最大程度降低获取个人数据的可能性，同时提高数据的可用性呢？那就是我们接下来要介绍的<strong>差分隐私</strong>了。</p><h2>差分隐私的原理</h2><p>差分隐私指的是一类能满足某一效果的算法。它们能够保证无论一个人是否在某一个数据库中，从这个数据库中查询得到的结果（如平均数或计数）的差距微乎其微。换言之，数据使用者无法确定某个人是否在某个数据库中，这样就能够保证用户个人数据的隐私。再换言之，除非数据使用者拥有整个数据库，否则他无法通过差分攻击来获取用户隐私。</p><p>例如，如果有两个数据库 x 和 y。数据库 x 包含一个班级 40 个同学的体重数据，数据库 y 除了包含这 40 个同学的体重数据，还加入了班主任的体重数据。现在提供一个网页，能够查询分别两个数据库所有数据的平均数。显然，如果网页能够直接输出两个数据库真实的平均数，我们能够很容易计算出班主任的体重。但如果我们有一种算法，能够每次在查询结果上加上一些随机数，让它与真实值不同。那么，显然每次查询得到的结果是随机的，不一定相同。如果这一种算法进一步能保证在 x 和 y 上进行查询，出现相同结果的概率差不多，那实际上就意味着，查询者无法辨别这两个数据库的查询结果，换言之，查询者无法确定班主任的数据在不在里面。此时，班主任就如同隐身一般，其体重就很难被反向计算出来。</p><h3>数学定义</h3><p>如果用数学语言来定义差分隐私，会是这样的：</p><p>对于任意两个只相差一个数据的数据库 x、y（比如 x 数据库比 y 数据库多了一个人，其他都是一样的），如果存在一个算法 M，（记M(x) 为在数据库中的查询结果，例如，如果是一个平均数算法，那得到的就是数据库的平均数），对于任意包含于 M 值域的集合 S 和 ϵ>0，都有：</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/08/12/c39b016fb3d84b425f18e740a141756a.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/c39b016fb3d84b425f18e740a141756a.png" referrerpolicy="no-referrer"></figure><p>那么我们称 M 算法满足 <strong>ϵ-差分隐私</strong>。</p><p>这个定义具体说了什么呢？我们可以通过变形上面的式子得到一些启示：</p><p>首先，从定义中知道，当 M 算法满足 ϵ-差分隐私时，只要两个数据库相差一个数据，上面的式子就会成立，所以我们可以把 x 和 y 调换一下顺序（因为「x 和 y相差一个数据」和「y 和 x 相差一个数据」是同一件事情），进行一些简单的变换：</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/08/12/e3b519ae159a692964fb36abee59c018.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/e3b519ae159a692964fb36abee59c018.png" referrerpolicy="no-referrer"></figure><p>显然，ϵ 越接近0，两个数据库的查询结果相同的概率会越接近于1，也就是说，攻击者几乎无法辨别相差一个数据的两个数据库的查询结果，也就是说差分攻击很难起作用。</p><h3>随机化回答（Randomized Response）</h3><p>通常而言，差分隐私通过添加随机性的方法，保护个人隐私。接下来，我们举一个最简单的差分隐私的例子：</p><p>有时候调查问卷收集者需要收集一些敏感信息：如违法犯罪行为，或者一些世俗道德意义上的「坏」行为。为了获得较为准确的回答，并避免泄露个人隐私或者承担任何包庇犯罪的法律风险，往往会让问卷填写者采用随机化的方式作答一些判断题（即回答「Yes/No」）：</p><ol><li>首先，问卷填写者自己扔一个硬币（正反的概率相等），结果只有他自己知道</li><li>如果是反面，就诚实回答问题</li><li>如果是正面，就再扔一次（也只有他自己知道）</li><li>如果是正面，就回答「Yes」；如果是反面，则回答「No」</li></ol><p>如果画一个图的话，会是这种情况，对一个真实答案为「Yes」的人：</p><figure class="image ss-img-wrapper image_resized" style="width:341px;"><img src="https://cdn.sspai.com/2021/08/12/490c1e2934d5cac6b5e1fc642a30c020.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/490c1e2934d5cac6b5e1fc642a30c020.png" referrerpolicy="no-referrer"></figure><p>对一个真实答案为「No」的人：</p><figure class="image ss-img-wrapper image_resized" style="width:349px;"><img src="https://cdn.sspai.com/2021/08/12/fd37cb268546c8ca75336db45a011df0.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/fd37cb268546c8ca75336db45a011df0.png" referrerpolicy="no-referrer"></figure><p>通过一些简单的概率计算，可以知道，无论哪种类型，都有 3/4 的概率说真话。假设真实类型为「Yes」的有 x 人，真实类型为「No」的有 y 人，从平均的角度来看，在问卷数量足够大的情况下，根据大数定律，我们可以近似得到如下方程：</p><figure class="image ss-img-wrapper image_resized" style="width:421px;"><img src="https://cdn.sspai.com/2021/08/12/32f3df985ce5ab5c38c762bc20498b73.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/12/32f3df985ce5ab5c38c762bc20498b73.png" referrerpolicy="no-referrer"></figure><p>这是一个非常简单的小学数学问题，很大概率能够准确求出两种类型的人分别有多少。同时，这种方法无法泄露个人隐私，因为完全无法确定每个人的真实类别（硬币结果只有填问卷的人自己知道）。可以证明的是，上述方法满足差分隐私的定义。</p><h2>部分厂商的差分隐私应用</h2><h3>苹果的差分隐私</h3><p>苹果在其<a href="https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf">官方文档</a>中提供了其差分隐私的部分使用场景：QuickType 提示、Emoji 提示、搜索提示、Safari 电量统计和健康统计。</p><p>苹果的数据在上传之前会在本地先通过 hash 算法处理成定长的一串字符，然后加上随机扰动项。也就是说，苹果永远不会接收没有经过混淆的数据，这样就极大程度保证了用户的个人隐私。这些隐私的扰动项通常是独立同分布的，这样就保证了在大样本条件下能够与均值相差无几，使得利用这些数据来进行用户体验的改进成为了可能。</p><p>例如，在 <strong>Emoji 提示场景</strong>，苹果可以先在本地统计个人使用各种 Emoji 的次数，然后加上均值为 0 的随机数，上传到服务器中。服务器将所有人的数据进行求和，计算每种 Emoji 出现次数所占的百分比。此时，随机数的影响会被抵消。苹果能够依次统计出最受欢迎的 Emoji，同时又无法确定个人到底最喜欢哪个 Emoji（因为添加了随机数）。</p><figure class="image ss-img-wrapper"><img src="https://cdn.sspai.com/2021/08/13/dcaadaaf87182a47370c3f3e6a96d8e2.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1" data-original="https://cdn.sspai.com/2021/08/13/dcaadaaf87182a47370c3f3e6a96d8e2.png" referrerpolicy="no-referrer"><figcaption>图片来源：Apple</figcaption></figure><p>此外，设备 ID 信息在上传的时候会被剔除，苹果在分析数据的时候会进一步删除诸如 IP 地址之类的信息。同时，用户隐私的上传在不同场景都有不同的次数限制。例如，对于「搜索提示」用途，用户一天最多上传两次；对于「健康统计」，一天只允许上传一次。而且，信息在苹果处只会保留三个月。这样，苹果从多个角度保证了用户的隐私。（不过也有<a href="https://arxiv.org/pdf/1709.02753.pdf">论文</a>指出 Apple 的差分隐私由于 ϵ 值过大导致隐私保护效果欠佳。）</p><h3>小米和魅族的差分隐私</h3><p>小米和魅族的差分隐私主要存在于定位场景。对于一些对定位精准度要求不高的使用场景（比如区域天气查询），用户可以选择提供模糊定位。模糊定位，顾名思义，就是手机会在上传定位信息之前，加上一些随机数，使得上传的数据与真实数据不同，但又在某一范围之内。如同Flyme 9 宣传片中展示的一样，模糊定位将个人准确定位点扩大到了一个圆的范围，这样就避免的个人位置信息的泄露。同时，软件厂商依旧可以利用这类模糊定位数据，统计出在某一范围的人大概有多少。</p><figure class="image ss-img-wrapper image_resized" style="width:648px;"><img src="https://cdn.sspai.com/2021/08/14/251f83fdcbda68a8b07967a6a6edb5c4.gif" data-original="https://cdn.sspai.com/2021/08/14/251f83fdcbda68a8b07967a6a6edb5c4.gif" referrerpolicy="no-referrer"><figcaption>Flyme 9 宣传片（来源：魅族）</figcaption></figure><h2>小结</h2><p>本文，或许有点干，但希望可以为你理解差分隐私提供一些帮助。如果提炼几个关键的事实，我认为是：</p><ul><li>数据的<strong>可用性</strong>及其<strong>隐私保护程度</strong>是一对矛盾</li><li>差分隐私能够在不泄露个人数据的情况下，对集体数据进行。较为准确的学习。</li><li>差分隐私的「差分」指的是对于两个只相差一个数据的数据库，能够保证查询结果差不多；也就是说，无法通过两个相似的查询来倒推出某人的信息。</li><li>差分隐私具有局限性，不适用于需要准确个人数据的场景（如导航）。</li></ul><h2>参考文献</h2><ol><li>《<a href="https://book.douban.com/subject/26419477/">The Algorithmic Foundations of Differential Privacy</a>》</li><li>《<a href="https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf">Robust De-anonymization of Large Sparse Datasets</a>》</li><li>《<a href="https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf">Differential Privacy Overview</a>》</li><li>《<a href="https://arxiv.org/pdf/1709.02753.pdf">Privacy Loss in Apple's Implementation of Differential Privacy on MacOS 10.12</a>》</li><li><a href="https://www.bilibili.com/video/BV1k54y1x7Ua?from=search&seid=10246404923049454811">Gautam Kamath 教授的网课</a></li></ol></div><!----></div><div style="border:1px solid transparent;" data-v-3e67f99b></div><div class="article-side sideTop" style="display:none;left:0;" data-v-7be936cf data-v-3e67f99b><div class="download-guide-container" data-v-14f9065e data-v-7be936cf><div class="btn-wrapper" data-v-14f9065e><!----><button class="btn btn-view" data-v-14f9065e><i class="iconfont iconfont-phone" data-v-14f9065e></i></button></div><a href="https://sspai.com/s/JYjP" target="_blank" data-v-14f9065e><!----></a></div><div class="item-wrapper" data-v-7be936cf><button class="btn btn-charge" data-v-7be936cf><i class="iconfont" data-v-7be936cf></i></button><span class="count" data-v-7be936cf>21</span></div><div class="item-wrapper" data-v-7be936cf><button class="btn-mini btn-comment" data-v-7be936cf><i class="iconfont iconfont-comment" data-v-7be936cf></i></button><span class="count" data-v-7be936cf>3</span></div><div class="item-wrapper" data-v-7be936cf><span data-v-7be936cf><div role="tooltip" id="el-popover-9884" aria-hidden="true" class="el-popover el-popper popper-share right ss-popper-dark-border" style="width:undefinedpx;display:none;"><!----><div class="article-side-share-btn"><a href="https://service.weibo.com/share/share.php?url=null?ref=weibo&title=%E3%80%90%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8A%A4%E4%B8%AA%E4%BA%BA%E9%9A%90%E7%A7%81%E7%9A%84%EF%BC%9F%E3%80%91%E9%9A%90%E7%A7%81%EF%BC%8C%E6%98%AF%E4%BA%92%E8%81%94%E7%BD%91%E6%97%B6%E4%BB%A3%E6%97%A0%E6%B3%95%E7%BB%95%E5%BC%80%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AF%9D%E9%A2%98%E3%80%82%E5%9C%A8%E9%9A%90%E7%A7%81%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AF%9D%E9%A2%98%E4%B8%AD%EF%BC%8C%E6%9B%BE%E7%BB%8F%E5%87%BA%E7%8E%B0%E8%BF%87%E6%9D%8E%E5%BD%A6%E5%AE%8F%E5%85%B3%E4%BA%8E%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%84%BF%E6%84%8F%E7%94%A8%E9%9A%90%E7%A7%81%E6%8D%A2%E5%8F%96%E4%BE%BF%E5%88%A9%E7%9A%84%E8%A8%80%E8%AE%BA%EF%BC%8C%E4%B9%9F%E6%B5%81%E4%BC%A0%E7%9D%80%E8%8B%B9%E6%9E%9C%E4%B8%BA%E4%BA%86%E4%BF%9D%E6%8A%A4%E7%94%A8%E6%88%B7%E9%9A%90%E7%A7%81%E8%80%8C%EF%BC%88%E6%9D%A5%E8%87%AA%20%40%E5%B0%91%E6%95%B0%E6%B4%BEsspai%EF%BC%89%E5%85%A8%E6%96%87%EF%BC%9A&pic=https%3A%2F%2Fcdn.sspai.com%2F2021%2F08%2F12%2F0823ef960fac455337051a5bc5770a14.jpg%3FimageMogr2%2Fauto-orient%2Fquality%2F95%2Fthumbnail%2F!1420x708r%2Fgravity%2FCenter%2Fcrop%2F1420x708%2Finterlace%2F1&appkey=3196502474#" target="_blank"><i class="icon icon-article_weibo right-16"></i></a><span><div role="tooltip" id="el-popover-823" aria-hidden="true" class="el-popover el-popper" style="width:undefinedpx;display:none;"><!----><div style="text-align:center;"><div id="qr-code"></div><small class="qr-small">扫码分享</small></div></div><span class="el-popover__reference-wrapper"><i class="icon icon-article_weixin right-16"></i></span></span><a href="https://twitter.com/share?text=%E3%80%90%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8A%A4%E4%B8%AA%E4%BA%BA%E9%9A%90%E7%A7%81%E7%9A%84%EF%BC%9F%E3%80%91%E9%9A%90%E7%A7%81%EF%BC%8C%E6%98%AF%E4%BA%92%E8%81%94%E7%BD%91%E6%97%B6%E4%BB%A3%E6%97%A0%E6%B3%95%E7%BB%95%E5%BC%80%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AF%9D%E9%A2%98%E3%80%82%E5%9C%A8%E9%9A%90%E7%A7%81%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AF%9D%E9%A2%98%E4%B8%AD%EF%BC%8C%E6%9B%BE%E7%BB%8F%E5%87%BA%E7%8E%B0%E8%BF%87%E6%9D%8E%E5%BD%A6%E5%AE%8F%E5%85%B3%E4%BA%8E%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%84%BF%E6%84%8F%E7%94%A8%E9%9A%90%E7%A7%81%E6%8D%A2%E5%8F%96%E4%BE%BF%E5%88%A9%E7%9A%84%E8%A8%80%E8%AE%BA%EF%BC%8C%E4%B9%9F%E6%B5%81%E4%BC%A0%E7%9D%80%E8%8B%B9%E6%9E%9C%E4%B8%BA%E4%BA%86%E4%BF%9D%E6%8A%A4%E7%94%A8%E6%88%B7%E9%9A%90%E7%A7%81%E8%80%8C%EF%BC%88%E6%9D%A5%E8%87%AA%20%40%E5%B0%91%E6%95%B0%E6%B4%BEsspai%EF%BC%89%E5%85%A8%E6%96%87%EF%BC%9A&url=null" target="_blank" class="twitter"><i class="icon icon-article_twitter right-16"></i></a></div></div><span class="el-popover__reference-wrapper"><button class="btn-mini btn-share" data-v-7be936cf><i class="iconfont iconfont-share" data-v-7be936cf></i></button></span></span></div><div class="item-wrapper" data-v-7be936cf><button class="btn-mini btn-collect" data-v-7be936cf><i class="iconfont iconfont-collect" data-v-7be936cf></i></button></div><!----></div><!---->  
</div>
            