
---
title: 'DeepMind评估AI多模态图像语言转换器在看图理解中对动词的识别力'
categories: 
 - 新媒体
 - MIT 科技评论
 - 首页
headimg: 'https://p26.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/641498ae1dd14142b83b8915b967fd73~tplv-tt-shrink:640:0.image'
author: MIT 科技评论
comments: false
date: Sat, 26 Feb 2022 09:31:00 GMT
thumbnail: 'https://p26.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/641498ae1dd14142b83b8915b967fd73~tplv-tt-shrink:640:0.image'
---

<div>   
<div style="margin-bottom: 18px; border: 0px; color: rgb(34, 34, 34); font-family: "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", "Helvetica Neue", Arial, sans-serif; font-size: 18px; text-align: justify;"><img src="https://p26.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/641498ae1dd14142b83b8915b967fd73~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 20px; border: 0px; margin-bottom: 0px !important;"></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">对于 AI 系统来说，将语言与视觉联系起来是它需要面对并学会解决的基本问题，例如在进行图像的检索时，AI 系统需要既能识别图像，也能识别语言，并将二者相关联起来。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">对于这类需要 AI 系统识别不同种类或形式的信息来源的任务中，就需要多模态机器学习（MML/Multimodal Machine Learning）来发挥作用。 所谓模态，指的是一种信息的来源或形式，例如文字、图像、视频、音频等都是模态。多模态机器学习是指利用机器学习来处理多种模态的信息。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">近些年来，在多模态机器学习领域中，多模态图像语言转换器（Multimodal image–language transformers）已经取得了深刻进展，尤其在解决各种需要微调的任务，如视觉问答、图像检索中发挥了关键性作用。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">但是，在既需要处理图像又需要处理语言文本的多模态机器学习任务中，有一类问题对于多模态图像语言转换器来说尤其棘手，那就是对文本中的动词的理解。例如要求 AI 系统来在图像中区分识别找出“踢球”和“抛球”这两种情景。在这一任务中，AI 系统不仅需要识别出图像中的“球”这一对象，还需要识别图像中不同对象之间的关系。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">为了评估近年来多模态图像语言转换器的预训练水平，尤其是在“看图理解”中对于上文所说的动词的识别能力。近日，DeepMind 开发出一套方法，并引入了名为 SVO-Probes 的“图像－句子对” 数据集，来评估不同 AI 系统的多模态预训练模型对于动词的理解水平，尤其是了解这些 AI 系统多模态转换器的预训练模型在结合语言文本来识别图像时，到底是既能够识别中图片中的物体、也能区分中图像中的动作，还是只能够识别出图中的物体。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">为了达到这一目的，DeepMind 建立的 SVO-Probes 数据集包含了 48000 个图像-句子对，可以测试 AI 系统对 447 个动词的理解，这些动词要么是视觉可以区分的，要么是在预训练数据中常见的，例如许多概念字幕数据集。这个数据集中的每个句子都可以分解成 一个 <主语、动词、宾语> 三元组，也就是 SVO 三元组，并分别配对有与句子描述的内容相符和不符的图像，它们在是实验中分别被称为“正实例图像” 和 “负实例图像”。</span></span></p><div style="margin-bottom: 18px; border: 0px;"><img src="https://p9.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/57be6a442379437b89564f3867225c79~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">图｜评估多模态语言图像转换器对于动词的识别能力的 SVO- Probes 数据集中的图像-句子对（来源：DeepMind）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">上图显示了图像-句子对的几个例子，以左上角的图像-句子对为例，分别显示了与句子“孩子、过、马路”相符的正示例图像，以及与“女士、过、马路”不符的负示例图像，通过这一对可以测试 AI 系统识别图中的对象——也就是名词的能力；而上方中间的图像-句子对，则分别显示了”人、唱歌、演唱会上“ 的正示例图像和”“人、跳舞、演唱会上“ 的负示例图像。通过这一对就可以既测试 AI 系统识别图中的名词的能力，也能测试 AI 识别动词的能力。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">在实验中使用这一 SVO-Probes 数据集以零样本的方式对 AI 预训练模型进行评估之后，DeepMind 的工程师发现，相比名词等其他词性，预训练模型在需要动词理解的情况下错误率要高很多。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">下面的条形图详细说明了测试的结果。标准多模态转换器模型经过测试后总体准确率达到 64.3%，这也显示了 SVO- Probes 数据集确实具有挑战性。而这一 AI 模型在对于主语和宾语判断的准确率分别为 67.0% 和 73.4%，但是对于动词判断的准确率却下降到 60.8%。这一结果表明，动词识别确实对 AI 系统模型具有挑战性。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">此外，该公司的工程师们还进一步总结调查了哪些类别的动词对于这些 AI 预训练模型尤其具有挑战性。结果发现，像“抓”这样的运动性动词以及“带领”这样在不同类型的语境中经常出现的动词对于 AI 来说更容易。而 AI 模型判断的正确率最高的动词有“打斗”“包围”“滑雪”“参加”等；而错误率最高的几个动词有“切”“争论”“断”等。</span></span></p><div style="margin-bottom: 18px; border: 0px;"><img src="https://p26.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/c807550297c04d6e9328f13c655fdd1b~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">图｜多模态机器学习的图像语言转换器对于 SVO-Probes 数据集进行判断测试之后的结果（来源：DeepMind）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">值得一提的是，当工程师们对哪些模型架构在 SVO-Probes 数据集上的表现更好这一问题进行探索时，他们惊讶地发现，相比图像建模能力更强的标准图像语言转换器模型，那些图像建模较弱的模型反而表现更好。对这一与直觉相反的发现的解释的一个假设是，标准转换器模型在图像识别方面可能有些“过度训练”了。</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; text-align: left; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">-End-</span></span></p><p style="margin-top: 18px; margin-bottom: 18px; border: 0px; height: 0px; font-size: 18px;"><br></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">参考：</span></span></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; text-align: left; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">https://deepmind.com/research/publications/2021/Probing-Image-Language-Transformers-for-Verb-Understanding</span></span></p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; text-align: left; font-size: 18px;"><span style="border: 0px; letter-spacing: 1px;"><span style="border: 0px; color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">https://aclanthology.org/2021.findings-acl.318.pdf</span></span></p><div style="margin-bottom: 18px; border: 0px;"><img src="https://p26.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/952770e5f8a54195b20e3278c72b0e7f~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 20px; border: 0px; margin-bottom: 0px !important;"></p><div style="margin-top: 18px; margin-bottom: 18px; border: 0px;"><img src="https://p26.toutiaoimg.com/img/tos-cn-i-qvj2lq49k0/d005fe7001aa4516ad51b901ec550946~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"></div></div></div></div></div>  
</div>
            