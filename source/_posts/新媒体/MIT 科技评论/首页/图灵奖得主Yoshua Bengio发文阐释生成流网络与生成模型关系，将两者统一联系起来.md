
---
title: '图灵奖得主Yoshua Bengio发文阐释生成流网络与生成模型关系，将两者统一联系起来'
categories: 
 - 新媒体
 - MIT 科技评论
 - 首页
headimg: 'https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/5c7dc9229a3e442094112e24b9dbd253'
author: MIT 科技评论
comments: false
date: Sun, 11 Sep 2022 14:15:07 GMT
thumbnail: 'https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/5c7dc9229a3e442094112e24b9dbd253'
---

<div>   
<div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><img src="https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/5c7dc9229a3e442094112e24b9dbd253" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">近日，全球公认的 AI 领域顶尖专家之一、图灵奖得主约书亚·本吉奥（Yoshua Bengio）对生成流网络（GFlowNet，Generative Flow Network）与深度生成模型之间的联系做了介绍。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>GFlowNet 是本吉奥提出的一种新的网络生成方法，涉及“强化学习、深度生成模型和基于能量的概率建模”，其也与变分模型和推理有一定联系。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>本吉奥在其个人网站曾提到，他很少对新的研究方向如此热衷，其中之一就是 GFlowNet。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><div><img src="https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/fe6454a874c4414882834f37a3525b92" referrerpolicy="no-referrer"></div><div>图 | 约书亚·本吉奥（Yoshua Bengio）（来源：本吉奥个人网站）</div><div><br><a href="http://www.sciphi.cn/article/view/undefined"></a><p style="text-align: center;"></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">本次的研究论文于 9 月 6 日，以《将生成模型与 GFlowNet 统一起来》（Unifying Generative Models with GFlowNets）为题提交在 </span></span><em><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">arXiv </span></span></em><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">上。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>首先对本吉奥做一简单介绍。他是加拿大蒙特利尔大学计算机与运筹学系教授，也是米拉-魁北克人工智能研究所的创始人和科学主任。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">他被认为是 1990 年代和 2000 年代对推动深度学习发展最大的几人之一，并于 2022 年成为世界上 H 指数（H-index）最高的计算机科学家。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>而在 2018 年，由于在深度学习方面的开创性工作和重要贡献，本吉奥与加拿大多伦多大学计算机科学系教授杰弗里·辛顿（Geoffrey Hinton）、Meta 副总裁兼首席AI科学家杨立昆（Yann LeCun）一起获得了国际计算机学会颁发的图灵奖（通常被称为“诺贝尔计算奖”）。他们三人有时也被称为“人工智能教父”和“深度学习教父”。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>据了解，本吉奥于 1991 年获加拿大麦吉尔大学计算机科学博士学位，之后在麻省理工学院和 AT&T 贝尔实验室担任博士后研究员。自 1993 年加入蒙特利尔大学至今。著有《深度学习（自适应计算和机器学习）》（Deep Learning（Adaptive Computation and Machine Learning））、《迈向生物学上合理的深度学习》（Towards Biologically Plausible Deep Learning）等图书和论文作品。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>2021 年，本吉奥以一作的身份发表了有关 GFlowNet 的重要论文《GFlowNet Foundations》（GFlowNet 基础）。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>目前，GFlowNet 已被引入到主动学习环境中，以对各种候选集合进行采样。它还为非参数贝叶斯建模和抽象表示的监督学习等方面提供了新视野。“其训练是为了使它们与给定的奖励函数成比例地进行近似采样。”论文中提到。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>除了解开解释性因果因素和与之相关的机制，GFlowNet 尤其对实施系统归纳偏差方面有帮助。GFlowNet 还是一个新的有难度的研究领域，为了理解和应用它，适当的优化算法仍在快速发展。其概念正逐步得到扩展。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>而在本次研究中，论文里提到：“深度生成建模有许多框架，每个框架都有自身特定的训练算法和推理方法。我们通过马尔可夫轨迹学习的视角，对深度生成模型和 GFlowNet 框架之间的联系给出一个统一的观点。这为统一训练和推理算法提供了一种方法，并为构建生成模型聚合提供了一种路径。”</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>从概率建模的角度来看，GFlowNet 是一种生成模型，其目的是根据给定的奖励函数 R(x) 的比例对 x 进行抽样。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>具体地说，一个 GFlowNet 将对一个长度为 n 的马尔可夫轨迹 τ=（S0，S1，……，Sn）进行采样。如果没有特别指定，将使用符号 X=Sn 来表示轨迹的最终状态。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>这个过程与强化学习有一种自然的联系，所有的状态 s 都在潜在状态空间中构造了一个有向非循环图。每个轨迹从相同的（抽象的）初始状态 S0 开始，并运行到一个不同的端点 Sn。理想情况下，希望通向x的流量等于给定的奖励。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>在论文中的“从数据中学习奖励函数”部分，研究团队提到：“基于能量的模型（EBM，Energy-based model）可以作为 GFlowNet 训练的（负对数）奖励函数。我们可以使用任何 GFlowNet 建模，且两种模型（EBM 和 GFlowNet）共同训练。”</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>此外，生成对抗网络（GAN，Generative Adversarial Network）与 EBM 密切相关，但其算法的计算效率更高。然而，虽然初看它可能是合理的，但不能直接使用鉴别器 D(x) 作为 GFlowNet 训练的奖励。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>如果是这样，在一个完美的训练结束时，将得到一个最优的鉴别器和最优的 GFlowNet 发生器分布。为了填补这一空白，本吉奥设计了一些更有意义的算法。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><div><img src="https://p6.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/3d352308837b40e1bedf47cc547e0cd4" referrerpolicy="no-referrer"></div><div>（来源：本吉奥个人网站）</div><div><br><a href="http://www.sciphi.cn/article/view/undefined"></a><p style="text-align: center;"></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">上图说明了为什么在 GFlowNet 中使用“流”这个词。这考虑了非规范化概率的流动，类似于有向非循环图（可能是指数级的，不需要在计算机中明确表示它）中从初始状态（左侧为 0）流出的水量，其轨迹对应于所有可能的动作序列（即决定状态转换的动作），以便按顺序构建复杂的对象，如分子图、因果图、对场景的解释或者我们脑海中的想法。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>论文最后的结论提到：“如今的生成模型可被理解成在样本轨迹上有着差异化策略的 GFlowNet。这为现有生成建模框架之间的重合部分，以及与训练它们的通用算法的关系，提供了一些观点。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">这种统一意味着一种构建不同类型集群的生成建模的方法，而由于推理和训练方面的优越性，GFlowNet 可作为其中的通用粘合剂。”</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><div><img src="https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/2405eb59620449c99bbe6c4e4b0f72cb" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="letter-spacing: 1px;"><strong><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;"><br></span></strong></span></p><p><span style="letter-spacing: 1px;"><strong><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;">参考资料：</span></strong><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;"><br>https://arxiv.org/abs/2209.02606<br>https://yoshuabengio.org/2022/03/05/generative-flow-networks/<br>https://en.wikipedia.org/wiki/Yoshua_Bengio</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;"><br></span></span></p><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/722dffe423fa4ea2a283e3e45a244ab1" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a></div></div></div></div></div>  
</div>
            