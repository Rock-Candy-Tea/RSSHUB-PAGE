
---
title: 'DeepMind开发_民主AI_制定最受欢迎经济政策，能在网络游戏中更好地分配投资收益'
categories: 
 - 新媒体
 - MIT 科技评论
 - 首页
headimg: 'https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/1fbe43752f1d49c1a32ffc5b4d485984'
author: MIT 科技评论
comments: false
date: Sun, 10 Jul 2022 15:50:42 GMT
thumbnail: 'https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/1fbe43752f1d49c1a32ffc5b4d485984'
---

<div>   
<div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/1fbe43752f1d49c1a32ffc5b4d485984" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">AI 能否适配人类的价值观，仍是科学家需要面对的一项难题。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>人类面临的不仅有诸多技术问题，还有许多问题需要我们在社会和经济中进行协调处理，从而实现更大的效益。如何在社会中重新分配资源一直是经济学家、政治学家等长期关注的问题。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>要想让 AI 能够在资源分配领域提供助力，AI 需要直接了解人类的价值观念。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>近日，DeepMind 开发了一个“民主 AI”，并使用强化学习（Reinforcement Learning，RL）方法来让该 AI 设计一种大多数人都喜欢的社会机制。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>在一个有关保留金钱还是与他人分享以获取集体利益的在线投资游戏里，通过设计不同的收入分配方法（其中一种由 AI 设计，其他由人类设计）让玩家选择，最终 AI 设计的机制赢得多数选票，并可以避免财富失衡、“搭便车者”（不出力但从中获利的人）等问题。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>7 月 4 日，相关论文以《采用“民主 AI”进行以人为中心的机制设计》（Human-centred mechanism design with Democratic AI）为题发表在 </span></span><em><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">Nature Human Behavior </span></span></em><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">上，</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>该论文提供了一个概念验证证明，通过针对人类偏好进行优化，深度 RL 可以在简单游戏中设计以多数票支持的经济政策。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>当一群人决定汇集资金进行投资，获利后的收益应如何分配？若简单地按平均原则分配收益，很可能有失公平，因为每个人的具体贡献多少并不相同。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><div><img src="https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/3b01fd8c6b734770807064218d840717" referrerpolicy="no-referrer">▲图 | 游戏和实验的说明（来源：Nature Human Behavior）<a href="http://www.sciphi.cn/article/view/undefined"></a><p style="text-align: center;"></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">为了训练“民主 AI”，DeepMind 记录了来自大量人类群体（4000 多人）的数据，以让 AI 复制人们玩游戏的方式进行训练，同时让其在在线四人经济游戏中进行模拟学习。这种模拟的群体可以生成无限的数据，从而能够使用数据密集型机器学习方法来训练RL智能体。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>然后，招募真实人类参与者，并将“民主 AI”设计的机制与通常的基线（自由意志主义政策）进行对比。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>最终，在玩家的投票中，发现 AI 设计的政策要更受欢迎。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/e2b21fd8cc814cf9a65b62664e0558c6" referrerpolicy="no-referrer">▲图 | 整体投票比例（来源：Nature Human Behavior）<a href="http://www.sciphi.cn/article/view/undefined"></a><p style="text-align: center;"></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">该方法的一个优点是，AI 直接学习最大化一群人的偏好（或投票），这可能有助于确保 AI 系统不会学习不安全或不公平的政策。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>“民主 AI”在选择将资金重新分配给人们时，会考虑每个人的初始手段和他们的贡献意愿，它会更偏向那些相对贡献更大的玩家。值得一提的是，该 AI 只是通过学习最大化人类选票来提出这些政策。因此，该方法能产出与人类兼容的解决方案。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>事实上，当分析“民主 AI”的政策时，发现它融合了人类思想家和专家以前提出的解决再分配问题的想法，反映出了来自各个政治派别的混合观点。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>据了解，AI 系统有时因学习可能与人类价值观不相容的政策而受到批评，而这种“价值一致性”的问题已成为 AI 研究中的主要问题。为了价值的一致性，可以利用与更广泛的人类社会相同的民主工具来达成共识，这些工具用于选举代表，决定公共政策或做出法律判断。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>在该研究中，通过要求人们投票，利用多数民主的原则来决定人们想要什么。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p style="text-align: center;"></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">但是，DeepMind 在论文中也提到，需要更多的研究来了解，如何通过设计来权衡多数和少数群体的相对偏好，以考虑到所有人的意愿。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">研究人员也对 AI 驱动的“多数人的暴政”表示担忧，在这种情况下，少数群体的需求被忽视了。并表示，该工作并不代表“AI 政府”的解决方案，也不会打造专业的政策制定 AI 工具。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>这或许是由于与人类提出的一些建议相比，AI 提案并不一定是独一无二的。另外，使用 AI 的部署方式可能会加剧社会中现有的偏见、歧视或不公平。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>如今，AI 越来越擅长解决从商业到生物医学等各个方面的复杂挑战，故尔使用它进一步来帮助设计社会问题的解决方案是一个有吸引力的想法。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>本次 DeepMind 开发的新方法，将 AI 与人类民主审议相结合，或能为社会困境提供更好的解决方案。但“民主 AI”只是设计一些更好政策的潜在方法，并不是在公共领域部署 AI 的“良药”。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br>目前来说，我们距离能帮助制定公共政策的机器还有很长一段路要走，但 AI 有一天可能会帮助人类找到超越既定意识形态的新解决方案。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></span></p><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/d08a668f03614214a1849c6b3e7f7bb4" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="letter-spacing: 1px;"><strong><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;"><br></span></strong></span></p><p><span style="letter-spacing: 1px;"><strong><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;">参考资料：</span></strong></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;">https://www.deepmind.com/publications/human-centred-mechanism-design-with-democratic-ai</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;">https://www.newscientist.com/article/2327107-deepminds-ai-develops-popular-policy-for-distributing-public-money/<br>https://www.analyticsinsight.net/deepminds-democratic-ai-distributes-public-money-might-make-an-ai-govt/</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(178, 178, 178); --tt-darkmode-color: #A3A3A3;"><br></span></span></p><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/10cadd7ad12546899382d9b3cc83d886" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><div><br></div><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/e93aaa4f66014080827044a98ac5ada1" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><div><br></div><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/7c263b20570c4ddaaef2b5bb1a557244" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a></div></div></div></div></div></div></div>  
</div>
            