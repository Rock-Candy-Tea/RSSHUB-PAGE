
---
title: 'NVIDIA扩大AI推理性能领先优势，在x86和Arm服务器上皆取得佳绩'
categories: 
 - 新媒体
 - MIT 科技评论
 - 首页
headimg: 'https://p5.toutiaoimg.com/img/pgc-image/e969ff2979e343599c511178ea7560ab~tplv-tt-shrink:640:0.image'
author: MIT 科技评论
comments: false
date: Sun, 26 Sep 2021 06:58:24 GMT
thumbnail: 'https://p5.toutiaoimg.com/img/pgc-image/e969ff2979e343599c511178ea7560ab~tplv-tt-shrink:640:0.image'
---

<div>   
<p style="margin-bottom: 20px; border: 0px; color: rgb(34, 34, 34); font-family: "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", "Helvetica Neue", Arial, sans-serif; font-size: 18px; text-align: justify; margin-top: 0px !important;">最新一轮的 MLPerf 推论基准（ V 1.1 ）于北京时间 9 月 23 日公布，NVIDIA 在本轮测试中再次占据主导地位，取得了较好成绩。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; color: rgb(34, 34, 34); font-family: "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", "Helvetica Neue", Arial, sans-serif; font-size: 18px; text-align: justify;">自 2018 年年初以来，NVIDIA 一直主导着 MLPerf 基准（训练和推理），连续三次在推理测试中创造性能和能效纪录。</p><div style="margin-top: 18px; margin-bottom: 18px; border: 0px; color: rgb(34, 34, 34); font-family: "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "WenQuanYi Micro Hei", "Helvetica Neue", Arial, sans-serif; font-size: 18px; text-align: justify;"><img src="https://p5.toutiaoimg.com/img/pgc-image/e969ff2979e343599c511178ea7560ab~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">（来源：NVIDIA 官网）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">据了解，MLPerf 是国际最具影响力的 AI 性能基准评测，在 2018 年由 AI 行业的领导者所创办，现由 2020 年 12 月成立的非盈利性机器学习开放组织 MLCommons 联盟管理。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">“MLCommons 有一个明确的使命——加速机器学习创新。我们很高兴能在 MLPerf 的基础上继续发展，并通过全球的合作伙伴，扩大其范围和影响。”MLCommons 联盟主席彼得•马特森（ Peter Mattson ）说道。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">MLCommons 的创始成员包括：</p><div style="margin-top: 18px; margin-bottom: 18px; border: 0px;"><img src="https://p9.toutiaoimg.com/img/pgc-image/c73b279a897048afafa119e616670de3~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">（来源：MLCommons 官网）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">其他成员目前还有：</p><div style="margin-top: 18px; margin-bottom: 18px; border: 0px;"><img src="https://p5.toutiaoimg.com/img/pgc-image/a006a02280d646548a3f6e2316a50307~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">（ 来源：MLCommons 官网 ）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">为了始终站在行业前沿，MLCommons 会定期进行测试并添加能够代表当前 AI 领域水平的新工作负载。MLPerf 推论是一个完整的系统基准，测试机器学习模型、软件和硬件，提供了公平的竞争环境，推动整个行业的创新。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">与之前的 MLPerf 推理类似，本次测试提交内容包括两个部分：封闭式和开放式。封闭式提交使用相同的参考模型，以确保跨系统公平竞争；而开放式的参与者则被允许提交各种模型。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">推理是指计算机通过 AI 软件使用深度学习模型来对对象进行识别或预测，从而发现人类所无法捕捉的结果。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">根据 MLCommons 发布的结果，NVIDIA AI 平台驱动的系统在全部7项推理性能测试中都位居前列。NVIDIA 是唯一取得所有 MLPerf 测试结果的公司。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">“NVIDIA 在 MLPerf 测试中运行数据中心和边缘的每个工作负载、每个场景、每个用例。我们是唯一这样做的公司。”NVIDIA 高级产品经理大卫·萨尔瓦托（ David Salvator ）说。</p><div style="margin-top: 18px; margin-bottom: 18px; border: 0px;"><img src="https://p6.toutiaoimg.com/img/pgc-image/abe067b05ae549e89e1e6f826bbdb653~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">（来源：NVIDIA 官网）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">值得注意的是，这是 Arm 服务器首次参与的测试。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">Arm 架构正凭借不断增长的能效性能和软件生态系统占据着世界各地越来越多的数据中心。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">在本次的一项测试中，Arm 服务器的性能超过了类似配置的 x86 服务器，同时其他测试两者提供的性能也几乎相同。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">“最新推理结果表明，Arm CPU 和 NVIDIA GPU 驱动的 Arm 系统已经能够应对各种 AI 工作负载。”Arm 高性能计算和工具高级总监大卫·莱孔伯（ David Lecomber ）说道。</p><div style="margin-top: 18px; margin-bottom: 18px; border: 0px;"><img src="https://p26.toutiaoimg.com/img/pgc-image/f8f96ed98993490eb79bbc33420a14e7~tplv-tt-shrink:640:0.image" style="margin-right: auto; margin-bottom: 8px; margin-left: auto; max-width: 100%; display: block; border-radius: 4px; height: auto;" referrerpolicy="no-referrer"><p style="margin-top: 0px; margin-bottom: 0px; border: 0px; position: relative; text-align: center; font-size: 14px; line-height: 20px; color: rgb(153, 153, 153);">（来源：NVIDIA 官网）</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">本次测试，7 家 OEM 厂商提交了 22 个 GPU 加速的平台，大多数都是 NVIDIA 认证系统。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">与上一次的 MLPerf 推理基准测试相比，NVIDIA 提升了高达 20% 的性能和 15% 的能效。据了解，NVIDIA 能够取得如此成绩的一个关键是其完整的软件栈。该软件栈仍旧处在不断改进中。NVIDIA 会将这些代码加入到自己的深度学习框架中。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">MLPerf 给软硬工程师设计不同场景的 AI 平台搭建了一个良性生态。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">在采购设备时我们需要有一个衡量性能的基准，否则，就难以对产品的价格有一个合理的判断。这个道理也可用于运行 AI 应用程序的服务器系统。这就是 MLPerf 基准测试存在的意义。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">本轮测试中大多数系统在短短 5 个月内改进了 5%~30%，有一些提交的内容甚至改进了两倍以上，这表明软件优化的价值将对 AI 工作负载产生了实际影响。在 AI 计算平台的选择方面，MLPerf 基准测试给用户提供了重要指导。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">MLCommons 执行主任大卫·坎特（David Kanter）表示：“在如此短的时间内所展示的进展非常出色。我们很高兴看到更多的软件解决方案提供商加入 MLPerf 社区，帮助改进机器学习。”</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">机器学习不同于传统软件（开发人员训练应用程序而不是编程），它需要一套全新的技术，类似于推动工业革命的精密测量、原材料和制造领域的突破。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">机器学习在医疗保健和汽车安全等领域具有巨大的潜力，并通过语音接口、自动翻译和自然语言处理等技术改善信息获取和理解。</p><p style="margin-top: 20px; margin-bottom: 20px; border: 0px; font-size: 18px;">厂商工作负载的日益多样化，使得企业需要各种 AI 优化的硬件架构。这些可以分为三个主要类别：AI 加速 CPU、AI 加速 GPU 和专用硬件 AI 加速器。虽然厂商硬件取得了长足进步，但 AI 模型复杂性的增长率远远超过了硬件进步。</p><p style="margin-top: 20px; border: 0px; font-size: 18px; margin-bottom: 0px !important;">总体来说，在测试中，NVIDIA 相对缺乏竞争对手。不过，这也有测试参与者数量有限的原因，这是 MLPerf 目前存在的一个问题。谷歌过去参与过，但没有参与此轮推理测试。同样，较新的厂商系统，如 Cerebras 和 Graphcore 也未参与。而这将如何影响 MLCommons 这个年轻的组织的长期计划尚不清楚。</p></div></div></div></div></div>  
</div>
            