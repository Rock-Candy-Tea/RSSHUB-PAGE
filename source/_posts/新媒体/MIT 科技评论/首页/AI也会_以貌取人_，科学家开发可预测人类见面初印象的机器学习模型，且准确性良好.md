
---
title: 'AI也会_以貌取人_，科学家开发可预测人类见面初印象的机器学习模型，且准确性良好'
categories: 
 - 新媒体
 - MIT 科技评论
 - 首页
headimg: 'https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/363ff3373436494fadf52a1288377b4a'
author: MIT 科技评论
comments: false
date: Sun, 01 May 2022 12:53:10 GMT
thumbnail: 'https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/363ff3373436494fadf52a1288377b4a'
---

<div>   
<p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><div><font color="#000000"><span style="caret-color: rgb(0, 0, 0);"><img src="https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/363ff3373436494fadf52a1288377b4a" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a></span></font><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">日常生活中，人们在与一个陌生人面对面接触时，自然地就会根据其外形、种族和肢体语言先入为主地做出一定判断。这就是人们常说的“以貌取人”，但由于存在偏见，常有判断不准确的情况发生。如果 AI 也以貌取人，会发生什么呢？</span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">面部属性推断的重要性毋庸置疑，这同时导致了面部科学建模技术的迅速发展，其中机器学习技术的表现尤为突出。生成对抗网络（Generative Adversarial Networks，简称 GAN）等深度神经网络能够根据图像共享网站抓取的大量照片对人脸进行建模，并为任意逼真的人脸图像提供富有表现力的面部刺激特征表示。然而，由于这些表示是通过黑盒优化算法产生的高维向量，将其与人类感知联系起来较为困难。</span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">近日，美国普林斯顿大学的研究团队联合斯蒂文斯理工学院和芝加哥大学布斯商学院，开发了一个“以貌取人”的机器学习模型。该模型能仅根据面部特征，准确预测出人类某张面孔的初印象以及产生的偏见，且其中不乏准确性良好的情况。</span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">相关论文以《肤浅面部判断的深层模型》（Deep models of superficial face judgments）为题发表在 </span></span><em><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">PNAS</span></span></em><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"> 上。</span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><img src="https://p6.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/9c70ec86380341778538dde558422cb5" referrerpolicy="no-referrer"></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="caret-color: rgb(136, 136, 136); color: rgb(136, 136, 136); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify;">图 | 相关论文（来源：</span><span style="outline: 0px; max-width: 100%; font-style: italic; caret-color: rgb(136, 136, 136); color: rgb(136, 136, 136); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify; visibility: visible; line-height: 34px; word-wrap: break-word !important;">PNAS</span><span style="caret-color: rgb(136, 136, 136); color: rgb(136, 136, 136); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify;">）</span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(89, 89, 89); font-size: 16px; letter-spacing: 1px; text-align: justify;"><br></span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(89, 89, 89); font-size: 16px; letter-spacing: 1px; text-align: justify;">此前，深度神经网络模型多用于识别人类面部表情以及项链、耳环和眼镜等特别配饰的存在。而这次，研究人员希望通过深度神经网络来模拟人类会根据面孔推断出的相关情况。</span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(89, 89, 89); font-size: 16px; letter-spacing: 1px; text-align: justify;"><br></span></div><div><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">据了解，该团队使用了 1004 张合成但逼真的⾯部图像，来对面部印象的感知基础进行建模和可视化，并生成 34 个感知可信度和年龄等社会和物理属性的逼真模型。这些模型利用并展示了深度学习在人脸评估中的效用，能够生成沿着各种感知属性维度变化的无限张人脸，且进行相应的一系列操作，并预测各类面部图像可能在⼀般人群中唤起的印象。</span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">为探索属性的推断结构，研究人员计算了每对属性的平均⾯部评分之间的相关性。他们发现，许多属性是高度相关的，包括快乐和外向、主导和值得信赖等，还有一些基本上完全不相关的属性，如聪明和吸引力、聪明和值得信赖等。</span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"></p><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/866764f7c22348cfbebf9faad2280f9f" referrerpolicy="no-referrer"></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(136, 136, 136); caret-color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify;">图 | 对 1000 多张面孔的 34 个属性评分的相关矩阵（来源：</span><span style="color: rgb(136, 136, 136); caret-color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify; outline: 0px; max-width: 100%; font-style: italic; line-height: 34px; word-wrap: break-word !important;">PNAS</span><span style="color: rgb(136, 136, 136); caret-color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify;">）</span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(89, 89, 89); letter-spacing: 1px; font-size: 17px; text-align: justify;"><br></span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(89, 89, 89); letter-spacing: 1px; font-size: 17px; text-align: justify;">然后，该团队研究了被评级的面孔数量对属性模型预测性能的影响，并得出大多数属性模型都受到被评分的面孔数量的影响，其预测性能随着被评分面孔数量的增加而发生显著变化。对于多数属性模型来说，添加更多的面孔图像即可在整个范围内提高其性能。有趣的是，与其他属性模型相比，判断女性/男性属性的模型要达到性能饱和，所需的图像更少。</span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><span style="color: rgb(89, 89, 89); letter-spacing: 1px; font-size: 17px; text-align: justify;"><br></span></div><div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">接着，研究人员对每个面部刺激获得的参与者评分数量与预测性能之间的关系进行了分析。他们发现，除了引起较少分歧的性别和年龄属性之外，对于其他属性的判断，模型预测性能都随评分数量增加模型性能而显着提高。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">最后，该团队探索了图像特征维数与预测性能之间的关系，其中图像特征维数在 10 到 512 之间的维数变化。研究表明，多数属性推断情况下，仅需 10 维模型预测性能就会很快饱和；而在某些情况下，模型性能会随着图像特征维数的增加不断提高，即需要更高的图像特征维数。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/8f3ec4a8e38f43b3b376a6a4c25b6e9d" referrerpolicy="no-referrer"></div><div><span style="caret-color: rgb(136, 136, 136); color: rgb(136, 136, 136); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify;">图 | 样本中被判断为平均得分从高到低的面孔（来源：</span><span style="outline: 0px; max-width: 100%; font-style: italic; caret-color: rgb(136, 136, 136); color: rgb(136, 136, 136); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify; line-height: 34px; word-wrap: break-word !important;">PNAS</span><span style="caret-color: rgb(136, 136, 136); color: rgb(136, 136, 136); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.5440000295639038px; text-align: justify;">）</span></div><div><span style="color: rgb(89, 89, 89); font-size: 16px; letter-spacing: 1px;"><br></span></div><div><span style="color: rgb(89, 89, 89); font-size: 16px; letter-spacing: 1px;">与另一深度神经网络模型 DeepFakes 相比，该团队表示，DeepFakes 是通过将人类置于其不希望或妥协的环境中来影响社会感知，而他们所提出的模型可以在个人面部本身内引起感知变化，并且在应用得足够巧妙时是很难被检测到的。</span></div><div><span style="color: rgb(89, 89, 89); font-size: 16px; letter-spacing: 1px;"><br></span></div><div><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">此外，研究人员认为，这些模型及其实现技术和支持数据应该从⼀开始就透明化，这样就可以开发出强大的检测和防御协议来保护其自身，如开发高度准确的图像取证技术来检测模型输出的合成人脸。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">需要注意的是，虽然这项研究的目标是通过科学建模为心理学家提供用于感知和社会认知实验的面孔图库，但其开发出的模型已经笼罩到图像处理软件的相关伦理。而且，由于涉及到人脸，可能存在滥用的可能。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;">对此，该团队称，在现有诽谤法未涵盖图像处理技术不当使用情形的状况下，通过在更广泛背景下提出的监管框架来限制这些技术的使用是适当的做法。</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(89, 89, 89); --tt-darkmode-color:  #595959;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(136, 136, 136); --tt-darkmode-color:  #888888;">-End-</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(136, 136, 136); --tt-darkmode-color:  #888888;"><br></span></span></p><div><img src="https://p3.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/7346317652bf4f4fbfbaef6f124a3243" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="letter-spacing: 1px;"><span style="color: rgb(136, 136, 136); --tt-darkmode-color:  #888888;"><br></span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(136, 136, 136); --tt-darkmode-color:  #888888;">参考：</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(136, 136, 136); --tt-darkmode-color:  #888888;">https://www.pnas.org/doi/10.1073/pnas.2115228119</span></span></p><p><span style="letter-spacing: 1px;"><span style="color: rgb(136, 136, 136); --tt-darkmode-color:  #888888;"><br></span></span></p><div><img src="https://p6.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/d720008a0a23490c9e69ab8054ecdda5" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a></div></div></div></div></div></div>  
</div>
            