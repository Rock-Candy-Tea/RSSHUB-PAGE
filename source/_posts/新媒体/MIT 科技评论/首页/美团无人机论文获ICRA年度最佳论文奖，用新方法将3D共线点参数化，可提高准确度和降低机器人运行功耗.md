
---
title: '美团无人机论文获ICRA年度最佳论文奖，用新方法将3D共线点参数化，可提高准确度和降低机器人运行功耗'
categories: 
 - 新媒体
 - MIT 科技评论
 - 首页
headimg: 'https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/b70e4ed875ae4d938d93f56c34e41769'
author: MIT 科技评论
comments: false
date: Sat, 04 Jun 2022 14:34:03 GMT
thumbnail: 'https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/b70e4ed875ae4d938d93f56c34e41769'
---

<div>   
<div style="caret-color: rgb(0, 0, 0); color: rgb(0, 0, 0);"><img src="https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/b70e4ed875ae4d938d93f56c34e41769" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">由机器人和自动化学会举办的机器人领域的国际顶级会议 ICRA 2022（国际机器人与自动化学术会议，International Conference on Robotics and Automation）于 5 月 23-27 日举办。来自美团无人机团队的视觉里程计相关论文获得 ICRA 2022 导航领域的年度最佳论文，论文题为《EDPLVO：一种更高效率的视觉里程计点-线直接方法》（EDPLVO: Efficient Direct Point-Line Visual Odometry）。该研究不仅可使机器人在行进时的功耗大幅降低，更能提升计算的效率和准确度。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">据悉，ICRA 2022 收到的投稿数量为 3344 份，其中，进入审稿阶段的共有 3263 份，而最终被接收的稿件数只有 1428 篇。美团无人机团队的论文也是今年 ICRA 唯一的第一作者和第一单位均来自中国的论文。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><div><img src="https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/b458c7dae0fc40b1aea283217dc4f842" referrerpolicy="no-referrer">图丨美团无人机团队有关视觉里程计的论文获得国际顶级机器人会议 ICRA 导航领域最佳论文大奖（来源：ICRA）</div><div><br><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">美团无人机团队这次获奖的论文与视觉里程计（Visual Odometry，VO）的进展有关，视觉里程计是即时定位与地图构建（simultaneous localization and mapping，SLAM）技术中至关重要的部分，也被称为“并发建图与定位”。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">SLAM 技术所解决的问题主要是，在机器人置于全新的位置环境里的未知位置时，用怎样的方法能够让机器人“边看边走”。也就是说，渐渐绘制机器人周围环境的完全地图，与此同时，可决定机器人下一步向哪个方向前进。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">SLAM 技术除了在机器人的定位与导航、路径规划与自主探索方面有重要的作用以外，在其他领域也可大显身手。例如在虚拟现实、增强现实领域，SLAM 技术可以创建视觉效果更真实的地图，通过 SLAM 技术渲染叠加在真实物体上的虚拟物体也更逼真。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">在无人机领域，通过 SLAM 技术能更迅速地创建局部 3D 地图。而在无人驾驶领域，SLAM 技术中的视觉里程计功能与其他定位方式的结合将使无人驾驶的定位更为精准。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">视觉里程计最早在 NASA 执行火星探索任务的漫游车勇气号和机遇号上使用。当时勇气号和机遇号火星车由于使用视觉里程计，不仅更好地自主判定前进方向，而且定位精度也更高，尤其是减少了传统里程计遇到车轮打滑、或惯性测量单元漂移时产生的定位误差。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">视觉里程计这一词语借鉴了汽车行业的“车轮里程计”的概念，这两个概念在用途上有一定的相似之处，但原理大不相同。车轮里程计主要是用来测量车速与行驶里程的，它通过车轮上的“计数器”传感器来增量式地推算估计车辆的状态。而视觉里程计则是以搭载的摄像机拍摄的连续图像为基础，即使在没有 GPS 定位的情况下也可以增量式地推断机器人自身目前的运动状态的。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">传统的里程计中有很多因素会造成误差，例如恶劣天气导致车轮打滑、汽车拐弯时左右车轮弯曲半径不同等。而视觉里程计不仅可以减少或避免上面所说的误差，更可以在 GPS 定位无法使用的情况下仍然保证机器人的定位功能。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">在视觉里程计领域，目前主要有两大类方法，即基于特征的间接方法和直接方法。长期以来，基于特征的间接计算方法一直主导着这一领域。不过最近，许多研究发现，直接方法表现出更高的精度和鲁棒性，即使是在对于间接方法来说很有难度的低纹理场景中也是如此。而美团无人机团队论文中介绍的，就是一种使用点和线的效率更高的直接 VO 算法。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">视觉里程计的直接方法中所采用的，通常是梯度足够大的像素点，包括线上的角点和点。如下图（a）所示，在机器人工作的许多场景中，线上的点的数量是超过角点的数量的。而按照目前的算法，通过光流来跟踪角点虽然容易，但对于线上的点的跟踪却仍有困难，这主要是由于线上存在的一维模糊性造成的。如果直接放弃线上点的共线约束，则将导致对于深度的估计不够确切，如下图（b）所示。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><div><img src="https://p9.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/5f0b7c07cc404a719b024b5a9b980fb5" referrerpolicy="no-referrer">图丨相关论文（来源：CMU）</div><div><br><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">而在此前的许多研究工作中，这些线上点的共线约束问题不是像下图所示的那样被直接忽略，就是将这一问题转移给最终的优化系统来处理并给系统带来繁重的计算负担。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><div><img src="https://p6.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/1cd3e60224a64859a34373b6922947d6" referrerpolicy="no-referrer">图丨相关论文（来源：CMU）</div><div><br><a href="http://www.sciphi.cn/article/view/undefined"></a><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;">而美团无人机团队则提出了一种新的方法来将 3D 共线点参数化，进而将此前仅仅针对点的光度误差扩展到了线。具体来说，该研究团队证明在一条 2D 线上的任意一个 3D 点，都可以由 2D 线的两个端点的逆深度来决定。这一方法不仅意味着可以显著减少变量的数量，而且可以在优化过程中更精确地满足共线约束，进而可以提高精度。欲了解论文全文，可点击下方参考链接。</span></p><p><span style="color: rgb(89, 89, 89); --tt-darkmode-color: #595959;"><br></span></p><p><span style="color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">-End-</span></p><p><span style="color: rgb(136, 136, 136); --tt-darkmode-color: #888888;"><br></span></p><p><span style="color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">参考：</span></p><p><span style="color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">https://www.cs.cmu.edu/~kaess/pub/Zhou22icra.pdf</span></p><p><span style="color: rgb(136, 136, 136); --tt-darkmode-color: #888888;">https://www.icra2022.org/program/awards</span></p><p><span style="color: rgb(136, 136, 136); --tt-darkmode-color: #888888;"><br></span></p><div><img src="https://p6.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/d1856b26fcea4baf93b87a4c148f03f5" referrerpolicy="no-referrer"><a href="http://www.sciphi.cn/article/view/undefined"></a></div></div></div></div></div>  
</div>
            