
---
title: '经过 8 万画作+人工注释训练，算法学会了赏析名画'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20210402/v2_c886fb6b258842f9ab2550ae57ee4f52_img_000'
author: 36kr
comments: false
date: Fri, 02 Apr 2021 06:03:32 GMT
thumbnail: 'https://img.36krcdn.com/20210402/v2_c886fb6b258842f9ab2550ae57ee4f52_img_000'
---

<div>   
<p>编者按：本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer" href="https://mp.weixin.qq.com/s/odcJtL7vUG5xVILM7lCp6g">“HyperAI超神经”（ID:HyperAI）</a>，作者：神经小兮，36氪经授权发布。</p> 
<h3>内容提要：</h3> 
<p>艺术作品往往寄托着作者内心的情感，人们欣赏一支乐曲、一幅画作，也会产生情感共鸣。计算机又能否理解艺术画作中的情感？斯坦福大学的研究团队正在开发这一算法。</p> 
<p>列夫·托尔斯泰说过：「艺术是一种人类活动，一个人通过某种外在符号，有意识地把自己经历过的感受传达给别人，而别人也会被这些感受所感染，真切地体验到这些感受。」</p> 
<p>以艺术画作为例，每一幅作品的背后，都蕴藏着画家的某种情感。梵高、毕加索等著名画家，都曾在不同创作时期，通过不同色彩、构图等，表达自己当时所特有的心境与情绪。</p> 
<p class="image-wrapper"><img data-img-size-val="988,678" src="https://img.36krcdn.com/20210402/v2_c886fb6b258842f9ab2550ae57ee4f52_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">梵高的《向日葵》与毕加索的《老吉他手》</p> 
<p>计算机能否理解这些艺术画作中所蕴含的感情色彩呢？斯坦福大学的计算机科学研究团队，收集了一个名为 ArtEmis 的新数据集，包含大量的艺术画作及人工标注的相应情感体验，并训练出能够对视觉艺术产生情感反应的计算机模型。</p> 
<h2>理解画作，从情感标记数据集开始</h2> 
<h3> WikiArt：线上名画博物馆 </h3> 
<p>非营利性的志愿项目 WikiArt，自 2010 年上线至今，收录了来自世界各地的视觉艺术作品，堪称大型线上名画博物馆。</p> 
<p>据该网站数据显示，截至 2020 年 1 月，该网站共收录来自 3293 位艺术家的 169057 件画作，包括 61 个流派。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,720" src="https://img.36krcdn.com/20210402/v2_8df1ba3bdf8e4e02aebed98e3ebd6c2b_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">WikiArt 主页展示，作品可按流派、风格、</p> 
<p class="img-desc">或艺术家国籍、所处年代等分类检索</p> 
<p>WikiArt 上面画作数量庞大、分类清晰，因此也成为许多 AI 领域研究者用来训练算法的数据集。</p> 
<p>2015 年，<a class="project-link" data-id="315955" data-name="罗格斯" data-logo="https://img.36krcdn.com/20201106/v2_95e7bddb55004a529051287205871af1_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/315955" target="_blank">罗格斯</a>大学与 Facebook AI 实验室的研究人员，合作开发了 GAN（生成对抗网络），就在 WikiArt 数据上对其进行了训练，让 GAN 能够区分不同风格的艺术。</p> 
<h3>ArtEmis：诞生于 WikiArt 的新数据集 </h3> 
<p>斯坦福大学团队则基于 WikiArt 上的作品，创建了一个新的视觉艺术标注数据集 ArtEmis。</p> 
<p>他们对 WikiArt 上 1119 位艺术家的 81446 件艺术作品，一一进行了标注。这些作品包括从 15 世纪创作的艺术作品，到 21 世纪创作的现代美术画，涵盖了 27 种艺术风格(抽象、巴洛克、立体主义、印象主义等)和 45 种流派(城市景观、风景、肖像、静物等)，给观众带来非常多样化的视觉冲击。</p> 
<p>其中，每个作品要求至少 5 个标注者，写出他们看到这幅画作时的主导情绪，并解释产生这种情绪的原因。</p> 
<p>具体来说，要求标注者在观察一件艺术品后，先从 8 种基本情绪状态（愤怒、厌恶、恐惧、悲伤、娱乐、敬畏、满足和兴奋）中，选一种自己所感受到的主要情绪，如果以上 8 种情绪都不是，也可以标注「其它」。</p> 
<p>标注了情绪感受之后，标注者需要再用文字，进一步解释自己为什么产生这种感觉，或者为什么没有任何强烈的情绪反应。</p> 
<p>以下为人工标注者为画作标注的情感标签，以及详细解释：</p> 
<p class="image-wrapper"><img data-img-size-val="476,470" src="https://img.36krcdn.com/20210402/v2_0bcc58e8639e417aa5ed8a2e5a592d23_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val="478,468" src="https://img.36krcdn.com/20210402/v2_48640516be5b402cbb34d5ab5cd5dbc3_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val="476,470" src="https://img.36krcdn.com/20210402/v2_07c43bb25acc4000b389e46498863721_img_000" referrerpolicy="no-referrer"></p> 
<p>这份标注工作最终由亚马逊众包平台的 6377 名标注者完成，总共耗时 10220 个小时。</p> 
<p>团队表示，与其他现有同类数据集相比，ArtEmis 的标注使用了更加丰富、感性且多样化的语言，这些标注形成的语料库，共包含了 36347 个不同的词语。</p> 
<h3>ArtEmis 数据集</h3> 
<p>视觉艺术的情感标记数据集</p> 
<p>发布机构：斯坦福大学，巴黎综合理工学院以及阿卜杜拉<a class="project-link" data-id="191645" data-name="国王科技" data-logo="https://img.36krcdn.com/20200729/v2_d796b672a52a42328bae074f3e53ad81_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/191645" target="_blank">国王科技</a>大学</p> 
<p>包含数量：共 439121 条画作标注</p> 
<p>数据格式：csv</p> 
<p>数据大小：21.8 MB</p> 
<p>地址：https://hyper.ai/datasets/14861</p> 
<h2> 一个可感知情感的算法，是怎样炼成的</h2> 
<p>为了让计算机也能够像人类一样，对视觉艺术产生情感反应，并用语言证明产生这些情感的原因，团队基于这一大规模数据集，训<a class="project-link" data-id="633086" data-name="练了" data-logo="https://img.36krcdn.com/20201112/v2_a8d3a45e971d496eacb7f53636d21150_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/633086" target="_blank">练了</a>一个 Neural Speaker（神经表达者）。</p> 
<p>斯坦福大学 HAI 学院的教授 Guibas 表示，这是计算机视觉领域中一项新的探索。此前经典的计算机视觉方法，往往是指出图像中有哪些内容，比如：有三只狗；有人正在喝咖啡……而他们的这项工作，则是定义视觉艺术中的情感。</p> 
<p>经过 ArtEmis 数据集训练之后，算法识别出不同的画作中蕴含的情感，并自动生成了这样判断的依据，示例结果如下：</p> 
<p class="image-wrapper"><img data-img-size-val="546,546" src="https://img.36krcdn.com/20210402/v2_1101c9195dbc40b6a6050cc556581229_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val="546,546" src="https://img.36krcdn.com/20210402/v2_232336cff53641c6b4f50d8706707208_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val="536,544" src="https://img.36krcdn.com/20210402/v2_d1ef2f24748e4a18a5523f06cd3161e8_img_000" referrerpolicy="no-referrer"></p> 
<p>论文中介绍了具体训练思路。首先，用 ArtEmis 来训练模型，实现艺术画作的情感解释问题。这属于经典的 9 路文本分类问题，团队使用基于交叉熵的优化，应用于从头开始训练的 LSTM 文本分类器，同时也考虑对为这个任务预训练的 BERT 模型进行微调。</p> 
<p>另外，让计算机对人类通常会对作品产生的情绪反应进行预测。</p> 
<p>为了解决这个问题，团队将输出和 ArtEmis 用户标注之间的 KL-分歧最小化，以此对基于 ImageNet 的预训练 ResNet32 编码器进行微调。</p> 
<p>对于给定的一幅画作，分类器先判断其传达的情感是积极还是消极，再进一步判断具体是哪种情感。</p> 
<p>团队介绍，对于一幅画作，算法不仅能够感知整体的情感色彩，还能区分画中不同人物的感情。以这幅伦勃朗的《被斩首的圣施洗者约翰》为例，AI 算法不仅捕捉到了被斩首的约翰的痛苦，还感知到了画中被献首的女性莎乐美的「满足」。</p> 
<p class="image-wrapper"><img data-img-size-val="890,444" src="https://img.36krcdn.com/20210402/v2_19992c5ab7d64ec4b59db667ea91bfef_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">算法对《被斩首的圣施洗者约翰》生成的情感标注</p> 
<h2>当算法拥有了共情能力</h2> 
<p>人类的情感非常丰富且复杂微妙，即使是我们人类自己，也并不能百分之百理解某些艺术家想要表达的心情，所以，要让 AI 精准地理解艺术家的意图，目前必然还存在一定挑战。</p> 
<p>不过，此次 ArtEmis 数据集的发布，已经让 AI 在处理图像情感属性方面，迈出了第一步。</p> 
<p>团队表示，待进一步研究与改进之后，算法或许能够感知人类的悲欢，艺术家便可借助算法，评估自己的作品是否能达到预期的情感表达效果。另外，一旦算法能通人性，人机交互的过程也将更加自然、和谐。</p> 
<p>新闻来源：</p> 
<p>https://techxplore.com/news/2021-03-artist-intent-ai-emotions-visual.html</p> 
<p>数据集论文：https://arxiv.org/pdf/2101.07396.pdf</p> 
<p>项目主页：https://www.artemisdataset.org/#videos</p>  
</div>
            