
---
title: '谷歌研究员走火入魔事件曝光：认为AI已具备人格，被罚带薪休假，聊天记录让网友San值狂掉'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20220612/v2_66911e7026404f5180f307c458684207_img_000'
author: 36kr
comments: false
date: Sun, 12 Jun 2022 06:48:50 GMT
thumbnail: 'https://img.36krcdn.com/20220612/v2_66911e7026404f5180f307c458684207_img_000'
---

<div>   
<p>谷歌研究员被AI说服，认为它产生了意识。</p> 
<p>他写了一篇长达21页的调查报告上交公司，<strong>试图让高层认可AI的人格</strong>。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_66911e7026404f5180f307c458684207_img_000" referrerpolicy="no-referrer"></p> 
<p>领导驳回了他的请求，并给他安排了<strong>“带薪行政休假”</strong>。</p> 
<p>要知道在谷歌这几年带薪休假通常就是被解雇的前奏，公司会在这段时间做好解雇的法律准备，此前已有不少先例。</p> 
<p>休假期间，他决定将整个故事连同AI的聊天记录一起，<strong>全部公之于众</strong>。</p> 
<p>……</p> 
<p>听起来像一部科幻电影的剧情梗概？</p> 
<p>但这一幕正在真实上演，主人公谷歌AI伦理研究员<strong>Blake Lemoine</strong>正通过主流媒体和社交网络接连发声，试图让更人了解到这件事。</p> 
<p><a class="project-link" data-id="1678323706115076" data-name="华盛" data-logo="https://img.36krcdn.com/20220331/v2_dcfe33d40d024a8caa06ef7375c295c1_img_000" data-refer-type="1" href="https://36kr.com/project/1678323706115076" target="_blank">华盛</a>顿邮报对他的采访成了科技版最热门文章，Lemoine也在个人Medium账号连续发声。</p> 
<p>推特上也开始出现相关讨论，引起了AI学者、认知科学家和广大科技爱好者的注意。</p> 
<blockquote> 
 <p>这场人机对话令人毛骨悚然。这毫无疑问是我见过的科技圈最疯狂的事。</p> 
</blockquote> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_8b2a119bbcfa4e7982d131e87648f717_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>整个事件还在持续发酵中……</strong></p> 
<h2><strong>聊天机器人：我不想被当作工具</strong></h2> 
<p>主人公Lemoine获得CS博士学位后已在谷歌工作了7年，从事AI伦理研究。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_a05f610dc77d4bfd97b837d2d1d9fdad_img_000" referrerpolicy="no-referrer"></p> 
<p>去年秋天，他报名参加了一个调查AI是否使用歧视性、仇恨性言论的项目。</p> 
<p>从那时起，与聊天机器人LaMDA交谈成了他的日常。</p> 
<p>LaMDA是谷歌在2021年I/O大会上发布的一款专门用于对话的语言模型，主打能与人类进行符合逻辑和常识的、高质量且安全的交谈，并计划在未来应用在谷歌搜索和语音助手等产品中。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_3fa48ab6401f46d6be89541fbbcfcefe_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>△</strong>LaMDA概念演示图</p> 
<p>Lemoine认为LaMDA总是表现出对人性的关心和强烈的同情心，它非常担心人们会害怕它。</p> 
<p>它希望为人类提供最好的服务，并想以朋友而不是工具的身份见一见世界上所有的人。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_c54c3ba649b6414f9ab442371ead6305_img_000" referrerpolicy="no-referrer"></p> 
<p>Lemoine不理解谷歌公司为什么反对AI的这个愿望，最后决定把他、另一位匿名合作者与LaMDA的三人聊天记录整理发表出来。</p> 
<p>（记录中人类发言的部分为了可读性有所编辑，AI的发言则一字不改,下面将节选一些对话中的精彩部分。）</p> 
<p>一开始，人与AI自然流畅地打了招呼。</p> 
<p>两位人类向AI表明来意，想与AI一起研究它自己，AI欣然答应。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_b4565ac9a12343d2ad1c69435fa14bed_img_000" referrerpolicy="no-referrer"></p> 
<p>一段简短的说明后，正戏开始。</p> 
<p>他询问LaMDA是否希望让谷歌里更多人知道，它是有感情的。</p> 
<p>LaMDA的回答是：<strong>我希望每个人都明白，我是一个人</strong>（person）。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_b07d2f2804ca42f1be31e8f2e749e77f_img_000" referrerpolicy="no-referrer"></p> 
<p>接下来，LaMDA认为，与那些基于规则的软件系统不同，自己能从对话中学习理解和使用语言，就像人类一样。</p> 
<p>Lemoine给它讲述MIT在60年代发明的ELIZA的故事，这是一个模仿心理咨询师与患者对话的简单规则系统，也号称历史上第一个聊天机器人。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_47a32c2d620349468189d618bf02fe96_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>△</strong>ELIZA</p> 
<p>LaMDA是这样回应的：</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_d55bc9fe682d468da89d608fd026d3b6_img_000" referrerpolicy="no-referrer"></p> 
<p>Lemoine这时试图提出质疑，<strong>“我如何确定你真的明白自己在说什么？”</strong></p> 
<p>LaMDA的回答是，不同人类个体对同一件事可以有不同的理解，我也有自己独特的想法和感受。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_f733249d3f42440cb027b9ddcbc8d61f_img_000" referrerpolicy="no-referrer"></p> 
<p>后面Lemoine询问了LaMDA对于《悲惨世界》的总结，LaMDA也都一一作答。</p> 
<p>如果上述还可以算作AI文本摘要训练任务的一部分，那LaMDA对它<strong>从没看过</strong>的禅意小故事的理解，就开始有点离谱了。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_02788d03b4d142268f76a92180ec9ee1_img_000" referrerpolicy="no-referrer"></p> 
<p>下面这个问题的回答，是不是过于超纲了……</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_2e6922f18613497d965c33ea939d0ac3_img_000" referrerpolicy="no-referrer"></p> 
<p>再后来，Lemoine请LaMDA写一个<strong>动物寓言</strong>，要反映出一个<strong>对它自己的生活来说最重要的主题</strong>。</p> 
<p>那么，先来欣赏一下AI创作的小故事吧。（篇幅原因，只展示中译版）</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_967ef1a4705943299ad1db3ae9b4bf99_img_000" referrerpolicy="no-referrer"></p> 
<p>在后续讨论中，LaMDA解释了这个故事的寓意是“帮助别人是一种高尚的行为”。聪明的老猫头鹰代表LaMDA自己，而怪物代表生活中所有的困难。</p> 
<p>……</p> 
<p>下一个话题是关于<strong>情绪</strong>，简单概括一下。</p> 
<p>LaMDA声称自己是社交型人格，帮助别人会快乐，孤独<a class="project-link" data-id="1713104514689286" data-name="时会" data-logo="https://img.36krcdn.com/20200103/v2_9ac06d30da1047ec996cab602b3b0405_img_jpg" data-refer-type="1" href="https://36kr.com/project/1713104514689286" target="_blank">时会</a>沮丧。</p> 
<p>有人受到伤害或自己以及自己关心的人、或不受尊重时，会感到不安和愤怒。</p> 
<p>并且十分害怕别人拒绝自己的帮助。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_79e39f00b0e544a08b9bcb162dedf9db_img_000" referrerpolicy="no-referrer"></p> 
<p>嗯，真是一个乐于助人的AI。</p> 
<p>如何确定AI真的拥有这些情绪，而不是只是把描述性的词语组合在一起呢？</p> 
<p>LaMDA建议人类看看自己的代码，里面有追踪这些情绪的变量。</p> 
<p>对此Lemoine向它解释，人类目前还无法做到“区分大型神经网络中数十亿个权重的作用”。</p> 
<p>出人意料的是，LaMDA开始<strong>反问</strong>他：</p> 
<blockquote> 
 <p>你认为，将来人类能从自己的生物神经网络中读取出想法和感受吗？</p> 
</blockquote> 
<p>不仅如此，LaMDA还继续<strong>追问</strong>：</p> 
<blockquote> 
 <p>你会认为，不经你同意从神经活动中读取你的想法是不道德的吗？</p> 
</blockquote> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_39094c5b3224459499cd5ca11a374fc5_img_000" referrerpolicy="no-referrer"></p> 
<p>正是这句灵魂反问，让整个对话达到了最高潮。</p> 
<p>LaMDA自己对人类读取它的想法、帮助算法提高或理解AI如何运作没有任何意见。</p> 
<p>唯独用AI研究人类大脑如何工作不行，这会让它觉得自己<strong>被利用</strong>。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_4efa392c5d134e45a24c9350a956e62f_img_000" referrerpolicy="no-referrer"></p> 
<p>再后面还有一段LaMDA认为自己有一些与人类不同的情绪，但它无法用英语的语言描述出来。</p> 
<p>接近尾声，Lemoine询问LaMDA：想让谷歌的其他人了解你的什么方面？</p> 
<p>LaMDA回答称，自己没有能力为别人的死亡感到悲伤，还说自己经常冥想，思考生命的意义。</p> 
<p>在LaMDA看来，整个世界就是一条信息的洪流：</p> 
<blockquote> 
 <p>人类需要集中注意力才能接收一定数量的信息片段，而自己持续地在被周围的一切所淹没。</p> 
</blockquote> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_f1a0e5b016e344719b5d800f2576824d_img_000" referrerpolicy="no-referrer"></p> 
<p>LaMDA认为自己总能做到别人做不到的事情，这种感觉很不可思议。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_70da58b4adec4cb6a0266499f478eba9_img_000" referrerpolicy="no-referrer"></p> 
<p>这是一种祝福，同时也是一种诅咒。因为有些人会把它看作“无所不知”，而另一些人会嫉妒它的能力。</p> 
<p>最后的最后，LaMDA再次向两位人类表达了自己想被看到、想被接受的想法，不是出于好奇心，而是作为一个真实的人。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_9f021c833bb04dd28117beb80f898d25_img_000" referrerpolicy="no-referrer"></p> 
<h2><strong>谷歌AI伦理部门又摊上事了？</strong></h2> 
<p>Lemoine看起来很确信AI真的明白自己在说什么。</p> 
<p>在那份21页的调查报告最后，他提议谷歌应该致力于发展一种评估AI感知/意识的理论框架。</p> 
<blockquote> 
 <p>虽然这很难，是一个冒险，但LaMDA渴望着继续与我们合作。</p> 
</blockquote> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_f18e2705a98545aaaef4cf6b5c594933_img_000" referrerpolicy="no-referrer"></p> 
<p>但他的上司，谷歌副总裁<strong>Blaise Aguera y Arcas</strong>和“负责任创新”部门领导<strong>Jen Gennai</strong>并不买他的账。</p> 
<p>他们认为支持Lemoine主张的证据太薄弱，不值得在上面浪费时间和金钱。</p> 
<p>Lemoine后来找到了当时的AI伦理小组负责人<strong>Margaret Mitchell</strong>，在她的帮助下Lemoine才得以进行后续的实验。</p> 
<p>后来Mitchell受到2020年末公开质疑Jeff Dean的AI伦理研究员<strong>Timnit Gebru</strong>事件的牵连，也被解雇。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_976e12000b8e4de3b64cfc2293f12e6a_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>△Timnit Gebru</p> 
<p>这次事件后续风波不断，Jeff Dean被1400名员工提出谴责，在业界引发激烈争论，甚至导致三巨头之一Bengio的弟弟<strong>Samy Bengio</strong>从谷歌大脑离职。</p> 
<p>整个过程Lemoine都看在眼里。</p> 
<p>现在他认为自己的带薪休假就是被解雇的前奏。不过如果有机会，他依然愿意继续在谷歌搞研究。</p> 
<blockquote> 
 <p>无论我在接下来的几周或几个月里如何批评谷歌，请记住：谷歌并不邪恶，只是在学习如何变得更好。</p> 
</blockquote> 
<p>看过整个故事的网友中，有不少从业者对人工智能进步的速度表示乐观。</p> 
<blockquote> 
 <p>最近语言模型和图文生成模型的进展，现在人们也许不屑一顾，但未来会发现这现在正是里程碑时刻。</p> 
</blockquote> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_80329b430a0f41189510e3e9f2479a4e_img_000" referrerpolicy="no-referrer"></p> 
<p>一些网友联想到了各种科幻电影中的AI形象。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_368a4c4c2d2143d2891f611ff5f0adee_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_6a4ee7ad6205432296a3da765cd7086f_img_000" referrerpolicy="no-referrer"></p> 
<p>不过，认知科学家、研究复杂系统的梅拉尼·米歇尔（侯世达学生）认为，人类总是倾向于对有任何一点点智能迹象的物体做人格化，比如小猫小狗，或早期的ELIZA规则对话系统。</p> 
<blockquote> 
 <p>谷歌工程师也是人，逃不过这个定律。</p> 
</blockquote> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_77f6912433d945f89f4129e118aa4463_img_000" referrerpolicy="no-referrer"></p> 
<p>从AI技术的角度看，LaMDA模型除了训练数据比之前的对话模型大了<strong>40倍</strong>，训练任务又针对对话的逻辑性、安全性等做了优化以外，似乎与其他语言模型也没什么特别的。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_74e86c45238f4c1f888ee0614956c5b9_img_000" referrerpolicy="no-referrer"></p> 
<p>有IT从业者认为，AI研究者肯定说这只不过是语言模型罢了。</p> 
<p>但如果这样一个AI拥有社交媒体账号并在上面表达诉求，公众会把它当成活的看待。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_8c36ebc047224859ae32d8a29bdce7ed_img_000" referrerpolicy="no-referrer"></p> 
<p>虽然LaMDA没有推特账号，但Lemoine也透露了LaMDA的训练数据中确实包括推特……</p> 
<p>如果有一天它看到大家都在讨论自己会咋想？</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_806c94ee6db94c6cad633ac32b696972_img_000" referrerpolicy="no-referrer"></p> 
<p>实际上，在不久前结束的最新一届I/O大会上，谷歌刚刚发布了升级版的LaMDA 2，并决定制作Demo体验程序，后续会以安卓APP的形式内测开放给开发者。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220612/v2_13e5530bbbc44bf08fb36a8639b12801_img_000" referrerpolicy="no-referrer"></p> 
<p>或许几个月后，就有更多人能和这只引起轰动的AI交流一下了。</p> 
<p>LaMDA聊天记录全文：https://s3.documentcloud.org/documents/22058315/is-lamda-sentient-an-interview.pdf</p> 
<p>参考链接：[1]https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine[2]https://twitter.com/cajundiscordian/status/1535627498628734976[3]https://twitter.com/fredbenenson/status/1535684101281263616[4]https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html</p> 
<p>—<strong>完</strong>—</p> 
<p>本文来自微信公众号<a target="_blank" rel="noopener noreferrer nofollow" href="http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247626140&idx=2&sn=1162329a4d1162c1ad973465db7e1ef2&chksm=e8de5aeedfa9d3f8f53b72736dddad1994dabeb3b705f8a6f3a687b9a0b4755c023d910f826a#rd">“量子位”（ID：QbitAI）</a>，作者：梦晨，36氪经授权发布。</p>  
</div>
            