
---
title: 'OpenAI核心人员集体离职创立新公司：人均大神，融资1亿多美金只为_初心_'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20210615/v2_bb77423bd8f6460c9698ab522fcfc0cf_img_000'
author: 36kr
comments: false
date: Tue, 15 Jun 2021 00:43:37 GMT
thumbnail: 'https://img.36krcdn.com/20210615/v2_bb77423bd8f6460c9698ab522fcfc0cf_img_000'
---

<div>   
<p>编者按：本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer" href="https://mp.weixin.qq.com/s/cL2si-6GmBxh0s4Vr-Oo7w">“硅星人”（ID:guixingren123）</a>，36氪经授权发布。</p> 
<p>作者｜杜晨</p> 
<p>编辑｜Vicky Xiao</p> 
<p>硅星人的读者应该都对 OpenAI 比较熟悉了。这家总部位于旧金山的实验室，是 AI 基础科研领域的全球领导者之一。它开发的 GPT 语言生成模型，一次又一次刷新人们对于深度学习能力的认知。OpenAI 原是非营利机构，但为了更好地实现产研结合，用期权留住员工，之前也成立了有限营利的公司。</p> 
<p>不过在去年12月，OpenAI 一批早期/核心员工集体离职，在领域内引起了不小的轰动。这次“出 OpenAI 记”并非普通的跳槽，相关离职人员也保持了很长时间的缄默，以至于<a class="project-link" data-id="66171" data-name="圈内人" data-logo="https://img.36krcdn.com/20200729/v2_622bc64f797946a29fdadd2461cf647f_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/66171" target="_blank">圈内人</a>士都不知道他们接下来有何打算。</p> 
<p>最近，这批 OpenAI 前核心员工终于宣布了他们前所未有的伟大计划：解决长久以来神经网络的“黑盒子”问题，为研究者们开发能够解释 AI 真正工作原理的工具。</p> 
<p class="image-wrapper"><img data-img-size-val="589,379" src="https://img.36krcdn.com/20210615/v2_bb77423bd8f6460c9698ab522fcfc0cf_img_000" referrerpolicy="no-referrer"></p> 
<p>他们创办了一家新公司 Anthropic，致力于提高 AI 安全和可解释性。这些创始成员相信，“通用人工智能” (artificial general intelligence) 不久后即将到来，而 AI 安全将会成为日最重要的研究方向。</p> 
<p>这家新公司也被投资者赋予了极大的期待。据了解，其 A 轮融资已经完成，规模高达1.24亿美元，投资人包括 Skype 创始人 杨·塔林（领投）、 埃里克·施密特、达斯汀·莫斯科维兹等。</p> 
<p>Anthropic 到底是一家怎样的机构？它的创始成员都有谁？它在做的事情对于整个 AI 基础和应用领域有何重大意义？让我们走近这家最近刚刚离开隐形状态的全新机构，一探它的真相。</p> 
<h2>让 AI 更安全、可解释</h2> 
<p>AI 一直是一个“黑盒子”。尽管人们形容神经网络是按照人脑神经工作原理设计的，它具体怎么工作，输入的数据是如何转化成输出的，具体的原理和各环的作用，一直很难被真<a class="project-link" data-id="214173" data-name="正解" data-logo="https://img.36krcdn.com/20201106/v2_67a7b1b51d1b4a2290589f4ec3cf5c40_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/214173" target="_blank">正解</a>释。</p> 
<p>在一小部分研究者看来，考虑到 AI 正在被应用到越来越高风险的系统当中，比如自动驾驶、医疗诊断、药物发现，甚至军事当中……它的不可解释性将会阻挡技术的真正进步，并且如果被持续忽视的话，甚至可能会引发不可逆转的严重恶果。</p> 
<p>不过，自从深度学习在十年前左右取得重要突破，这项技术已经成为了 AI 技术进步的根基。越来越大的模型、更强的算力，让 AI 变得似乎“无所不能”，而不可解释性一直没有被公众看作是大问题——这也是为什么虽然目前 AI 领域内很多人，特别是那些从事应用领域的，并没有关注 AI 的黑盒子问题。</p> 
<p class="image-wrapper"><img data-img-size-val="1024,512" src="https://img.36krcdn.com/20210615/v2_56cd99e6bf06406f9f693c428a67dcac_img_000" referrerpolicy="no-referrer"></p> 
<p>AI 的黑盒子问题：黑盒子是一个算法，能够将数据转变成其它东西。问题在于，黑盒子在发现模式的同时，经常无法解释发现的方法。 图片来源 | Topbots</p> 
<p>2015年底成立的 OpenAI，其使命是实现通用人工智能，打造一个能够像人的心智那样，具有学习和推理能力的机器系统。成立以来，OpenAI 一直从事 AI 基础研究，主要以 GPT 语言生成模型（特别是 GPT-3）被人们所熟知。</p> 
<p>但其实，增强 AI 的可解释性，让它能够更加安全地应用，也是 OpenAI 的研究方向之一。只不过，这部分工作在名气更大的 GPT-3 的面前，似乎显得没有那么重要。</p> 
<p>而在去年年底离职的这一批员工，认为随着模型变大、算力变强，通用人工智能离我们越来越近，在可预见的未来就有可能实现——而在这样的前提下，AI 可解释性和安全性变得无比重要。这批员工，被认为是AI领域的“有效利他主义者”。简单来说，他们不仅认为应该投入重金进行 AI 基础研究让世界变得更好，并且也要注重实际功效。</p> 
<p>他们的理念和 OpenAI 并没有本质上的冲突，但是 OpenAI 变得越来越不透明，且逐渐功利化的趋势，令他们感到担忧。一个最直接的例子，就是 OpenAI 尚未解决偏见和安全问题，就把 GPT-3 开发成了商用化的 API，提供给行业里的大公司使用。</p> 
<p class="image-wrapper"><img data-img-size-val="300,168" src="https://img.36krcdn.com/20210615/v2_a455d458522547a1aec89496a5144746_img_000" referrerpolicy="no-referrer"></p> 
<p>最终，这批核心员工在去年年底集体离职。其中不少人，都参与到了今天硅星人介绍的这家 Anthropic 公司当中。</p> 
<p>所以其实这样解释 Anthropic 可或许更准确一些：一家<a class="project-link" data-id="498684" data-name="重拾" data-logo="https://img.36krcdn.com/20201106/v2_3e3f9a09003f4dfa840432864828ca15_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/498684" target="_blank">重拾</a> OpenAI 慢慢忘却的初心的“正统” AI 基础科研机构。</p> 
<p>Anthropic 的官网这样介绍自己：我们是一家AI 安全和研究公司，致力于开发可靠、可解释和可调整的 AI 系统。“今天的大规模的通用（AI）系统能够带来很高的收益，但他们同时却是不可预测、不可靠，和不透明的。我们的使命是在这些问题上做出进步。”</p> 
<p>“Anthropic 的使命是从事基础科研，让我们可以打造能力更强、更通用、更可靠的 AI 系统，并且应用这些系统从而让人类获益，”Anthropic 联合创始人兼 CEO Dario Amodei 表示。</p> 
<p class="image-wrapper"><img data-img-size-val="710,579" src="https://img.36krcdn.com/20210615/v2_7426dd2461604573ad8b328c30ae2d10_img_000" referrerpolicy="no-referrer"></p> 
<p>对于“神经网络到底是什么”这类问题，通常的白话答案是“一种模仿人脑神经工作方式的计算系统”。然而很多专业人士都不愿意提及的是：我们对人脑的工作原理至今并未完全了解。</p> 
<p>而深度学习领域的现状是：我们正在疯狂地把这些“一知半解”的知识用于神经网络，并且把这样开发出来的 AI 系统用于越来越高风险的场景，却又缺乏对可解释性，对安全的思考。</p> 
<p>比如，我们知道一个神经网络的参数量越大、泛用性似乎就越强，但无法解释某几个参数之间的关系到底是什么，进行怎样的调整会导致输出结果怎样变化；再比如，我们知道偏见在社会中客观存在，也必然会投射到社会资料聚合而成的数据集当中，而为数据集是 AI 系统带有偏见的重要原因，但除了低效地改善数据集之外，我们对于消除 AI 系统的偏见暂时别无他法。</p> 
<p>Amodei 接受美国媒体 Vox 旗下 Future Perfect 采访时表示，AI 研究人员应该增加对机器学习系统内在工作原理的了解，并且用这些知识来开发更安全的系统，而不是执迷于“放卫星”似的盲目开发越来越大的神经网络。</p> 
<p>为什么呢？举个例子：深度学习有一个经典的激励“扭曲”现象，比如你想让机器 agent 走出迷宫，设计分数（豆子）激励它——结果它执迷于获得更高的分数，遍历了每<a class="project-link" data-id="3969340" data-name="一条" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3969340" target="_blank">一条</a>错误的路，吃掉了所有的豆子，却从未将走出迷宫当作真正目标。</p> 
<p>当神经网络变得更大、更强，如果中间出现了某种主观或客观导致的激励扭曲，它真正做的事情和它的设计初衷之间的差距只会越来越大，应用在现实场景中，有可能导致严重后果。</p> 
<p>如果我们能够获得一种工具，能够更清楚直白地了解神经网络的工作原理，知道如何调整网络的哪个部分，能够避免此类情况，对于接下来的 AI 进步将有很大帮助。所有研究者都希望掌握这个工具，但问题就在于，我们现在并没有这样的工具。</p> 
<p>而 Anthropic 的任务就是开发出这样的工具，并把它送到更多 AI 研究者的手上。</p> 
<h2>明星创始团队+投资人</h2> 
<p>去年年底从 OpenAI 离职的核心员工当中就包括 Dario Amodei 和他的同胞姐妹 Daniela。LinkedIn 资料显示，他们于今年2月创办了 Anthropic 公司，Dario 任 CEO，Daniela 任总裁。</p> 
<p>Dario是 OpenAI 的早期员工之一，曾发表多篇 AI 可解释性、安全等方面的论文，离职前在 OpenAI 担任研究 VP。在此之前，Dario 还曾在<a class="project-link" data-id="28215" data-name="百度" data-logo="https://img.36krcdn.com/20210325/v2_fa02010c4a8b46da9f4e1d3b1fd59f22_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/28215" target="_blank">百度</a>担任研究员，在前首席科学家吴恩达手下工作。他博士毕业于普林斯顿大学，后回到本科毕业的斯坦福大学担任博士后学者。他是 OpenAI 的前核心成员，也被认为是深度学习领域最为前沿的研究员之一。</p> 
<p class="image-wrapper"><img data-img-size-val="630,476" src="https://img.36krcdn.com/20210615/v2_17201e77aeb541eea7c0ef6eb4e7cee5_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">Dario Amodei 图片来源 | RedHat</p> 
<p>Dario 的胞妹 Daniela Amodei 之前也在 OpenAI 从事和 Dario 相同方向的工作，曾担任安全和政策 VP。Daniela 过往的任职经历包括 Stripe（其创始人是 OpenAI 投资人之一）、美国国会等。</p> 
<p class="image-wrapper"><img data-img-size-val="885,484" src="https://img.36krcdn.com/20210615/v2_d00cb9f2ac8d49babe26ea61e672a587_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">OpenAI 部分成员合影，Amodei 兄妹用红箭头标出 图片来源 | OpenAI</p> 
<p>Anthropic 的创始团队成员，大多为 OpenAI 的重要员工或关联成员，包括（排名不分先后）Jared Kaplan、Sam McCandlish、Tom Brown、Gabriel Goh、Kamal Ndousse、Jack Clark、Ben Mann、Chris Olah 等。</p> 
<p>这些研究员曾参与 OpenAI 其多项重要课题研究，包括 GPT-3、“显微镜”神经元可视化工具、神经网络里的多模态神经元、AI 模型安全设计事故分析、引入人类偏好的强化学习等——失去这些关键人员，OpenAI 未来在相关课题上可能会略显颓势。</p> 
<p>举一个例子：Chris Olah 是 OpenAI 多模态神经元论文的作者之一。他是领域里小有名气的“怪胎”，曾经拒绝 Yoshua Bengio 的研究生邀请，而是去了 Google Brain 团队。他在<a class="project-link" data-id="3968996" data-name="谷歌" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968996" target="_blank">谷歌</a>带过博士生，论文的引用数量甚至超过拥有博士学位的研究者，自己却连本科都没毕业……</p> 
<p class="image-wrapper"><img data-img-size-val="1080,608" src="https://img.36krcdn.com/20210615/v2_5c85f41c973241ae9efc121bb5b6c2ca_img_000" referrerpolicy="no-referrer"></p> 
<p>简单介绍一下 Olah 参与的 OpenAI 多模态神经元论文：多年以前有研究者发现，大脑中的一些神经元可以对模态不同但概念相同的触<a class="project-link" data-id="34528" data-name="发条" data-logo="https://img.36krcdn.com/20201111/v2_568621fe7d6749b3a8ea0d76871fcda5_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/34528" target="_blank">发条</a>件产生反应，比如当提到“哈莉·贝瑞”的名字、照片、简笔画像的时候，同一个神经元都可以产生反应。</p> 
<p>OpenAI 的多模态神经元研究，基于该机构今年发布的 CLIP 泛用性视觉系统。论文作者发现在 CLIP 的神经网络倒数第二层也存在这样的一颗“神经元” （Neuron 244）。这项研究预示着，“抽象”这一自然视觉领域的概念，很可能在计算机合成视觉领域同样存在。</p> 
<p>有着如此强大团队，Anthropic 成为了投资者眼中的最新热门标的。目前该公司已经完成了规模高达1.24亿美元的 A 轮融资，并正式走出隐形状态。</p> 
<p>A 轮的领投者是 Jaan Tallinn，原 Skype 的联合创始人。Tallinn 还是 DeepMind 的早期投资人。（至于为什么他能在一众其它科技大佬/大牌投资人当中拿到领投资格，一个重要原因应该是他和 Anthropic 创始团队哲学理念一致，是“有效利他主义”运动的主要资助者之一。）</p> 
<p class="image-wrapper"><img data-img-size-val="1080,720" src="https://img.36krcdn.com/20210615/v2_ca04b5bc3ddc456cbbf886f80e3329fc_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">Jaan Tallinn 图片来源 | Enterprise Estonia</p> 
<p>Anthropic 的其它投资人还包括 Dustin Moskovitz（Asana CEO、Facebook 联合创始人）、埃里克·施密特（谷歌前董事长、CEO）、詹姆斯·麦克雷夫等，绝对是相当豪华的投资人阵容了。</p> 
<p>Anthropic 表示公司的钱主要花在计算密集型的基础科研上，虽然未来也有商业化的打算，短期内不会作为主要目标。但不管怎样，A 轮 1.24亿美元的融资规模，足以表明 Anthropic 的投资人预期它的估值完全有追赶 OpenAI 的希望。</p> 
<p>在这个 AI 基础科研<a class="project-link" data-id="95377" data-name="得到" data-logo="https://img.36krcdn.com/20200929/v2_fcdf767846d041309970adf0877fc666_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/95377" target="_blank">得到</a>比以往更多关注的时代，Anthropic 无疑将成为 OpenAI、DeepMind 的有力“竞争者”，和一家值得继续密切关注的研究型公司。</p>  
</div>
            