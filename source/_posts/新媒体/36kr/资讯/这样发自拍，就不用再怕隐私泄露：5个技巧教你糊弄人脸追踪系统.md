
---
title: '这样发自拍，就不用再怕隐私泄露：5个技巧教你糊弄人脸追踪系统'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20210506/v2_eba98fe933d14b7da55cf076a00acf82_img_000'
author: 36kr
comments: false
date: Thu, 06 May 2021 04:00:35 GMT
thumbnail: 'https://img.36krcdn.com/20210506/v2_eba98fe933d14b7da55cf076a00acf82_img_000'
---

<div>   
<p>编者按：本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a href="https://mp.weixin.qq.com/s/sxyfXgb7gp2mJQvZoGzjog">“硅星人”（ID:guixingren123）</a>，36氪经授权发布。</p> 
<p>作者｜杜晨 光谱</p> 
<p>编辑｜Vicky Xiao</p> 
<blockquote> 
 <p>想象你注册了一个约会网站，上传了照片，没放太多的资料，避免不必要的隐私泄露。结果有无聊的人用你的照片去进行反向搜索，找到了你的全名、工作单位、教育经历，其它平台的账号等等……有了这些信息，他开始跟踪你，非常 creepy。</p> 
</blockquote> 
<p>这并非你的错，但有什么自己能做的，可以避免类似的情况出现呢？</p> 
<p>一家名叫 DoNotPay 的公司，最近推出了一项人脸反识别服务，叫做 Photo Ninja：在照片中肉眼不可察觉的地方进行像素级的修改，从而破坏掉人脸识别系统赖以工作的那些关键特征。最终的结果图片，就连 Google 这样的主流搜索引擎的图片搜索功能，都认不出来。</p> 
<p>比如下面这张美国总统<a class="project-link" data-id="652580" data-name="拜登" data-logo="https://img.36krcdn.com/20201113/v2_92bfb5af14d9459abe7929d26dac143d_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/652580" target="_blank">拜登</a>的官方照片，一是做了镜像处理（左右对调），还在人脸上进行了更多微弱的处理。最终结<a class="project-link" data-id="418191" data-name="果成" data-logo="https://img.36krcdn.com/20201112/v2_93aedf804bd141c6ae6b5ef773a2ed72_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/418191" target="_blank">果成</a>功骗过了 Google，让它完全搜不出来图中人是谁，甚至找不到类似的照片结果。</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_eba98fe933d14b7da55cf076a00acf82_img_000" data-img-size-val="663,512" referrerpolicy="no-referrer"></p> 
<p>原图：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_761920e118244820aeb7eba71457f198_img_000" data-img-size-val="1080,1350" referrerpolicy="no-referrer"></p> 
<p>2015年，<a class="project-link" data-id="3968996" data-name="谷歌" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968996" target="_blank">谷歌</a>的AI研究员开发了一种全新的技术，能够在计算机视觉的算法层面对其进行“攻击”。</p> 
<p>以物体为例，识别算法的工作方法，就是从非常细微的像素层面提取特征，总结出规律，才能识别物体。而如下图所示，只要在像素层面加入非常微弱的“噪点”，就能够达到攻击效果，导致神经网络输出完全不同的，错误的结果……</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_ca9a0bb524134ed18356575e5c047c9c_img_000" data-img-size-val="1000,300" referrerpolicy="no-referrer"></p> 
<p>这种技术名为对抗机器学习 (adversarial machine learning)，可以用于图像/物体和语音。今天我们介绍的 Photo Ninja，就是对抗机器学习的一种应用。</p> 
<p>对抗机器学习概念的提出已经有相当长一段时间了，但随着技术的进步，在近几年的发展速度明显变快。刚才提到谷歌提出的攻击方式，在2015年成功击破了 GoogLeNet，而 GoogLeNet 前一年刚刚拿下 ImageNet 挑战赛的冠军……</p> 
<p>技术没有好坏，但用技术的人有善恶之分。对抗机器学习也是一样，如果到了坏人手中，它可能会引发严重的后果。比如，坏人可以到马路上，“破坏” stop sign 等重要的交通指示牌，虽然不会影响到普通车辆和人类司机，但有可能严重干预自动驾驶系统的正常工作，导致交通事故的发生。</p> 
<p>当然，至少在 Photo Ninja 案例中，对抗机器学习技术并没有被滥用。</p> 
<p>硅星人的读者可能还记得我们之前写过 DoNotPay 这家公司。作为“Compound Startup”的代表，DoNotPay<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODg4ODEwMA==&mid=2247496005&idx=1&sn=d70108053ea82f8f4a8ddfbb9c057cbc&chksm=eb529a8edc25139860e2b6068c59a14f58cb5b5d91fb6073529331ac9877a5b792933b569cf9&scene=21#wechat_redirect">只有一个手机app，却包含了上百种服务</a>，主要都是帮用户省钱的，比如自动申诉交通罚单、切断自动续费服务、起诉电信诈骗、快速生成一次性信用卡、自动撰写各种法律文书等——堪称一个“掌上维<a class="project-link" data-id="3804" data-name="权大师" data-logo="https://img.36krcdn.com/20210422/v2_d617bdbc4f36495682ce1d8ec1372fab_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4775900200" target="_blank">权大师</a>”app，资费只有$3/月。</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_4a0d3d1a33604d30972c85a62ca74a0e_img_000" data-img-size-val="1080,602" referrerpolicy="no-referrer"></p> 
<p>至于 Photo Ninja，该公司宣称，在面对亚马逊、<a class="project-link" data-id="3967413" data-name="微软" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3967413" target="_blank">微软</a>、谷歌等主流公司开发的相关人脸识别系统时，这项照片反识别技术都能够取得大约99%的成功率。</p> 
<p>当然，Photo Ninja 也并非没有势均力敌的对手。Clearview AI 是一家专注监控市场的 AI 公司，跟全美上千家执法部门都有合作。DoNotPay 的 CEO Joshua Browder 表示，Photo Ninja 没法保证能够骗过 Clearview AI 的技术。</p> 
<p>这可能是由于，Clearview AI 早就从互联网的公开渠道抓取保存了超过30亿张的人脸照片，数据<a class="project-link" data-id="629729" data-name="量之" data-logo="https://img.36krcdn.com/20201107/v2_e8475c59dec2413fb14114f385aed6d9_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/629729" target="_blank">量之</a>大，甚至超过美国政府和其它硅谷大公司的程度（该公司也因此饱受舆论争议。）</p> 
<p>随着对抗机器学习技术的推进，攻击和防御的手段也都在进步。不排除有可能，该公司已经对照片进行过修改测试，开展过对抗攻击演练，然后进一步调整自己的识别算法——真是魔高一尺道高一丈啊！</p> 
<p>去年，Clearview AI 自曝数据库被入侵，包含600多家客户的名单泄露。人们担心，拥有如此海量数据的一家监控公司，如果下一次整个图片数据库也失守，结果只会更加严重。</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_075f7c1804ff4f9696613768ec8263e1_img_000" data-img-size-val="959,639" referrerpolicy="no-referrer"></p> 
<p>回到文章开头所提出的那个情况。确实，这个年代想要安全地网上冲浪，简直有太多需要顾虑的东西了。那么，怎样才能继续发自拍，但又不用担心被不怀好意者嗅探隐私呢？以及，如果把范畴扩大到现实生活中，摄像头已经无处不在，还有什么办法，可以让我们至少在需要的时候，不被人脸识别系统抓到，保留最后的那一份隐私呢？</p> 
<p>所幸，还有很多方法能够帮助我们避开人脸/图像识别系统，从软件/硬件思路出发的都有，而且成本并不算高。</p> 
<p>去年，<a href="http://mp.weixin.qq.com/s?__biz=MzI3ODg4ODEwMA==&mid=2247495602&idx=1&sn=c5b75578d981d8163b8f2df860631400&chksm=eb528479dc250d6f96f1664f41efb96a464a22c36bd614b7e2db1551317ba538b51618f76dd5&scene=21#wechat_redirect">硅星人也有一篇文章简要介绍过几种能够让你在人脸识别系统里“隐形”的手段。</a>今天，我们也可以分享更多的类似技术。</p> 
<h2 label="一级标题" style>“假脸” HyperFace</h2> 
<p>2017年圣丹斯电影展上，一群女性开发者展示了一款能够骗过人脸识别系统的围巾。当然，围巾只是一个用于展示技术的原型产品，我们今天仅仅介绍这项技术。</p> 
<p>在人脸识别算法“看来”，是有一种最理想化的人脸表达样式存在的（大概和下图差不多）：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_22ebb0fa6983402d93a18968939a9878_img_000" data-img-size-val="700,818" referrerpolicy="no-referrer"></p> 
<p>而如果把这种样式变成图案，印制在围巾、帽子、上衣上，人脸识别系统就会过于关注这些图案，反而避开真实的人脸。如下面这张热力/显着图显示，高亮的区域是人脸识别系统最为关注的地方。</p> 
<p>也就是说，HyperFace 的工作方式，是把人脸识别系统的注意力“带偏”。</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_eb428a6f645b4fab9e4a3a9119247269_img_000" data-img-size-val="960,651" referrerpolicy="no-referrer"></p> 
<p>不过，仅就上面这个图案来说，它的有效性已经不是很高了，因为这个图案针对的是 OpenCV，而更新的人脸识别技术会采用卷积神经网络等更加复杂的算法，对应的图案也不一样，而且就算图案做出来了，效果也无法被保证。开发团队成员 Adam Harvey 也在项目网站上澄清，HyperFace 的原型图案已经过时。</p> 
<p>但是，HyperFace 背后的技术思路还是行得通的。如果感兴趣的话，你可以自己找一些类似的图案，印在围巾上衣甚至口罩上试一试（毕竟疫情过后，一些人脸识别系统已经可以仅靠眼部露出的特征完成识别，口罩已经不能骗过它们了，甚至带着口罩都能解锁 iPhone。）</p> 
<p>“变脸” URME Surveillance</p> 
<p>很多人应该都看过吴宇森的《变脸》，剧情中 FBI 探员为了打入犯罪团伙内部，自愿和恐怖分子换脸，结果恐怖分子清醒后又抢走了探员的脸……</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_b4740056e99c433eb104f4de87e869ff_img_000" data-img-size-val="1080,608" referrerpolicy="no-referrer"></p> 
<p>这样的剧情在现实中不太可能出现。不过，一位艺术家 Leonardo Selvaggio 愿意把他的脸借给你，让你每天以他的身份招摇过市，让他来替代你承担隐私泄露的风险……</p> 
<p>Selvaggio 对自己的脸进行了高精度扫描，然后生产出超高还原度的面罩，放到网上销售，价格$200。他把这个项目称为 URME（你就是我）</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_de9a8f3a29894ac2b87ff7517cfdda51_img_000" data-img-size-val="1080,361" referrerpolicy="no-referrer"></p> 
<p><img src="https://img.36krcdn.com/20210506/v2_0d26dead15474d7580aa53fa2aa77ed7_img_000" data-img-size-val="400,400" referrerpolicy="no-referrer"></p> 
<p>很遗憾，生产面罩的公司 ThatsMyFace 后来破产了，Selvaggio 还没有找到替代的生产商。不过与此同时，用户也可以下载脸图的平面版，自己打印出来戴上，只是看起来很假而已……</p> 
<p>所以本质上讲，URME 并没有对人脸识别系统带来什么根本性的打击，只是用一个假身份去替代佩戴者的真实身份而已。</p> 
<p>当然了，甭管<a class="project-link" data-id="362555" data-name="黑猫" data-logo="https://img.36krcdn.com/20201112/v2_df3a3e1bcdba48a29f4e02324dc2a81e_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/362555" target="_blank">黑猫</a><a class="project-link" data-id="3969020" data-name="白猫" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3969020" target="_blank">白猫</a>，能抓老鼠就是好猫……</p> 
<p>红外光</p> 
<p>前面我们提到，破坏掉人脸识别系统追踪的特征，就可以让这类系统失灵。和 Photo Ninja 低调的操作相比，红外光在破坏特征方面更加简单和暴力。</p> 
<p>1）2018年，复旦、港中文、印第安纳大学和<a class="project-link" data-id="7133" data-name="阿里巴巴" data-logo="https://img.36krcdn.com/20201030/v2_504c85fa199d4413a7f31069f7faa667_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/7133" target="_blank">阿里巴巴</a>共同发表了一项研究，在帽子上加装红外 LED，对着人脸，不仅能够骗过人脸识别系统——如果对 LED 灯的照明位置、方向进行细微的调整，从而扭曲佩戴者的面部特征，甚至还能让人脸识别系统以为佩戴者是其他人，如下图：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_f7c414c2c6c74e409f7cab026019d8dc_img_000" data-img-size-val="716,537" referrerpolicy="no-referrer"></p> 
<p>2）日本国立情报学研究所的一位教授，做了一个更加直接方案，把红外 LED 等直接放到眼镜上。LED 开启，人脸识别算法就无法将正确的区域识别为人脸了：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_2d21a19e51854e53ade0ae359f0ad569_img_000" data-img-size-val="400,225" referrerpolicy="no-referrer"></p> 
<p>3）考虑到很多监控摄像头本身就在使用红外光进行照明，那么直接把眼镜的框架和镜片加入红外反射材料，会产生一个巨大的光斑，也能够达到反监控的效果。</p> 
<p>Phantom 就是这样一款眼镜，由美国人 Scott Urban 制作并在 Kickstarter 上发布，售价$148，去年10月底已经发货。当你带着这副眼镜，其它人看到的你还是正常的样子：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_39762cf66c184b2eb49229944a879535_img_000" data-img-size-val="1000,1101" referrerpolicy="no-referrer"></p> 
<p>然而在红外摄像头拍到的画面中，你看起来像神一样：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_0cc964c896b64400a4422bebdb454209_img_000" data-img-size-val="768,433" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题" style>“魔性”贴纸</h2> 
<p>三位比利时科学家曾经做过一个有趣的实验：只是在身上加了一块怪异的贴图，在计算机的眼里，人就不再是人了：</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_bca359e4987847088aabebc7aec8c1d4_img_000" data-img-size-val="627,456" referrerpolicy="no-referrer"></p> 
<p>这个方法同样利用了本文前面提到的对抗机器学习，只是效果更肉眼可见而已。或者换一种说法：这个方法更好地解释了基于图片的对抗攻击方式的工作原理。出于某些原因，这些贴图会破坏了人形的特征，让识别系统无法正常工作。</p> 
<p><img src="https://img.36krcdn.com/20210506/v2_16e962844236452cb4d101773be092cb_img_000" data-img-size-val="1073,739" referrerpolicy="no-referrer"></p> 
<p>理论上，我们可以专门生产带有这类贴图印花的服装，穿上它走到监控摄像头面前，其实就跟隐形了一样……</p> 
<p>综上所述，想要骗过人脸识别系统和无处不在的监控摄像头，还是有很多种途径的。只是，随着监控技术的不断进步和大规模推广，无论是在网上还是在现实中，想要完全保持”匿名“只会变得越来越难。</p> 
<p>而就像本文一开始提的那个例子，在这样的环境中，那些监控技术滥用的受害者，并不一定是这些系统想要打击的坏人，反而更有可能是无辜者。</p>  
</div>
            