
---
title: '智能化时代，我们该相信人还是相信AI？'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://picsum.photos/400/300?random=3509'
author: 36kr
comments: false
date: Thu, 13 Jan 2022 01:47:27 GMT
thumbnail: 'https://picsum.photos/400/300?random=3509'
---

<div>   
<blockquote> 
 <p><strong>内容来源</strong>： 2021年12月19日，由苇草智酷主办的第五届互联网思想者大会——新人机世界：重新定义生产。</p> 
 <p><strong>分享嘉宾：</strong>胡泳， 北京大学新闻与传播学院教授，苇草智酷创始合伙人。</p> 
 <p><strong>注</strong>：笔记侠作为合作方，经主办方审阅授权发布。</p> 
</blockquote> 
<h2><strong>一、预测的魅力与悖论</strong></h2> 
<p><strong>1.变革的世纪</strong></p> 
<p>首先，我们从英国作家伊恩·莫蒂默（Ian Mortimer，历史学家、作家）的一本书谈起，我把书名翻译成《变革的世纪》（Centuries of Change，国内出版名为《欧罗巴一千年：打破边界的历史》）。</p> 
<p>这位作家在书中阐述了，人类在过往的历史长河中，每个世纪所发生的重要变革。</p> 
<p>我们可以简单地罗列一下：</p> 
<blockquote> 
 <p>11世纪：城堡；</p> 
 <p>12世纪：法律和秩序；</p> 
 <p>13世纪：市场；</p> 
 <p>14世纪：瘟疫，横扫欧洲的黑死病；</p> 
 <p>15世纪：哥伦布；</p> 
 <p>16世纪：个人暴力的减少；</p> 
 <p>17世纪：科学革命；</p> 
 <p>18世纪：法国大革命；</p> 
 <p>19世纪：通信。</p> 
</blockquote> 
<p>20世纪是人类历史上翻天覆地的世纪，它最重要的变革是什么？</p> 
<p>在这个世纪中，人类爆发了两次世界大战，美国向日本广岛投下了原子弹，人类实现登月，还有发明互联网等。</p> 
<p>但作者给出的答案出乎意料，20世纪最重要的变革是：发明未来。</p> 
<p>现在，预测我们生活中会发生的变化，已成为常态。</p> 
<p>比如，出门前，我们会查看当天的天气预报。炒股时，我们会关心股市大盘的走向。买卖房屋时，会关注房价的涨跌趋势。</p> 
<p>伊恩·莫蒂默认为，人类到20世纪才真正开始思考未来。换言之，到这个世纪，我们才第一次讲述关于未来的事情，远远超过讲述已经发生的事情。</p> 
<p>为此，人类中出现一个崭新的群体，我们称之为“未来学家”。</p> 
<p><strong>2.未来学家</strong></p> 
<p>这样的未来学家，我深度接触过的就有两位。</p> 
<p>第一位，尼古拉·尼葛洛庞帝（NicholasNegroponte，美国计算机科学家）。我翻译过他的著作《数字化生存》（Being Digital）。</p> 
<p>第二位，戴维·温伯格（David Weinberger，哈佛大学伯克曼互联网与社会中心资深研究员）。我也有幸翻译了他的书籍《知识的边界》（Too Big to Know）。</p> 
<p>2019年，戴维·温伯格出版了一本新书Everyday Chaos。中信出版社今年1月份会出版这本书的中文译本，书名为《混沌：技术、复杂性和互联网的未来》。温伯格强调的混沌不是一种理论上的东西，而是日常<a class="project-link" data-id="45684" data-name="生活里" data-logo="https://img.36krcdn.com/20210807/v2_d5eabe9ba08e4d78af7070062cddb963_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/45684" target="_blank">生活里</a>面普遍存在的事物，所以他叫做“日常的混沌”。</p> 
<p>温伯格在这本书里讨论了人工智能、大数据、现代科学和互联网，这些都在揭示一个基本事实——世界比我们所看到的复杂得多，也难以预测得多。</p> 
<p>这就产生了一个严重的悖论。温伯格是以预测为生，在这本书中他却承认，预测并不见得有用。</p> 
<p>他认为，有关网络的声音，并没有以言说者期待的方式改变世界。商业和技术总是比预言家更快。</p> 
<p>这是由于，世界的不可预测性增加了。正是“深不可测的复杂性”令我们开始启用人造的机器来打破预测的旧界限。</p> 
<p><strong>3.“温伯格之问”</strong></p> 
<p>20世纪，预测深入了我们的基因，我们特别热衷于预测。但对预测，我们需要讨论两个问题。</p> 
<p>第一，世界的不可预测性空前增加。</p> 
<p>各种各样的因素，导致不确定性增加、风险加大，因此很难预测世界的发展。</p> 
<p>第二，人类的预测是不是可欲的？</p> 
<p>如果人类真的可以预测未来，这是不是我们想要的？即使它可行，但是否可欲？</p> 
<p>这两个问题，我们需要认真地思考。</p> 
<p>因为，预测方式的故事，也是我们对世界运行方式理解的故事。换而言之，这牵扯到人类的核心认知问题。预测在眼下已经变成我们认知的一个基本工具。</p> 
<p>人是一种能够理解世界运行机制的特殊生物。若该假设不再成立，宇宙就从可知的变为不可知的。在此基础上，温伯格提出了更深刻的问题，来自西方文明的两大源头。</p> 
<p>第一，希伯来文明。</p> 
<p>从希伯来文明诞生后，产生一种强烈的认知，人类作为上帝创造的独一无二的杰作，可以通过启示发现真理。</p> 
<p>第二，古希腊文明。</p> 
<p>古希腊时期，认为人类是理性的思考者，可以发现这个世界混乱表象下的基本逻辑。</p> 
<p>今天，通过更深的挖掘。温伯格提出了以下问题，我把这些问题称作“温伯格之问”。</p> 
<p>第一，如果我们发现，我们不仅不知道自己不知道的东西，我们也不理解自己认为知道的东西，那会如何？</p> 
<p>第二，如果我们需要放弃对这个世界的理解，我们对不可解释的事情，也需要从不接受到接受，那又会如何？</p> 
<p>这两个富有挑战性的问题，是我们今天讨论的核心。我们先聚焦温伯格，来看一下他是如何理解这些问题的。</p> 
<h2><strong>二、不是预测未来，而是创造可能性</strong></h2> 
<p><strong>1.人类为何喜欢预测未来</strong></p> 
<p>说到预测未来，如果把时间拉回过去，在人类历史上，总会在特定时刻出现一些特定的人，他们向全世界宣告，这个世界的运行不是我们想的那个样子，也不是我们想要的那个结果。</p> 
<p>我们耳熟能详的牛顿、爱因斯坦、哥白尼、达尔文，甚至弗洛伊德，都扮演过这类角色。</p> 
<p>而现在，温伯格似乎期待着人工智能（AI）来承担该角色。</p> 
<p>回到一个根本问题上，为什么人类对预测如此痴迷呢？</p> 
<p>人类热衷预测的原因很简单，未雨绸缪。</p> 
<p>我们喜欢提前了解所有的可能性，并为它们做准备。这会形成三种结果。第一，准备过度；第二，准备不足；第三，准备不当，即准备的东西没有用。人类经常犯这三种错误。</p> 
<p>假如上述这三种情况发生，社会就不得不承担巨大的成本。</p> 
<p><strong>2．用AI预测</strong></p> 
<p>为什么要发明AI？因为机器可以替人类更好地作出预测。如果机器预测得足够精准，我们可以避免人类所犯的三种过失。机器可以让我们的准备恰如其分。</p> 
<p>我们要把预测的行使权从人类的手中，转交到机器手中。现在，这种情况正在发生。</p> 
<p>举个例子，纽约某医学院的研究人员做了一个机器学习系统，我们可以把这个系统理解为一个“吞吃数据的庞大怪物”。</p> 
<p>他们往这个系统里输入了70万份病例，这是非常庞大的数据量。有意思的是，研究人员并不下达指令，而是让系统无限制地找出它能做的事情。</p> 
<p>结果，被称之为“深度患者”的医疗诊断系统，作出的诊断与预测的准确性，远远超出人类医生。</p> 
<p>唯一的问题在于，作出诊断后，系统无法解释它是如何诊断的，为什么给出这个诊断。用行业术语来说，这是一个“黑盒子”（指从用户的观点来看一个器件或产品时，并不清楚其内部构造和原理，只关心它的功能及如何使用这些功能）诊断系统，但是它的确比人类医生更精准。</p> 
<p>“深度患者”只是深度学习的一种。所有的深度学习，本质都是“黑盒子”。它的好处是不需要你理解，也不需要把世界简化为人类可以理解的层次。</p> 
<p>随着机器学习在全球的广泛应用与发展，混沌理论转向混沌实践，并将这一理论令人兴奋的想法应用于日常生活。</p> 
<p><strong>3.混沌实践</strong></p> 
<p>当混沌理论应用到日常生活后，可能会导致哪些结果？</p> 
<p>按照温伯格的分析，越来越多的事情不再基于预测开展，这种转向并非始于人工智能，而是从有互联网就发生了。</p> 
<p>各行各业都采取了那些完全避免预测未来的做法，我们来举一些例子。</p> 
<blockquote> 
 <p>柔性生产（以“制造系统响应内外环境变化的能力”建设为核心的生产方式与方法论）；</p> 
 <p>敏捷开发（是一种以用户的需求进化为核心、迭代、循序渐进的开发方法）；</p> 
 <p>A/B测试（是一种用数据进行产品决策的方法）；</p> 
 <p>最简可行产品（MVP，用最快、最简明的方式建立一个可用的产品原型）；</p> 
 <p>开放平台（Open Platform，比如微博、百度等）；</p> 
 <p>用户可修改的视频游戏（modding）。</p> 
</blockquote> 
<p>这些事情并不需要预测，只需找到一种方法来验证某个想法是否可行。而且这些事的可行度相当高，最后的结果也能够达到要求。</p> 
<p>温伯格甚至极而言之地说：“过去20年日新月异的发明与革新，都不是通过预测完成的。恰恰相反，是为了避免预测未来而做的。”</p> 
<p>因此，他得出一个结论：互联网没有试图预测未来并为其准备，而是通过创造更多深不可测的可能性来造就我们的繁荣。</p> 
<p>至此，基本的认知模型已被颠覆，人们有了新认知的可能性。</p> 
<h2><strong>三、用战略创造更多可能性</strong></h2> 
<p><strong>1.线性思维的局限性</strong></p> 
<p>我们如何把温伯格的理论应用在企业战略上？战略的目的就是要做长期的准备，通过对未来的精心设计，来决定企业下一步的方向。</p> 
<p>企业计划的核心，是在众多可能性中，找到资源最匹配的可能性并全力以赴，把赌注押在这个可能性上。因此，战略的本意是缩小可能性。</p> 
<p>其实，当认知模型转换后，要把它应用在企业经营当中。我们的最佳战略，往往需要尽可能地忍住不去预测。</p> 
<p>以前，一些规模化公司把战略理解为3-5年的长期规划。现在，却只做半年的计划。</p> 
<p>这意味着什么？我们通常的战略思维是一个线性思维，战略规划被视为一种限制性操作，它先识别可能性，并选择企业想要实现的可能性。</p> 
<p>举个例子，在过去企业界，甚至国际政治中，场景规划（Scenario Planning）是一种广泛应用的战略制定方法。</p> 
<p>曾经被视为顶尖的战略规划思路的场景规划，是否完美无缺？</p> 
<p>我们设想出，关于一个组织或者国家，可能有几种未来的发展，比如崩溃或者繁荣，我们通过几个可能发生的场景来规划未来故事。为了避免崩溃场景的出现，或者为了让繁荣的场景能够实现，我们基于这些思考来制定战略规划。</p> 
<p>其实这是一种非常典型的线性思维。不论线性思维把世界规划成几种方案，它都受限于一种错误的世界观，世界的可能性远远超过这些方案。比如新冠肺炎疫情，它暴发前，不会出现在任何战略图上。</p> 
<p>我记得参加达沃斯世界经济论坛时，遇到很多有意思的参会者。他们不仅讨论经济问题，甚至一些历史学家，针对“为什么没有人预测到苏联的解体”展开激烈的辩论。</p> 
<p>作为历史学家，为什么预测不到？因为他们都是线性思维的信奉者。线性思维可以增加自身的复杂性维度，但是它无论趋向多么复杂，世界都不会有如其所愿的规则结构。</p> 
<p>所以，我们需要的是非线性思维。</p> 
<p><strong>2.非线性思维</strong></p> 
<p>我们举个例子，我非常推崇丽塔·麦克格拉斯（Rita Gunther McGrath，全球知名战略专家）写的《瞬时竞争力：快经济时代的6大制胜战略》（The End of Competitive Advantage，也叫《竞争优势的终结》）。</p> 
<p>书中剑锋直指战略界鼎鼎大名的迈克尔·波特（Michael E.Porter，美国“竞争战略之父”）。迈克尔·波特提出，企业都要追求“可持续竞争优势”。</p> 
<p>麦克格拉斯则认为，根本没有所谓的可持续竞争优势，唯一可以做的就是“持续重构战略”。</p> 
<p>这种战略的理解，要求公司必须对环境中的任何变化保持警惕，拥有特定的组织结构和文化，使其能够通过脱离当前的轨迹来作出反应，及时抽身，从而创造一个新的轨迹。这就是非线性思维。</p> 
<p>生活中所有场景都告诉我们，一定要关注大的变化趋势。但是，麦克格拉斯理论认为，任何微小的变化都可能颠覆我们的生活。关注大的变化，也无法保证我们可以持续地重构。</p> 
<p>所以，混沌状态下的战略，应转变思路，不是缩小可能性，而是尽量去创造更多的可能性。</p> 
<h2><strong>四、以预测准确性为目标，但放弃可解释性</strong></h2> 
<p><strong>1.接受不可理解</strong></p> 
<p>接下来我要进入问题的核心，即我们能不能完全地以预测的准确性作为目标，而放弃可解释性。人类有没有勇气，去接受那些超出我们理解能力的系统。</p> 
<p>比如，把路线导航的任务全部交给<a class="project-link" data-id="28215" data-name="百度" data-logo="https://img.36krcdn.com/20210806/v2_f96267de58b643faae02c0cb24debbed_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/28215" target="_blank">百度</a>或高德，让它们帮助我们寻找最佳路线。像出租车行业，以前的出租司机都以熟悉大街小巷为傲。现在，不论驾驶员，还是乘客，都会形成默契，按导航行驶，把线路规划的任务交给系统。</p> 
<p>温伯格在此扮演了AI代言人的角色，为了让机器更好地发挥潜力，他建议我们接受超出我们理解能力的系统，这些系统只需要以预测准确性为目标，而无须保证可解释性。</p> 
<p><strong>2.底线价值观</strong></p> 
<p>当然，温伯格同样意识到，如果把我们的日常生活全部交给AI，AI出错了怎么办？算法本身有偏见怎么办？AI没有伦理怎么办？因此，他提出了底线价值观。</p> 
<p>如果不加以控制，系统很可能以最残酷的方式对待最弱势的群体。比如对外卖骑手进行系统压榨。</p> 
<p>人工智能系统需要底线价值观。然而，人类关于价值观的讨论，往往是混乱、不精确和争论不休的。</p> 
<p><strong>3.人应该向机器投降吗</strong></p> 
<p>如果人类关于价值观的讨论无法达成统一，是否应该停止向机器输入人的价值观？</p> 
<p>其实，温伯格在暗自敦促人类向机器投降。</p> 
<p>我们为什么要向机器投降？这有两个前提。</p> 
<p>第一，机器会越来越多地接手人类事务。这似乎是一个无法阻挡的趋势。</p> 
<p>第二，机器本身可能教会我们新的伦理。</p> 
<p>比如自动驾驶的新伦理。麻省理工做了一项大规模的调查，当面对复杂情况的时候我们会选择如何驾驶，通过人们的选择，来训练自动驾驶汽车作出相应的选择。</p> 
<p>在这个过程中，机器遇到千奇百怪的情况，与此同时，会给我们带来更多新的可能性。</p> 
<p>因此，温伯格其实是在说：机器不光是我们的管家，某种程度上，还可以扮演我们的导师。</p> 
<p>也正是这个观点，使我对他的论述产生了怀疑。</p> 
<h2><strong>五、人类面临的选择</strong></h2> 
<p>以上的内容，都是温伯格逻辑的延展，接下来分享一下我对温伯格之问的回应。</p> 
<p><strong>1.AI时代的知识</strong></p> 
<p>毋庸置疑，人工智能的未来关键在于，到底我们应该放弃理解，还是致力于建立可以理解的人工智能？这样的问题将把我们带向人工智能算法研究的前沿。</p> 
<p>《知识的边界》讨论的是网络化知识，我个人非常喜欢这本书。不仅是因为我翻译了这部著作，更是因为这本书具有入木三分的洞见，解释了知识在网络时代的延展。因此，我姑且把温伯格的《混沌》理解为，他在讨论AI时代的知识。</p> 
<p>我把温伯格对AI时代知识的理解，归纳为以下几点：</p> 
<p>第一，人类努力获得对复杂系统的理解。然而，我们基于“人类的理解”所作的预测没有像人工智能那样准确。虽然人工智能并不真正理解任何东西，但它确实比我们预测的要准确。</p> 
<p>第二，因为基于人工智能的预测比基于人类理解的预测更准确，我们应该放弃对理解的追求，而专注于建立能够为我们做决定的人工智能。正所谓鱼与熊掌不可兼得，这种选择势在必行。</p> 
<p>第三，一旦将主导权交给预测性的人工智能，我们将迎来人类进化的下一个阶段。</p> 
<p><strong>2.AI“可理解性”的两种观点</strong></p> 
<p>支持温伯格这些观点的大有人在。关于AI可理解性的讨论分为两派。</p> 
<p>第一，认为建造根据规则和逻辑进行推理的机器是最有意义的事。我们可以通过透明的代码，检查它的内部运作。面对机器的时候，人仍然是上帝。</p> 
<p>第二，如果机器可以从生物学中获得灵感，并通过观察和体验来学习，那么智能将更容易出现。</p> 
<p>基于发展速度的原因，我们今天采用人工智能的发展路径，恰恰是第二种。人工智能系统的机器学习，基本上是自己编程。</p> 
<p>我在大学教书，很多人经常问我，未来是不是每个人都要会编程？孩子要不要做程序员，这样才不会失业？这种想法没有与时俱进。</p> 
<p>几年前，程序员执行的是上帝的角色，我们想让机器干什么，编个代码，它就遵照我们的指令来执行。</p> 
<p>如今，程序员更像是驯兽师，训练机器，机器自己学习。未来，大部分程序员将被淘汰，真正的驯兽师是少数的程序天才。<strong>3.对“黑盒子”的信任问题</strong></p> 
<p>一旦面对“黑盒子”，就产生了人对系统的信任问题。这也是我演讲的主题，我们是相信人，还是相信机器？</p> 
<p>人类的信任往往基于我们对其他人如何思考的理解，以及对这些思考的可靠性的经验了解。</p> 
<p>AI对于大多数人来说，仍然是相当新颖和陌生的。同自己不明白的事情互动，会引起焦虑，并使我们感觉自己失去了控制。</p> 
<p>比如，对于AI医生诊病，我们会在多大程度上信任这位医生？如果AI医生只告诉我们病症，但不能解释病因，我们是否能够接受？</p> 
<p>还有一个麻烦群体，人类医生。AI医生应运而生，人类医生该何去何从？</p> 
<p>那时，对AI的诊断就会产生两种反应。</p> 
<p>第一种，如果AI医生诊断结果跟人类医生一致，那么人类医生会问，AI医生的存在有何意义？</p> 
<p>第二种，如果AI医生诊断结果跟人类医生不一致，那更糟了，人类医生会说，AI医生不能解释为什么这样诊断，无法证明自己的准确性，我为什么要听从它？</p> 
<p>我们再举一个例子，芯片制造商<a class="project-link" data-id="3969182" data-name="英伟达" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3969182" target="_blank">英伟达</a>推出的自动驾驶汽车。</p> 
<p>它与<a class="project-link" data-id="3968996" data-name="谷歌" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968996" target="_blank">谷歌</a>、<a class="project-link" data-id="132410" data-name="特斯拉" data-logo="https://img.36krcdn.com/20200729/v2_e76e3d3d44c440138f072b13bc84a6dc_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/132410" target="_blank">特斯拉</a>的车截然不同，这款汽车彰显人工智能的崛起，完全依靠算法。这种算法通过观察人类的行为，学会自己驾驶。所有的传感器将数据传入人工<a class="project-link" data-id="295888" data-name="神经元网络" data-logo="https://img.36krcdn.com/20210810/v2_048a53bb10114fe085453fce5a0804d8_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/295888" target="_blank">神经元网络</a>加以处理，然后提供操作方向盘、刹车和其他系统所需的命令。驾驶完全由机器自己操作。</p> 
<p>大部分时候，它表现不错，跟驾驶车辆的司机行为相差无几。但是，也可能会遇到一些问题，比如，遇到绿灯，却停滞不前，或者突然驶向大树。</p> 
<p>它似乎就是按照逻辑演算进行操作，但是没有办法与它交流，不存在可解释系统。如果有一天它做出一些出乎意料的事情，按现在的情况，我们可能很难找到它出错的原因。</p> 
<p><strong>4.重新理解技术</strong></p> 
<p>未来，这些问题会越来越广泛地出现在各个领域。那么，我们该如何来理解技术？</p> 
<p>我这里引用麻省理工学院研究机器学习应用的教授托米·贾科拉（Tommi Jaakkola）的话，“这是一个已经凸显意义的问题，而且在未来它将变得更有意义，无论是投资决策、医疗决策，还是可能的军事决策，你都不希望仅仅依靠‘黑盒子’方法解决问题”。</p> 
<p>反对者天天强调，机器不可理解。如果一个人做出来影响千百万人的决定，他是否能够给你解释清楚缘由？</p> 
<p>实际上，我们最后会回到一个微妙的地方，智力性质的特点。智力只有一部分被暴露在理性解释之下。而另外一些是本能的、潜意识的，或不可捉摸的。</p> 
<p>如果我们意识到智力的特点，面对人工智能的判断，人类面临两种选择。</p> 
<p>第一，完全选择相信，这是温伯格给我们提出的建议。</p> 
<p>第二，如果不理解，就不使用。</p> 
<p>相信或者不使用，这种判断将不得不纳入社会智能。换言之，我们要有社会规范，才能决定路径的选择。</p> 
<p>对于机器可理解性，表示支持的不乏其人。</p> 
<p>著名的哲学家丹尼尔·丹尼特（Daniel Dennett）说过：“如果我们要使用这些机器并依赖它们，那么让我们尽可能坚定地掌握它们是如何和为什么给我们答案。如果没有完<a class="project-link" data-id="131482" data-name="美的" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/131482" target="_blank">美的</a>答案，我们应该对人工智能的解释持谨慎态度，就像人类对彼此的解释一样。无论机器看起来多么聪明，如果它们不能比我们更好地解释它在做什么，那么就不要相信它。”</p> 
<p>这是一个很坚定的观点。</p> 
<h2><strong>结尾</strong></h2> 
<p>最后，我阐述一下我的观点，应用人工智能有三个应用条件：</p> 
<p>第一，一定要打开“黑盒子”，让AI能够解释自己所做的事情。</p> 
<p>第二，致力于发现与减轻训练算法和数据中的偏见。我们现在是按照机器编程的想法在走人工智能之路。如何训练，变得至关重要。</p> 
<p>第三，为人工智能系统赋予伦理价值。</p> 
<p>所有人都要深刻地认识到，机器学习的兴起是人类历史上最重大的变革之一。越来越多的机器学习模型将成为我们的知识库，就像图书馆和人类的头脑一样。</p> 
<p>然而，机器学习模型里没有知识，这将意味着我们需要重新思考知识的性质与用途，甚至重新思考作为能够了解自己世界的生物，我们到底是谁？</p> 
<p>我的分享就到这里，谢谢大家！</p> 
<p>*文章为作者独立观点，不代表<a class="project-link" data-id="96519" data-name="笔记侠" data-logo="https://img.36krcdn.com/20210807/v2_7a22d77fdb1e4535a1be7600e96c0de3_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/96519" target="_blank">笔记侠</a>立场。</p> 
<p>本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer" href="http://mp.weixin.qq.com/s?__biz=MzIxNTAzNzU0Ng==&mid=2654750862&idx=2&sn=2c25217acdf36087a53586a6c83eff55&chksm=8c568b8bbb21029d8123f8de3fdd4100423ee26a74a98a373a50c5d033b787aba0d650ccb098#rd">“笔记侠”（ID：Notesman）</a>，笔记达人：桃之夭夭，轮值主编：智勇，责编&值班编辑：少将，36氪经授权发布。</p>  
</div>
            