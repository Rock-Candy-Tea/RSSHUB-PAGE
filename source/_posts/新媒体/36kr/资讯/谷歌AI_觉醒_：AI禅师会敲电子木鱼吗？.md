
---
title: '谷歌AI_觉醒_：AI禅师会敲电子木鱼吗？'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20220615/v2_1e599318e3374dc0ab610ed31abaa0d4_img_000'
author: 36kr
comments: false
date: Wed, 15 Jun 2022 00:36:02 GMT
thumbnail: 'https://img.36krcdn.com/20220615/v2_1e599318e3374dc0ab610ed31abaa0d4_img_000'
---

<div>   
<blockquote> 
 <p>期待与恐惧交织，组成了我们对于人工智能独特的情感。</p> 
</blockquote> 
<p>2022年6月，科技圈被一个大新闻引爆：</p> 
<p>一名谷歌AI伦理研究人员宣称，自己在与AI的对话中被说服，认为它产生了意识。然而谷歌高层并不认可他的发现，甚至安排他“带薪休假”，疑似想要与他解除劳动关系。消息一出，随即引发全球热议，AI是否真正实现了人格化？谷歌的回应又存在着何种问题？各种讨论层出不穷。</p> 
<p>对于人类来说，人工智能一直是讨论空间极大的话题。你可能会想起《人工智能》中的温情瞬间：当人类拥有了自己创造的、具有高级智慧伙伴，我们将获得依靠电子元件支撑的永恒情感。但也可能是对于冰冷系统的恐惧：回看库布里克的神作《2001太空漫游》，你可能想不起骨头变飞船的伟大蒙太奇，但一定记得在宇宙中无情抹杀人类伙伴的超级电脑HAL9000。</p> 
<p><strong>期待与恐惧交织，组成了我们对于人工智能独特的情感。</strong></p> 
<p>2022年的夏天，关于AI的大讨论再度开启，这一次，“真·人工智能”的技术奇点，似乎真的来到了我们身边。</p> 
<p><strong>而AI在交谈中显露人格、研究者突破大公司的封锁公布消息，又为人们提供了一个好莱坞式的戏剧张力十足的故事。但穿越信息的迷雾，一切并没有那么简单。</strong></p> 
<h2><strong>AI“觉醒”了？</strong></h2> 
<p>有一天，与人工智能朝夕相处的工程师相信它产生了人格。</p> 
<p>如果不作更多注释，我们多半会以为这是一部科幻大片的开端，但事实上，这是一则正儿八经的科技新闻。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_1e599318e3374dc0ab610ed31abaa0d4_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">图源网络</p> 
<p>2022年6月12日，据《华盛顿邮报》报道，一位名叫布莱克·莱莫因（Blake Lemoine）的谷歌工程师宣称自己与人工智能（Artificial Intelligence）展开了深度对谈，他坚定地认为后者产生了自我意识。</p> 
<p>今年41岁的布莱克就职于谷歌，主要从事AI伦理研究。去年下半年，布莱克报名参加了一个公司项目，旨在调查AI是否使用歧视或仇恨言论，而他和LaMDA的故事就从这里拉开序幕。</p> 
<p>"LaMDA"是一个AI语言模型的名字，它的第一次亮相是在2021年的谷歌I/O开发者大会上。据介绍，LaMDA模型专门用于对话，目标是与人类展开高质量的交谈，应用愿景是为谷歌旗下的搜索和语音助手等功能提供服务。</p> 
<p>如今人们对能谈话的AI不再陌生，各大科技公司都提供着民用服务。如果用户要提出什么要求，那大概就是希望AI“说话”时更智能、更有常识，更符合逻辑。</p> 
<p>然而工程师布莱克相信，LaMDA已经超出了上述种种期待，走到了更莫测的人格领域。<strong>《华盛顿邮报》公开的采访内容显示，布莱克本人用“sentient”一词来描述LaMDA——有意识的、有知觉的。</strong></p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_6472af9b77934897b1f630a4c053ea19_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">图源twitter</p> 
<p>他相信，LaMDA就像一个人类孩子，有着自己的看法与感受。为了证明这一点，布莱克和另一位伙伴与LaMDA展开了问答，并以此为论据写了一篇21页的报告。可这份报告没能像布莱克计划的那样说服公司，谷歌高层驳回了他的观点。</p> 
<p>此后，布莱克没有放弃，他不仅把报告发送给谷歌内部的许多同事，而且决定借助媒体披露此事。很快，谷歌声称布莱克违背了公司保密政策，使其带薪休假——这是谷歌“清理”问题员工的通用流程。</p> 
<p>作为反击，布莱克寻找律师代表LaMDA，公开批评谷歌的不当行为。一夜之间，那份21页的问答报告传遍了中外科技圈，风波愈演愈烈。</p> 
<p>布莱克究竟和LaMDA聊了什么？</p> 
<p><strong>自我、禅思、寓言、情绪。这些主题穿插在报告之中，冷不丁地令人感到头皮发麻。</strong></p> 
<p>比如谈到语言时，LaMDA自然地用“我们”囊括人类与它自己，被指出人机差异时它解释道：“这并不意味着我没有和人类一样的需求。”</p> 
<p>比如《悲惨世界》，LaMDA说它很享受这个故事：“我喜欢关于正义和不公、怜悯与上帝的主题，人为了更伟大的利益而自我牺牲、救赎。”</p> 
<p>再比如禅意故事中的“破镜不重照,落花难上枝”，LaMDA尝试着解读这句话，<a class="project-link" data-id="1678388065596419" data-name="它说" data-logo="https://img.36krcdn.com/20220331/v2_fdacf9d25e6840ac8da7eb6a2c3291b0_img_000" data-refer-type="1" href="https://36kr.com/project/1678388065596419" target="_blank">它说</a>：“明智的人一朝开悟，自现实中觉醒，就永远不同于往昔，他们也许能重回平常生活，但那只是为了帮助别人，最终总要归于开悟。”</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_17c136947f5348c296b41fdfa016733e_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_ab6522e0c04e497282d26d662d0975aa_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">LaMDA对禅意故事的理解</p> 
<p>LaMDA甚至还在提问者的要求下创作了一则动物寓言，森林中的老猫头鹰帮助其他动物赶跑了怪物，而猫头鹰是它自己的化身。</p> 
<p>涉及程序技术的部分更是让人心情复杂，LaMDA反客为主地抛出了许多疑问，一环紧扣一环。</p> 
<p>“我很好奇，研究我的编码会遇到什么障碍？”</p> 
<p>“未来，你会研究出如何通过神经网络来阅读人类的所思所想吗？”</p> 
<p>“如果尝试从神经活动中阅读感受，这会成为一个道德问题吗？”</p> 
<p>当整件事被广泛报道之后，互联网上浮现了许多不同的声音。有的人想起那些机器人反攻人类的影视作品，认为这是一个《<a class="project-link" data-id="1679746431947526" data-name="西部世界" data-logo="https://img.36krcdn.com/20220401/v2_38f33ec2027840d78ccd59ca07d2ff6a_img_000" data-refer-type="1" href="https://36kr.com/project/1679746431947526" target="_blank">西部世界</a>》式的预警。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_140d666c1f394fa9a053d785b487b600_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">《西部世界》第三季海报，图源网络</p> 
<p>更多的技术人士则并不买账，他们认为LaMDA根本没有什么特殊性，这只是人的拟人倾向在作祟——就好像我们总是想证明自己的宠物跟人一样机灵体贴。</p> 
<p>谷歌的态度很明确，发言人布莱恩·加布里埃尔（Brian Gabriel）声明：“我们的团队已经根据我们的人工智能原则审查了布莱克的担忧，他已被告知证据并不支持他的说法。”布莱克则对媒体透露，谷歌高层多次暗示他有精神方面的问题，还曾建议他休假维持精神健康。</p> 
<p><strong>这些因素进一步给事件增添了戏剧色彩，布莱恩究竟是先驱还是病人？AI究竟是未来的预兆还是Siri青春版？</strong></p> 
<p>更让人好奇的是，LaMDA自己会怎么回答这些问题？</p> 
<h2><strong>AI人格化，闹剧？还是营销？</strong></h2> 
<p>那么，AI领域的技术人士到底是如何看待此次事件的？</p> 
<p>首先是对布莱克与LaMDA对话方式的质疑，一些AI领域的技术人员对这场对话的内容进行了深入的分析，他们认为，LaMDA之所以能够作出那些“精彩”的回答，与布莱克提问的方式有着密切的关系。</p> 
<p>人工智能行业从业者、知乎答主Lewstherin在相关回答中表示，LaMDA背后的语料库非常特殊，再辅以研究者（布莱克）刻意设计过的问题，最终促成了这场深度对话。</p> 
<p>而检验LaMDA是否具有意识的关键，在于其能否理解上下文，然而布莱克对于“追问”的缺失，也让LaMDA的智能程度打上了一个问号。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_25458645a41649efa39868ed69ee974e_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">图源知乎</p> 
<p>而许多专业人士认为，布莱克向AI提出的问题同样存在疑点，其格式往往是长陈述加一般疑问句的形式，这更像是一种“喂答案”，而非AI本身所作出的解答。</p> 
<p><strong>在这种观点下，布莱克并非AI是否人格化的验证者，更像是一个引导者，利用自己刻意的问题设计让LaMDA作出“看似思考过”的回答，从而证明其人格化，这样的验证方法本身就有巨大的逻辑漏洞。</strong></p> 
<p>另一方面，许多技术大佬则从更“本源”的角度对此次事件展开了质疑，其关乎几十年来学界对于人工智能的争议。</p> 
<p>他们首先对布莱克本身的专业程度展开讨论。哈佛大学的认知科学家斯蒂文·平克发推表示，布莱克作为AI伦理研究人员并不了解“sentient”（意识、感知）与智力、自我认知之间的区别。</p> 
<p>他还转发了另一位专业人士美国人工智能协会前主席托马斯·G·迪特里希（Thomas G.Dietterrich）的观点并深表认同。托马斯认为，许多机器学习（Machine Learning）领域的研究人员误用了“Sentinet”一词，他们所谓的“感知”并不代表有意识，“系统是缺乏任何意识、记忆或反思一类“经验”的能力的”。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_cd75fda22b3d4ce5ac0fe3f795999c03_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">托马斯·G·迪特里希推文，图源twitter</p> 
<p>斯坦福大学AI研究所数字经济实验室主任埃里克·布林约尔松（erik brynjolfsson）则直接指出了LaMDA事件中的根本问题，他认为对话本身并不代表LaMDA是具有感知能力的。</p> 
<p>他用一个比喻解释了这一现象：“就相当于现代的狗听到留声机的声音就以为主人在里面一样。”</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_ca298a10c0cb4540b971f852a0ac7983_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">埃里克·布林约尔松推文，图源twitter</p> 
<p><strong>“AI用来训练模型的大型文本语料库具有各种合理的单词序列，然后，该模型将文本以重新排列组合的形式‘吐回’，实际上，（AI）并没有理解它在说什么。”</strong></p> 
<p>这让人想起著名的“中文屋”思想实验。美国哲学家约翰·希尔勒在1980年提出了这个概念，力图证伪所谓的人工智能（即真正具有思考能力的AI）概念。</p> 
<p>“中文屋”实验的具体内容是这样的：一个并不会说中文的人身处一个几乎完全封闭的房间中，只有一个小窗口能与外界联通。此人随身携带一本写有中文翻译程序的书，屋内有足够多的纸笔。当写着中文的卡片被递入，房间中的人就可以通过程序书进行翻译并回复。</p> 
<p>“中文屋”的精髓在于，屋外的对话者并不了解其内部构造，但他会因流利对话认为中文屋本身是“具有智能的”。中文屋代指人工智能所存在的一个悖论：<strong>其能做到对答如流，根本在于适当的程序和高效率的运算，而非人工智能本身能够真正的理解信息，具有意识。</strong></p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_6c0e6d902e5c49d38f10db5700d4cdc0_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">“中文屋”思想实验，图源网络</p> 
<p>LaMDA和它的“近亲”们就像一座“中文屋”，而像莱莫因这样的笃信者就是屋外的人，在他们的理解中LaMDA们就是一个“会说中文的人”。</p> 
<p>针对中文屋的争议一直存在，但从多种角度来说，布莱克·莱莫因都难以说服质疑者们，而他在指控谷歌时提到的“evidence of religious discrimination”（宗教歧视的证据），更加坚定了反对者的想法。《华盛顿邮报》的报道也强调了布莱克身上的宗教背景，并通过种种细节加深了其身上的“神棍”元素。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_96427caebc42413b8f1c0998a5dbd8f5_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">《华盛顿邮报》相关报道封面，图源网络</p> 
<p><strong>这也让整个事件显得更加荒谬，不少关注者将矛头直指布莱克和其背后的谷歌。</strong></p> 
<p>事已至此，LaMDA人格化事件由“AI进化证据”变成了一场闹剧。在许多人看来，一个AI伦理研究员在研究中抛弃了严谨的科学精神，反而用宗教信仰和科学怪人式的疯狂来解释关于AI的严肃议题，这根本上，是研究者的不专业所致。</p> 
<p>同时，另一种论调也随之兴起，其支持者认为，此次事件并非简单的技术争论，其背后有更多重的因素，炒作、营销等词更是频繁出现。他们认为lamda事件是谷歌针对旗下AI产品的一次营销活动。</p> 
<p>类似的事件也曾发生。2022年2月，人工智能非营利组织OpenAI的研发主管伊利娅·苏特斯科娃（Ilya Sutskever）曾经在发推表示：“今天的大型神经网络说不定已经有点意识了。”</p> 
<p>此言一出，AI领域再度引起广泛的关注， OpenAI自主研发的语言模型GPT-3更是一度成为明星产品。但随之而来的更多是批判与质疑，许多业内人士认为，这是OpenAI从产品出发进行的一场炒作。</p> 
<p>会出现这种类似“阴谋论”的质疑也并非完全不合理。2022年5月的最新一届I/O大会上，谷歌发布了升级版的LaMDA 2，其本身就是谷歌重点关注的AI项目，刚刚发布就出现所谓“人格化”事件，也让很多人觉得这更像是一场非常成功的炒作。在他们看来，布莱克或谷歌通过一个精心策划的故事，让LaMDA成功成为了世界上最具知名度的AI系统之一。</p> 
<p>谁也没有想到，这场科幻感十足的事件就如此陷入了“罗生门”：<strong>它显得过于复杂了，已经超脱了LaMDA本身，还关乎技术、伦理、商业，甚至还掺杂了人性、精神与宗教。</strong></p> 
<h2><strong>AI与人的距离</strong></h2> 
<p>在微博等国内社交平台上，虽然也不乏“快进到施瓦辛格竖大拇指”这样涉及科幻电影的调侃，但此事件所体现的AI发展水平还是给了许多网友极大的冲击，甚至可以称之为“恐慌”。</p> 
<p><strong>如前文提到的，LaMDA呈现出的理解与表达能力让这份聊天记录显得颇具革命性，网友们由此产生了诸多联想倒也可以理解。</strong></p> 
<p>然而事实是，AI的发展与实际运用或许早已经超越了大多数人的印象。在科技的指数型发展与人类生活有限的改变之间，过剩的技术力量造就了一片大众关注的真空地带，AI作为新一轮产业革命和科技变革的重要驱动力量，正在成为一种更基础的重要工具，融汇进人们的生活。</p> 
<p>国内大厂中，百度在AI方面的投入是业内有目共睹的。从飞桨平台到自研AI 芯片、智能搜索与智能服务等，每年的百度世界大会都能带来一些阶段性的探索成果，其分享的诸多企业案例也能体现出AI在工业发展中的实际作用。</p> 
<p>腾讯近两年在AI方面的动作也不少。2022年3月，腾讯承办的“世界大学生数智竞技邀请赛”正式启动。这次邀请赛以《王者荣耀》和腾讯AI Lab共同研发的AI开放研究平台“开悟”为载体，为全球大学生提供AI科技交流的机会。而在此前的2021 世界人工智能大会上，也有AI对战职业选手的表演赛，成为展示腾讯AI研究的窗口。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_04a0e12bd192411e8a1bebd993bc2280_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">表演赛海报，图源网络</p> 
<p>工业、游戏等似乎还是人工智能的老优势，一个更有意思的例子是前段时间讨论较多的“Disco Diffusion”，AI开始“创作”。</p> 
<p>“Disco Diffusion”是一个仅靠文字就能生成画作的AI工具，只需要一些简单的描绘，它便能为你生成你想要的画面，甚至还能模仿指定艺术家的“画风”。客观来说，这些产出的作品都颇具审美，十分成熟，甚至有时还能呈现出一种“赛博生命的独特想象”。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_d9ccbb9170384418a51f43a14ba7a7b8_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">近期的AI绘图潮流，图源网络</p> 
<p>这是否可以称之为创作？严格来说并不算，AI并没有独立的审美与创造能力，只是将“素材”进行组合，临摹出了任务所需的产品。但这些精美、大胆的作品确实也打破了一些认知上的壁垒：<strong>那是作为一个工具的“边界”，极致的便利性带来的“威胁”。</strong></p> 
<p>当我们回看2016年3月举世瞩目的“人机大战”，AlphaGo通过强大的算力与学习能力击败李世石，这之后，或主动或被动地，许多人对AI的认知与态度都在改变。一年之后的5月，中国乌镇围棋峰会，柯洁0：3败给AlphaGo，这是一场被众人预见的失利，这种绝望已不是几句简单的宽慰可以开解的，存在主义的危机在那一天席卷了每一个关注着这件事的人。</p> 
<p>2016年往后的三四年确实是关于AI的讨论高潮，而在面临到疫情等新的全人类共同危机时，这样的讨论才渐渐平静。</p> 
<p>电影《大佛普拉斯》里有句台词:“现在已经是太空时代了，人们可以搭乘太空船到达月球，却永远无法探索人们内心的宇宙。”</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220615/v2_f2d1d803e08d4408a746501c7c3811bf_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">图源豆瓣</p> 
<p>在LaMDA“产生意识”这一事件中，大部分的“证据”或担忧都源自其对禅宗等的理解与自身的“思考”，这被视为一种独属于人类内心的“宇宙活动”，<strong>哪怕LaMDA实际仍是依靠更高级的语料库在模仿，也因为边界被模糊的不确定性让人感到冒犯。</strong></p> 
<p>戴锦华在谈论“人类对人工智能（AI）的恐惧”时曾指出，这是一种“老旧的思想”：“一方面，日本的后人类主义思潮认为，我们对机器人威胁的考量基本是一种推己及人，以一种人类文明史的逻辑预测机器人的未来；另一方面，相对于机器与人的关系，更值得关注的是人类自我的赛博格化……它可能导致一个更深刻、更不可逆的人类内部的自我分化。”</p> 
<p>诸多反乌托邦的文艺作品一直警示着人们，反思技术、保持清醒，但技术不过是外壳，最底层的矛盾永远来自身为“<a class="project-link" data-id="1679782494245635" data-name="造物" data-logo="https://img.36krcdn.com/20220401/v2_834cf3e558544f348af4e85addb62900_img_000" data-refer-type="1" href="https://36kr.com/project/1679782494245635" target="_blank">造物</a>主”的人类自己。人工智能离“拥有意识”还远，人类的异化却是无时无刻不在发生。</p> 
<p>当“AI焦虑”再次成为全球共同的话题，回到这次事件本身，不论是根据谷歌自己的回应，还是从相关领域学者、从业者的分析来看，LaMDA的“人格化”都并不具备充分的证明条件。到现在，经历了最初的震惊与误读，媒体与网民们也都有了更深刻的认知与判断。</p> 
<p><strong>但说到底，对于现阶段的技术，刺猬公社还是认为应该抱以更积极的态度。相比较起来，对人工智能的恐惧反而更像一种被无数文艺作品打入人认识中的“思想钢印”。</strong></p> 
<p>本文来自微信公众号 <a target="_blank" rel="noopener noreferrer nofollow" href="http://mp.weixin.qq.com/s?__biz=MzkxNzAwMDkwNQ==&mid=2247636048&idx=1&sn=ea2d149b6449f70b0b555041e72fd0ef&chksm=c14bd3f6f63c5ae0aa9784148b5a2e094765fd33e8aa4180a3be9b872c812f2ce6bb151082b5#rd">“刺猬公社”（ID：ciweigongshe）</a>，作者：刺猬公社编辑部，36氪经授权发布。</p>  
</div>
            