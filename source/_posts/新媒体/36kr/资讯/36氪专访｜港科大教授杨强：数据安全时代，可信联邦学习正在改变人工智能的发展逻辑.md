
---
title: '36氪专访｜港科大教授杨强：数据安全时代，可信联邦学习正在改变人工智能的发展逻辑'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://picsum.photos/400/300?random=5117'
author: 36kr
comments: false
date: Fri, 06 May 2022 05:27:24 GMT
thumbnail: 'https://picsum.photos/400/300?random=5117'
---

<div>   
<p>文｜张婧怡</p> 
<p>编辑｜苏建勋</p> 
<p>这是一个隐私和数据安全比以往更受关注的时代。</p> 
<p>人工智能技术正在各行业应用落地，随之提高的是人们对用户隐私和数据安全的关注度。用户更加关注隐私信息是否未经许可便被他人出于商业或其他目的而利用，甚至滥用。</p> 
<p> 同时，随着相关法律法规的进一步实施，已有很多互联网、金融机构等企业由于泄露用户数据而被重罚。</p> 
<p> 另一方面，国家强调探索建立安全规格的数据要素流通规则。这意味着，监管趋严背景下，机构对数据的采集、流通与应用愈发谨慎；而同时现实又在不断推动数据要素加速走向开放共享。</p> 
<p> 因此，联邦学习——作为隐私增强计算与人工智能相结合的新型技术范式，成为了解决数据安全与开放共享矛盾的一个重要技术路径。</p> 
<p> 联邦学习中，客户可以在自己的终端使用本地数据对模型进行训练，并将模型的加密参数进行上传汇总，将不同的模型更新进行融合，优化预测模型。</p> 
<p> 而2022年将成为一个新的技术分水岭——从联邦学习到可信联邦学习。</p> 
<p> 针对近两年来隐私计算和联邦学习发展和应用中面临的安全、效率等挑战，“可信联邦学习”被提出，这一范式将隐私保护、模型性能、算法效率作为核心，共同构成了更加安全可信的联邦学习。</p> 
<p> 举例来说，在一个新能源车厂的营销项目中，营销项目甲乙方两边的数据不能互传，但是又有业务合作，因此一定要在合作高效率的前提下，又保证数据安全。</p> 
<p> 这时，可信联邦算法的出现就极大地降低了数据被攻击的可能性，又能极大提高效率。同时，算法能高效防止终端有恶意用户“下毒”，使得整个系统都是可信的。</p> 
<p> 针对可信联邦学习这一新范式，香港科技大学计算机与工程系讲席教授、FATE开源社区技术指导委员会主席，可信联邦学习提出者杨强院士在接受36氪采访时表示：“现在越来越多的公司主动要求引入隐私计算的解决方案，所以可信联邦学习的商业前景的大门是开的，只不过技术的人要更加聪敏地设计平衡的方案。”</p> 
<p> 杨强表示，任何多方参与进行人工智能建模的过程，都绕不开可信联邦学习这一通用的机器学习范式。</p> 
<p> “可信联邦学习的核心命题是结合分布式机器学习和人工智能算法，找到联合建模可信、可行及可控的解决方案，极大降低隐私计算的成本，提升隐私计算应用质量，进而推动隐私计算的加速发展。”杨强介绍。</p> 
<p> 同时，杨强认为，目前开源已成为大势所趋，成为隐私计算产业生态核心组成部分。以国内首个联邦学习开源社区FATE为例，作为向隐私计算、联邦学习开源生态中的开发者、贡献者、用户及生态伙伴建立的学习与交流平台，帮助开发人员快速实现联邦学习应用开发与部署，可通过可信联邦学习中模型的“版权保护”(FedIPR)，实现数据版权的保护和结果可溯源、可审计、可解释；通过开源、开放和共享，实现普惠。</p> 
<h3>以下是36 氪等媒体与香港科技大学计算机与工程系讲席教授、可信联邦学习提出者杨强的采访实录，经编辑后发布：</h3> 
<p><span style="letter-spacing: 0px;">媒体：与传统联邦学习相比，可信联邦学习进行了哪些拓展？其优势是如何体现的？</span></p> 
<p>杨强：传统上，隐私计算更多强调“安全”，就是不可见的部分。但是在实践当中，不管是用联邦学习也好、用多方安全计算也好，还是用什么其他的安全计算范式，在利用多方数据的安全前提下建模，都离不开联邦学习的整体框架，并且一定要把“可用”提到和“安全”一样的高度。</p> 
<p>所以问题是如何把安全效率和模型效能，就是模型的准确率和算法的效率，时间、复杂度，这三者如何做一个有机平衡。</p> 
<p> 目前，我们已经有了一些进展：理论上，我们研究了通用的多方合作的联合建模、联合使用模型的方式，发现不管是联邦学习也好、隐私计算也好、安全多方计算也好，都逃不出这样一个均衡问题。我们把这个问题通俗易懂地描述成「没有免费的午餐」，就是不可能有乌托邦式的安全，也不可能有乌托邦式的效率。在实践当中，这三者的有效平衡是对每一个算法设计者和法律设计者的考验。下一阶段，我们在隐私计算和联邦学习技术的发展上，应该对这样的平衡非常重视。</p> 
<p> 同时我们也认为，后期的管理非常重要。比方我们建立一个模型，这个模型另外一方使用。在使用过程中，万一它把模型进行二次售卖，在我不知情或者没有收益的情况下，就相当于把我的书复印了一份到其他的市场售卖一样的道理，是一个违法行为。</p> 
<p> 另外就是互通互联，我们希望各家的解决方案能够很容易地互相联通，有共用的基础模块，最后大家可以把这些模块建成我们所要的基础架构，软件架构、硬件架构，这就好像我们盖房子一样，我们有各种材料，最后把这些材料盖成我们想要的房子。因此，开源尤其重要。</p> 
<p> 开源对于安全机制也非常有效，因为大家都可以监管，在阳光下有漏洞的可能性远远小于在阴暗的角落发展出一个黑箱所可能犯的错误。所以，我们非常鼓励开源和普惠。</p> 
<p> 媒体：今年应该是深度学习的十周年，在过去十年这一波人工智能是由深度学习驱动的，您认为可信联邦学习对于以深度学习为基础的人工智能发展的逻辑，是否会带来一些改变呢？</p> 
<p> 杨强：我觉得有几个改变是非常明显的，也可以看作转折点。</p> 
<p> 第一，现在发现深度学习驱动的人工智能发展确实非常有效，因为它促进了人工智能指数型的发展。但是现在也有很多的迹象表明并没有我们想象的那么理想，其中一个重要的原因是，它在输入端并没有大家想象的那么顺畅。数据都有属主，属主有它的考虑、有它的利益、有它的隐私，因此安全性、对隐私的保护也被提出，这些都是转折点的<a class="project-link" data-id="1679823831733000" data-name="驱动力" data-logo="https://img.36krcdn.com/20220401/v2_306a51c64b454eeca3d42c78c4c9e075_img_000" data-refer-type="1" href="https://36kr.com/project/1679823831733000" target="_blank">驱动力</a>。</p> 
<p> 第二个，在算法上，过去都是基于一个单计算中心设计的。但是当我们有了上千万的手机、有了上百万级的无人车，每一个端点都是一个计算中心。这种状态下，分布式的数据和分布式的计算，如何能够安全高效地进行人工智能的模型训练，这是过去没有考虑过的问题，这又是一个转折点。</p> 
<p> 现在看到很多大模型都能做非常复杂的工作，但是他们在实用上却少之又少，也就是说它们现在变成一个“奥运会”的比赛，并没有深入到千家万家，为什么这样，原因就在这，数据不是这样分布的，数据真正是分布式的，算法没有跟上，所以在算法层面我们是要研究一种算法。</p> 
<p> 最后，当我们有了这种分布式数据格局和伦理考虑之下，更多的不是数据在网络当中传输，是模型在传输，所以未来的世界是一个多模型世界，在多模型世界下，模型的治理、审计、合作、安全就被提出来了，在深度学习驱动的AI里面没<a class="project-link" data-id="1713118059047428" data-name="有解" data-logo="https://img.36krcdn.com/20200424/v2_a55b83a38993466a99e2251c6aa4cd0f_img_png" data-refer-type="1" href="https://36kr.com/project/1713118059047428" target="_blank">有解</a>决这样一个模型驱动世界的难题。</p> 
<p>媒体：从商业化的角度来看，可信联邦学习未来的商业潜力是怎样的？</p> 
<p> 杨强：从大概三四年以前，隐私计算和联邦学习进入大家视野，到现在已经有了很多实际应用的案例，有些案例也给我们很多启发。其中一个重要的启发就是效率是一个非常关键的问题，如果使用一个隐私计算的解决方案使得算法的效率大为下降，这就属于一个不可用的技术。所以，我们既要安全又要效率，这是商用需求的一个前提，不是我们提出来的，这是很多需求方首先提出来的。</p> 
<p> 首先是可用和安全并举，而不是空泛的安全，所以这方面的商业前景主要看需求，这个需求是非常强烈的。并且，我们也同时看到在法律和国家法规的要求下，现在普法的工作做得非常彻底，现在越来越多的公司主动要求引入隐私计算的解决方案，所以我觉得这个商业前景的大门是开的，只不过技术的人要更加聪敏地设计平衡的方案。</p> 
<p> 媒体：未来我们会进入一个数据密态的时代，肯定要保证数据安全，它才能被更多人使用，但安全的提升是不是意味着全社会的数据流通的性能要下降呢，是不是意味着我们会迎来一个更慢的互联网？未来在这方面会不会引发新一轮的技术创新？</p> 
<p> 杨强：实际上，我们希望数据是流通的。加了法律以后，大家都有所忌惮，可能在一个极端的情况下，大家都不合作，这个情况下是最安全的。</p> 
<p> 现在我们也看到了这样一个现象，比方欧盟出了GDPR法案以后，很多公司不敢到欧洲去做生意了，这是因为它的禁止。所以，如果我们没有一个既合法又能够促进模型和数据的交流的技术手段，那就会形成一种孤岛和停滞的局面，这是我们不希望看到的。</p> 
<p> 所以我们比较的不是那种野蛮状态下的互联网效率，而是在合法、安全状态下的互联网率。</p> 
<p>应该说，我们用了可信联邦学习，效率反而提高了，因为比较的对象是停滞的孤岛状态，孤岛是没有任何商业交流和合作的。</p> 
<p>相反，比那种野蛮生长的会不会更慢呢？野蛮生长是对谁有利呢？只对寡头有利，我们不认为野蛮生长是对大众有利的。</p> 
<p> 这会不会引发软硬件结合新一轮的创新，我认为会。比方在隐私计算里面，可能在业界对隐私计算和联邦学习谁是谁的子集这样的问题，大家都有混淆。其实答案是非常简单的，我们有两个概念，一个是目标，一个是工具，隐私计算和联邦学习都可以是目标，它的目标在AI的角度来看，都是联合建模，利用分布式的数据建模，所以它们没有区别，你可以用一个名字作为另外一个名字的代名词。</p> 
<p>但是同时，它们又是工具，作为工具来说，他们都是工具箱的一员。比如安全多方计算是工具箱的一员，TEE硬件解决方案也是这个工具箱的一员，联邦学习这种分布式架构也是一员。我们可以把这些工具作为满足刚才说的隐私计算和联邦学习目标的手段和它们的组合作为一个手段，所以这样一个架构的隐私计算和联邦学习就并不是矛盾的，或者安全多方计算和联邦学习并不是二选一，而是大家都有用，可以组合完成我们的总目标。</p> 
<p>如何利用这些作为基础的建筑材料，有些是砖头、有些是混凝土、有些是门框，我们需要他们所有的互通互联能够搭建一个房子，这个房子就是隐私计算和联邦学习。所以从这一点来看，新的创新确实是在发生。</p> 
<p>媒体：您觉得在可信联邦学习模型最终成熟或者落地之后，下一个公共数据安全的挑战点还会出现在哪个方面？</p> 
<p>杨强：可信联邦是数字经济的一个赋能者。但是赋能归赋能，我们看到最终的目的是建立一个数字经济，在数字化的互联网上面进行的商业活动是满足一系列的伦理、道德、法律、规章，同时又高效，又可以产生商业价值，它的这个商业分配机制也是公平的。那么从我们现在的状态到刚才的理想状态中间，还有很多的路要走。我们建立一个可信联邦学习就是建立了这条公路，我们到达目标这条公路。</p> 
<p>因此在这之后可能会有各种不同的挑战，如何能够把需求变成一个真正的需求，而不是可有可无的一个状态。</p> 
<p>举例来说，我们现在所使用的软件，包括我们在PC、在手机上使用的软件还是比较落伍的。原因是我们现在基于的数据都是本地的，我们数据的传输还是在做数据上传，我们在进行一项工作的时候，往往是利用不到其他数据源上数据来帮助我们提高效率。</p> 
<p>但未来的软件也许会升级好几个版本，也就是说应该是“联邦学习inside”，每一个软件应该是自动地带有联邦学习的特性，大家可以自主地形成合作，可以分配合理的收益，并且合法合规，并且安全可信，可以大为提高我们的生产效率和生活质量。</p> 
<p>而在现在，我们正处于一个“拓荒期”。举例来说，好比我们刚刚从“石器时代”走入“铁器时代”，但是后面还有很多的路要走，才能真正走到 “数字时代”。 </p>  
</div>
            