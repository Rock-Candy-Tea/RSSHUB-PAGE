
---
title: '美国报告：特斯拉FSD全自动驾驶软件缺乏安全保障'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://picsum.photos/400/300?random=9204'
author: 36kr
comments: false
date: Wed, 21 Jul 2021 03:52:01 GMT
thumbnail: 'https://picsum.photos/400/300?random=9204'
---

<div>   
<p>7月21日消息，电动汽车制造商<a class="project-link" data-id="132410" data-name="特斯拉" data-logo="https://img.36krcdn.com/20200729/v2_e76e3d3d44c440138f072b13bc84a6dc_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/132410" target="_blank">特斯拉</a>上周发布了其司机驾驶辅助软件的最新原型版本后，车主的报告引起了美国权威杂志《消费者报告》和其他研究人员、安全专家的注意，他们对该系统的性能和安全性表示担忧。</p> 
<p>在Model Y SUV从特斯拉收到被称为FSD Beta 9的软件更新后，《消费者报告》的测试人员即开始对其进行独立测试。</p> 
<p>到目前为止，测试人员已经观看了社交媒体上发布的其他司机测试视频，并对他们看到的情况感到担忧，包括车辆错过转弯、闯入灌木丛以及朝着停放的汽车行驶等。</p> 
<p>就连特斯拉首席执行官埃隆·马斯克（Elon Musk）也敦促司机在使用FSD Beta 9时要谨慎，他在推特上写道：“会有未知的问题，所以请保持多疑。”</p> 
<p>FSD Beta 9是特斯拉所谓“全自动驾驶”功能的原型，尽管它的名字中含有“全自动驾驶”字眼儿，但它还不能让特斯拉汽车实现全自动驾驶。</p> 
<p>尽管特斯拉多年来始终在为其车辆发送软件更新，而且每次发布都会增加新功能，但FSD Beta 9的升级对车辆的操作方式进行了一些最彻底的改变。</p> 
<p>这次软件更新现在自动化了更多驾驶操作，例如，安装了该软件的特斯拉汽车现在可以在司机监督下导航穿过十字路口和城市街道。</p> 
<p>《消费者报告》汽车测试中心的高级主管杰克·费舍尔（Jake Fisher）说：“FSD beta 9的实际运行视频并没有显示出能让驾驶更安全、甚至压力更小的系统。消费者只是在花钱做测试工程师，因为特斯拉开发的技术没有足够的安全保护。”</p> 
<p>与之前的更新一样，《消费者报告》担心特斯拉仍在使用其现有车主及其车辆在公共道路上对新功能进行测试。这让许多道路安全专家感到担忧，因为其他司机以及骑单车者和行人，都没有意识到他们已经成为正在进行的实验的一部分，他们对此甚至并不知情。</p> 
<p>麻省理工学院教授、先进车辆技术(AVT)联盟(研究车辆自动化的组织)创始人布莱恩·<a class="project-link" data-id="392170" data-name="雷默" data-logo="https://img.36krcdn.com/20201106/v2_3559b26cc2fa478bac8f36ff593b544d_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/392170" target="_blank">雷默</a>(Bryan Remer)称：“虽然司机可能意识到他们假设的风险增加了一些，但其他道路使用者，包括司机、行人、骑单车者等，并没有意识到他们在测试车辆面前，也没有同意承担这种风险。”</p> 
<p>特斯拉的做法与其他开发自动驾驶汽车技术的公司形成了鲜明对比，如Argo AI、Cruise和Waymo。</p> 
<p>这些公司的代表解释称，他们将软件测试限制在私人道路上，或使用训练有素的安全司机作为监督。这些公司的代表都拒绝直接回答关于特斯拉的问题，只谈论他们自己的研究项目。特斯拉没有回应置评请求。</p> 
<p>费舍尔和其他人认为，特斯拉至少应该实时监控司机，以确保他们在使用新软件时注意到了增加的风险。</p> 
<p>例如，费舍尔说，更新后的软件有“令人印象深刻”的屏幕图形，但他担心，即使司机看了显示屏，耽误的时间可能也太长了，无法防止汽车撞上其他车辆或行人。</p> 
<p>许多新的特斯拉汽车配备了实时司机监控摄像头，尽管《消费者报告》的专家对其有效性提出了质疑。</p> 
<p>费舍尔说：“特斯拉仅仅要求人们注意是不够的，其司机辅助驾驶系统需要确保人们在系统运行时参与进来。”他建议特斯拉使用车内司机监控系统，以确保司机的眼睛盯着道路。费舍尔说：“我们已经知道，在没有足够司机支持的情况下，测试开发自动驾驶系统可能会导致致命事故。”</p> 
<p>2018年，49岁的伊莱恩·赫兹伯格(Elaine Herzberg)在凤凰城地区横穿街道时，被Uber的自动驾驶测试车撞死。</p> 
<p>一项调查发现，测试车后座上的司机当时分心了，没有及时接管汽车。一项联邦调查将撞车事故部分归咎于Uber监管不足和缺乏安全政策。在那场悲剧之后，许多公司制定了更严格的内部安全政策来测试自动驾驶系统，比如监控司机以确保他们不会分心，以及更多地依赖模拟和封闭的测试车道。</p> 
<h2 label="一级标题" style>“就像酒驾司机”</h2> 
<p>除了《消费者报告》的工程师，观看过FSD Beta 9运行视频的行业专家也对其性能表达了担忧。</p> 
<p>华盛顿特区美国大学公共事务学院研究自动驾驶汽车的教授塞利卡·乔西亚·塔尔博特(Selika Josiah Talbott)表示，她在视频中看到配备了FSD Beta 9的特斯拉“几乎就像酒驾司机”，很难保持在车道线之间。她说：“虽然汽车在右转弯时看起来相当顺畅，但左转弯称得上狂野。”</p> 
<p>用户AI Addit上传到YouTube上的视频显示，在停放的车辆周围和通过十字路口时，FSD Beta 9的导航效果令人印象深刻，但这辆车也犯了很多错误：在驾驶过程中，特斯拉撞到了灌木丛中，转弯后走错了车道，然后直接冲向停放的汽车，并且还有其他问题。该软件在驾驶时偶尔也会脱离接触，突然让司机承担起驾驶的责任。</p> 
<p>美国杜克大学人类与自主实验室主任、自动化专家米西·卡明斯(Missy Cummings)说：“仅仅通过观看这些视频，很难知道到底发生了什么问题，但只要看这些视频，就很容易发现其存在物体检测或分类问题。”换句话说，汽车正在努力确定它感知到的物体是什么，或者如何处理这些信息，或者两者兼而有之。</p> 
<p>根据卡明斯的说法，特斯拉最终有可能制造一款自动驾驶汽车。但到目前为止，这家汽车制造商所做的测试数量不足以在现有软件中支持这种能力。卡明斯称：“我不排除在未来的某个时候，特斯拉将推出自动驾驶汽车的可能。但他们现在成功了吗？还没有。他们真的接近目标了吗？同样没有。”</p> 
<h2 label="一级标题" style>未经同意被纳入测试</h2> 
<p>卡明斯说，尽管特斯拉将FSD Beta 9测试版软件直接交到消费者手中的做法在计算机软件开发过程中很常见，但这可能会在道路上造成真正的问题。</p> 
<p>她说：“完成80%的软件开发进度，然后发布它，让用户帮助找出问题，这是在硅谷十分常见的做法。也许这对你的手机来说没问题，但对关键的安全系统来说却并非如此。”</p> 
<p>麻省理工学院的雷默教授说，他认为路上的任何人都不应该受到测试车的威胁。但他已经注意到，通过对比新旧视频中的特斯拉自动驾驶任务，FSD Beta 9性能有了显著的提高。他说：“有趣的是，特斯拉的工程师在以多快的速度使用数据来提高系统性能。”</p> 
<p>但费舍尔说，在特斯拉汽车实现完全自动驾驶之前，这种渐进式的改进可能会降低司机的安全性，因为他们开始依赖汽车为自己做决定。</p> 
<p>他说：“当软件在大多数情况下都运行良好的时候，一个小小的故障可能会造成灾难性的后果，因为司机会更加信任系统，在需要的时候无法及时作出反应。”</p> 
<p>为了打击这种自满情绪，费舍尔、雷默、卡明斯和其他人呼吁特斯拉整合实时工作的强大司机监控系统，并确保一旦汽车无法处理驾驶任务，司机能够及时准备好控制汽车，这是特斯拉过去一直不愿采取的行动。</p> 
<p>监管机构汽车安全中心的执行董事杰森·莱文(Jason Levine)表示，除非特斯拉改变路线，否则其自动化方法可能会适得其反。莱文说，自动化可以拯救生命，但如果司机不清楚其局限性，就不能发挥积极作用。</p> 
<p>他表示：“汽车制造商未经同意，选择在司机和公众身上对未经证实的技术进行测试，往好里说，这会危及人们的安全，往坏里说，会导致本可避免的撞车事故甚至死亡。”此外，莱文和其他人表示，特斯拉使用的营销术语，如“全自动驾驶”，给人一种虚假和欺骗性印象，认为车辆可以在没有人类干预的情况下自动驾驶。</p> 
<h2 label="一级标题" style>更安全的方法？</h2> 
<p>美国大学教授塔尔博特(Talbott)表示，特斯拉在没有任何司机监控功能的情况下在公共道路上测试软件的方法，使这家汽车制造商成为他认为的“安全行业独狼”。</p> 
<p>他说：“业内其他人说，‘我们希望做好这件事，希望公众有信心，希望监管机构成为合作伙伴。’到目前为止，‘把它做好’意味着在公共道路上测试之前，使用训练有素的安全司机和封闭的测试道路来验证车辆软件。”</p> 
<p>Waymo发言人桑迪·卡普(Sandy Karp)表示：“我们软件的每一次更新都要经过严格的发布过程，并通过模拟测试、封闭赛道测试和在公共道路上进行驾驶测试。”Cruise发言人雷·韦特（Ray Wert）也称，只有在公司觉得自动驾驶车辆比人类司机驾驶更安全后，该公司才会部署这些车辆。Argo AI的代表指出，该公司广泛的司机培训和软件开发标准都可以在网上公开获得。</p> 
<p>行业组织自动车辆教育合作伙伴(Pave)指出，该机构支持使用训练有素的专业测试安全操作员，使用未经培训的安全司机可能会危及公众对车辆自动化的信任。</p> 
<p>最终，可能要由联邦监管机构来决定哪些车辆软件可以在公共道路上使用，但这是他们到目前为止一直不愿采取的一步。塔尔博特说：“我从来没有见过类似特斯拉的特权，当涉及到这家特定公司的行动时，美国交通部似乎总是对此保持睁一只眼闭一只眼。”</p> 
<p>但最近的监管趋势似乎越来越严格。例如，美国国家公路交通安全管理局(NHTSA)已下令对使用司机辅助驾驶系统时发生撞车事故的车辆提出新的报告要求。</p> 
<p>雷默说：“我希望这些数据能让NHTSA在未来几十年里更好地监控和管理致力于完善自动化系统的汽车和科技公司。”</p> 
<p>最终，监管机构将不得不赶上汽车制造商测试快速开发的自动驾驶汽车技术的计划。</p> 
<p>《消费者报告》的安全政策经理威廉·<a class="project-link" data-id="34279" data-name="华莱士" data-logo="https://img.36krcdn.com/20201021/v2_25808adb529b4ebb8f19a80496d1119f_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/34279" target="_blank">华莱士</a>(William Wallace)表示：“汽车技术发展非常迅速，自动化有很大潜力，但政策制定者需要加快步伐，制定强有力、合理的安全规则。否则，有些公司只会把我们的公共道路当作私人试验场来对待，几乎不会被追究安全责任。” </p> 
<p>本文来自<a href="https://new.qq.com/omn/20210721/20210721A02T1600.html">腾讯科技</a>，审校：金鹿，36氪经授权发布。</p>  
</div>
            