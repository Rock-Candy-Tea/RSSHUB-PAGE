
---
title: '清华大学用6个无线传感器搞定全身动作捕捉，可跑可跳可打滚'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20210607/v2_4d29410a1fd64d29b2590765c85454c6_img_000'
author: 36kr
comments: false
date: Mon, 07 Jun 2021 11:57:24 GMT
thumbnail: 'https://img.36krcdn.com/20210607/v2_4d29410a1fd64d29b2590765c85454c6_img_000'
---

<div>   
<p>编者按：本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer" href="https://mp.weixin.qq.com/s/M5mYgiNdsb8SIXQMmvbCnw">“量子位”（ID:QbitAI）</a>，作者：梦晨，36氪经授权发布。</p> 
<p>来自清华的研究团队发布了一段视频：</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_4d29410a1fd64d29b2590765c85454c6_img_000" referrerpolicy="no-referrer"></p> 
<p>两人打球的动作精准又流畅地被右下角的笔记本电脑捕捉到。</p> 
<p>但是房间里没看到摄像头，两人身上也好像没穿戴什么装备？</p> 
<p>印象中的全身3D动捕的一套装备和场地布置，可是这样的：</p> 
<p class="image-wrapper"><img data-img-size-val="1080,720" src="https://img.36krcdn.com/20210607/v2_c1bcccaa03fc41d3b96126740062073c_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">△光学动捕，《最后生还者》拍摄现场</p> 
<p>或是这样的：</p> 
<p class="image-wrapper"><img data-img-size-val="800,700" src="https://img.36krcdn.com/20210607/v2_5693d9fbc1d848ea893e7bb85b9cd0be_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">△惯性动捕</p> 
<p>最轻便的也得有5、6斤，价格便宜的就更重了能达到10几斤。穿在身上影响动作的灵活性，而且很快就会累了，基本无法日常使用。</p> 
<p>视频中的装备，后面标记出来才看到，两人身上各自只戴了6个小型惯性传感器，还是无线的。</p> 
<p class="image-wrapper"><img data-img-size-val="1000,546" src="https://img.36krcdn.com/20210607/v2_6d235175386c41759727b56e70406ecf_img_000" referrerpolicy="no-referrer"></p> 
<p>现在市面上的VR设备主要用的是光学动作捕捉。</p> 
<p>要知道VR刚出来那会不管有线无线，最大的障碍是要在房间周围摆上3到6个柱子。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,607" src="https://img.36krcdn.com/20210607/v2_4d57a455133244cb8fb393bc4edc1399_img_000" referrerpolicy="no-referrer"></p> 
<p>后来简化成了头戴设备上的摄像头向外扫描周围的环境实现定位，加上两个手柄上的惯性传感器，如PSVR。</p> 
<p>但动作捕捉的范围就只能是以头部和手部为主，腿部动作一直是难题。移动只能在画面里前进，并不能将腿部的具体动作在游戏中表现出来。</p> 
<p class="image-wrapper"><img data-img-size-val="800,448" src="https://img.36krcdn.com/20210607/v2_be406e8d103e486aaad2c43105486906_img_000" referrerpolicy="no-referrer"></p> 
<p class="img-desc">△VR游戏《半条命：Alyx》中的移动方式之一</p> 
<p>或者健身环，简单地检测到你在抬腿，再模拟成游戏中固定的腿部动画，或借用游戏中的交通工具。</p> 
<p class="image-wrapper"><img data-img-size-val="500,281" src="https://img.36krcdn.com/20210607/v2_f4fb517c54d844d18b773b5bb6779940_img_000" referrerpolicy="no-referrer"></p> 
<p>而现在，清华大学的新方法，可以实时捕捉跳跃和蹲爬，帧数都是90fps：</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_ced768b551e8452d9a56a16f565263a5_img_000" referrerpolicy="no-referrer"></p> 
<p>跨越障碍，甚至是躺下打滚都没问题：</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_dab6d43a744b4a61b284728fda0e800b_img_000" referrerpolicy="no-referrer"></p> 
<p>除了能跟踪人体的全身动作，还能实现在空间上的定位。由于不需要固定的传感器，长距离移动也没问题。</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_fe3ade09179a4859b23dc686622b53a8_img_000" referrerpolicy="no-referrer"></p> 
<p>与光学动捕相比，惯性动捕还有两个好处。一个是不怕环境障碍物遮挡。</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_bac1ec0a54734e588e76233cbac378d2_img_000" referrerpolicy="no-referrer"></p> 
<p>第二个是对照明环境没有要求，夜间也可以。</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_bac1ec0a54734e588e76233cbac378d2_img_000" referrerpolicy="no-referrer"></p> 
<p>除了个人VR游戏外，新的惯性动捕技术还可能降低商业动作捕捉的成本，让小规模的制作团队也有机会用上。</p> 
<p>在游戏和动画电影中，动作捕捉摄影棚是这样的：</p> 
<p class="image-wrapper"><img data-img-size-val="1000,788" src="https://img.36krcdn.com/20210607/v2_26e0e63e8c5e4572baf6e3f56113130e_img_000" referrerpolicy="no-referrer"></p> 
<p>这恐怕只有大公司才承担得起了。</p> 
<p>除了娱乐外，动作捕捉技术在医疗领域也有应用，可以用数据指导伤者更好地进行康复训练。</p> 
<h2>双向循环神经网络</h2> 
<p>这么好的方法是怎么实现的呢？原来是靠深度学习。</p> 
<p>研究团队分阶段将动作捕捉拆成3个子任务。先从惯性数据算出5个主要节点头部和四肢的位置，再细化成全部23个节点的位置，最后通过反向动力学(IK)求解。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,199" src="https://img.36krcdn.com/20210607/v2_f7ea1490d6b24ef7b4674c8ee52601d0_img_000" referrerpolicy="no-referrer"></p> 
<p>由于预测连续的动作不仅要依赖前面的计算结果，还要参考后面一层的结果。所以在这一步用到的是双向循环神经网络(biRNN)。</p> 
<p class="image-wrapper"><img data-img-size-val="764,270" src="https://img.36krcdn.com/20210607/v2_66da4fc2e46648c4aa3d6a8bcedd131f_img_000" referrerpolicy="no-referrer"></p> 
<p>在空间定位问题也是拆成两部分。一个是脚与地面接触的概率分布，再结合根结点的速度，算出在世界坐标的速度，同样用到RNN与biRNN。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,263" src="https://img.36krcdn.com/20210607/v2_2085cb5807314741a9d052863f608369_img_000" referrerpolicy="no-referrer"></p> 
<p>对于不同的任务使用不同的公开数据集进行训练，包含300名受试者超过40小时的姿势和空间位置参数。</p> 
<p>与之前的研究相比，任务拆解的方法有助于用更少资源获得更高帧数，可以胜任高速运动的捕捉。</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_942615766db040b8aea49cdab1643d73_img_000" referrerpolicy="no-referrer"></p> 
<p>并且实现了动作捕捉的同时进行空间定位。</p> 
<p class="image-wrapper"><img data-img-size-val="600,328" src="https://img.36krcdn.com/20210607/v2_12d38a5e80054be6a0fa31ad71d6f5d6_img_000" referrerpolicy="no-referrer"></p> 
<p>不过，还是有两点不足。一个是动作捕捉的效果依赖于训练数据集，对训练集中没有的动作效果就一般。</p> 
<p>还有在计算脚与地面的接触概率分布时，假定了接触时脚是固定不动的，不能适用于滑板等运动。</p> 
<h2>作者团队</h2> 
<p>本项目论文已被计算机图形顶会SIGGRAPH 2021接受。</p> 
<p>研究团队来自清华大学北京信息科学与技术国家研究中心和<a class="project-link" data-id="491126" data-name="软件学院" data-logo="https://img.36krcdn.com/20201106/v2_ded7efc34caa4c31b0b731a724df7ba9_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/491126" target="_blank">软件学院</a>。</p> 
<p class="image-wrapper"><img data-img-size-val="960,260" src="https://img.36krcdn.com/20210607/v2_fd3a28582e44446598fab5b982c0aeb2_img_000" referrerpolicy="no-referrer"></p> 
<p>徐枫团队副教授团队，第一作者伊昕宇。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,150" src="https://img.36krcdn.com/20210607/v2_8fe6f64e64874e0caaba3f60e8eb6d89_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val="564,326" src="https://img.36krcdn.com/20210607/v2_c5019be38d134f2bb1b016cbf204c5ec_img_000" referrerpolicy="no-referrer"></p> 
<p>项目地址：https://xinyu-yi.github.io/TransPose/</p> 
<p>论文地址：https://arxiv.org/abs/2105.04605</p>  
</div>
            