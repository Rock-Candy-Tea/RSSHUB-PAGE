
---
title: '英伟达连甩20枚AI核弹，800亿晶体管GPU、144核CPU来了'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20220323/v2_2191cb3dbdb84bd7bf44a788b88efe5b_img_000'
author: 36kr
comments: false
date: Wed, 23 Mar 2022 00:25:14 GMT
thumbnail: 'https://img.36krcdn.com/20220323/v2_2191cb3dbdb84bd7bf44a788b88efe5b_img_000'
---

<div>   
<p>芯东西3月23日凌晨报道，今日，NVIDIA（<a class="project-link" data-id="3969182" data-name="英伟达" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3969182" target="_blank">英伟达</a>）携基于最新Hopper架构的H100 GPU系列新品高调回归！ </p> 
<p>英伟达创始人兼CEO黄仁勋依然穿着皮衣，不过这次他没有出现在几乎已成GTC大会“标配”的厨房场景中，而是在一个更具科幻感的虚拟空间。 </p> 
<p class="image-wrapper"><img data-img-size-val="1078,598" src="https://img.36krcdn.com/20220323/v2_2191cb3dbdb84bd7bf44a788b88efe5b_img_000" referrerpolicy="no-referrer"></p> 
<p>延续以往风格，黄仁勋在主题演讲中继续秒天秒地秒空气，公布多个“全球首款”。这次他带来一系列堪称“地表最强”的AI重磅新品，随便一个精度的AI性能，都比上一代A100高出3~6倍。 </p> 
<p>虽然英伟达并购Arm的计划刚刚告吹，但它的数据中心“三芯”总路线（GPU+DPU+CPU）依然不动摇——继去年推出其首款数据中心CPU后，今天，英伟达又亮出一款基于Arm架构的Grace CPU超级芯片。 </p> 
<p class="image-wrapper"><img data-img-size-val="1000,563" src="https://img.36krcdn.com/20220323/v2_ed27ea88b7d140cd9d920c71b0c48f97_img_000" referrerpolicy="no-referrer"></p> 
<p>此外，黄仁勋再次派出自己的虚拟数字人化身“玩偶老黄”Toy Jensen，并跟这个表情生动的玩偶进行了一番流畅的实时问答对话。 </p> 
<p class="image-wrapper"><img data-img-size-val="1079,608" src="https://img.36krcdn.com/20220323/v2_eaf5ebdb040e494cb6c80e88e060616a_img_000" referrerpolicy="no-referrer"></p> 
<p>凭借押中图形处理和人工智能（AI）两大赛道，英伟达已经成为全球半导体市值TOP1。截至文章发布时间，英伟达的市值超过6600亿美元，比第二名<a class="project-link" data-id="47873" data-name="台积电" data-logo="https://img.36krcdn.com/20210807/v2_7e267a93d13d4526bbc0e2324e1f85e1_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/47873" target="_blank">台积电</a>足足多了近1100亿美元。 </p> 
<p>下面就让我们来看看本场GTC大会的完整干货： </p> 
<p><strong>1、H100 GPU：</strong>采用台积电4N工艺，拥有800亿个晶体管，实现了首个GPU机密计算，相比A100，FP8性能提升6倍，FP16、TF32、FP64性能各提升3倍。 </p> 
<p><strong>2、全新NVLink Switch系统：</strong>高度可扩展，支持256块H100 GPU互连。 </p> 
<p><strong>3、融合加速器H100 CNX</strong>：耦合H100 GPU与ConnectX-7和以太网智能网卡，可为I/O密集型应用提供更强劲的性能。 </p> 
<p><strong>4、DGX H100：</strong>配备8块H100 GPU，总计有6400亿个晶体管，在全新的FP8精度下AI性能比上一代高6倍，可提供900GB/s的带宽。 </p> 
<p><strong>5、DGX SuperPOD：</strong>最多由32个DGX H100组成，AI算力可达1EFLOPS。 </p> 
<p><strong>6、Eos超级计算机：</strong>全球运行速度最快的AI超级计算机，配备576台DGX H100系统，FP8算力达到18EFLOPS，PF64算力达到275PFLOPS。 </p> 
<p><strong>7、Grace CPU超级芯片：</strong>由两个CPU芯片组成，采用最新Armv9架构，拥有144个CPU核心和1TB/s的内存带宽，将于2023年上半年供货。 </p> 
<p><strong>8、为定制芯片集成开放NVLink：</strong>采用先进封装技术，与英伟达芯片上的PCIe Gen 5相比，能源效率高25倍，面积效率高90倍。<strong>英伟达还将支持通用小芯片互连传输通道UCIe标准。</strong></p> 
<p><strong>9、CUDA-X：</strong>60多个针对CUDA-X的一系列库、工具和技术的更新。 </p> 
<p><strong>10、Riva 2.0：</strong>对话式AI服务Riva全面发行，2.0版本支持识别7种语言，可将神经文本转换为不同性别发声的语音。 </p> 
<p><strong>11、Merlin 1.0：</strong>可帮助企业快速构建、部署和扩展先进的AI推荐系统。 </p> 
<p><strong>12、Sionna：</strong>一款用于6G通信研究的AI框架。 </p> 
<p><strong>13、OVX与OVX SuperPod：面向工业数字孪生的数据中心级服务器和超级集群。</strong></p> 
<p><strong>14、Spectrum-4：</strong>全球首个400Gbps端到端网络平台，交换吞吐量比前几代产品高出4倍，达到51.2Tbps。 </p> 
<p><strong>15、Omniverse Cloud：</strong>支持协作者们随时随地实现远程实时协同工作。 </p> 
<p><strong>16、DRIVE Hyperion 9：</strong>汽车参考设计，拥有14个摄像头、9个雷达、3个激光雷达和20个超声传感器，总体传感器数量是上一代的两倍。 </p> 
<p><strong>17、DRIVE Map：</strong>多模态地图引擎，包含摄像头、激光雷达和雷达的数据，同时兼顾安全性。 </p> 
<p><strong>18、Clara Holoscan MGX：</strong>可供医疗设备行业在边缘开发和部署实时AI应用的计算平台，AI算力可达每秒254~610万亿次运算。 </p> 
<p><strong>19、Isaac for AMR：</strong>提供自主移动机器人系统参考设计。 </p> 
<p><strong>20、Jetson AGX Orin开发者套件：</strong>在边缘实现服务器级的AI性能。 </p> 
<p>黄仁勋还介绍了英伟达创建的NVIDIA AI加速计划，通过与AI生态系统中的开发者合作，开发工程化解决方案，以确保客户放心部署。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,601" src="https://img.36krcdn.com/20220323/v2_8ecbbe6f801d4674b92e01dd6f453a61_img_000" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题" style><strong>01 </strong><strong style="letter-spacing: 0px;">H100 GPU：800亿晶体管、六大创新</strong></h2> 
<p>每次英伟达的GPU新架构都会以一位科学家的名字来命名，这次同样如此。 </p> 
<p>新Hopper架构的命名取自美国计算机科学家格蕾丝·赫柏（Grace Hopper），她是耶鲁大学第一位数学女博士、世界上第三位程序员、全球首个编译器的发明者，也是第一个发现“bug”的人。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,834" src="https://img.36krcdn.com/20220323/v2_af18c97bad2c465b97a223a65cda9501_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>▲格蕾丝·赫柏正在教学COBOL编程语言</p> 
<p>1945年9月9日，格蕾丝使用的Mark Ⅱ机出现故障，经过近一天的排查，她找到了故障的原因：继电器中有一只死掉的蛾子。后来，“bug”（小虫）和“debug”（除虫）这两个词汇就作为计算机领域的专用词汇流传至今。 </p> 
<p>基于Hopper架构的一系列AI计算新品，被冠上各种“全球首款”。按行业惯例，但凡比较AI算力，必会拿英伟达最新旗舰GPU作为衡量标准。 </p> 
<p>英伟达也不例外，先“碾压”一下自己两年前发布的上一代A100 GPU。 </p> 
<p>作为全球首款基于Hopper架构的GPU，英伟达 H100接过为加速AI和高性能计算（HPC）扛旗的重任，FP64、TF32、FP16精度下AI性能都达到A100的3倍。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,601" src="https://img.36krcdn.com/20220323/v2_6142adf090a74f428b26d96bf7d10490_img_000" referrerpolicy="no-referrer"></p> 
<p>可以看到， NVIDIA 越来越热衷于走 稀疏化路线 。过去六年，英伟达相继研发了使用FP32、FP16进行训练的技术。 此次H100的 性能介绍又出现了 新的 Tensor 处理格式FP8，而FP8精度下的AI性能可达到4PFLOPS，约为A100 FP16的6倍。 </p> 
<p>从技术进展来看，H100有6项突破性创新： </p> 
<p><strong>1）先进芯片：</strong>H100<strong>采用台积电4N工艺、台积电CoWoS 2.5D封装，有800亿个晶体管</strong>（A100有540亿个晶体管），搭载了HBM3显存，可实现近<strong>5TB/s</strong>的外部互联带宽。 </p> 
<p>H100是<strong>首款支持PCIe 5.0的GPU</strong>，也是<strong>首款采用HBM3标准的GPU</strong>，单个H100可支持40Tb/s的IO带宽，实现3TB/s的显存带宽。黄仁勋说，<strong>20块H100 GPU便可承托相当于全球互联网的流量。</strong></p> 
<p><strong>2）新Transformer引擎：</strong>该引擎将新的Tensor Core与能使用FP8和FP16数字格式的软件结合，动态处理Transformer网络的各个层，在不影响准确性的情况下，可将Transformer模型的训练时间从数周缩短至几天<strong>。</strong></p> 
<p><strong>3）第二代安全多实例GPU：</strong>MIG技术支持将单个GPU分为7个更小且完全独立的实例，以处理不同类型的作业，为每个GPU实例提供安全的多租户配置。H100能托管7个云租户，而A100仅能托管1个，也就是<strong>将MIG的部分能力扩展了7倍。</strong> 每个H100实例的性能相当于两个完整的英伟达云推理T4 GPU。 </p> 
<p><strong>4）机密计算：</strong>H100是<strong>全球首款具有机密计算功能的GPU加速器</strong>，能保护AI模型和正在处理的客户数据，可以应用在医疗健康和金融服务等隐私敏感型行业的联邦学习，以及共<a class="project-link" data-id="402732" data-name="享云" data-logo="https://img.36krcdn.com/20210811/v2_7f7b22bf1222475aa5cb32afa9271ec4_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/402732" target="_blank">享云</a>基础设施。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,564" src="https://img.36krcdn.com/20220323/v2_f60ce194ba61418285710d38a375f397_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>5）第4代英伟达NVLink：</strong> 为了加速大型AI模型，NVLink结合全新外接NVLink Switch，可将NVLink扩展为服务器间的互联网络， <strong>最多连接多达256个H100 GPU</strong> ，相较于上一代采用英伟达 HDR Quantum InfiniBand网络， <strong>带宽高出9倍</strong> 。 </p> 
<p><strong>6）DPX指令：</strong>Hopper引入了一组名为DPX的新<a class="project-link" data-id="6632" data-name="指令集" data-logo="https://img.36krcdn.com/20220120/v2_4472a2ea6015486eb82c2f4f4ddb0cef_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4854500224?mp=zzquote" target="_blank">指令集</a>，DPX可加速动态编程算法，解决路径优化、基因组学等算法优化问题，与CPU和上一代GPU相比，其<strong>速度提升分别可达40倍和7倍</strong>。 </p> 
<p>总体来说，H100的这些技术优化，将对跑深度推荐系统、大型AI语言模型、基因组学、复杂数字孪生、气候科学等任务的效率提升非常明显。 </p> 
<p>比如，用H100支持聊天机器人使用的monolithic Transformer语言模型Megatron 530B，<strong>吞吐量比上一代产品高出30倍，同时能满足实时对话式AI所需的次秒级延迟。</strong></p> 
<p>再比如用H100训练包含3950亿个参数的混合专家模型，<strong>训练速度可加速高达9倍，训练时间从几周缩短到几天。</strong></p> 
<p class="image-wrapper"><img data-img-size-val="1080,599" src="https://img.36krcdn.com/20220323/v2_a4e68d85b1fc44a9ab5119d1d6266f72_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>H100将提供SXM和PCIe两种规格</strong>，可满足各种服务器设计需求。 </p> 
<p>其中H100SXM 提供4 GPU和8 GPU配置的HGX H100服务器主板； H 100 PCIe通过NVLink连接两块GPU，相较PCIe 5.0可提供7倍以上的带宽。 PCIe规格便于集成到现有的数据中心基础设施中。 </p> 
<p>这两种规格的电力需求都大幅增长。 H100 SXM版的散热设计功耗（TDP） 达到700W，比A100的400W高出75%。据黄仁勋介绍，H100采用风冷和液冷设计。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,571" src="https://img.36krcdn.com/20220323/v2_2c2bb5e4067e4c50adaa26059c222358_img_000" referrerpolicy="no-referrer"></p> 
<p>这款产品预计于今年晚些时候全面发售。<a class="project-link" data-id="8432" data-name="阿里云" data-logo="https://img.36krcdn.com/20220120/v2_319a0380d9d44e369e65322c73b135bb_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4893500204?mp=zzquote" target="_blank">阿里云</a>、AWS、<a class="project-link" data-id="28215" data-name="百度" data-logo="https://img.36krcdn.com/20210806/v2_f96267de58b643faae02c0cb24debbed_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/28215" target="_blank">百度</a>智能云、谷歌云、微软Azure、Oracle Cloud、<a class="project-link" data-id="24961" data-name="腾讯" data-logo="https://img.36krcdn.com/20201201/v2_016524a9a477434cb3584e1558f3257a_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/24961" target="_blank">腾讯</a>云和<a class="project-link" data-id="542656" data-name="火山引擎" data-logo="https://img.36krcdn.com/20220120/v2_1fb667131e1440f197730b9159d63e56_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4778401130?mp=zzquote" target="_blank">火山引擎</a>等云服务商均计划推出基于H100的实例。 </p> 
<p>为了将Hopper的强大算力引入主流服务器，英伟达推出了<strong>全新的融合加速器H100 CNX</strong>。它将网络与GPU直接相连，耦合H100 GPU与英伟达ConnectX-7 400Gb/s InfiniBand和以太网智能网卡，使网络数据通过DMA以50GB/s的速度直接传输到H100，能够避免带宽瓶颈，为I/O密集型应用提供更强劲的性能。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,577" src="https://img.36krcdn.com/20220323/v2_defd61c65db54575b1702c24bbf2523e_img_000" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题" style><strong>02 </strong><strong style="letter-spacing: 0px;">更强企业级AI系统，全球最快AI超算</strong></h2> 
<p>基于A100，英伟达最先进的企业级AI基础设施DGX H100系统、DGX POD、DGX SuperPOD以及一一登场。它们将从今年第三季度开始供应。 </p> 
<p>黄仁勋称，在财富10强企业和100强企业中，分别有8家和44家企业使用DGX作为AI基础架构。 </p> 
<p>英伟达DGX系统现在包含英伟达AI Enterprise软件套件，该套件新增了对裸金属基础设施的支持。DGX客户可使用软件套件中的预训练AI平台模型、工具包和框架来加快工作速度。 </p> 
<p><strong>1、DGX H100：最先进的企业级AI基础设施</strong></p> 
<p>第四代英伟达DGX系统DGX H100是一款基于英伟达H100 Tensor Core GPU的AI平台。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,545" src="https://img.36krcdn.com/20220323/v2_3201bb122fab482d8502f1d66d8a1de7_img_000" referrerpolicy="no-referrer"></p> 
<p>每个DGX H100系统配备8块H100 GPU，总计有6400亿个晶体管，由NVLink连接，在全新的<strong>FP8精度下AI性能可达32Petaflops，比上一代系统性能高6倍</strong>。 </p> 
<p>DGX H100系统中每块GPU都通过第四代 NVLink连接，可<strong>提供900GB/s的带宽，是上一代系统的1.5倍</strong>。DGX H100的显存带宽可达24TB/s。 </p> 
<p>该系统支持双x86 CPU，每个系统还包含2个英伟达BlueField-3 DPU，用于卸载、加速和隔离高级网络、存储及安全服务。 </p> 
<p>8个英伟达ConnectX-7 Quantum-2 InfiniBand网卡能够提供<strong>400GB/s的吞吐量</strong>，可用于连接计算和存储，这一速度<strong>比上一代系统提升了1倍</strong>。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,597" src="https://img.36krcdn.com/20220323/v2_e75462b0e0f24c60a3e6ec76b25b2f8b_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>2、DGX SuperPOD：FP8 AI性能达1Exaflops</strong></p> 
<p>DGX H100系统是新一代英伟达DGX POD和DGX SuperPOD超级计算机的构建模块。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,608" src="https://img.36krcdn.com/20220323/v2_fbc6e393c73545cb96ac45800f98b8a0_img_000" referrerpolicy="no-referrer"></p> 
<p>借助NVLink Switch系统，拥有32个节点、256个GPU的DGX Pod，其HBM3显存达20.5TB，显存带宽高达768TB/s。 </p> 
<p>“相比之下，整个互联网不过只有100TB/s。”黄仁勋感慨道。 每个DGX都可借助4端口光学收发器连接到NVLink Switch，每个端口都有8个100G-PAM4通道，每秒能够传输100GB，32个NVLink收发器连接到1个机架单元的NVLink Switch系统。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,590" src="https://img.36krcdn.com/20220323/v2_91923b274e7c4c0fb6c64a600aff8eab_img_000" referrerpolicy="no-referrer"></p> 
<p>新一代DGX SuperPOD<strong>可提供1Exaflops的FP8 AI性能，比上一代产品性能高6倍，能够运行具有数万亿参数的大型语言模型工作负载</strong>；还有20TB的HBM3显存、192TFLOPS的SHARP网络计算性能。 </p> 
<p>通过采用Quantum-2 InfiniBand连接及NVLink Switch系统，新DGX SuperPOD架构在GPU之间移动数据的<strong>带宽高达70TB/s，比上一代高11倍</strong>。 </p> 
<p>Quantum-2 InfiniBand交换机芯片拥有570亿个晶体管，能提供64个400Gbps端口。多个DGX SuperPOD单元可组合使用。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,577" src="https://img.36krcdn.com/20220323/v2_c1d8df38580e47e38cfbc656adcae360_img_000" referrerpolicy="no-referrer"></p> 
<p>此外，英伟达推出新的DGX-Ready托管服务计划，以助力简化AI部署。其DGX Foundry托管的开发解决方案正在全球扩展，北美、欧洲和亚洲的新增地点支持远程访问DGX SuperPOD。 </p> 
<p>DGX Foundry中包含英伟达Base Command软件，该软件能够使客户基于DGX SuperPOD基础设施，<a class="project-link" data-id="61037" data-name="轻松管" data-logo="https://img.36krcdn.com/20210807/v2_37f13083fd7747bcbc7f3cea1786a521_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/61037" target="_blank">轻松管</a>理端到端AI开发生命周期。 </p> 
<p><strong>3、Eos：全球运行速度最快的AI超算</strong></p> 
<p>黄仁勋还透露说，英伟达正在打造Eos超级计算机，并称这是“首个Hopper AI工厂”，将于数月后推出。 </p> 
<p>该超算包含18个DGX POD、576台DGX H100系统，共计4608块DGX H100 GPU，预计将提供<strong>18.4Exaflops的AI算力</strong>，这<a class="project-link" data-id="81186" data-name="比目" data-logo="https://img.36krcdn.com/20210807/v2_4c8370884047480786d785d18c11d12a_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/81186" target="_blank">比目</a>前运行速度最快的日本富岳（Fugaku）超级计算机<strong>快4倍</strong>。在传统科学计算方面，Eos预计可提供<strong>275Petaflops的性能</strong>。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,589" src="https://img.36krcdn.com/20220323/v2_876d6fb4a883466ab25597d3789355ed_img_000" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题" style><strong>03 </strong><strong style="letter-spacing: 0px;">由两个CPU组成的超级芯片</strong></h2> 
<p>除了GPU外，英伟达数据中心“三芯”战略中另一大支柱CPU也有新进展。 </p> 
<p>今日，英伟达推出<strong>首款面向HPC和AI基础设施的基于Arm Neoverse的数据中心专属CPU——Grace CPU超级芯片。</strong></p> 
<p>这被黄仁勋称作“<strong>AI工厂的理想CPU”</strong>。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,607" src="https://img.36krcdn.com/20220323/v2_abeba21f5bc6471686d48fea95e61989_img_000" referrerpolicy="no-referrer"></p> 
<p>据介绍，Grace Hopper超级芯片模组能在CPU与GPU之间进行芯片间的直接连接，其关键驱动技术是内存一致性芯片之间的NVLink互连，每个链路的速度达到900GB/s。 </p> 
<p><strong>Grace CPU超级芯片也可以是由两个CPU芯片组成</strong>。它们之间通过高速、低延迟的芯片到芯片互连技术<strong>NVLink-C2C</strong>连在一起。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,601" src="https://img.36krcdn.com/20220323/v2_05596a9565014836adc20532ea53a2ac_img_000" referrerpolicy="no-referrer"></p> 
<p>它 <strong>基于最新的Armv9架构，单个socket拥有144个CPU核心，</strong> 具备最高的单线程核心性能，支持Arm新一代矢量扩展<strong>。</strong></p> 
<p>在SPECrate®2017_int_base基准<a class="project-link" data-id="8712" data-name="测试" data-logo="https://img.36krcdn.com/20220318/v2_d188db412f2e4db89c6424314ac39971_img_jpg" data-refer-type="2" href="https://36kr.com/projectDetails/8712" target="_blank">测试</a>中，Grace CPU超级芯片的<strong>模拟性能得分为740</strong>， 据英伟达实验室使用同类编译器估算，这一结果 <strong>相比当前DGX A100搭载的双CPU高1.5倍以上</strong> 。 </p> 
<p>此外，Grace CPU超级芯片可实现<strong>当今领先服务器芯片内存带宽和能效的2倍</strong>。 </p> 
<p>其依托带有纠错码的LPDDR5x内存组成的创新的内存子系统，能实现速度和功耗的最佳平衡。LPDDR5x内存子系统提供两倍于传统DDR5设计的<strong>带宽，可达到1TB/s</strong>，同时功耗也大幅降低，<strong>CPU加内存整体功耗仅500瓦</strong>。</p> 
<p>Grace CPU超级芯片可运行所有的英伟达计算软件栈，结合英伟达ConnectX-7网卡，能够灵活地配置到服务器中，或作为独立的纯CPU系统，或作为GPU加速服务器，可以搭配1块、2块、4块或8块基于Hopper的GPU。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,601" src="https://img.36krcdn.com/20220323/v2_8fa358a684d94be1a31cf1d4f9b5800e_img_000" referrerpolicy="no-referrer"></p> 
<p>也就是说，用户只维护一套软件栈，就能针对自身特定的工作负载做好性能优化。 </p> 
<p>黄仁勋说，Grace超级芯片有望明年开始供货。 </p> 
<h2 label="一级标题" style><strong>04 </strong><strong style="letter-spacing: 0px;">为定制芯片集成开放NVLink，</strong><strong style="letter-spacing: 0px;">将支持UCIe小芯片标准</strong></h2> 
<p>我们单独来说一下NVLink-C2C技术。 </p> 
<p>前面说的Grace CPU超级芯片系列、去年发布的Grace Hopper超级芯片都采用了这一技术来连接处理器芯片。 </p> 
<p>NVIDIA超大规模计算副总裁Ian Buck认为：“为应对摩尔定律发展趋缓的局面，必须开发小芯片和异构计算。” </p> 
<p>因此，英伟达利用其在高速互连方面的专业知识开发出统一、开放的NVLink-C2C互连技术。 </p> 
<p>该技术将<strong>支持定制裸片与英伟达GPU、CPU、DPU、NIC和SoC之间实现一致的互连</strong>，从而通过小芯片构建出新型的集成产品，助力数据中心打造新一代的系统级集成。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,598" src="https://img.36krcdn.com/20220323/v2_bfabd19358e942538193784d8938dbe8_img_000" referrerpolicy="no-referrer"></p> 
<p><strong>NVLink-C2C现已为半定制芯片开放</strong>，支持其与NVIDIA技术的集成。 </p> 
<p>通过采用先进的封装技术，英伟达NVLink-C2C互连链路的<strong>能效最多可比NVIDIA芯片上的PCIe Gen 5高出25倍，面积效率高出90倍</strong>，可实现<strong>每秒900GB</strong>乃至更高的一致互联带宽。 </p> 
<p>NVLink-C2C支持Arm AMBA一致性集线器接口（AMBA CHI）协议，或CXL工业标准协议，可实现设备间的互操作性。 当前英伟达和Arm正在密切合作，以强化AMBA CHI来支持与其他互连处理器完全一致且安全的加速器。 </p> 
<p>NVIDIA NVLink-C2C依托于英伟达的SERDES和LINK设计技术，可从PCB级集成和多芯片模组扩展到硅插入器和晶圆级连接。这可提供极高的带宽，同时优化能效和裸片面积效率。 </p> 
<p>除NVLink-C2C之外，<strong>NVIDIA还将支持本月早些时候发布的通用小芯片互连传输通道UCIe标准。</strong></p> 
<p class="image-wrapper"><img data-img-size-val="1080,895" src="https://img.36krcdn.com/20220323/v2_a5487475f45843e0a8d1bee9796ea051_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>▲UCIe标准</p> 
<p>与NVIDIA芯片的定制芯片集成既可以使用UCIe 标准，也可以使用NVLink-C2C，而<strong>后者经过优化，延迟更低、带宽更高、能效更高。</strong></p> 
<h2 label="一级标题" style><strong>05 </strong><strong style="letter-spacing: 0px;">AI软件：对话式AI服务全面发行，</strong><strong style="letter-spacing: 0px;">推出推荐系统AI框架1.0版本</strong></h2> 
<p>如今英伟达已经能提供全栈AI，除了AI计算硬件外，其AI软件也有不少进展。 </p> 
<p>黄仁勋说，AI已经从根本上改变了软件的能力以及开发软件的方式，过去十年，英伟达加速计算在AI领域实现了百万倍的加速。 </p> 
<p>今日，英伟达发布了<strong>60多个针对CUDA-X的一系列库、工具和技术的更新</strong>，以加速量子计算和6G研究、网络安全、基因组学、药物研发等领域的研究进展。 </p> 
<p>英伟达将使用其首台AI数字孪生超级计算机Earth-2来应对气候变化挑战，并创建了Physics-ML模型来模拟全球天气模式的动态变化。 </p> 
<p class="image-wrapper"><img data-img-size-val="1053,597" src="https://img.36krcdn.com/20220323/v2_e574a7a297d34e7e9cc57ff07f932a21_img_000" referrerpolicy="no-referrer"></p> 
<p>英伟达还与来自加州理工学院、伯克利实验室等高校及科研机构的研究人员们开发了一个天气预报AI模型FourCastNet，该模型基于10TB的地球系统数据进行训练，首次在降水预测上达到比先进的数值模型更高的准确率，并使预测速度提高了4~5个数量级。 以前，传统的数值模拟需要一年时间，而现在只需几分钟。 </p> 
<p class="image-wrapper"><img data-img-size-val="1000,563" src="https://img.36krcdn.com/20220323/v2_3c7d5a8cc0084b28b54e3a8a8ac9b6c4_img_000" referrerpolicy="no-referrer"></p> 
<p>NVIDIA Triton是一款开源的、超大规模的模型推理服务器，是AI部署的“中央车站”，它支持CNN、RNN、GNN、Transformer等各种模型、各类AI框架及各类机器学习平台，支持在云、本地、边缘或嵌入式设备运行。 </p> 
<p>同时，黄仁勋宣布英伟达<strong>对话式AI服务Riva全面发行</strong>，Riva 2.0版本支持识别7种语言，可将神经文本转换为不同性别发声的语音，用户可通过其TAO迁移学习工具包进行自定义调优。 </p> 
<p>Maxine是一个AI模型工具包，现已拥有30个先进模型，可优化实时视频通信的视听效果。比如开远程视频会议时，Maxine可实现说话者与所有参会者保持眼<a class="project-link" data-id="58423" data-name="神交" data-logo="https://img.36krcdn.com/20210807/v2_8b43e93cdd1343bb95b485182139ad63_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/58423" target="_blank">神交</a>流，并能将说的语言实时切换成另一种语言，而且音色听起来不变。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,495" src="https://img.36krcdn.com/20220323/v2_6fccb51327ec45c1ac42fd4c2e1502a2_img_000" referrerpolicy="no-referrer"></p> 
<p>本次GTC发布的版本增加了用于回声消除和音频超分辨率的新模型。 </p> 
<p>此外，黄仁勋也宣布推出英伟达<strong>面向推荐系统的AI框架Merlin的1.0版本</strong>。 </p> 
<p>Merlin可帮助企业快速构建、部署和扩展先进的AI推荐系统。比如，<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>用Merlin将短视频推荐延迟缩短为原来的1/4，并将吞吐量提升了10倍。从CPU迁移至GPU，腾讯在该业务上的成本减少了1/2。 </p> 
<p>在医疗健康领域，黄仁勋谈道，过去几年，AI药研初创公司获得了超400亿美元的投资，数字生物学革命的条件已经成熟，他称这将是“NVIDIA AI迄今为止最伟大的使命”。 </p> 
<p>6G标准于2026年左右问世，一些相关基础技术逐渐成形。对此，黄仁勋宣布推出了一款<strong>用于6G通信研究的AI框架Sionna</strong>。 </p> 
<h2 label="一级标题" style><strong>06 </strong><strong style="letter-spacing: 0px;">Omniverse：首推数字孪生</strong><strong style="letter-spacing: 0px;">专用服务器和超级集群</strong></h2> 
<p>黄仁勋认为，第一波AI学习是感知和推理，下一波AI的发展方向是机器人，也就是使用AI规划行动。英伟达Omniverse平台也正成为制造机器人软件时必不可少的工具。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,609" src="https://img.36krcdn.com/20220323/v2_c9c3ae3b34c945cc8dc36a4e307ad8b2_img_000" referrerpolicy="no-referrer"></p> 
<p>作为虚拟世界的仿真引擎，Omniverse平台能遵循物理学定律，构建一个趋真的数字世界，可以应用于使用不同工具的设计师之间的远程协作，以及工业数字孪生。 </p> 
<p>黄仁勋认为，工业数字孪生需要一种专门构建的新型计算机，因此英伟达打造了面向工业数字孪生的OVX服务器和OVX SuperPOD超级集群。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,598" src="https://img.36krcdn.com/20220323/v2_bf3f9873bd4a4063bcbec3b55a95b754_img_000" referrerpolicy="no-referrer"></p> 
<p>OVX是<strong>首款Omniverse计算系统</strong>，由8个英伟达A40 RTX GPU、3个ConnectX-6 200Gbps网卡（NIC）和2个英特尔至强Ice Lake CPU组成。 </p> 
<p><strong>32台OVX服务器可构成OVX SuperPOD超级集群</strong>，实现这一连接的关键设施是英伟达今日新推出的Spectrum-4以太网平台。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,597" src="https://img.36krcdn.com/20220323/v2_754eea2baf2843e39cfb7ffa13ceee3f_img_000" referrerpolicy="no-referrer"></p> 
<p>据悉，这是<strong>全球首个400Gbps端到端网络平台，其交换吞吐量比前几代产品高出4倍，聚合ASIC带宽达到51.2Tbps，</strong>支持128个400GbE端口。 </p> 
<p>Spectrum-4实现了<strong>纳秒级计时精度，相比典型数据中心毫秒级抖动提升了5~6个数量级</strong>。这款交换机还能加速、简化和保护网络架构。与上一代产品相比，<strong>其每个端口的带宽提高了2倍，交换机数量减少到1/4，功耗降低了40%。</strong></p> 
<p>该平台由<strong>英伟达Spectrum-4交换机系列、ConnectX-7智能网卡、BlueField-3 DPU和DOCA数据中心基础设施软件</strong>组成，可提高AI应用、数字孪生和云基础架构的性能和可扩展性，大幅加速大规模云原生应用。 </p> 
<p>Spectrum-4 ASIC和SN5000交换机系列<strong>基于4nm工艺，有1000亿个晶体管</strong>，并经过简化的收发器设计，实现领先的能效和总拥有成本。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,604" src="https://img.36krcdn.com/20220323/v2_700adca42edb42c6a455b698eecdd7c1_img_000" referrerpolicy="no-referrer"></p> 
<p>Spectrum-4可在所有端口之间公平分配带宽，支持自适应路由选择和增强拥塞控制机制，能显著提升数据中心的应用速度。 </p> 
<p>Spectrum-4 ASIC具有12.8Tbp加密带宽和领先的安全功能，例如支持MACsec和VXLANsec，并通过硬件信任根将安全启动作为默认设置，帮助确保数据流和网络管理的安全性和完整性。 </p> 
<p>现在各大计算机制造商纷纷推出OVX服务器，对于想在OVX试用Omniverse的客户，英伟达在全球多地提供LaunchPad计划，第一代OVX正由英伟达和早期客户运行，第二代OVX正被构建中。 Spectrum-4的样机将在今年第四季度末发布。 </p> 
<p>随后，曾在往届GTC大会展示过的黄仁勋虚拟化身“玩偶老黄”Toy Jensen再度现身。 </p> 
<p class="image-wrapper"><img data-img-size-val="667,372" src="https://img.36krcdn.com/20220323/v2_f2fa2bfc195e4cd59c1145a919a39c09_img_000" referrerpolicy="no-referrer"></p> 
<p>它不是录像，而能做到完全实时地进行眼神交流与对话。黄仁勋现场问它“什么是合成生物学”、“你是如何制作出来的”等问题，它都对答<a class="project-link" data-id="4262382" data-name="如流" data-logo="https://img.36krcdn.com/20220120/v2_66b3cd2df7c446c38eb200e99f261129_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4256001234?mp=zzquote" target="_blank">如流</a>。 </p> 
<p>使用英伟达Omniverse Avatar框架，企业就能快速构建和部署像Toy Jensen这样的虚拟形象，从模仿声音到细微的头部及身体运动，乃至高保真度的形象塑造，都让<a class="project-link" data-id="42359" data-name="虚拟人" data-logo="https://img.36krcdn.com/20210807/v2_5fe9f59dd24748d79d96a82e7debce7d_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/42359" target="_blank">虚拟人</a>更加灵动。 </p> 
<p>最后，得益于Riva中的最新对话式AI技术和超大语言模型Megatron 530B NLP，虚拟人可以听<a class="project-link" data-id="76636" data-name="懂你" data-logo="https://img.36krcdn.com/20210807/v2_a3ae83f62e304b9e8e52e7975494e63c_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/76636" target="_blank">懂你</a>问的问题，也能跟你实时聊天互动。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,599" src="https://img.36krcdn.com/20220323/v2_bd2e290238464d74b12f4c8e1f2a2d54_img_000" referrerpolicy="no-referrer"></p> 
<p>在此基础上，英伟达宣布将<strong>推出Omniverse Cloud</strong>。通过Omniverse Cloud连接，协作者们使用英伟达RTX PC、笔记本电脑和工作站，均可实现远程实时协同工作。 </p> 
<p>用户如果没有RTX计算机，只需点击一下，即可从GeForce Now上启动Omniverse。 </p> 
<h2 label="一级标题" style><strong>07 </strong><strong style="letter-spacing: 0px;">汽车：预告DRIVE Hyperion 9，</strong><strong style="letter-spacing: 0px;">推出多模态地图引擎</strong></h2> 
<p>Omniverse平台是整个工作流程的核心，DRIVE平台则相当于AI司机。 </p> 
<p>黄仁勋宣布下一代DRIVE Hyperion 9将从2026年起搭载到汽车中，它将拥有14个摄像头、9个雷达、3个激光雷达和20个超声传感器，总体传感器数量将是Hyperion 8的两倍。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,600" src="https://img.36krcdn.com/20220323/v2_fc1bc3b5017942eca5a537261bee8923_img_000" referrerpolicy="no-referrer"></p> 
<p>此外，英伟达推出了一种<strong>多模态地图引擎NVIDIA DRIVE Map</strong>，包含摄像头、激光雷达和雷达的数据，同时兼顾安全性。 </p> 
<p>DRIVE Map有两个地图引擎，真值测绘地图引擎和众包车队地图引擎。黄仁勋谈道，<strong>到2024年，他们预计绘制并创建北美、西欧和亚洲所有主要公路的数字孪生，总长度约为50万公里。</strong></p> 
<p>“我们正在构建<strong>地球级别的自动驾驶车队数字孪生</strong>。”黄仁勋说。 </p> 
<p>合作方面，全球第二大电动汽车制造商<a class="project-link" data-id="25207" data-name="比亚迪" data-logo="https://img.36krcdn.com/20210806/v2_cccfa9fccee4441cac1abb779d953122_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/25207" target="_blank">比亚迪</a>将在2023年上半年开始投产的汽车中搭载DRIVE Orin计算平台。自动驾驶独角兽企业<a class="project-link" data-id="3742" data-name="元戎启行" data-logo="https://img.36krcdn.com/20210806/v2_734386e2ed7b4b7f91f9d1b84fca5183_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/3742" target="_blank">元戎启行</a>、中国自动驾驶创<a class="project-link" data-id="215793" data-name="企云" data-logo="https://img.36krcdn.com/20210809/v2_802dc1a2b3444a6aa919651807296bb3_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/215793" target="_blank">企云</a>骥智行也宣布将在其L4级自动驾驶车规级量产方案中搭载NVIDIA DRIVE Orin SoC芯片。 </p> 
<p>美国电动汽车公司Lucid Motors、中国L4级自动驾驶科技公司文远知行、中国新型电动车公司悠跑科技均宣布将应用英伟达DRIVE Hyperion自动驾驶汽车平台。 </p> 
<h2 label="一级标题" style><strong>08 </strong><strong style="letter-spacing: 0px;">机器人平台：从医疗设备到自主移动机器人</strong></h2> 
<p>黄仁勋认为下一波AI<a class="project-link" data-id="457408" data-name="浪潮" data-logo="https://img.36krcdn.com/20210812/v2_079b6194026a457fb6ca0d50e1203979_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/457408" target="_blank">浪潮</a>是机器人，英伟达正在构建多个机器人平台，包括用于自动驾驶汽车的DRIVE、用于操纵和控制系统的Isaac、用于自主式基础架构的Metropolis、用于医疗设备的Holoscan等。 </p> 
<p>他将机器人系统的工作流程简化为<strong>真值数据生成、AI模型训练、Omniverse数字孪生、机器人技术栈</strong>四大支柱。 </p> 
<p>Clara Holoscan MGX是一个开放可扩展的机器人平台，其设计符合IEC-62304医疗级规格，核心计算机为Jetson AGX Orin和ConnectX-7智能网卡，并可选配NVIDIA RTX A6000 GPU。 </p> 
<p>该平台AI算力可达<strong>每秒254~610万亿次运算</strong>，目前向早期体验客户开放，<strong>正式上市时间是5月，并将于2023年第一季度完成医疗级准备</strong>。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,586" src="https://img.36krcdn.com/20220323/v2_e09ea91cecb94e13a06c58008241eabd_img_000" referrerpolicy="no-referrer"></p> 
<p>Metropolis平台的下载量已经达到30万次，拥有1000多个生态系统合作伙伴，并在超过100万个设施中运营。 </p> 
<p>机器人发展最快的领域之一是自主移动机器人（AMR），它本质上是室内无人驾驶，速度偏低但环境高度非结构化。 </p> 
<p>今天，英伟达<strong>推出Isaac for AMR</strong>，它有四大核心：用于真值生成的NVIDIA DeepMap、用于训练模型的NVIDIA AI、搭载Orin的AMR机器人参考设计、Isaac机器人技术堆栈中的新Gem及基于Omniverse的新版Isaac Sim，每个都单独可用且完全开放。 </p> 
<p>与DRIVE Hyperion类似，Isaac Nova是一个AMR机器人系统参考设计，整个Isaac堆栈都基于此构建。<strong>Nova有2个摄像头、2个激光雷达、8个超声波雷达和4个鱼眼摄像头。</strong></p> 
<p>英伟达还宣布推出<strong>Jetson Orin开发者套件</strong>，<strong>以在边缘实现服务器级的AI性能。</strong></p> 
<p>Nova AMR将于第二季度上市，它将配备英伟达新的DeepMap雷达制图系统，可以扫描和重建环境，以进行路线规划和数字孪生仿真。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,571" src="https://img.36krcdn.com/20220323/v2_a9e2317899f4408697965074a076d172_img_000" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题" style><strong>09 </strong><strong style="letter-spacing: 0px;">结语：AI开发者的前沿技术盛宴</strong></h2> 
<p>这些年来，英伟达GTC大会已经成为一场面向AI、HPC、科学计算、数字孪生及自动驾驶等诸多前沿领域的技术盛宴。 </p> 
<p>在这场盛宴中，我们不仅看到技术突破如果改变各行各业的生产效率和工作方式，也看到英伟达围绕计算世界的最新布局。 </p> 
<p>随着新一代大规模云技术的出现，数据中心架构有待转型。在稳拥GPU基本盘的基础之上，英伟达的角色正从图形显示和加速计算“偏科学霸”，转向围绕数据中心三大芯片支柱全面发展。 </p> 
<p>黄仁勋认为，数据中心正在转变成“AI工厂”，它通过处理海量的数据来实现智能，而今日推出的H100便是实现企业AI业务加速的引擎。 </p> 
<p>H100的多项技术创新，数据中心专属Grace CPU超级芯片的特殊设计，以及AI和Omniverse平台的持续升级，进一步扩大了英伟达在加速AI训练及推理领域的领导地位。 </p> 
<p>在为期4天的英伟达GTC大会上，我们还将看到更多不同细分领域的专家，分享他们如何利用AI和加速计算领域的技术创新，来开展各类开创性的研究或解决正面临的挑战。 </p> 
<p class="editor-note">本文来自微信公众号<a target="_blank" rel="noopener noreferrer nofollow" href="https://mp.weixin.qq.com/s/KtbJD1oWEadpMHK-s3XHaA">“芯东西”（ID:aichip001）</a>，作者：ZeR0 ，编辑：漠影 ，36氪经授权发布。</p>  
</div>
            