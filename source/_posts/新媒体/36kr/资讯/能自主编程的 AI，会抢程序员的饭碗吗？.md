
---
title: '能自主编程的 AI，会抢程序员的饭碗吗？'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20220308/v2_3c92fa8e62e74b339097ec836273af28_img_000'
author: 36kr
comments: false
date: Tue, 08 Mar 2022 08:17:58 GMT
thumbnail: 'https://img.36krcdn.com/20220308/v2_3c92fa8e62e74b339097ec836273af28_img_000'
---

<div>   
<p>口述：</p> 
<p>科普作家 瘦驼  </p> 
<p>Jina AI 创始人兼 CEO 肖涵 </p> 
<p><a class="project-link" data-id="427226" data-name="一流科技" data-logo="https://img.36krcdn.com/20210812/v2_bebf9fcc71804220873878a0076948a4_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/427226" target="_blank">一流科技</a> OneFlow 创始人兼 CEO 袁进辉</p> 
<p><a class="project-link" data-id="28246" data-name="极客公园" data-logo="https://img.36krcdn.com/20210806/v2_2c82e87fac314e71ac5bacf9f189420f_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/28246" target="_blank">极客公园</a>创始人兼总裁 张鹏</p> 
<p>整理：汤一涛 </p> 
<p>春节期间，开发出 AlphaGo 的人工智能公司 DeepMind 又发布一个能够自主编程的新模型——AlphaCode。</p> 
<p>在编程竞赛网站 Codeforces 举办的 10 场比赛中，AlphaCode 取得了前 54.3% 成绩。这意味着，它打败了将近一半的人类选手。更为关键的是，比赛中的所有代码都是由 AlphaCode 自动生成的，全程无需人工监督。</p> 
<p>AlphaCode 取得的成绩意味着什么？它会抢走程序员的饭碗吗？在基础科学领域，AI 发挥了怎样的作用？该如何理解人类和 AI 的关系？</p> 
<p>上周，《今夜科技谈》邀请到了科普作家瘦驼、Jina AI 创始人兼 CEO 肖涵、一流科技 OneFlow 创始人兼 CEO 袁进辉，聊了聊和 AI 有关的话题。</p> 
<p class="image-wrapper"><img data-img-size-val="512,288" src="https://img.36krcdn.com/20220308/v2_3c92fa8e62e74b339097ec836273af28_img_000" referrerpolicy="no-referrer"></p> 
<h2><strong>如何评价 AlphaCode 取得的成绩？它还需要人工训练吗？</strong></h2> 
<p><strong>肖涵：AlphaCode 其实不是一个单一的算法，它是根据 GPT-3 模型搭建出来的一个系统。所以我们不认为 AlphaCode 是AI算法上的突破，它的突破在于产生了一个能够胜任比较复杂任务的系统。</strong></p> 
<p>就算法训练来说，人工智能的第一步是<strong>预训练</strong>。就是把 GitHub 上的程序都拉下来，让这个模型对编程有一个初步的认识。</p> 
<p>第二步是<strong>微调</strong>。因为预训练<a class="project-link" data-id="95377" data-name="得到" data-logo="https://img.36krcdn.com/20210807/v2_966db147ab4646ef82349f069ce61219_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/95377" target="_blank">得到</a>的知识并不都是有用的，它们给出了一个大体的世界观，但如果要解决具体的问题，就需要定向调整。</p> 
<p>AlphaCode 做的另外一件事就是构建了一套<strong>评判系统</strong>。因为基于给定的题目，AlphaCode 可以生成大量答案，但它并不知道这些答案正确与否。所以把问题答案和他给出的答案输入到这个系统中，它就可以评判答案正确与否。</p> 
<p>整个过程确实就像 AlphaCode 发布时所宣称的，是可以做到完全无监督的。</p> 
<p><strong>袁进辉：</strong>我认为 AlphaCode 是<strong>里程碑式的进展</strong>，根据自然语言描述，自动生成可解决算法问题的完整程序，这很了不起。</p> 
<p>其实我对 AlphaCode，经历了从低估到高估再到低估的心理转变。</p> 
<p>我在看到论文细节之前，低估了 AlphaCode。和 GPT-3 训练自然语言类似，AlphaCode 本质上也是抓取了 GitHub 上的几百亿行代码，捕捉语言结构，再生成。并且，相比于非常不规律的自然语言，代码的语法是非常规律的。从这个角度来说，AlphaCode 和以前解决问题的方法差不多。</p> 
<p>但令我感到意外的是，我本来以为 AlphaCode 的原理是自动搜索代码库中已有的代码片段，但实际上这些代码都是预训练模型自动生成的。传统上我们认为 AI 解决的通常是低精度的问题，比如图片识别准确率 90% 已经很高了，但让 AI 做到 100% 的准确率是极难的。而代码恰恰要求 100%，即使是写错一个变量名称，或者少打一个「;」，程序也会报错。所以这时我又高估了 AlphaCode。</p> 
<p>后来我又看了 AlphaCode 的论文，发现它确实可以自己生成完整程序，但中间也用了一些取巧的成分。比如说它会为一个问题生成 100 万份程序，其中当然有对有错。AlphaCode 会筛选掉 99% 的代码，留下 1%。在这 1% 的几千份代码中，AlphaCode 又通过<a class="project-link" data-id="438924" data-name="聚类" data-logo="https://img.36krcdn.com/20210812/v2_546858945a464e60b59f4f13b43869e1_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/438924" target="_blank">聚类</a>筛选等方式，筛选出 10 个答案提交到 Codeforces。只要这 10 个答案中有一个正确答案，就算过了。</p> 
<p>所以 AlphaCode 并不是一次性生成解决问题的程序，而是为一个问题生成数十万、上百万的程序，经过简单测试、样例筛选，最终筛选出正确答案。</p> 
<h2><strong>对比 Codex、Github Copilot 这些辅助编程工具，AlphaCode 有什么不同？</strong></h2> 
<p><strong>袁进辉：</strong>我觉得有两点，一是解决的问题不同，二是方法不同。</p> 
<p>AlphaCode 解决的问题，还是有一定难度的问题。</p> 
<p>二是 AlphaCode 不是网上搜索的现成代码片段，是自己生成的。像 Github Copilot，就是搜索的现成代码片段。之前有人做过实验，发现它会从 Stack Overflow（代码问答网站）上抓取代码，因为它把程序员写在代码里的注释都抓取过来了。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,777" src="https://img.36krcdn.com/20220308/v2_3422744df1f942fb982441182b3a5e86_img_000" referrerpolicy="no-referrer"></p> 
<h2><strong>这些 AI 编程工具，会取代程序员吗？</strong></h2> 
<p><strong>肖涵：</strong>其实这些 AI 辅助编程工具，都是为了帮助开发者能有更好的编程体验。只不过 AI 发展到今天已经非常强大，它可以自动把代码写完，而不仅仅是填函数名这么简单。</p> 
<p><strong>但是今天所有的AI都没有到达取代开发者的程度，开发者本身还是那个最终的决策人。</strong>AI 所生成的代码，仅仅是一个参考。</p> 
<p><strong>瘦驼：</strong>作为一个文字工作者，我还是想把这件事映射到「自然语言」的领域来。</p> 
<p>首先，让 AI 生成一段没有任何语法错误的代码没有那么难。在自然语言里有大量不符合逻辑和语法的东西，我们在说话的时候并不是严格遵循某种规律的。但代码本身是严格遵守语法的，它有一套通用的逻辑。</p> 
<p>第二点，我觉得码农其实不必太紧张，对于文字创作者来说，我们在前几年已经碰到过类似的挑战了。现在一些固定格式的文本已经大量地由 AI 生成，比如比赛结果、股市播报、天气预报。对于这种有规律可循的文本来说，AI 写得比人快多了。但是想让 AI 写一些有创造性的东西还是非常困难的，因为创造性本质上是对现有逻辑和体系的挑战，甚至创造性包含了允许 AI 犯错。<strong>对 AI 来说，它很难保持一定的个性</strong>，比如《红楼梦》里，贾宝玉的诗和林黛玉的诗就有明显的不同。这种能力，AI 现在可能还很难做到。</p> 
<p><strong>肖涵：我觉得性格的差别，无非就是训练语料的不同。</strong>如果我想生成一个朦胧派诗人的风格，我就把所有朦胧派诗人的语料收集起来，训练一下就可以了。</p> 
<p>所以我觉得对 AI 最重要的还是<strong>数据</strong>。算法模型如果能更好地挖掘数据，把数据的价值充分利用起来，那其实所谓的性格也就达成了。</p> 
<p><strong>袁进辉：</strong><a class="project-link" data-id="4261651" data-name="我来" data-logo="https://img.36krcdn.com/20220120/v2_39e15b54549447b28c9c84a547d3c6c2_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4277700122?mp=zzquote" target="_blank">我来</a>补充一个反方向。按照肖涵的逻辑，那如果没有朦胧派的语料，就生成不出朦胧派的 AI；如果没有梵高这个人，就训练不出梵高风格的绘画。所以 AI 在创造层面，本质上还是更像一种记忆，差别在于是一种机械的记忆还是比较聪明的记忆，但其实都跳脱不出原有的范畴。</p> 
<p>专业术语里有两个词，「exploitation」和「exploration」。exploitation 指的是保守地在应有的范围内工作，exploration 指的是在范围之外探索。</p> 
<p>也许我们需要给 AI 一点犯错空间。</p> 
<h2><strong>在 AI 崛起的背景下，怎么做一个有价值的程序员？</strong></h2> 
<p><strong>袁进辉：</strong>AI 比较擅长做比较机械的工作，但写代码也是需要创造性的，写到一定程度，我们也把它称之为艺术。</p> 
<p>代码里面也有好坏，写出来的代码是不是足够简洁优雅，是否有创造性的审美，这可能还是人类的优势。</p> 
<p><strong>张鹏：</strong>但这种美，是不是也要能体现在效率上高于丑和复杂的东西，商业世界才会认可？</p> 
<p><strong>袁进辉：</strong>这种美，确实在效率上有体现。判断代码美丑的一个标准，就是可复用性。简单的代码有更好的扩展性，未来就可以在更多的地方复用。如果我的代码只在当前的任务可以用，就是不太好的实践。</p> 
<p><strong>肖涵：</strong>我想起来之前国外论坛上有一个特别火的帖子，就是说一个律所雇佣了一个小伙子做类似报表整理之类的工作。恰好这个小伙子懂一点编程，就把这个工作自动化了，程序运行 5 分钟就可以做完原来一周的工作。两周之后，这个小伙子内心有点愧疚，就把这件事发到了论坛上，问大家该不该告诉老板这件事。</p> 
<p>我觉得这件事反映了一点——不管他有没有告诉老板，机械化的工作一定会被取代。甚至他自己也觉得做这种工作没有意义，否则就不会有这种纠结。人生总要有点追求，何必在这里浪费时间？</p> 
<p>其次是我觉得出现这些代码辅助 AI 不是坏事。人类发展到今天，不管是工业革命还是流水线的引入，人类总会从事更高级的职业，会创造更高的价值。总体来说，我觉得这是一件正向的事。</p> 
<h2><strong>怎么理解当下很火热的低代码、软件 2.0 这些概念？</strong></h2> 
<p><strong>肖涵：低代码出现的原因，其实是过去几十年我们已经积累了大量的代码资本。今天任何一个软件，都不是从头开始写的，它们都有自己的上游依赖关系——软件库。</strong></p> 
<p>实际上我们构建现代软件的时候，最重要的往往不是创新，而是<strong>可复用性</strong>。可复用性指的就是，这个软件完成之后，一定要成为更大型软件中的一个组件，而不是从头开始重复造轮子。</p> 
<p>当「可复用性」这种概念深入人心之后，于是才有了低代码、无代码这种概念。今天我们构建的代码越来越高级，不再是操作系统这种底层软件，更多的是面向 C 端用户的高级软件。这种情况下就非常凸显低代码、无代码的重要性。</p> 
<p>如果纵观整个人类的工程史，其实可复用性就是非常关键的转折点——一旦一个东西可以被复用，人类的文明就会发展到一个新高度。我们可以假想一下，一个原始人拿着两块石头碰触了火花，这是一个偶然吗？还是说它成为了可以被复用的经验，于是人类就此掌握火的使用？</p> 
<p>所以我更想强调的是，低代码和无代码肯定是发展趋势。但趋势背后的原因在于，我们现在面向的是更高级的软件开发，这种开发尤其强调复用性。</p> 
<p><strong>袁进辉：</strong>我来补充一下软件 2.0。</p> 
<p>软件 1.0 说的是<strong>代码是数据</strong>。我们在代码的基础上，基于数据训练一个 AI 模型。</p> 
<p>软件 2.0 指的是<strong>模型是代码</strong>。在 AlphaCode 之前，AI 的模型早就开始为人写代码了。比如图形识别模型，它的原理是计算机视觉科学家写了一堆规则——图片里有哪些特征，那这张图片就是汽车。但是这么做了几十年之后，发现这种方法识别率并不高。所以现在的做法是从一堆数据中训练出一个模型。</p> 
<p>以前代码必须由程序员理解问题之后转化成计算机理解的语言，计算机才能帮我们解决问题，本质上是一个从物理世界迁移到数字世界的过程。模型即代码的意思就是，现在我们不需要经过人脑了，只要收集一堆数据，计算机就能自动挖掘数据中的规律，生成模型。</p> 
<h2><strong>可复用性是判断代码好坏的一个重要标准。现在代码间复用的情况也越来越普遍，但如果引用的底层代码本身就有问题，该怎么办？</strong></h2> 
<p><strong>肖涵：</strong>现实世界中确实发生过这样的事。前几个月 Log4j 软件包出错，就造成了非常多软件公司的恐慌。这样的问题，在低代码和无代码的环境下会更难发觉。因为没有多少人会去写这种底层的代码了，大家关注的更多是更高级的软件业务逻辑。</p> 
<p>之前在 Javasript 社区还发生了一件事。维护底层代码的程序员因为觉得别人在网上攻击他，一怒之下把代码删了。这导致的后果就是整个复用的链条断了。</p> 
<p>所以说在低代码、无代码的环境下，一定要保证上游足够稳健。即使出错也要能够及时修复，这一点非常重要。</p> 
<p><strong>袁进辉：</strong>其实 AI 的模型是很脆弱的，非常容易被攻击。实际上训练 AI 模型的就是一堆数据，简单理解就是高维空间中的<strong>一个方向</strong>。如果进来的数据是沿着这个方向的，AI 就判断得很准。如果进入的数据和那个方向垂直，那 AI 的判断就会出错。</p> 
<p>前几年有人在<a class="project-link" data-id="132410" data-name="特斯拉" data-logo="https://img.36krcdn.com/20200729/v2_e76e3d3d44c440138f072b13bc84a6dc_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/132410" target="_blank">特斯拉</a>的激光雷达上做了一个实验，用一个小纸片稍微改变一下传进去的信号，特斯拉的识别就出错了。</p> 
<p><strong>张鹏：</strong>前段时间我还听到过这种观点。就图像识别技术而言，在最初构建 ImageNet（视觉影像网数据库）的时候，因为当时数据的局限，导致现在形成了一些偏差，比如 AI 对人类的歧视问题。但今天 ImageNet 已经成为了一个基础设施，无数人在这之上构建了新的设施，这种偏差就成为了一个逐级感染的问题，越来越难以克服。</p> 
<p>可能在某些时刻，需要一个根本性的重启，才能解决这个问题。</p> 
<h2><strong>在基础科学领域，AI 能够发挥哪些作用？</strong></h2> 
<p><strong>瘦驼：</strong>对于很多数据敏感型的行业来说，AI 确实解放了很多科学家，让这些科学家可以去做更多有创造性的工作。</p> 
<p>之前讨论过，在人类的天文学家中，最容易被 AI 取代的可能是埃德文·哈勃。他花了几十年时间，从大量数据中发现了星系的「红移-距离关系」。这本质上是一个数据相关性的问题，放在今天的 AI 身上，可以立刻发现这种数据间的规律。</p> 
<p>又比如说快速射电暴，它以前经常被人忽略。因为快速射电暴太短暂了，很容易被认为是数据中出现的一个异常。但是有了 AI 这样的工具后，它就可以从这些不断出现的偶然异常中发现规律。</p> 
<p>我觉得 AI 的出现改变了科学发现的范式，让我们具备了从数据中找出被忽略的规律的能力。</p> 
<h2><strong>AI 公司的商业化都很困难，但 DeepMind 在去年盈利了，怎么理解这家公司？</strong></h2> 
<p><strong>肖涵：</strong>首先我对 DeepMind 是非常崇敬的，但我不会做这种公司，我个人认为 DeepMind 风险性是非常高的，回本的机率很低。</p> 
<p>首先在深度学习的前提下，算力成本和存储成本的投入是非常高的，这个很好理解。</p> 
<p>第二个是人员原因。每年 DeepMind 都有一两篇轰动性的论文面世，很重要的原因就在于，它储备了大量全世界最顶尖的人才。这种人才成本，不是每个公司都能承担的。深度学习发展到今天，实际上拉大了大公司和小公司间的贫富差距。</p> 
<p>我个人其实更看重 AI 在工程领域的突破，如何更好地解决已有的问题，而不是找到一个从没被解决过的新问题去突破。</p> 
<p><strong>袁进辉：</strong>DeepMind 的确不太典型，他理论上不是一家商业公司。大部分商业公司，一定是要做一个可复制的商业化产品，更多的是考虑市场规模等一系列更实际的问题。</p> 
<p>DeepMind 更像一家科研机构。只不过它不像科研机构申请经费那么困难，DeepMind 背后<a class="project-link" data-id="610396" data-name="有谷" data-logo="https://img.36krcdn.com/20210814/v2_8ae4fc1814f64be68058ae14a7e28ec4_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/610396" target="_blank">有谷</a>歌源源不断地投入资金。</p> 
<h2><strong>这些年，AI 的发展思路有什么变化？</strong></h2> 
<p><strong>肖涵：</strong>我觉得有两点，一是 AI 的解释性，二是 AI 的训练过程。</p> 
<p><strong>1、解释性。</strong>AI 这些年其实经历了从可解释到不可解释的过程。 </p> 
<p>早期的 AI 是基于一套规则生成的，比如最早的问答机 Eliza，它的逻辑在于，识别你说的话包含哪些字符，经过因果判断，返回特定的答案。这些回答都是可以解释的，因为程序是写死的。</p> 
<p>后来 AI 发展到 2000 年左右，出现了参数化模型。参数化模型会把图片、声音、文本等信息描述成一个数据函数，AI 所要做的，就是填入系数。这一阶段的 AI 也是可解释的。</p> 
<p>自 2010 年以来，AI 逐渐转向了深度学习框架，AI 开始变得不可解释。因为深度学习框架拆分到最细，其实是由一个一个非线性函数叠加而成的。如果只有一个非线性函数的话还比较好解释，但叠加在<a class="project-link" data-id="81906" data-name="一起" data-logo="https://img.36krcdn.com/20210709/v2_647b9860d6f7437caf1be2501d37698a_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4772100123" target="_blank">一起</a>的非线性函数有点类似蝴蝶效应，基本上是不可能溯源的。</p> 
<p>我们整个深度学习网络是一个非常深的非线性系统，比如 AlphaCode 就包含 400 多亿个参数，实际上无法追根溯源，到底是哪个参数产生的影响。这就好像我们无法判断，到底是哪一个神经元令人脑产生了意识一样。</p> 
<p>但是今天，又有一些人要求 AI 具有可解释性。因为随着 AI 越来越聪明，我们要求它承担它的社会责任了，比如不能歧视黑人。当出现问题时，就可以找到出现问题的原因，这就要求 AI 可以被解释。</p> 
<p><strong>2、训练过程</strong>。AI 的训练过程，从一开始的「端到端」过程，拆分成了「预训练」和「微调」两步，专业术语叫迁移学习。 </p> 
<p>其实我本人非常喜欢迁移学习，因为它为机器学习指明了一个大方向。以往的机器学习，每解决一个问题，就要专门构建一个模型。即使是解决两个非常相似的问题，比如识别是篮球新闻还是足球新闻，哪怕都是自然语言处理，在传统机器看来都是不同的任务。</p> 
<p>机器学习将端到端训练的过程拆分成了两部分。一部分是预训练，从大规模的语料中学到一个相对通用的知识。然后是微调，将通用的知识去解决特定的细节问题。</p> 
<p>这样拆分的好处在于，大规模语料训练的模型可以得到复用。因为不是所有公司都有能力构建这种超大规模的模型。可以复用之后，中小公司就可以拿这个模型针对自身特定的领域微调，就能产生子领域上的业务价值，节省了大量的人力、物力和时间成本。</p> 
<p><strong>袁进辉：</strong>我想补充的是，这种大模型还没到头，以后还会越来越大。像 GPT-3，参数已经达到 1700 亿，但和人脑的神经元连接数相比，还差 1000-10000 倍左右。</p> 
<p>一个可能的猜想是，智能或许没有那么神奇，只是一个规模的问题，最后会由量变产生质变。</p> 
<p>另一种观点认为，预训练模型在脑科学和神经科学上也有一定的支撑。人之所以这么聪明，有一部分是后天习得的，但主要还是先天决定的。在一个婴儿出生之前，大脑皮层间的连接和神经元的突起，就已经大致由基因决定了。在婴儿出生看到这个物理世界后，神经元之间的连接会根据物理信号微调——有的连接会越来越强，不太使用的连接就会变弱。</p> 
<p>这整个过程都非常类似预训练和微调的模式。所以从某种意义上来说，大模型预训练，的确有生物的合理性。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,1350" src="https://img.36krcdn.com/20220308/v2_2d12ecc12feb47e1afd3be5a878fbdfe_img_000" referrerpolicy="no-referrer"></p> 
<h2><strong>AI 和人类会是怎样的关系？</strong></h2> 
<p><strong>肖涵：</strong>我对 AI 能力的增强是非常有信心的。但是，在目前这套方法之下，我认为 AI 可能最终无法产生自我意识。</p> 
<p>可话说回来，<strong>难道AI一定要有自我意识吗？</strong></p> 
<p>50 年后可能 AI 仍然没有自我意识，但它可以解决非常多重要的问题，要比人类解决得好得多，这个时候你会愿意承认这种形态的东西是「智能」吗？</p> 
<p><strong>袁进辉：</strong>我倾向于从正面理解这件事，就是 AI 可以解放人类，让人类去追求更本质的东西，就好像蒸汽机把我们从体力劳动中解放出来一样。</p> 
<p>这让我想起了刘慈欣的小说《<a class="project-link" data-id="426935" data-name="朝闻道" data-logo="https://img.36krcdn.com/20200729/v2_dfcc638954cb4968827819ce4254e01d_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/426935" target="_blank">朝闻道</a>》中的一个设定：地球人可以向外星人提任何问题，外星人会告诉你正确答案。但代价是知道答案后，这个提问者会立刻死去。但最终有一个人问了外星人这样一个问题：<strong>宇宙的目的是什么？</strong></p> 
<p>外星人也不知道，于是他崩溃了。</p> 
<p><strong>张鹏：</strong>虽然我们被冠以「拥有自我意识」，但全世界也有大量的人不知道自己的目的是什么。所以我觉得以自我意识来定义也许是一种人类沙文主义。</p> 
<p><strong>瘦驼：</strong>我觉得对于 AI 的思考有几个层面。</p> 
<p>一个是哲学层面上的。我认为<strong>如果未来AI变得像人一样，那一定是失败的 AI。</strong>他有人的缺点，有人自己都搞不清的逻辑错误，那我们为什么要造 AI？直接造人不是简单得多吗？我们之所以要造 AI，一定是它可以解决人类解决不了的问题，这样 AI 才有意义。</p> 
<p>另外我也有一些应用层面上的顾虑。刚刚几位也说到，AI 很脆弱。如果我们已经高度依赖 AI 了，一旦底层的东西有问题，会造成非常大的影响。</p> 
<p>然后是关于解释性的困局。解释性的困局其实是用来解放人类自己的，就是想求一个安心。但即便这个说法本身没有意义，也一定会让很多人心生警惕。这种警惕，从人作为社会性动物的角度来说，就会对 AI 的发展产生影响。我们需要有一定的准备，不要让这种警惕发酵到一个比较尖锐的地步，那到时状况就比较糟糕了。</p> 
<p><strong>张鹏：我觉得真正的问题是，AI今天还有大量的基础工作要做好。</strong>我们可以确定，AI 会成为人类未来文明进程中重要的伙伴，但它距离这个角色，其实还有很长的路要走。</p> 
<p>今天我们对于 AI 的探讨，如果是针对「不要犯一些基础错误」，是有意义的。但在 AI 能力还比较羸弱的时候过度讨论「自我意识」之类的话题，其实是很务虚的。</p> 
<p>图片来源：Unsplash，DeepMind</p> 
<p class="editor-note">本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer nofollow" href="https://mp.weixin.qq.com/s/yBzBn-7OVhRt1tN8Mj_DTw">“极客鹏友说”（ID:geekpys）</a>，作者：今夜科技谈，36氪经授权发布。</p>  
</div>
            