
---
title: '谷歌人像抠图出新作：以后五一足不出户游世界'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20210503/v2_8217e0eccdf44d3b9ce2761c8b7e678b_img_000'
author: 36kr
comments: false
date: Mon, 03 May 2021 06:30:00 GMT
thumbnail: 'https://img.36krcdn.com/20210503/v2_8217e0eccdf44d3b9ce2761c8b7e678b_img_000'
---

<div>   
<p>编者按：本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer" href="https://mp.weixin.qq.com/s/JMzyeZbfS0-hyUWwOjgltg">“机器之心”（ID:almosthuman2014）</a>，36氪经授权发布。</p> 
<p><strong>编辑：维度、陈萍</strong></p> 
<p>人像抠图又出新作！来自<a class="project-link" data-id="3968996" data-name="谷歌" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968996" target="_blank">谷歌</a>的研究者提出了一种新的人像重照明和背景替换系统，可对图像背景进行替换，生成的肖像图的光照条件与新背景保持一致，还能有效地去除图片中的强光，细节恢复较好。</p> 
<p>在人像抠图中，前景预测背景替换是至关重要的组成部分，此前也出现过各种效果不错的抠图方法，如商汤等提出的只需单张图像、单个模型的方法 MODNet、华盛顿大学单块 GPU 实现 4K 分辨率每秒 30 帧的 Background Matting 2.0 等。这些方法或多或少都有其局限性。 </p> 
<p>近日，来自谷歌的几位研究者提出了一种全新的人像重照明（portrait relighting）和背景替换系统，该系统不仅保留了高频边界细节，并精确地合成了目标人像在新照明下的外观，从而为任何所需场景生成逼真的合成图像。 </p> 
<p>相关论文已被 SIGGRAPH 2021 会议接收。 </p> 
<p class="image-wrapper"><img data-img-size-val="1080,163" src="https://img.36krcdn.com/20210503/v2_8217e0eccdf44d3b9ce2761c8b7e678b_img_000" referrerpolicy="no-referrer"></p> 
<p>论文地址：https://augmentedperception.github.io/total_relighting/total_relighting_paper.pdf </p> 
<p>该研究的亮点和核心是通过 <strong>前景蒙版（alpha matting）、重照明（relighting）和合成（compositing</strong> ）进行前景估计。 </p> 
<p>研究者在论文中表示，每个阶段都可以在一个连续的 pipeline 中处理，无需使用先验知识（如已知背景或已知照明），也无需专门的采集技术，仅使用单个 RGB 肖像图和新的目标 HDR 照明环境作为输入。 </p> 
<p>模型训练中使用到了光阶段计算照明（ light stage computational illumination ）系统捕获的重照明肖像图，该系统记录了多种照明条件、高质量几何形状和精确的前景蒙版。 </p> 
<p>此外，为了实现真实的重照明合成，研究者在深度学习框架中引入了一种新的每像素照明表征，它显式地建模肖像图外观的漫反射和镜面反射组件，生成了具有绝佳渲染非朗伯效果（如镜面反射高光）的重照明肖像。实验表明，该方法在处理自然环境图像中是有效的。 </p> 
<p>合成效果是这样的： </p> 
<p class="image-wrapper"><img data-img-size-val="788,425" src="https://img.36krcdn.com/20210503/v2_0265f1bb8c8e46c89261dc2a9a3fa0bd_img_000" referrerpolicy="no-referrer"></p> 
<p>‍实景动态展示，能看出来是合成的吗？ </p> 
<p class="image-wrapper"><img data-img-size-val="790,366" src="https://img.36krcdn.com/20210503/v2_bad9ebd6efca4c538126d8208dd8aae6_img_000" referrerpolicy="no-referrer"></p> 
<p class="image-wrapper"><img data-img-size-val="790,366" src="https://img.36krcdn.com/20210503/v2_8dd465595c9c47be988df22a8d65ed00_img_000" referrerpolicy="no-referrer"></p> 
<h3><strong>框架方法</strong></h3> 
<p>研究者提出的框架包含以下几个步骤，首先 matting 模块根据给定的 RGB 肖像图估计前景蒙版和前景，然后估计的前景和目标 HDR 照明环境馈入重照明模块，该模块负责推理表面几何形状和反照率，并使用每像素重照明表征来显式地建模着色后外观的漫反射和镜面反射组件。 </p> 
<p>最后，前景蒙版、重照明结果和新背景合成在<a class="project-link" data-id="81906" data-name="一起" data-logo="https://img.36krcdn.com/20210422/v2_9d94d5f89e394f8082c3b500e50c340d_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4772100123" target="_blank">一起</a>，生成了一张具有新背景的重照明肖像图，并且肖像图的光照条件与新背景保持一致。 </p> 
<p>整体架构如下图 3 所示： </p> 
<p class="image-wrapper"><img data-img-size-val="1080,324" src="https://img.36krcdn.com/20210503/v2_8a3ea073680640beb007cfb56d4948f9_img_000" referrerpolicy="no-referrer"></p> 
<p>重照明模块又包含以下几个步骤，首先使用几何网络（Geometry Network）来估计输入前景的每像素表面法线 N，然后利用表面法线和前景 F 来生成反射率（albedo）A。使用扩散和镜面卷积运算对目标 HDR 照明环境进行预过滤，然后通过表面法线或者反射<a class="project-link" data-id="89972" data-name="向量" data-logo="https://img.36krcdn.com/20201106/v2_75b590267c7e4d18a665b261a9f40def_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/89972" target="_blank">向量</a>对预过滤后的 map 进行采样，从而生成目标照明（光照图）漫反射和镜面反射的每像素表征。接着，使用着色网络（Shading Network）生成最终的重照明前景。 </p> 
<p>下图 4 展示了重照明模块的详细工作流程： </p> 
<p class="image-wrapper"><img data-img-size-val="1080,448" src="https://img.36krcdn.com/20210503/v2_44783462332f4c01a9ab734c13504415_img_000" referrerpolicy="no-referrer"></p> 
<p>着色网络是如何工作的呢？首先，使用镜面网络（specular network）来预测单个镜面光照图，并作为输入。然后，将预测<a class="project-link" data-id="95377" data-name="得到" data-logo="https://img.36krcdn.com/20200929/v2_fcdf767846d041309970adf0877fc666_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/95377" target="_blank">得到</a>的镜面光照图与漫反射分量和反射率连接，并经由最终的神经渲染网络生成重照明前景。具体工作流程如下图 5 所示： </p> 
<p class="image-wrapper"><img data-img-size-val="869,444" src="https://img.36krcdn.com/20210503/v2_410c9291ae5c4bb5a259a68a6869f2e5_img_000" referrerpolicy="no-referrer"></p> 
<p>最后，使用神经渲染器执行实际的图像合成，所使用架构 U-Net 与 Geometry Net 和 Albedo Net 的结构相同。研究者利用神经渲染器补偿近似（approximation）以及预测到中间图像中的任何残差。 </p> 
<p>下图 6 展示了神经渲染器合成图像的过程： </p> 
<p class="image-wrapper"><img data-img-size-val="842,650" src="https://img.36krcdn.com/20210503/v2_fce0a5e28d694a0ebd48a14953228ea1_img_000" referrerpolicy="no-referrer"></p> 
<h3><strong>效果对比</strong></h3> 
<p>在实验中，研究者从 <strong>重照明效果和 matting 模块</strong> 效果两个方面将提出的方法和 SOTA 方法进行了比较。 </p> 
<h4><strong>重照明效果的对比</strong></h4> 
<p>该研究将重照明模块与两种 SOTA 单幅肖像重照明方法进行了比较：对于在光照阶段拍摄的评估对象，该研究有真实重光照结果，可以对不同技术进行定性和定量比较。定性结果如下图 10 所示，所提出的方法优于以前 SOTA 方法，增加了照片的真实性。 </p> 
<p class="image-wrapper"><img data-img-size-val="1014,1198" src="https://img.36krcdn.com/20210503/v2_52e214880be74e8587dcf501af48bacc_img_000" referrerpolicy="no-referrer"></p> 
<p>定量评价结果如下表 1 所示，该研究所提出的方法在肖像重照明任务的每个指标上都优于 SOTA 技术。 </p> 
<p class="image-wrapper"><img data-img-size-val="1032,368" src="https://img.36krcdn.com/20210503/v2_5f52628e000c45658a6f2c95139b50e5_img_000" referrerpolicy="no-referrer"></p> 
<p>研究者还比较了在任意光照条件下拍摄的户外人像的不同方法，其定性结果如下图 11 所示。结果表明，该方法在从输入图像（第一列）中 <strong>去除强光高光方面特别有效</strong> ，并且可以很好地泛化到户外图像。 </p> 
<p class="image-wrapper"><img data-img-size-val="842,855" src="https://img.36krcdn.com/20210503/v2_67902e0aac7649119b6975e9320ea634_img_000" referrerpolicy="no-referrer"></p> 
<h4><strong>Matting 效果对比</strong></h4> 
<p>为了验证自定义人像 matting 模块的必要性，研究者将提出的方法与 Li and Lu [2020] 和 Xu [2017] 等人的方法进行了对比。 </p> 
<p>下表 2 为带有真值标签肖像数据集的定量结果： </p> 
<p class="image-wrapper"><img data-img-size-val="1043,604" src="https://img.36krcdn.com/20210503/v2_39628af709ca4a6f973a98c4b155f7a5_img_000" referrerpolicy="no-referrer"></p> 
<p>值得注意的是，这种尤其针对人像训练的方法要优于以往的预训练方法。下图 13 中展示了定性结果，该研究提出的方法能够恢复更清晰的边界和精细的细节，从而获得更精确的前景蒙版。 </p> 
<p class="image-wrapper"><img data-img-size-val="1079,1394" src="https://img.36krcdn.com/20210503/v2_d4b6e7c292154b499b1d08b2e7dd2954_img_000" referrerpolicy="no-referrer"></p>  
</div>
            