
---
title: '英伟达新核弹GPU：4nm制程800亿晶体管，20张即可承载全球互联网流量，全新Hopper架构太炸了'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20220323/v2_ff6325cb893941ac9cd42c4a308a94b9_img_000'
author: 36kr
comments: false
date: Wed, 23 Mar 2022 01:26:31 GMT
thumbnail: 'https://img.36krcdn.com/20220323/v2_ff6325cb893941ac9cd42c4a308a94b9_img_000'
---

<div>   
<p><span style="letter-spacing: 0px;">他来了他来了，老黄带着<a class="project-link" data-id="3969182" data-name="英伟达" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3969182" target="_blank">英伟达</a>的最新一代GPU来了。</span></p> 
<p class="image-wrapper"><img data-img-size-val="480,246" src="https://img.36krcdn.com/20220323/v2_ff6325cb893941ac9cd42c4a308a94b9_img_000" referrerpolicy="no-referrer"></p> 
<p>之前大家猜的5nm错了，一手大惊喜，老黄直接上了<strong>台积电4nm</strong>工艺。</p> 
<p>新卡取名H100，采用全新Hopper架构，直接集成了800亿个晶体管，比上一代A100足足多了<strong>260亿个</strong>。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,507" src="https://img.36krcdn.com/20220323/v2_8394d8c3aed847cfbb66dd330a731e7c_img_000" referrerpolicy="no-referrer"></p> 
<p>内核数量则飙到了前所未有的<strong>16896个</strong>，达到上一代A100卡的2.5倍。</p> 
<p>浮点计算和张量核心运算能力也随之翻了至少3倍，比如FP32就达到了达到60万亿次/秒。</p> 
<p>特别注意的是，H100面向AI计算，<strong>针对Transformer</strong>搭载了优化引擎，让大模型训练速度直接×6。</p> 
<p>（可算知道5300亿参数的威震天-<a class="project-link" data-id="577369" data-name="图灵" data-logo="https://img.36krcdn.com/20210814/v2_19eb19dd79d245f38db7412db4375a42_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4781700122" target="_blank">图灵</a>背后的秘诀了。）</p> 
<p>作为一款性能爆炸的全新GPU，不出意外，H100将与前辈V100、A100一样成为AI从业者心心<a class="project-link" data-id="41985" data-name="念念" data-logo="https://img.36krcdn.com/20210807/v2_aa65bdc4ab384b4bb6c7eb9e3c13288c_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/41985" target="_blank">念念</a>的<a class="project-link" data-id="530507" data-name="大宝" data-logo="https://img.36krcdn.com/20210813/v2_12d738e6ad014778ac6ca950550ff1b3_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/530507" target="_blank">大宝</a>贝。</p> 
<p class="image-wrapper"><img data-img-size-val="410,264" src="https://img.36krcdn.com/20220323/v2_21ccff40b8d34ba98d007473f55f34b7_img_000" referrerpolicy="no-referrer"></p> 
<p>不过不得不提，它的功耗也爆炸了，达到了史无前例的<strong>700W</strong>，重回核弹级别。</p> 
<p>关于自研的Grace CPU，这次大会也公布了更多细节。</p> 
<p>没想到，老黄从库克那里学来一手<strong>1+1=2</strong>，两块CPU“粘”在<a class="project-link" data-id="81906" data-name="一起" data-logo="https://img.36krcdn.com/20210709/v2_647b9860d6f7437caf1be2501d37698a_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4772100123" target="_blank">一起</a>组成了CPU超级芯片——Grace CPU Superchip。</p> 
<p>Grace CPU采用最新Arm v9架构，两块总共拥有144个核心，拥有1TB/s的内存带宽，比苹果最新M1 Ultra的800GB/s还高出一截。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,601" src="https://img.36krcdn.com/20220323/v2_a023d885628940eba0cfe324a783c8c3_img_000" referrerpolicy="no-referrer"></p> 
<p>基于全新CPU、GPU基础硬件，这次发布会也带来了下一代企业级AI基础设施DXG H100、全球最快AI超算Eos。</p> 
<p>当然，英伟达作为真正的元宇宙先驱，也少不了Omniverse上的新进展。</p> 
<p>下面具体来看看。</p> 
<h2><strong>首款Hopper架构GPU，性能暴增</strong></h2> 
<p>作为上一代GPU架构A100（安培架构）的继承者，搭载了全新Hopper架构的H100有多突飞猛进？</p> 
<p class="image-wrapper"><img data-img-size-val="1080,599" src="https://img.36krcdn.com/20220323/v2_274b3bc573a7474e965f30576af6b87b_img_000" referrerpolicy="no-referrer"></p> 
<p>话不多说，先上参数：</p> 
<p>老黄可谓下血本，先是直接采用了<strong>台积电4nm</strong>工艺，晶体管一口气集成了<strong>800亿</strong>个。</p> 
<p>要知道，上一代A100还只是7nm架构，这次发布会出来前，外界不少声音猜测老黄会用5nm制程，结果一发布就给大家来了个大惊喜。</p> 
<p>最恐怖的是CUDA核心直接飙升到了<strong>16896个</strong>，直接达到了A100的近2.5倍。（要知道从V100到A100的时候，核心也不过增加那么一丝丝）</p> 
<p>这次可不能感慨老黄刀法精准了。</p> 
<p>再看浮点运算和INT8/FP16/TF32/FP64的张量运算，性能基本全部提升<strong>3倍</strong>不止，相比来看，前两代的架构升级也显得小打小闹。</p> 
<p>这也使得H100的热功耗（TDP）直接达到了前所未有的<strong>700w</strong>，英伟达“核弹工厂”名副其实（手动狗头）。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,619" src="https://img.36krcdn.com/20220323/v2_0a998ab522234f538322f540279590c1_img_000" referrerpolicy="no-referrer"></p> 
<p>话又说回来，这次H100也是首款支持PCle 5.0和HBM3的GPU，数据处理速度进一步飞升——内存带宽达到了3TB/s。</p> 
<p>这是什么概念？</p> 
<p>老黄在发布会上神秘一笑：只需要20个H100在手，全球互联网流量我有。</p> 
<p>整体参数细节究竟如何，与前代A100和V100对比一下就知道了：</p> 
<p class="image-wrapper"><img data-img-size-val="1080,1302" src="https://img.36krcdn.com/20220323/v2_15c12a7ecffd4ed593ac75fd97f24d42_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style><strong>△</strong>图源@anandtech</p> 
<p>值得一提的是，Hopper架构的新GPU和英伟达CPU Grace名字组在一起，就成了著名女性计算机科学家<strong>Grace Hopper</strong>的名字，这也被英伟达用于命名他们的超级芯片。</p> 
<p>Grace Hopper发明了世界上第一个编译器和COBOL语言，有“计算机软件工程第一夫人”之称。</p> 
<h2><strong>训练3950亿参数大模型仅1天</strong></h2> 
<p>当然，Hopper的新特性远不止体现在参数上。</p> 
<p>这次，老黄特意在发布会上着重提到了Hopper首次配备的<strong>Transformer引擎</strong>。</p> 
<p>嗯，专为Transformer打造，让这类模型在训练时保持精度不变、性能提升<strong>6倍</strong>，意味着训练时间从几周缩短至几天。</p> 
<p>怎么表现？</p> 
<p>现在，无论是训练<strong>1750亿</strong>参数的<strong>GPT-3</strong> （19小时），还是<strong>3950亿</strong>参数的Transformer大模型（21小时），H100都能将训练时间从一周缩短到1天之内，速度提升高达9倍。</p> 
<p>推理性能也是大幅提升，像英伟达推出的<strong>5300亿 </strong>Megatron模型，在H100上推理时的吞吐量比A100直接高出30倍，响应延迟降低到1秒，可以说是完美hold住了。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,523" src="https://img.36krcdn.com/20220323/v2_150a1886066f4f43b4ede80e2f93017f_img_000" referrerpolicy="no-referrer"></p> 
<p>不得不说，英伟达这波确实突入了Transformer阵营。</p> 
<p>在此之前，英伟达一系列GPU优化设计基本都是针对<strong>卷积</strong>架构进行的，接近要把“I love 卷积”这几个字印在脑门上。</p> 
<p>要怪只怪Transformer最近实在太受欢迎。（手动狗头）</p> 
<p>当然，H100的亮点不止如此，伴随着它以及英伟达一系列芯片，随后都会引入NVIDIA <strong>NVLink</strong>第四代互连技术。</p> 
<p>也就是说，芯片堆堆乐的效率更高了，I/O带宽更是扩展至900GB/s。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,403" src="https://img.36krcdn.com/20220323/v2_208e8125ed9849429a4ccaf0aeae668a_img_000" referrerpolicy="no-referrer"></p> 
<p>这次，老黄还着重提到了GPU的<strong>安全性</strong>，包括实例之间具有隔离保护、新GPU具有机密计算功能等。</p> 
<p>当然，数学计算能力也提升了。</p> 
<p>这次H100上新的DPX指令可以加速动态规划，在运算路径优化和基因组学在内的一系列动态规划算法时速度提升了7倍。</p> 
<p>据老黄介绍，H100会在今年<strong>第三季度</strong>开始供货，网友调侃“估计也便宜不了”。</p> 
<p>目前，H100有两个版本可选：</p> 
<p>一个就是功率高达700W的SXM，用于高性能服务器；另一个是适用于更主流的服务器PCIe，功耗也比上一代A100的300W多了50W。</p> 
<h2><strong>4608块H100，打造全球最快AI超算</strong></h2> 
<p>H100都发布了，老黄自然不会放过任何一个搭建超级计算机的机会。</p> 
<p>基于H100推出的最新DGX H100计算系统，与上一代“烤箱”一样，同样也是配备8块GPU。</p> 
<p class="image-wrapper"><img data-img-size-val="480,266" src="https://img.36krcdn.com/20220323/v2_1d19595983a7458ba253d919e8e6ef84_img_000" referrerpolicy="no-referrer"></p> 
<p>不同的是，DGX H100系统在FP8精度下达到了32 Petaflop的AI性能，比上一代DGX A100系统整整<strong>高了6倍</strong>。</p> 
<p>各GPU之间的连接速度也变得更快，900GB/s的速度接近上一代的<strong>1.5倍</strong>。</p> 
<p>最关键的是，这次英伟达还在DGX H100基础上，搭建了一台<strong>Eos超级计算机</strong>，一举成为AI超算界的性能TOP 1——</p> 
<p>光就18.4 Exaflops的AI计算性能，就比日本的“富岳”（Fugaku）超级计算机<strong>快了4倍</strong>。</p> 
<p>这台超算配备了576个DGX H100系统，直接用了<strong>4608块H100</strong>。</p> 
<p>即使是传统科学计算，算力也能达到<strong>275 Petaflops</strong> （富岳是442 Petaflops），跻身前5的超算是没什么问题。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,593" src="https://img.36krcdn.com/20220323/v2_195d069a644f4f67986703a95856809c_img_000" referrerpolicy="no-referrer"></p> 
<h2><strong>“拼装”CPU，跑分成了TOP1</strong></h2> 
<p>本次GTC大会，老黄仍然“提了几嘴”超级服务器芯片Grace。</p> 
<p>它在去年4月份的GTC大会就已经有所亮相，和当时一样，老黄表示：<strong>有望</strong>2023年可以开始供货，反正今年是不可能碰上了。</p> 
<p>不过，Grace的性能倒是值得一提，有了“惊人进展”。</p> 
<p>它被用在两个超级芯片中：</p> 
<p>一个是<strong>Grace Hopper超级芯片</strong>，单MCM，由一个Grace CPU和一个Hopper架构的GPU组成。</p> 
<p>一个是<strong>Grace CPU超级芯片</strong>，由两个Grace CPU组成，通过NVIDIA NVLink-C2C技术互连，包括144个Arm核心，并有着高达1TB/s的内存带宽——带宽提升2倍的同时，能耗“只要”500w。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,601" src="https://img.36krcdn.com/20220323/v2_98416f95434d4faba591ed00465f8bf4_img_000" referrerpolicy="no-referrer"></p> 
<p>很难不让人<a class="project-link" data-id="195613" data-name="联想" data-logo="https://img.36krcdn.com/20200924/v2_e165f4830deb4b83866bb3a5bb92599a_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/195613" target="_blank">联想</a>到苹果刚发的M1 Ultra，看来片间互连技术的进展，让“拼装”成了芯片行业一大趋势。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,592" src="https://img.36krcdn.com/20220323/v2_bbc1b1b037cd4e82a4957285d0929080_img_000" referrerpolicy="no-referrer"></p> 
<p>Grace超级芯片在SPECrate®2017_int_base基准<a class="project-link" data-id="8712" data-name="测试" data-logo="https://img.36krcdn.com/20220318/v2_d188db412f2e4db89c6424314ac39971_img_jpg" data-refer-type="2" href="https://36kr.com/projectDetails/8712" target="_blank">测试</a>中的模拟性能达到了740分，是当前DGX A100 搭载的CPU的1.5倍（460分）。</p> 
<p>Grace超级芯片可以运行在所有的NVIDIA计算平台，既可作为独立的纯CPU系统，也可作为 GPU加速服务器，利用NVLink-C2C技术搭载一块至八块基于Hopper架构的GPU。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,602" src="https://img.36krcdn.com/20220323/v2_957035a3f8ce4acaa0dec0c9bc07b7f6_img_000" referrerpolicy="no-referrer"></p> 
<p>（嗯，刚说完，老黄的芯片堆堆乐就堆上了。）</p> 
<p>值得一提的是，英伟达<strong>对第三方定制芯片开放了NVLink-C2C</strong>。</p> 
<p>它是一种超快速的芯片到芯片、裸片到裸片的互连技术，将支持定制裸片与NVIDIA GPU、CPU、DPU、NIC 和SOC之间实现一致的互连。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,883" src="https://img.36krcdn.com/20220323/v2_9d3cda35bb3743c6831bbf56972e5b3d_img_000" referrerpolicy="no-referrer"></p> 
<p>或许，<strong>任天堂新掌机</strong>可以期待一波？</p> 
<h2><strong>连工业也要在元宇宙里搞</strong></h2> 
<p>当然，除了上述内容之外，这次英伟达也透露了不少与工业应用相关的案例。</p> 
<p>而无论是自动驾驶、还是包括虚拟工厂的数字孪生等场景，都与计算机渲染和仿真技术有着密不可分的关系。</p> 
<p>英伟达认为，工业上同样能通过在虚拟环境中模拟的方式，来增加AI训练的数据量，换而言之就是“<strong>在元宇宙里搞大训练</strong>”。</p> 
<p>例如，让AI智能驾驶在元宇宙里“练车”，利用仿真出来的数据搞出半真实环境，增加一些可能突发故障的环境模拟：</p> 
<p class="image-wrapper"><img data-img-size-val="480,266" src="https://img.36krcdn.com/20220323/v2_c48b4da9c499473aaa21977cccd57fa8_img_000" referrerpolicy="no-referrer"></p> 
<p>又例如，搞出等比例、与现实环境中材料等参数完全一样的“数字工厂”，在建造前先提前开工试运行，以及时排查可能出现问题的环境。</p> 
<p class="image-wrapper"><img data-img-size-val="480,266" src="https://img.36krcdn.com/20220323/v2_1572cd56d0a94b309b1ad7fed24a0758_img_000" referrerpolicy="no-referrer"></p> 
<p>除了数字孪生，数字资产的生产也是元宇宙早期建设阶段需要着重考虑的部分。</p> 
<p>在这方面，英伟达推出了随时随地能在云端协作的<strong>Omniverse Cloud</strong>。</p> 
<p class="image-wrapper"><img data-img-size-val="1080,544" src="https://img.36krcdn.com/20220323/v2_a84f842c83d44bd59547b1dc615e6d0b_img_000" referrerpolicy="no-referrer"></p> 
<p>最有意思的是，这次发布会上还演示了一套AI驱动虚拟角色系统。</p> 
<p>现实中3天，虚拟角色在元宇宙里<strong>靠强化学习苦练10年功夫</strong>。</p> 
<p class="image-wrapper"><img data-img-size-val="900,473" src="https://img.36krcdn.com/20220323/v2_6e5c510c39be458aa67840fa44ca5ee6_img_000" referrerpolicy="no-referrer"></p> 
<p>等练成一身本领，出来无论到游戏还是动画里都是个好“动作演员”。</p> 
<p>用它生成动画无需再绑定骨骼、k帧，用自然语言下指令即可，就像导演和真人演员一样沟通，大大缩短开发流程。</p> 
<p class="image-wrapper"><img data-img-size-val="600,628" src="https://img.36krcdn.com/20220323/v2_5a4704a68ff54c0d9f5cedc38dc2f49a_img_000" referrerpolicy="no-referrer"></p> 
<p>要论<strong>元宇宙基建</strong>还得看老黄啊。</p> 
<p>Venturebeat对此评价称，“这些案例给元宇宙赋予了真正的意义”。</p> 
<p>那么，你看好英伟达的omniverse前景吗？</p> 
<h3 label="二级标题" style>更多详情，可以戳完整演讲地址（带中字哦）</h3> 
<p>https://www.nvidia.cn/gtc-global/keynote/?nvid=nv-int-bnr-223538&sfdcid=Internal_banners</p> 
<h3 label="二级标题" style>参考链接</h3> 
<p>[1]https://www.anandtech.com/show/17327/nvidia-hopper-gpu-architecture-and-h100-accelerator-announced</p> 
<p>[2]https://venturebeat.com/2022/03/22/nvidia-gtc-how-to-build-the-industrial-metaverse/</p> 
<p class="editor-note">本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer nofollow" href="https://mp.weixin.qq.com/s/la3-8rGtIiNT1LSLjm-fvg">“量子位”（ID:QbitAI）</a>，作者：丰色 萧箫，36氪经授权发布。</p>  
</div>
            