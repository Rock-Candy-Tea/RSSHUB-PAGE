
---
title: '推特_头像裁剪_算法更爱_白幼瘦_，瑞士小哥用StyleGAN2识破算法癖好，登顶悬赏赛'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20210817/v2_2948f18c364e4c23bb3d613b05ba4a5b_img_000'
author: 36kr
comments: false
date: Tue, 17 Aug 2021 05:41:18 GMT
thumbnail: 'https://img.36krcdn.com/20210817/v2_2948f18c364e4c23bb3d613b05ba4a5b_img_000'
---

<div>   
<p>如今，社交媒体当道。</p> 
<p>相信不少人在首次注册社交媒体时，平台都会要你上传一张照片当做头像。</p> 
<p>有人会选择喜欢的明星，也有人会用自己的真实照片。</p> 
<p>但这都不是最关键的，可能你没有发现，在上传头像照片时，平台对某些照片存在不同程度的偏好。</p> 
<p>比如，某些平台内置的算法会偏爱<strong>肤色较浅、纹理较光滑且没有戴眼镜</strong>的照片，或者是<strong>更年轻的面孔</strong>：</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_2948f18c364e4c23bb3d613b05ba4a5b_img_000" referrerpolicy="no-referrer"></p> 
<p>而这已经在推特<a class="project-link" data-id="95377" data-name="得到" data-logo="https://img.36krcdn.com/20210807/v2_966db147ab4646ef82349f069ce61219_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/95377" target="_blank">得到</a>了证实。</p> 
<p>根据国外多家媒体报道，推特的照片裁剪算法存在较大的漏洞，算法在预览和聚焦不同照片中的“亮点”时，对<strong>肤色、胖瘦、性别和年龄</strong>有不同的优先级。</p> 
<p>也就是说，算法会更偏好“肤色更浅、更苗条、更年轻”的面孔，而不是“肤色更深、脸型更宽、年纪更大”的面孔。</p> 
<p>对此，有网友指出，如此看来，算法也称得上是某种极端主义者了。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_448836023fa64ba5874d349cf8b61874_img_000" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题"><strong>用StyleGAN2拆解推特算法的偏好</strong></h2> 
<p>这个研究结果来自瑞士联邦洛桑理工学院的研究生Bogdan Kulynych。</p> 
<p>在推<a class="project-link" data-id="2817" data-name="特赞" data-logo="https://img.36krcdn.com/20210806/v2_44690011913244dba66577886234193a_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/2817" target="_blank">特赞</a>助的“算法漏洞悬赏大赛”中，Kulynych发现，推特的照片裁剪算法对照片中的特征存在不同程度的偏好。</p> 
<p>Kulynych使用<strong>StyleGAN2</strong>生成了大量逼真的面孔，他根据肤色、身材、年龄和女性化等标签对这些面孔进行了分类，然后将这些数据放入了推特的照片裁剪算法中。</p> 
<p>Kulynych发现，推特的算法对<strong>肤色</strong>有着最为明显的偏好趋势，算法更喜欢那些“苗条、年轻、具有典型女性面部特征”的面孔。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_fb8250b9c7b243de93b89404c1bcff12_img_000" referrerpolicy="no-referrer"></p> 
<p>其次便是<strong>年龄</strong>，该算法对灰头发和白头发的用户存在明显的歧视行为。紧接着的是图片中的<strong>文字</strong>，相较于阿拉伯数字，算法会更喜欢英语。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_394cea2389c5467b8f0f80c9f0d47769_img_000" referrerpolicy="no-referrer"></p> 
<p>GitHub链接：</p> 
<p>https://github.com/bogdan-kulynych/saliency_bias </p> 
<p>Kulynych在总结中补充说：“当应用算法时，这些内部偏见本质上会<strong>转化为代表性不足的危害</strong>，从而剔除那些不符合算法对体重、年龄、肤色偏好的人。”</p> 
<p>Kulynych在大赛中获得了第一名，推特称Kulynych的发现“展示了算法模型如何放大现实世界的偏见和社会对<a class="project-link" data-id="131482" data-name="美的" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/131482" target="_blank">美的</a>期望”。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_221d66337a894a858d9c52496476af7b_img_000" referrerpolicy="no-referrer"></p> 
<h2 label="一级标题"><strong>推特不喜欢iPhone？漏洞得到官方承认</strong></h2> 
<p>在更早的时候，相关漏洞就已经被指出。</p> 
<p>去年，一位推特用户试图发布他在Zoom的面部识别中注意到的一个问题，即在通话中没有显示出一位黑人同事的脸，当他发帖到Twitter上时，他注意到推特同样<strong>更偏向于他的脸而不是黑人同事的脸</strong>。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_56dd5763125541f68342a9539614bda6_img_000" referrerpolicy="no-referrer"></p> 
<p>这对<strong>卡通人物</strong>同样适用。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_8804829856ba49feab23cc9f33de07d4_img_000" referrerpolicy="no-referrer"></p> 
<p>甚至，还有网友发现，与iPhone相比，推特的算法更倾向于显示<a class="project-link" data-id="3967413" data-name="微软" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3967413" target="_blank">微软</a>已停产Windows手机。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_d67506861294473db6f6b6505ed0760e_img_000" referrerpolicy="no-referrer"></p> 
<p>当推特首次上线照片裁剪功能时，研究人员在博客文章中解释了他们如何从面部识别开始裁剪图像，但实际上，并非所有的图像都包含人脸。</p> 
<p>此外，人脸检测器会经常漏掉人脸，也会在没有人脸的情况下错误地检测到人脸。如果没有发现人脸，视角会自动地被聚焦在图像中心，这可能会导致尴尬的裁剪图像。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_ab0bf8d9f2744e898ed6da486e295687_img_000" referrerpolicy="no-referrer"></p> 
<p>随后，推特官方也进行了调查，他们发现：</p> 
<p>在男性和女性之间，人口统计学上的平等偏向于女性的差异为<strong>8%</strong>；</p> 
<p>在黑人和白人的比较中，白人和黑人的人口比例相差<strong>4%</strong>；</p> 
<p>在黑人女性和白人女性的比较中，白人女性在人口平等方面的差距为<strong>7%</strong>；</p> 
<p>在黑人和白人男性的比较中，白人男性在人口统计学上有<strong>2%</strong>的差异。</p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20210817/v2_24bd23eebf274ee4b90c7bc7bf250f46_img_000" referrerpolicy="no-referrer"></p> 
<p>同时，推特还通过随机选择<strong>100张</strong>男性和女性呈现的图像来测试“男性凝视”，这些图像在图像中具有多个被算法识别为显着的区域，并观察模型如何选择裁剪图像。</p> 
<p>他们发现，每组每100张图像，没有裁剪到头部位置的情况大约<strong>3张</strong>，在这种情况下，算法会裁剪图像的其他特征，例如运动衫上的字母。</p> 
<p>5月，推特下线了图片裁剪功能，只允许用户完整地发布照片，或自己决定如何裁剪照片。</p> 
<p>“我们的结论之一是，并不是推特上的所有东西都适合使用算法，在这种情况下，<strong>如何裁剪图片是一个最好由人做出的决定</strong>。”推特软件工程总监Rumman Chowdhury在一篇关于该团队发现的博文中写道。</p> 
<p>Chowdhury表示：“当我们考虑模型中的偏见时，不仅仅是关于学术或实验，而是它与我们在社会中思考的方式有关。”</p> 
<h2 label="一级标题"><strong>如何对待算法偏见？</strong></h2> 
<p>近年来，随着人工智能的逐渐发展，算法偏见也开始得到了重视。</p> 
<p>对于此，英国谢菲尔德大学计算机专家Noel Sharkey表示，应该<strong>在可能改变生活方式的所有领域中禁止使用算法</strong>。</p> 
<p>Sharkey对一系列机器学习系统存在偏见的现象<a class="project-link" data-id="4072786" data-name="深表" data-logo="https://img.36krcdn.com/20210422/v2_74e266dbeb214ebba59dca3d1a844ac5_img_000" data-refer-type="1" href="https://www.36dianping.com/space/4801201132" target="_blank">深表</a>担忧，Sharkey表示：“现在有很多偏见发生，从工作面试到社会福利，再到决定谁应该保释谁应该入狱等等，很明显我们必须停止使用决策算法。我一直对监管非常重视，我认为它会扼杀创新。”</p> 
<p>“但后来我意识到，有些创新应该被扼杀，或者至少要有所保留。因此应该暂停所有影响人们生活的算法，这些算法并没有在发挥实际用处，反而在加深人们的偏见。”</p> 
<p>Sharkey曾与<a class="project-link" data-id="3968996" data-name="谷歌" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968996" target="_blank">谷歌</a>和微软等公司就偏见问题进行了交谈，“他们知道这是一个问题，过去几年他们也一直在努力寻找解决方案，但到目前为止还没有找到”。</p> 
<p>“在实验室里，系统可以对白人男性的识别率达到98%，但女性的识别率会偏低，深色皮肤的人效果会更下一层楼。在后面两种情况下，我们都可以说，系统并不能准确识别人脸。”</p> 
<p>归根结底，算法背后是人，算法偏见背后其实就是人的偏见，算法的选择也就是在大数据处理之后人的选择。在针对相关现象进行批评时，更应需要关注现实中的偏见，保持内省。</p> 
<p>这对每个人来说，都极为重要。</p> 
<h3 label="二级标题">相关报道：</h3> 
<p>https://www.dailymail.co.uk/sciencetech/article-9879871/Twitters-photo-cropping-algorithm-favours-young-beautiful-light-skinned-faces-study-confirms.html </p> 
<p>https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm </p> 
<p>https://www.theguardian.com/technology/2019/dec/12/ai-end-uk-use-racially-biased-algorithms-noel-sharkey </p> 
<p>本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号 <a target="_blank" rel="noopener noreferrer" href="http://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651704162&idx=1&sn=1203cd90a125e710b577c1f2d05347da&chksm=bd4cecf18a3b65e729fadbbdaf870e9fc305454807b8967f082b5f7853a441663f77e7119932&scene=27#wechat_redirect">“大数据文摘”（ID：BigDataDigest）</a>，作者：Caleb，36氪经授权发布。</p>  
</div>
            