
---
title: '相比于机器，我们对人类的错误更加宽容吗？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202111/21/141606494264.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
author: 虎嗅
comments: false
date: Sun, 21 Nov 2021 08:00:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202111/21/141606494264.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">人们会“评估结果与目的”。本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/lZwnOQJFLuRshaYdbeM2qg" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">第三设计观察所（ID：No3_DesignView_OP）</span></a><span class="text-remarks">，经原文作者Jean-marc Buchert授权翻译，译者：No3.所长，原题为：<a href="https://uxdesign.cc/are-users-more-forgiving-of-human-mistakes-than-machine-errors-5ed2a87f5368" target="_blank" rel="nofollow"></a></span><a href="https://uxdesign.cc/are-users-more-forgiving-of-human-mistakes-than-machine-errors-5ed2a87f5368" target="_blank" rel="nofollow" style="text-decoration: none;"><em><span class="text-remarks" label="备注">Are users more forgiving of human mistakes than machine errors?</span></em></a><span class="text-remarks">，头图来自：视觉中国</span></p><p>你对频繁死机的电脑感到崩溃吗？<br></p><p>我们可能认为：相比于笨拙的人类，我们对功能失常的应用程序或设计糟糕的算法会更为苛刻。然而这只是一种模糊的猜测。</p><p>事实上，用户对机器反而可能更具有同情心，他们似乎并不会对机器的错误感到生气或者苛责。根据César A. Hidalgo<span class="text-remarks" label="备注">①</span><span class="text-remarks" label="备注">（经济学家，前MIT研究员）</span>的说法：这主要是因为用户审判机器是根据它们的行为结果，而不是行为目的。</p><p>无论是面对有偏见的结果还是不公平的决定，<strong>用户似乎从来没有真正的在机器身上寻找道德原因，而只是把它们当成功能的载体</strong><span class="text-remarks" label="备注">（只关乎是否完成其工作）</span>。</p><p>这产生了四个新视角诠释人机交互的有趣行为科学结论。</p><h3 label="大标题" class="text-big-title">一、AI决策和人类判断</h3><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202111/21/141606494264.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="700" data-h="393" src="https://img.huxiucdn.com/article/content/202111/21/141606494264.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">一幅由机器学习还原的奥巴马打码照片<br></p><p>无论是辅助人类做决策，又或是雇佣新员工，识别人脸，我们都听说过算法偏见是如何影响人工智能的。算法收集的数据保留了系统性的判断偏见<span class="text-remarks" label="备注">（judgmental biases）</span>，这有时候会反映在对某些个体的歧视性决策中。</p><p>但是人类对机器制造不公平行为有什么感觉呢？相比于人类的歧视，他们会更反感机器吗？</p><p>César Hidalgo试图通过社会实验来回答这些问题。他向参与者展示了几种歧视情况，并要求他们判断决策在人类或者机器负责下的公平性。这些场景里有：HR在候选人相同资质相同的情况下从不选择某种特定出身的候选人，和警察总是关押一些相同族群的无辜群众。</p><p>在这些情况下，<strong>参与者都认为人类的行为更具有目的性，因此更需要责任感。</strong>因为参与者认为人类的行为带有自己的主观意愿，所以他们的行为比机器的错误判断更受到指责。然而，<strong>当问起他们应该由谁来取代这些歧视者，他们的答案更倾向于选择更正直的人。</strong></p><h3 label="大标题" class="text-big-title">二、人类对自动化工作的模糊认知</h3><p>当面对自动化工作<span class="text-remarks" label="备注">（work automation）</span>或者工作替代<span class="text-remarks" label="备注">（job replacement）</span>的时候，这种模糊性再次出现。Hidalgo通过类似的实验研究了人们对这种情况的反应。他向参与者讲述了一些故事：比如公司员工要么被AI机器人取代，要么被效率更高，更有精力的外国年轻员工取代。Hidalgo询问参与者在不同情景和不同行业内对此会有什么感受。</p><p>令人惊讶的是，<strong>参与者更情愿取代他们工作的是机器人，而不是外国人。</strong>虽然他们的偏好因情况而异：更接受司机被自动驾驶卡车取代，而不是老师被教学机器人取代，但他们通常同意他们更喜欢自动化而不是另一位工人。</p><p>对这类情况的解释有几种。参与者可能觉得技术的发展是不可避免的，而被外国工人取代会激发他们的归属感。他们可能能更加切身的体会到后者<span class="text-remarks" label="备注">（外国工人）</span>的威胁性，因为这发生得更为频繁。人力替代感觉上也更不公平，因为同等资质的外国工人凭什么更有权利获得工作？</p><p>这也解释了为什么和1990～2000年间欧美企业外迁劳动力<span class="text-remarks" label="备注">（到发展中国家）</span>相比，自动化引发的情绪抵抗似乎没有那么的极端。</p><h3 label="大标题" class="text-big-title">三、对机器事故的毫不宽容<br></h3><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202111/21/143757639781.jpeg?imageView2/2/w/1000/format/jpeg/interlace/1/q/85" data-w="1000" data-h="667" src="https://img.huxiucdn.com/article/content/202111/21/143757639781.jpeg?imageView2/2/w/1000/format/jpeg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">自动驾驶汽车比人类驾驶员更负责任吗？<br></p><p>随着自动驾驶离现实越来越近，我们可能好奇：相比于人类驾驶员，用户如何看待自动驾驶汽车需要承担的责任？</p><p>为了回答这个问题，Hidalgo和他的团队把参与者置于各种各样的道路事故<span class="text-remarks" label="备注">（包含了人类司机或自动驾驶汽车）</span>之中。这些事故的严重程度可能取决于内在或外在因素，也包含了是伤害司机还是路人的抉择。</p><p>这项实验首次提出了自动驾驶汽车担负了巨大的责任。参与者对涉及自动驾驶汽车的事故判断更为消极，认为它们会造成更严重的伤害。其中一个原因是因为<strong>他们更容易把自己带入人类驾驶员的视角</strong><span class="text-remarks" label="备注">（而不是机器的视角）</span>，<strong>他们更能同理人类司机做出的反应</strong><span class="text-remarks" label="备注">（毕竟在自己身上可能也会发生这样的情况）</span>，尤其这是由外部因素导致的事故<span class="text-remarks" label="备注">（比如一棵树倒在了路上）</span>。</p><p>因此，参与者对造成事故的机器毫不宽容，希望它们更可靠安全。</p><h3 label="大标题" class="text-big-title">四、机器的好坏完全取决于结果<br></h3><p>我们可以从这些研究中得出什么结论呢？</p><p label="图片备注" class="text-img-note"><video src="https://ali-video.huxiucdn.com/mda-mkkkeaun2q8jnw5t/mda-mkkkeaun2q8jnw5t.mp4" poster="https://v2-img.huxiucdn.com/mda-mkkkeaun2q8jnw5t/mda-mkkkeaun2q8jnw5t.jpg" controls="controls" width="100%">您目前设备暂不支持播放</video><br>César Hidalgo | How Humans Judge Machines | Talks at Google（建议前往youtube观看）</p><p>首先，<strong>当整体看待受伤害感和行为目的的关系时，人们认为人类行为比机器行为更带有目的。</strong>然而矛盾的是，<strong>参与者仍然会更容易原谅人类的行为，因为他们更容易将人为错误视为坏运气的结果，而机器错误则是需要纠正的错误。</strong></p><p>当我们在研究行为目的和不公正之间的关系时，我们发现了一个更符合人类判断的事实：对于那些带有当事人强烈主观意图的场景<span class="text-remarks" label="备注">（比如侮辱和歧视）</span>，人们显然会对人类行为做出更为负面的评价。人们认为人类需要为自己的邪恶意图负责任，而机器则被默认为没有自己的意图和目的。另一方面，一些本身不带有目的的情况<span class="text-remarks" label="备注">（比如交通事故）</span>，机器则承担的责备会更多。因为我们已经假定了机器的程序可以避免任何错误。</p><p>最后通过评估不公正的感知和伤害范围之间的关系，我们发现：对受害人造成的伤害越小，机器就越被视为罪魁祸首；相反，当伤害越大，人类当事人承担的评价就越为负面。</p><p>总之，<strong>我们看到了两种截然不同的判断模式。</strong></p><p>当涉及人类当事人时，观众就会通过当事人的意图来评判他们的行为：他们可以犯错，但如果居心不良，他们就需要对自己的行为负责。</p><p>另一方面，机器的评估标准是行为的结果：如果它们无法避免破坏性的错误，无论发生的是什么，它们都会被批评。好的一面是，对于一些通常被定性为非常严重的情况<span class="text-remarks" label="备注">（歧视或恶意羞辱）</span>，因为机器行为不带有目的，所以常常不被苛责。</p><p>但这也意味着，作为设计师的我们，需要尽量减少数字服务和智能应用程序可能产生的间接伤害和歧视。<strong>因为可没有人会同情设计糟糕的算法</strong><span style="color:#999999">（见译者注）</span>。</p><h3 label="大标题" class="text-big-title">译者注：设计师和算法的关系</h3><p>由于译者正好从事自动驾驶行业，所以就简单聊聊这个话题。可能有人会认为糟糕算法是程序员的问题，这和设计师有什么关系？</p><p>但事实上在以正向研发为主要流程的企业内，一个需求落地至少要经过产品经理，设计师，研发和测试四个阶段。产品和设计师需要根据客户/用户的诉求去定义和产品的功能和使用方式，然后研发才会在设计的框架内去实现这些功能。自然<strong>当设计师遗漏或者忽视一些安全问题时，研发是无法发现的，因为在他们的角度，功能的上下文是不明确的，他们只专注于功能本身的研发。</strong></p><p>举个例子，假设我们设计一个工业园区内使用的远程自动驾驶汽车遥控器，它的功能是给车辆派发运货订单，并且可以远程启动车辆。那么如果设计师对于使用场景足够了解，他会发现如果远程启动车辆，突然的启动可能会对周围在装卸货的工人带来安全隐患。所以需要在这个阶段提供预警或者二次鉴权的操作。而这可能是客户的原始需求中没有提及或者客户觉得麻烦的功能<span class="text-remarks" label="备注">（客户只想点一次！）</span>，如果产品和设计没有深入研究，自然研发无法发现这样的问题。这就是我理解的为什么设计师需要对算法负责。</p><p>关于设计师的责任这一块，有兴趣的朋友可以看一看前文《<a href="https://mp.weixin.qq.com/s?__biz=MzkzODI5OTQ4NA==&mid=2247483671&idx=1&sn=1115e64c150aaaab60b13d3a73f2b0bb&chksm=c2831824f5f491327ac0ec1e8731b105359e2ede284ced9f37c2fcd65ed4d0ded33920f0853c&scene=21#wechat_redirect" target="_blank" rel="nofollow">负责任的设计：设计师应该承担多少产品责任？</a>》。我也和一些人交流过这个问题，刚毕业的设计师觉得，我们需要为用户负责！我们要站出来说话！在社会中摸爬滚打了多年的设计师多会认为这非常的理想。</p><p>确实，从企业角度来讲，道德如果无关乎企业生存，是会被自动忽视的<span class="text-remarks" label="备注">（毕竟罗翔老师也说过，法律只是规定了道德的底线）</span>，或者当成一种营销手段。只有一些和道德高度绑定的行业，比如说自动驾驶行业，设计师才会有必要，有能力去考虑一些道德问题。</p><p>当然，我也不是说设计师不需要也没有能力去承担责任，而是说希望大家能够多去思考自己的正在做的产品，而不是说盲目地为了KPI或者OKR去完成设计任务。可能你的一次轻微的尝试就会给产品带来一些正面的影响。</p><p><span class="text-remarks" label="备注">参考文献：</span></p><p><span class="text-remarks" label="备注">①《人类如何评判机器》How Humans Judge Machines</span></p><p><span class="text-remarks" label="备注">https://book.douban.com/subject/35557225/</span><br></p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/lZwnOQJFLuRshaYdbeM2qg" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">第三设计观察所（ID：No3_DesignView_OP）</span></a><span class="text-remarks">，经原文作者Jean-marc Buchert授权，由No3.所长翻译</span></p>  
</div>
            