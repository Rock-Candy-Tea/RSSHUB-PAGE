
---
title: '苹果扫描用户图片，可能开启后门魔盒？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202108/27/173008243419.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
author: 虎嗅
comments: false
date: Fri, 27 Aug 2021 10:45:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202108/27/173008243419.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODA2NTk2MA==&mid=2650133195&idx=1&sn=4318b863b5195e3afb4b95d42e6d864c&chksm=bed1108c89a6999a54d1a1f836272b6902bcec59affc4ad2f42d49d185b2786d9fb824015618&mpshare=1&scene=1&srcid=0827QYrPJvsyDG4uwVO7LIjF&sharer_sharetime=1630056283237&sharer_shareid=7f708c6bc34f09f833d7815bcf0209b2&version=3.1.8.70033&platform=mac#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">新浪科技（ID：techsina）</span></a><span class="text-remarks">，作者：郑峻，原文标题：《苹果扫描用户图片：正义的特例，还是魔盒的开启》，题图来自：视觉中国</span></p><h3 label="大标题" class="text-big-title">一、高举保护隐私大旗</h3><p>这是出于正义的特例，还是潘多拉魔盒的开启？虽然事情已经宣布了半个月，但就像是一石激起千层浪，引发的争议与猜测却迟迟无法平息。而真正的后续影响，可能会在未来逐渐显现。</p><p>“iPhone里发生的，就留在iPhone里”。还记得这张覆盖整座大楼的巨幅广告吗？在2019年的拉斯维加斯CES展会上，没有参展的苹果给自己打了最好的广告。过去几年时间，苹<strong>果一直都在科技行业高举保护用户隐私的大旗，把这当成自己最大产品的卖点之一</strong>，打出了“iPhone是专为保护用户隐私设计”的口号。</p><p>不仅于此，苹果还将抨击矛头对准了那些靠用户大数据盈利的互联网公司。库克多次公开点名批评Facebook等互联网公司出卖用户隐私谋利，强调苹果绝不会碰用户数据，甚至在今年通过iOS系统更新，让用户自己决定是否允许数据追踪，给Facebook等互联网公司的定位广告模式带来了重大冲击。</p><p>为了确保用户数据安全，苹果在过去几年时间还挡住了来自美国政府的压力，坚决拒绝了美国政府以反恐为名在iPhone中设置数据读取后门的要求。此外，2016年和2020年，苹果至少两次公开拒绝美国政府解锁恐怖分子iPhone要求，甚至与政府在法庭争锋相对进行诉讼。</p><p>这两起事件的背景分别是加州圣伯纳迪诺枪击案和佛罗里达海军基地枪击案，枪手背后都有伊斯兰极端宗教势力的渗透，联邦调查局希望从手机通讯记录中调查恐怖分子的作案动机与联络机构。由于遭到苹果的坚决抵制，最后美国政府寻求第三方破解公司的帮助，从恐怖分子手机上获取了数据。</p><p>然而，这样无条件保护用户隐私的苹果，竟然会搬起石头砸自己的脚，公开宣布要扫描用户文件，而且还是存在iPhone本地的照片。即便出发点是维护正义，这件事情也非常不符合苹果的作风，更引发了关于用户隐私的诸多热议。这究竟是怎么一回事？</p><h3 label="大标题" class="text-big-title">二、本地扫描用户照片</h3><p>本月早些时候，苹果公开宣布要在晚些时候发布的iOS和iPadOS系统升级里推出新功能，在本地扫描用户设备是否存有儿童色情相关的照片，与美国官方的儿童性剥削数据库图片进行比对。如果发现存在大量违法图片，苹果会通知执法人员。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/27/173008243419.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="545" src="https://img.huxiucdn.com/article/content/202108/27/173008243419.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>这项功能是苹果的打击侵害儿童整体项目的一部分。此外，iMessage短信服务也会加入家长控制功能，如果12岁或以下的未成年人通过iMessage发送或浏览裸体图片，他们的父母会收到系统报警。</p><p>即便阻止剥削儿童和贩卖人口是在维护正义，但扫描用户本地图片这一功能还是过于敏感，引发了诸多争议和忧虑。新闻发布十天之后，面临着外界诸多猜测和批评，苹果负责iOS的高级副总裁费德里希<span class="text-remarks" label="备注">（Craig Federighi）</span>最终还是不得不出来再次澄清。</p><p>费德里希具体解释这一功能：<strong>当iPad和iPhone用户将本地图片上传到iCloud云端的时候，苹果会在本地设备中对这些图片进行扫描，与美国国家失踪与受剥削儿童中心<span class="text-remarks" label="备注"></span></strong><span class="text-remarks" label="备注">（NCMEC）</span><strong><span class="text-remarks" label="备注"></span>的数据图进行比对。</strong>如果发现大量图片相吻合，即意味着用户持有失踪与性剥削儿童的图片，苹果会发送给审核部门，再次确认后通知执法部门，而用户本身并不会获得提醒。不过苹果随后也会封锁该用户的iCloud账号，相当于变相告知用户。</p><p>但值得注意的是，<strong>系统只有在比对发现大量违规图片时才会触发警示，单张图片出现问题并不会，这显然是为了避免出现识别错误</strong>。而且，苹果会聘请第三方的审查员来确认系统识别出来的内容是否违法，由他们来通知警方。不过，苹果并没有透露这个识别违规内容的数量阈值，外界并不知道比对发现多少违规图片才会自动触发。</p><p>此前苹果曾经表示，这项扫描功能只会先在美国推出，在其他国家会在未来视情况推出。费德里希进一步解释，这个CSAM数据库是包括在iOS和iPadOS的系统升级中，只是在美国市场激活；“我们在中国、欧洲和美国的设备都使用同样的软件，包括同样的数据库。”</p><h3 label="大标题" class="text-big-title">三、儿童色情不属隐私</h3><p>最注重用户隐私的苹果为什么要公开宣布扫描用户本地照片？用户存在iPhone和iPad的照片，是否完全属于用户隐私？互联网公司是否要为此类违法内容负责？</p><p>美国1996年《联邦通信规范法》230条款规定，“任何交互式计算机服务的提供商或者用户不应被视为另一信息内容提供商提供的任何信息的发布者和发言人。”<strong>这一条款又被视为互联网公司的免责保护伞。</strong></p><p>这个条款实际上包括两个意思：互联网公司无须为平台上的第三方信息负责，用户在平台发布的内容与平台无关；互联网公司无须为他们善意删除平台内容的行为负责，他们有权根据审核标准删除用户发布的内容。</p><p>但是这把保护伞也并不是没有边界的。2018年美国国会通过《打击性贩卖行为法》，明确规定互联网公司有责任举报和移除网络平台上的此类违法内容，否则将会面临相关法律的处罚；其中明确包括了儿童色情内容。这是230免责条款的第一个豁口。</p><p>根据这一法律，如果用户开通了iCloud图片上传，存在本地设备的图片连上了互联网，那么苹果作为互联网平台，就有责任和权力举报和处理此类违法内容。而大多数iPhone用户，iCloud上传功能是默认开启的。</p><p>实际上，美国各大互联网企业早就扫描用户图片库，识别儿童色情相关内容。Facebook、Twitter、Reddit都会对用户存在自己平台的内容进行比对扫描，无论是否公开发布。和苹果一样，他们也是通过NCMEC的数据库进行比对，发现违规之后进行报警。</p><p>更为重要的是，儿童色情内容并不属于美国宪法第一修正案关于言论自由权利的保护范围。用户持有儿童色情图片本就是违法行为，无论传播与否。美国《打击儿童性剥削法》和《打击贩卖儿童法》都明确规定，生成、分发、接受和持有此类内容都属于联邦重罪，会面临着至少5年，至多30年监禁的严厉惩罚。</p><p>在欧洲，这方面的互联网监管措施甚至更早。早在2013年，英国就已经制定监管细则，要求从互联网服务提供商<span class="text-remarks" label="备注">（ISP）</span>这里屏蔽色情内容，用户必须自己手动关闭过滤内容，才能访问色情网站。同一时期，英国政府还要求谷歌微软等搜索服务商移除儿童色情搜索结果。不过，儿童色情图片原本就很少出现在搜索结果中。</p><h3 label="大标题" class="text-big-title">四、不会扫描其他内容</h3><p>即便美国互联网企业早就开始打击儿童色情内容，但苹果宣布扫描用户图片依然引发了诸多质疑。苹果向美国媒体确认，此前也曾经对iCloud Mail内容进行此类内容的扫描，但却从未扫描过用户的iCloud Photos图片数据。网络信息安全专家泰特<span class="text-remarks" label="备注">（Matt Tait）</span>指出，儿童色情图片本来就是美国执法部门打击的高压线，执法部门很容易获得传票，要求苹果扫描用户iCloud图片库，苹果也会愿意配合这一要求。</p><p>苹果所做的，和其他互联网公司有什么不同？其他互联网公司是扫描用户上传在云端服务器的内容，而此次苹果则是在用户本地进行扫描<span class="text-remarks" label="备注">（前提是开启iCloud同步）</span>。为什么苹果会选择在本地进行扫描？</p><p>苹果高级副总裁费德里希强调，这项扫描机制将在设备本地进行，而不是联网进行比对，目前只面向美国市场。“如果有人在云端扫描图片，那谁知道会扫描什么内容<span class="text-remarks" label="备注">（意思是可能会失控）</span>。在我们这项功能里面，NCMEC的数据库是传输到本地的。”</p><p>在iOS和iPad新版系统中，将自带一个叫NeuralHash的工具，对图片分解成诸多碎片进行标注与识别，对比NCMEC的数百万份碎片数据进行比对。发现吻合的违规内容之后，在iOS或iPadOS之中生成一个包括违规内容的“保险库文件”，在此类违规内容积累到一定阈值之后才会发送给苹果的审核人员。</p><p>苹果隐私主管纽恩施万德特别对此强调，如果用户关闭了iCloud图片同步功能，那么NeuralHash工具就无法运行，苹果不会，也无法进行儿童色情图片扫描。</p><p>即便苹果已经尽可能公开透明地宣布这项扫描功能，依然引发了一些互联网隐私保护机构的不满和担忧。这毕竟是苹果第一次对用户在本地的文件进行扫描和监控，如果这次是打击儿童色情，那么下次又会是什么，反恐？</p><p>苹果高级副总裁费德里希再次强调，除了非法的CSAM儿童色情内容，苹果不会扩大目前的数据扫描范围。他强调，“如果某国政府向我们提出CSAM内容之外的数据扫描要求，我们会直接拒绝。如果你对此没有信心，不相信苹果会敢于拒绝，那么我们还设置了多层的保护机制，我们希望让用户安心，在扫描什么文件的问题上，你不需要相信任何公司，或是任何国家。”</p><h3 label="大标题" class="text-big-title">五、可能开启后门魔盒</h3><p>苹果的确公开拒绝过美国政府的反恐后门和解锁手机的要求，也不害怕和美国政府打官司抵制行政命令，但是如果面临着司法部门的合法传票和命令，苹果也只能接受和服从，这是他们所无力抗拒的。</p><p>就在两个月前，苹果承认他们曾经在2018年2月按照特朗普政府司法部的要求，提供了一系列用户的身份识别码，用于确认一些用户的电子邮件和电话号码。当时处在“通俄门”调查中的特朗普政府正在秘密调查是谁向民主党众议员泄露了政府机密。</p><p>苹果之所以愿意配合特朗普政府调查，是因为收到了联邦大陪审团的传票，而且这份传票还附带保密要求。这意味着苹果不仅需要遵守命令要向政府交出数据，还必须就此事守口如瓶，直到今年5月保密期限结束后，苹果才通知相关用户。除苹果之外，微软也收到了此类附带保密要求的传票。</p><p>美国电子前线基金会<span class="text-remarks" label="备注">（Electronic Frontier Foundation）</span>在向新浪科技发送的声明中明确表示，苹果以打击儿童色情为由的扫描用户文件行为违反了苹果此前关于保密用户隐私和加密通信的承诺，创造了一个很容易被政府利用进行监控和审核的技术架构。这一机制会让苹果未来无力抵制政府的更多要求。</p><p>电子前线基金会谈到，美国政府从不避讳要求获得用户加密通信，通过搜查令和法庭命令等手段施压科技公司帮助他们获得数据。虽然苹果一直承诺会抵制政府<span class="text-remarks" label="备注">（设立后门）</span>要求降低用户隐私保护的命令，但在推出这一扫描机制之后，苹果不得不继续抵制政府扩大扫描范围的压力。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/27/173010378987.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="627" src="https://img.huxiucdn.com/article/content/202108/27/173010378987.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>这样的处境并不只是在美国。2018年“五眼联盟”<span class="text-remarks" label="备注">（美国、英国、加拿大、新西兰和澳大利亚）</span>曾经明确表示，如果科技公司拒绝提供加密数据，他们会通过技术、执法、立法以及其他手段实现合法获取数据。随后英国通过《调查权限法》<span class="text-remarks" label="备注">（IPA）</span>，要求电信运营商通过技术手段，在政府发布数据获取命令时提供协助。</p><p>尽管这次苹果在iOS和iPadOS系统设置扫描机制，是为了打击儿童色情和性剥削的正义目的，但也给自己预埋了一个危险的“地雷”。2016年苹果在拒绝美国司法部解锁圣伯纳迪纳恐怖分子iPhone时，曾经公开表示自己没有在iOS设置任何后门。但这一次呢？“如果你设置了<span class="text-remarks" label="备注">（后门）</span>，他们就会跟进。苹果此举是给全球各国加强监控审核开启了后门。”电子前线基金会这样总结。</p><p>“iPhone里发生的，就留在iPhone里”，苹果的这一标志性承诺现在需要加上一个豁免条款——如果不涉及儿童色情的话，未来是否还有更多的例外？</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODA2NTk2MA==&mid=2650133195&idx=1&sn=4318b863b5195e3afb4b95d42e6d864c&chksm=bed1108c89a6999a54d1a1f836272b6902bcec59affc4ad2f42d49d185b2786d9fb824015618&mpshare=1&scene=1&srcid=0827QYrPJvsyDG4uwVO7LIjF&sharer_sharetime=1630056283237&sharer_shareid=7f708c6bc34f09f833d7815bcf0209b2&version=3.1.8.70033&platform=mac#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">新浪科技（ID：techsina）</span></a><span class="text-remarks">，作者：郑峻</span></p>  
</div>
            