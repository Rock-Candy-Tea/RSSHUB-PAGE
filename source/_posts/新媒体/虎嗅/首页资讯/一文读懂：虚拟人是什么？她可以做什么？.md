
---
title: '一文读懂：虚拟人是什么？她可以做什么？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://www.huxiu.com/article/undefined'
author: 虎嗅
comments: false
date: Fri, 02 Jul 2021 10:34:00 GMT
thumbnail: 'https://www.huxiu.com/article/undefined'
---

<div>   
<img alt="一文读懂：虚拟人是什么？她可以做什么？" data-v-ea68b0d0 src="https://www.huxiu.com/article/undefined" referrerpolicy="no-referrer"><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/vy2x1wCa4BRB3Jr94ZiR4A" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">腾讯研究院（ID：cyberlawrc）</span></a><span class="text-remarks">，作者：胡璇（腾讯研究院数字内容中心高级研究员），原文标题：《一文读懂虚拟人：她会梦见电子羊吗？》，题图来自：《银翼杀手2049》</span></p><p>创造栩栩如生、真情实感的数字化人类，既是《银翼杀手》等科幻作品的想象，也是数字内容创作的不懈追求。近年，“造人”紧随“造车”成为业界高度关注的话题，不仅有虚拟偶像、MMD<span class="text-remarks" label="备注">（MikuMikuDance，虚拟角色跳舞）</span>等文化现象大流行，更在AI加持下为数字人类初步赋予自主智能。在可见的未来里，我们是否能轻松拥有自己在赛博空间中的“复制体”——虚拟人呢？</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172605038972.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202107/02/172605038972.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">《银翼杀手2049》中的虚拟人</p><h3 label="大标题" class="text-big-title">一、虚拟人与数字人、虚拟偶像</h3><p>虚拟人与数字人两个概念多数时候可以通用，相比之下，<strong>虚拟人更侧重其在外观、智能等方面与人的相似性，在难辨真假的同时可以进行交互</strong>。笼统地说，通过3D图像软件或其它模拟仿真工具制作，以数据形式存在的人与类人角色，都可以算作数字人<span class="text-remarks" label="备注">（digital humans）</span>，游戏和影视中也可叫做数字角色<span class="text-remarks" label="备注">（digital character）</span>。</p><p><strong>虚拟偶像，则是从应用场景出发的一种称谓</strong>，无论2D、3D或怎样的表现形式，只要以满足用户对成长、美好的向往为出发点进行公开活动，都可划分到偶像范畴。虚拟人可以被打造为虚拟偶像，同样也可以成为虚拟演员、虚拟作家等等。</p><p>按照美术风格，可以大体划分为高保真风格、写实风格与卡通渲染。其中写实—卡通是一种谱系而非存在泾渭分明的界线，而卡通风格也可进一步细分，比如美式卡通、韩系风格、二次元风格等。</p><p><strong>除风格及场景外，虚拟角色还可以按照制作主体、方式、驱动方式进行分类。</strong>艺术家从创意想象出发，经过2D原画—3D建模—绑定—动画等流程制作出的，属于PGC类型；一般用户基于平台工具，将自己的照片、视频上传后自动化生成，或组合已有的面部特征、修改参数进行“捏人”的，属于UGC类型。</p><p>让角色动起来的方式也很多样，可以手动调整动画的关键帧，再平滑模拟出过渡帧，实现角色动画；或像MMD那样，导入预先制作好的动画方案，让角色模型舞动起来；还可以通过面部、身体动作捕捉，将真实运动映射到虚拟角色的身体，部分虚拟主播、虚拟偶像就采用这种方案。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172608442476.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202107/02/172608442476.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><h3 label="大标题" class="text-big-title">二、学界：发展数十年的前沿交叉领域</h3><p>早在20世纪70年代，对虚拟人的研究就已经在学术界起步。虚拟人<span class="text-remarks" label="备注">（virtual human或computersynthesized characters）</span>指人在计算机生成空间<span class="text-remarks" label="备注">（虚拟环境）</span>中的几何特性与行为特性的表示。</p><p><strong>人是一个复杂体，不同的学科领域，对抽象和模拟人类的侧重点也不同。</strong>比如体育、军事等，关注虚拟人运动和行为的模拟仿真；医疗领域着重对数字化的人体结构进行重建和分析；图形学、影视的课题则是如何让虚拟人的外形达到真实人类的高度还原。因此，<strong>虚拟人已逐步发展为涉及计算机图形学、运动学和动力学、多功能感知、人工智能和虚拟现实等多个学科的前沿交叉领域。</strong>随着人工智能研究深入，如何让虚拟人具有一定程度的自主感知能力、逻辑推理、语言甚至情感，成为了学界和产业界共同关心的前沿阵地。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172611156039.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="727" data-h="473" src="https://img.huxiucdn.com/article/content/202107/02/172611156039.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">医学意义的虚拟人，显然不是我们要讨论的……</p><h3 label="大标题" class="text-big-title">三、业界：高保真、智能化、工具化是焦点</h3><p><strong>泛互联网产业中所谈及的虚拟人技术与案例，大体有风格化—高保真、离线渲染—实时驱动两种发展维度</strong>：风格化以打造时尚、美丽、萌系等有视觉吸引力的形象为要点，高保真则一般拥有现实中的原型；离线渲染方式呈现的是预制作的图片、视频，而实时驱动则能够跟随真人的动作、语音文字等信息进行现场“表演”。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172613330580.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="1000" src="https://img.huxiucdn.com/article/content/202107/02/172613330580.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">英雄联盟中的卡通风格角色Seraphine，以推特账号分享自己的“照片”<br label="图片备注" class="text-img-note"></p><p><strong>本文集中关注的方向是高保真、可实时驱动的虚拟人，有以下三个重要的技术方向：高保真、智能化、工具化。</strong>我们距离超级数字场景中千人千面的数字化存在，又有力地前进了一步。</p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>在视觉表现层面，做出从外形、表情到动作都1：1还原真实人的高保真虚拟人<span class="text-remarks" label="备注">（Digital Doubles）</span>，如数字奥巴马；</p></li></ul><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>运用人工智能，使虚拟人初具智能和情感表达，如微软小冰；</p></li></ul><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p>开发更轻量、便捷的工具，让艺术家和普通用户都能快速生产高品质美术资产，或自己的数字孪生体，如Epic的metahuman creator。</p></li></ul><p>为什么要首先瞄准这些方向？</p><p><strong>首先，做1：1还原的虚拟人存在很多技术难点，值得挑战。</strong>人类视觉对同类的形象、特别是对面部高度敏感，在似像非像的阶段，很容易跌入“恐怖谷”。所谓画鬼容易画人难。因此，制作风格化的虚拟角色成为另一种选择，卡通形象做出夸张化的动作表情并不会吓到观众，还为艺术创作留下很大空间。影视等非实时渲染领域，也探索出数字化复制、合成真实人类外形的技术，正向实时渲染的游戏、远程会议等领域进行迁移。</p><p><strong>即使突破了静态下拟真的瓶颈，如何让虚拟人自然地动起来，更是一大难题。</strong>人类能从对方的表情、肢体中读取丰富的非语言信息，反过来说，虚拟人表情和动作中些微的不自然都能被察觉到。简单一个皱眉，牵动骨骼肌肉皮肤一系列变化；如果用手工的方式调整，工作量极其巨大。AI在此有不可替代的价值——通过合理架构，利用人类动作和表情数据集，AI 能以人类为蓝本来学习，甚至学到被人类忽略的微妙细节，比如辨别目标是否在说谎。</p><p>未来在类似头号玩家的数字场景中，每个用户都需要自己的虚拟形象，开放世界中大量的非用户角色<span class="text-remarks" label="备注">（NPC）</span>也需要做到千人千面。影视级制作的流程和效率显然不适用。因此，需要为艺术家、一般创作者和普通人，提供符合各自能力和需求的制作工具与素材。</p><p>要做到这些方向，需要基础学科的支撑，需要一系列精密硬件、技术、算法和软件的相互配合，更需要跨界的力量。</p><h3 label="大标题" class="text-big-title">四、从很像到很真：影视级照片建模技术</h3><p>制作实时渲染、高保真、可交互的数字人类，需要影视、游戏两个领域技术的取长补短。影视很真实但不实时，游戏正好相反。<strong>影视领域的成熟技术light stage光场摄影，率先解决了“真实度”这一难题。</strong></p><p><strong>通过传统流程制作出的游戏角色，仍与真人在细节上有一定差距。</strong>角色制作遵循一条由虚向实的路径，一般流程为2D原画设计—3D建模—贴图—骨骼绑定—动画制作。因显卡运算能力和引擎渲染能力不断攀升，写实风格的角色效果正不断向影视级靠近：角色可使用的面数不断增加，材质提升，细节完善，这从《古墓丽影》系列主角劳拉的形象变化可见一斑。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172623588818.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="408" src="https://img.huxiucdn.com/article/content/202107/02/172623588818.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">历代劳拉，越发真实<br label="图片备注" class="text-img-note"></p><p><strong>影视领域则选择由实向虚，高保真数字模型制作与后期处理能力结合，诞生出让人瞠目结舌的特效成果。</strong>电影《本杰明·巴顿奇事》讲述了主角返老还童的一生，将布拉·德皮特的面部模型与不同体型的演员合成，演绎角色从老年至婴儿的形象变化。这也是在电影中实现的第一个照片级真实数字主角<span class="text-remarks" label="备注">（the first photoreal digital main character in a film——Paul Debevec）</span>。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172624427987.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="608" data-h="252" src="https://img.huxiucdn.com/article/content/202107/02/172624427987.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">皮特本人与使用面部合成技术后的形象<br label="图片备注" class="text-img-note"></p><p>关键技术支撑，来自南加州大学教授Paul Debevec自2000年启动的<strong>light stage光场摄影</strong>项目研究。这属于photogrammetry范畴，使用单个场景拍摄的多张不同角度照片来重建3D空间中的 CG 模型。回忆下《黑客帝国》中的子弹时间特效，现场有多台摄像机，用不同角度的影像重建出可360°旋转的场景。</p><p>light stage正是通过构造相机阵列，以多角度、高精度照片，既还原拍摄人物的三维结构，也获取面部的反射信息，从而能在不同环境光下重构人脸模型光效。light stage在不断迭代中解决了技术和工程难点，包括高精度皮肤纹理合成、光照与环境随时统一、更准确快速的采集过程。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172626761041.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="750" src="https://img.huxiucdn.com/article/content/202107/02/172626761041.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">light stage5，《本杰明巴顿奇事》《蜘蛛侠3》《阿凡达》等均使用过<br label="图片备注" class="text-img-note"></p><p>以下是Paul Debevec团队在SIGGRAPH 2008发布的Digital Emily，你能分辨出哪一个是真人，哪一个是虚拟人吗？</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172629581912.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" data-w="600" data-h="373" src="https://img.huxiucdn.com/article/content/202107/02/172629581912.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">（左边是虚拟人）</p><p>来自影视的照相建模、高精度3D扫描、面部和动作捕捉相关技术，已经应用到游戏的实时渲染领域，为表现力带来飞跃。<strong>如何进一步满足虚拟人实时交互的需求呢，比如，让演员的表情与虚拟人达成“神同步”？</strong>多个技术团队展开了探索。</p><h3 label="大标题" class="text-big-title">五、从形似到有神：AI助力多样化人物驱动</h3><p>为了让虚拟人和我们自然地交流互动，腾讯NExT Studios与AI Lab在虚拟人Siren<span class="text-remarks" label="备注">（演员实时表情动作驱动）</span>—Siren AI<span class="text-remarks" label="备注">（语音文字驱动）</span>—Matt AI<span class="text-remarks" label="备注">（更真实情感表达）</span>项目历程中，逐步探索“秀外慧中”的全方位能力。</p><p><strong>2017年启动的虚拟人 Siren项目，目标正是Crossingthe boundary：</strong>跨越影视和实时渲染边界，制作可实时交互的数字人物；在高保真角色基础上，进一步增加高精度的实时动作捕捉与渲染。</p><p>2018 年 5 月， Siren 惊艳亮相，激起了人们对虚拟人技术的无限畅想。<strong>Siren的特性是实时表情动作驱动，涉及多方向的技术突破，在多国企业协同合作下完成</strong>：美国的Epic发起和协调项目，以Unreal引擎整合模型、贴图、动作等数据资源；塞尔维亚的3Lateral制作高精度人物模型，同时建立绑定，为演员和虚拟人的同步搭建转换桥梁；英国的Cubic Motion，负责实时的表情捕捉；NExT作为项目所有者，提供基于Unreal引擎的高质量的人物渲染，也积极参与研发的全过程。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172632823554.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="562" src="https://img.huxiucdn.com/article/content/202107/02/172632823554.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">Siren亮相2018年GDC，演员是姜冰洁小姐姐<br label="图片备注" class="text-img-note"></p><p>技术的进步为Siren赋予了逼真的3D形象，我们能否进而为她赋予精致的“灵魂”呢？2018 年下半年的 Siren AI 项目，旨在让虚拟人不止步于“提线木偶”，将智能音箱、语音助手与人自主交互的能力赋予Siren，让她独立做到能听、会说。这涉及多个AI研究和工程领域，包括语音识别<span class="text-remarks" label="备注">（ASR）</span>、自然语言处理<span class="text-remarks" label="备注">（NLP）</span>，语音合成<span class="text-remarks" label="备注">（TTS）</span>，语音驱动面部动画<span class="text-remarks" label="备注">（ADFA）</span>。难点集中在最后一步，核心是利用AI训练出语音/文字和面部模型肌肉控制间的对应关系，然后进入渲染引擎、驱动虚拟人。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172633192605.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="624" data-h="253" src="https://img.huxiucdn.com/article/content/202107/02/172633192605.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">原理展示 <br label="图片备注" class="text-img-note"></p><p>2019年，NExT自主制作了男性虚拟人Matt，自主完成一整套高保真虚拟人的研发流程，并探索语音自驱动且能表达情绪的虚拟人技术，将语音、情感、生动的面部表情紧密关联起来。相关研究在 2019 年的 SIGGRAPH 顶级会议上展示。</p><p>为此，团队建立了一套精确的面部动捕流程，以不同情感下的动作捕捉，来训练语音驱动模型，最终构造了一个长约20个小时、13339条语句的，包含语音、面部运动和身体运动的多模态训练数据集。在Siren AI 基础上，增加情感维度数据，让Matt拥有微笑、蹙眉等微表情，多了更自然的“人情味”。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172634833655.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202107/02/172634833655.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">Matt的官方靓照</p><h3 label="大标题" class="text-big-title">六、从PGC到UGC：工具化支持高效创作</h3><p>从0开始制作虚拟人，需要较长周期，耗费较高成本。例如Siren项目从启动采集到能够自然地活动，就用了接近半年时间。<strong>在积累了一定数量人脸数据和素材的基础上，更高效的工具应运而生</strong>，既满足游戏制作流程中艺术家创造多样化角色的需求，也让普通人能够便捷生成属于自己的虚拟形象。较为有代表性的是腾讯NExT Studios的xFaceBuilder™与Epic的Metahuman Creator。</p><p>xFaceBuilder™是一套面向专业开发者的全流程管线，能够敏捷生产适用多种终端设备的数字人脸。平台基于自建的高保真人脸库xFaceDepot，提供影视级人脸建模、绑定、动画生产管线；针对手机、PC、主机等不同的平台和美术需求，提供了灵活的配置方式，已支持多款研发中的游戏内容。</p><p>平台还结合AI Lab技术，支持单张/多张照片AI捏脸。绑定好的模型可通过三种方式动起来：大型项目、复杂动作使用Dynamixyz光学动捕；如果需求不复杂，甚至可以直接打开最新款iPhone后置摄像头，基于Apple ARKit的轻量级面部动捕，以及更轻量级的语音驱动面部动画生成。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172637867783.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="830" data-h="468" src="https://img.huxiucdn.com/article/content/202107/02/172637867783.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">NExT Studios和新华社联合打造的数字记者小诤<br label="图片备注" class="text-img-note"></p><p><strong>近期，AI Lab的相关研究又取得了进一步的进展：仅需一段手机自拍视频，就能在 30 秒内合成一个高拟真度的 3D 虚拟人。</strong>视频输入到 AI 模型后，只需 30 秒处理时间就能生成一个高拟真度的虚拟人，不仅脸型和五官形状非常贴合，而且具有毛孔、唇纹、毛发级别的细节。再借助虚幻 4 引擎等基于物理的渲染引擎<span class="text-remarks" label="备注">（PBR）</span>，可以得到真实感很强的虚拟人。相关研究发表在了计算机图形学顶级期刊ACM Transactions on Graphics。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172639571750.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="357" src="https://img.huxiucdn.com/article/content/202107/02/172639571750.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">自拍快速生成虚拟人的流程及效果<br label="图片备注" class="text-img-note"></p><p>2021年初Epic公布的Metahuman Creator工具，让零基础用户也能“捏人成功”。产品基于预先制作的高品质人脸素材库，允许用户以自动混合、手动调节的方式快速生成虚拟人。Siren项目后，Epic收购了3Lateral公司，得到多年积累的大量真人扫描高精度数字资产。</p><p>主要特性首先是高效的模版混合技术，可以融合多张基础脸后快速得到一个全新面孔，且栩栩如生，拥有细腻的微表情动画；二是云端渲染，使用者无须拥有高端显卡，本地操作通过网络传输到云端，渲染后传回视频流，使制作过程做到轻量、优质、便捷。但这种方式也有局限性，利用已有人脸数据意味着无法随心所欲地创造角色。因此，工具定位在零基础操作、高品质、快生产，小团队可以直接生成自己的作品主角，大幅提升美术效果、节约创作成本；大公司则可以批量制作3A级游戏中的NPC。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172641350908.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="523" src="https://img.huxiucdn.com/article/content/202107/02/172641350908.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">Metahuman Creator制作界面</p><h3 label="大标题" class="text-big-title">七、虚拟人可以做什么？</h3><p>虚拟主播的风靡，证明风格化的虚拟角色在商业层面充满可能性。那高保真风格的虚拟人又适用于怎样的场景呢？</p><p label="小标题" class="text-sm-title">1. 真实系虚拟偶像</p><p>尽管当下二次元风格的虚拟主播更为主流，但真实系偶像的潜力同样不可小觑。当虚拟人的制作精度、动作自然度跨越恐怖谷，自然也有望跨入优质偶像的行列，并有更广的应用场景。</p><p>韩国艺术家金贤日<span class="text-remarks" label="备注">（Hyeong-il Kim）</span>创立的SUA项目正是<strong>以打造真实人类形象的虚拟偶像为目标</strong>。SUA由CG技术制作，在Unity引擎中实时渲染。虽然外形精度不及扫描真人模型后制作的效果，但也足够拟真。如果使用最新款支持面部捕捉的iPhone，小姐姐会模仿你做出扭头、撅嘴、转动眼睛的动作，十分流畅。SUA拥有自己的Twitter，不定期更新自己的日常活动。金贤日正在“培养”SUA的各种才艺技能，让她“出道”后可以应对各种各样的场景任务，如模特、演员、歌手等。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172644832844.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" data-w="586" data-h="718" src="https://img.huxiucdn.com/article/content/202107/02/172644832844.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">虚拟人SUA用iPhone 12 mini实时跟踪的效果<br label="图片备注" class="text-img-note"></p><p label="小标题" class="text-sm-title">2. 在数字影片中担任演员</p><p>使用游戏引擎制作写实风格的影像短片已并非难事，但“虚拟演员”，也就是高质量的人形美术资产，在数量和质量上都不易达到影视制作的需求。在虚拟人制作逐步成熟后，这一问题得到了初步解决。</p><p>在2021年Epic官方及合作伙伴发起的短片竞赛中，科幻题材实时渲染短片《K.I.T》就使用了多个虚拟人作为主要演员，以精良制作斩获多个传统电影奖项。短片中“出演”的角色包括Renderpeople、3DPeople中的数字人物角色，及从Eisko官网下载的免费高保真虚拟人Demo——露易丝<span class="text-remarks" label="备注">（Louise）</span>。作者布兰登·希尔<span class="text-remarks" label="备注">（Brandon Hill）</span>是一位就读于查普曼大学道奇电影与媒体艺术学院的学生。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172648780229.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="425" src="https://img.huxiucdn.com/article/content/202107/02/172648780229.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172649025338.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="982" data-h="496" src="https://img.huxiucdn.com/article/content/202107/02/172649025338.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">上图：短片《K.I.T》中的露易丝</p><p label="图片备注" class="text-img-note">下图：露易丝照片（左）及渲染后的虚拟形象（右）</p><p label="小标题" class="text-sm-title">3. 重现已故的人</p><p>还原已故的名人、亲人形象，虽存在一定伦理挑战，但也是很多人的真实需求。韩国MBC电视台纪录片频道在2020年2月曾利用VR与虚拟人技术，让一位母亲与三年前因白血病去世的女儿实现“重逢”。母亲戴上VR眼镜后，可以通过触觉手套感知孩子的头发、握住女儿的手，在虚拟空间中与女儿共度生日。她在“重新见到”女儿Nayeon时泣不成声，接受采访时表示，“可能这就是真实的天堂”。技术人员通过Nayeon生前的影像和对同龄孩子进行动作捕捉，合成了Nayeon的声音、动作和面部表情。台湾电视剧《想见你》中也设计了类似剧情。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172650162349.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="900" data-h="499" src="https://img.huxiucdn.com/article/content/202107/02/172650162349.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">三寸天堂<br label="图片备注" class="text-img-note"></p><p>电影《速度与激情7》拍摄中，主要演员之一保罗沃克意外去世。虚拟人特效技术复原了他本人形象，以特效完成了剩余镜头拍摄，并特意在片尾设计一段他驶上分岔路、与主角团及观众挥手道别的场景，让影迷们积郁的悲伤得以释放。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202107/02/172653877046.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="635" data-h="348" src="https://img.huxiucdn.com/article/content/202107/02/172653877046.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">再见，保罗</p><h3 label="大标题" class="text-big-title">八、发展趋势：更自然、更跨界、更安全</h3><p><strong>使虚拟人表现更自然，驱动方式更多样。</strong>特别是面部表情、眼神、肌肉运动的细腻流畅，既需要更多的真实数据、更优质的算法，也需要生物学、图形学、影视业的跨界支持。躯体动作的加强也是未来方向，个性化的动作组合能彰显虚拟人迥异的性格，增加亲和力和可信度，这对虚拟主持、主播、客服等需要和直面用户的领域十分重要。此外，从用遥感和按键来“操作”角色，到用实时动补、语音和文字带动角色，未来还需要更直观、适合每个人的驱动方式。</p><p><strong>推动产学研多方合作，推进行业联盟建设。</strong>如数字人类联盟Digital Human League<span class="text-remarks" label="备注">（DHL for short）</span>就是由多个高校、产业、行业专家共同成立，并建立了Wikihuman网络项目，提供来自 DHL 成员的博客文章、图文视频资料及联盟成员可以公开的虚拟人项目文件。例如南加州大学ICT视觉与图形实验室就在项目中分享了2015年成果——虚拟人Emily的原始数据、shader步骤、参考图像和模型，使研究者能够跟进与实践。</p><p><strong>加强对人脸数据、AI技术的合理使用，倡导“科技向善”。</strong>尽管技术上已初步支持通过照片、视频快速生成虚拟人，同时3D虚拟人因为与周围环境融合效果差，较难伪造人脸识别结果。但我们也要在未来发展中，重视加强合理使用和风险防范。</p><p>例如，人脸合成应用初期发布时出现了一些滥用案例，包括合成恶意影像、伪造虚假录像等。业界正在积极开发活体识别等技术，以便能尽早发现和清除网站中的伪造内容。</p><p><span class="text-remarks" label="备注">感谢腾讯NExT Studios顾煜、葛诚、姚安，腾讯AI Lab暴林超，厦门大学郭诗辉，腾讯研究院曹建峰等多位老师在本文写作过程中给予的支持与帮助！</span></p><p><span class="text-remarks" label="备注">参考文献：</span></p><p><span class="text-remarks" label="备注">[1]腾讯NExT Studios SIREN. https://www.nextstudios.com/cn/tech/siren.html</span></p><p><span class="text-remarks" label="备注">[2]腾讯AI lab虚拟人能力python代码开源地址 https://github.com/tencent-ailab/hifi3dface</span></p><p><span class="text-remarks" label="备注">[3]知乎专栏 Wang Hawk 《LightStage: 无限真实的人脸三维扫描》https://zhuanlan.zhihu.com/p/163719726</span></p><p><span class="text-remarks" label="备注">[4]知乎问题《如何拍摄一部短片或者微电影？》中用户“毁男孩的小图纸”的回答：https://www.zhihu.com/question/25310626/answer/1932877078</span></p><p><span class="text-remarks" label="备注">[5]Eisko公司的虚拟人露易丝（Louise）https://www.eisko.com/services/digital-humans</span></p><p><span class="text-remarks" label="备注">[6]Wikihuman 项目网站http://www.wikihuman.org/</span></p><p><span class="text-remarks" label="备注">[7]南加州大学ICT实验室官网 https://vgl.ict.usc.edu/Data/DigitalEmily2/</span></p><p><span class="text-remarks" label="备注">[8]环球网，韩国母亲通过VR技术与去世女儿重逢https://smart.huanqiu.com/article/3wzQ981IkgQ，2020-2-11</span></p><p><span class="text-remarks" label="备注">[9]基于Unity渲染的SUAhttps://zhuanlan.zhihu.com/p/345423886</span></p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/vy2x1wCa4BRB3Jr94ZiR4A" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">腾讯研究院（ID：cyberlawrc）</span></a><span class="text-remarks">，作者：胡璇</span></p>  
</div>
            