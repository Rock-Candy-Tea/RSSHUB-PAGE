
---
title: '寻觅意识，人工智能将何去何从？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202201/30/164608262752.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85'
author: 虎嗅
comments: false
date: Sun, 30 Jan 2022 10:33:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202201/30/164608262752.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/smfpyyEhGPeeBFVtDQGTjg" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks" label="备注">Neugeist（ID：Neugeist）</span></a><span class="text-remarks" label="备注">，作者：John Farrell，译者：Sixin，编辑&校对：杨银烛，头图来自：视觉中国</span></p><h3 label="大标题" class="text-big-title">一、故障、洗脑、窥视与“大力出奇迹”——尚不可靠的人工智能</h3><p>在许多科学家看来，人工智能并没有达到其支持者的宣传效果：安全的无人驾驶汽车现在还没有出现，在短时间内也不会出现；机器人不会承担我们所有的家务劳动，让我们腾出更多的时间玩乐。不过，往好处想，机器人也不会像电影中那样接管世界，把人类变成奴隶。</p><p>尽管如此，人们确实有理由担心人工智能已经产生的影响。加里·马库斯<span class="text-remarks" label="备注">（Gary Marcus）</span>和欧内斯特·戴维斯<span class="text-remarks" label="备注">（Ernest Davis）</span>在他们的书《重启AI：建立我们可以信任的人工智能》（<em>Rebooting AI：Building Artificial Intelligence We Can Trust</em>）中写道：“我们现在拥有的人工智能根本无法信任。”在他们看来，<strong>我们越是过早地把权力交给目前的机器系统，我们就越应该担心</strong>。他们写道：“有的问题不严重，比如Alexa*随机傻笑<span class="text-remarks" label="备注">（或者在半夜把你吵醒）</span>，或者iPhone把本来是‘生日快乐，亲爱的西奥多’<span class="text-remarks" label="备注">（Happy Birthday，dear Theodore）</span>自动改成‘生日快乐，死去的西奥多’<span class="text-remarks" label="备注">（Happy Birthday，dead Theodore）</span>。但其它的问题 ，例如宣传假新闻或者歧视求职者，可能就很严重了。”</p><p>马库斯和戴维斯引用了AI Now研究所的一份报告。这份报告详细介绍了人工智能在许多不同领域的问题，比如医疗补助资格的确定、对监禁的判决和对教师的评估：</p><blockquote><p>华尔街的闪电崩盘导致股市暂时下跌，而令人恐惧的侵犯隐私现象也开始出现<span class="text-remarks" label="备注">（比如有一次，Alexa录制了一段对话，并无意中将其发送到了用户联系人名单上的一个随机人员）</span>；还有多起车祸发生，其中有些造成了死亡。人工智能驱动的电网出现重大故障并不会让人惊讶，但如果此事发生在炎热的夏天或者死寂的冬天，就可能会造成很多人死亡。</p></blockquote><p>计算机科学家杰伦·拉尼尔<span class="text-remarks" label="备注">（Jaron Lanier）</span>曾在谷歌工作过，<strong>他</strong><strong>列举了人工智能的黑暗面，并将其归咎于人工智能已经被脸书和谷歌等社交媒体巨头利用</strong>。在他看来，这些社交媒体促进了用户之间的派系主义和分裂，这一点鲜明地体现在2016年和2020年的选举中。当时，俄罗斯黑客创建了虚假的社交媒体账户，将美国选民推向唐纳德·特朗普。拉尼尔在他的书《立刻删除社交媒体账户的十个理由》<span class="text-remarks" label="备注">（Ten Arguments for Deleting Your Social Media Accounts Right Now）</span>里面写道，<strong>人工智能驱动的社交媒体，天生就是为了霸占用户的注意力，侵犯他们的隐私，用没有经过事实核查或审查的内容来淹没他们</strong>。事实上，他总结道，这些媒体的目的是“将人们变成白痴”。</p><p>弗兰克·帕斯夸莱<span class="text-remarks" label="备注">（Frank Pasquale）</span>是布鲁克林学院法学教授和《天下》<span class="text-remarks" label="备注">（Commonweal）</span>杂志撰稿人，发表过著作《黑匣子社会：控制金钱与信息的秘密算法》<span class="text-remarks" label="备注">（The Black Box Society: The Secret Algorithms That Control Money and Information）</span>。他在书中指出：个人隐私的丧失也令人忧心。当强大的企业、金融机构和政府机构将他们的行为隐藏在保密协议、“专有方法”和禁言规则的背后时，普通消费者的生活对他们来说却越来越一目了然。“<strong>我们在网上所做的一切都被记录了下来</strong>。”帕斯夸莱写道：</p><blockquote><p>仅剩的问题是：这些数据将提供给谁？将保留多长时间？匿名软件也许能暂时保护我们，但谁知道，试图隐藏的行为本身，是否会成为充满警惕的当局的眼中钉呢？监控摄像头、数据代理、传感器网络和“超级缓存”<span class="text-remarks" label="备注">（supercookies）</span>记录了我们开车的速度、吃的药、读的书和访问的网站。法律在商业领域积极地保护秘密，却在涉及个人隐私时越来越沉默。</p></blockquote><p>同时，拉尼尔指出，这些大型科技公司正在公开进行着异常奢侈的人工智能“竞赛”，并往往给其最大的优先级。拉尼尔认为，这种竞赛是疯狂的。“我们忘记了，人工智能不过是一个编造的故事，在我们计算机科学家依赖政府机构拨款的时候，这个故事帮助我们获得资金。它不过是一种实用主义的把戏。而现在，人工智能已经成了一个不受控制的庞然大物。”</p><p><strong>在马库斯和戴维斯看来，整个领域需要重新集中精力，让人工智能对常识更敏感。</strong>而要做到这一点，我们就需要对“如何为机器编程”进行彻底的反思。</p><h3 label="大标题" class="text-big-title">二、“反事实”会形成意识吗？</h3><p>“<strong>设想自己的意图，然后将其作为因果推理的证据，这已经达到了拥有自我觉知<span class="text-remarks" label="备注">（self-awarness）</span>乃至意识<span class="text-remarks" label="备注">（consciousness）</span>的水平。而我所知道的任何机器都没有达到这一水平。</strong>”朱迪亚·珀尔<span class="text-remarks" label="备注">（Judea Pearl）</span>写道。他是一位重要的人工智能支持者，整个职业生涯都在研究机器智能。“我希望能够把将机器引向诱惑，然后让它说‘不’。”在珀尔看来，目前的计算机并不真正构成人工智能，它们只是构成了<span class="text-remarks" label="备注">（可能的）</span>真正的人工智能的基础。拥有一个使你的生活更加容易的应用程序，与拥有一台能够像另一个人一样推理与回应我们的机器，是完全不同的。</p><p>珀尔与丹娜·麦肯锡<span class="text-remarks" label="备注">（Dana McKenzie）</span>合著了《为什么：关于因果关系的新科学》<span class="text-remarks" label="备注">（Book of Why：The New Science of Cause and Effect）</span>。在书中，他阐述了要制造能够独立思考的机器而需要应对的挑战。目前的人工智能系统能够比任何人类更快地扫描成片的数据，找出其中的规律和模式。它们可以学会击败国际象棋冠军和围棋冠军。根据《科学》<span class="text-remarks" label="备注">（Science）</span>杂志中的一篇文章，现在甚至有台计算机可以在多人扑克游戏中击败人类。然而，这些都是狭义的任务，不需要珀尔所说的“为自己思考”。在他看来，使用数据的机器还没学会如何“摆弄”数据。要为自己思考，他们需要学会利用数据来回答因果问题。更为关键的是，它们需要学会提出反事实的问题，即，如何以不同的方式使用同样的数据。简单来说，<strong>他们必须学会问对每个三岁小孩来说都很自然的问题：“为什么？”</strong></p><p>“对我来说，强大的人工智能应该是一个能够反思自己的行为，并从过去的错误中学习的机器。它应该能够理解‘早知今日，我当初就该以不同的方式行事’这一说法，无论这一结论是被人类告知还是自己得出的。”珀尔围绕他所谓的的<strong>三级“因果关系阶梯”</strong>建立了他的方法。人类则站在这个阶梯的顶峰，是唯一能够以真正的因果关系进行思考、能够提出反事实问题<span class="text-remarks" label="备注">（“如果……会发生什么？”）</span>的物种。</p><p>但随之而来的问题是：<strong>这样的人工智能会像我们一样有意识吗？或者，它只是一种更先进的“智能”机器，纯粹为人类服务而存在？</strong>我们有理由持怀疑态度。哲学家大卫·查尔莫斯<span class="text-remarks" label="备注">（David Chalmers）</span>在2019年接受《纽约时报》采访时告诉普拉桑特·拉马克里希纳<span class="text-remarks" label="备注">（Prashanth Ramakrishna）</span>，<strong>智能并不一定意味着主观意识</strong>。</p><blockquote><p>智能是关于一些系统的行为能力的：它们能做什么？在给定输入的情况下，它们能产生什么输出。谈到智力，核心问题是，给定一些问题和目标，你能使用正确的手段达到目的吗？如果你能，这种能力就是智力的标志。而意识，则更多是关于主观经验的。你我都有智能，但我们也有主观性；它就像某种内在的东西。这种主观性——意识——赋予我们的生活意义，也赋予我们人类道德地位。</p></blockquote><p>在查尔莫斯看来，试图证明机器拥有意识并不容易。“也许一个人工智能系统，向我描述它自己的心灵状态‘我正经历着痛苦、欢乐或悲伤’，可以证明它‘有意识’。但也许最重要的是'它'对自己的精神状态感到的一些困惑：‘客观上，我知道我只是一个硅电路的集合体，但主观上，我却远不止于此。’”</p><p>珀尔并未直接解决这个关于意识的哲学问题。他似乎假设了：如果人工智能强大到能进行因果思考，就没有理由不相信它有查尔莫斯所承认的意识。然而，这种看法，许多哲学家与神学家，以及许多人工智能科学家都不同意。计算机科学家欧内斯特·戴维斯<span class="text-remarks" label="备注">（Ernest Davis）</span>在邮件里告诉我，意识不会自发地，或者以涌现的方式出现：</p><blockquote><p>人类是有可能朝着这个方向制造系统的。但我要说，那是不明智的，不是因为它们会有恶意或者太强大，而是因为它们会变得很难预测……电影《机械姬》<span class="text-remarks" label="备注">（Ex Machina）</span>里的“邪恶机器为了摆脱禁锢杀掉其创造者”的场景是非常不可能出现的，除非你特意把机器设计成那样<span class="text-remarks" label="备注">（这同样超过了目前的技术）</span>。</p></blockquote><p>在戴维斯看来，若试图制造有意识的系统，更有可能出现的，是一个行为诡异而无意义，因此时不时随机破坏的人工智能。当前，人工智能程序只是工具，而好的工具是那些我们能对其有信心的工具。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202201/30/164608262752.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="1344" src="https://img.huxiucdn.com/article/content/202201/30/164608262752.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">AI程序只是工具，而好的工具是那些我们能对其有信心的工具。— Björn Öberg</p><p>珀尔工作的诱人之处在于，他一直强调的、用来实现强人工智能的因果思维，可能悄悄地暗示了我们人类自己的意识是如何演化而来的。作为在以色列长大的犹太教徒，珀尔认为，在演化的某个时候，人类意识到世界不仅有事实<span class="text-remarks" label="备注">（数据）</span>，还有因果关系网络。这些因果关系，而非事实，才是人类知识的主要组成部分。最后，在珀尔看来，<strong>从原始数据的肉身处理者转换到解释的建构者，这个过程不是渐变的，而是需要某种飞跃</strong>。</p><p label="正文" class="text-normal">在珀尔看来，《创世纪》<span class="text-remarks" label="备注">（Book of Genesis）</span>中亚当与夏娃受惩罚的故事，代表了我们独特的因果思维能力的涌现。“我们知道，《创世纪》的作者努力回答的是他那个时代的哲学问题。同理，我们觉得这个故事承载了‘智人获得对这个星球统治权’的文化足迹。那么，这个快速超级进化的过程的步骤是什么？”<strong>珀尔认为，步骤就是在因果关系阶梯上的快速爬升，从观察，到干预，再到因果思维。</strong></p><p>圣经可能会告诉我们一些关于“珀尔阶梯”的顶层<span class="text-remarks" label="备注">（提出反事实问题的需要和能力）</span>的信息。亚当与夏娃故事的悲剧性正体现在它是一个伟大的反事实问题，正如基督教关于堕落和原罪的教义中阐释的那样：如果亚当和夏娃没有犯罪，我们的境况会有多大的改善？如果堕落没有发生，世界会是什么样子？这个问题困扰着许多神父和后来的神学家，包括托马斯·阿奎那。</p><p>我们知道动物会为家庭成员的死亡悲伤和失落，也知道它们会经历拒斥<span class="text-remarks" label="备注">（我们观察到，一只雌性黑猩猩在她的孩子死亡后，将尸体背在背上好几天，仿佛它还没有死；一只虎鲸也为她死去的幼鲸做同样的事情）</span>。但我们并没有证据表明它们会思考“事情本可以有所不同”。只有人类才有自我意识，能问自己“如果我们当初走的是那条路而不是这一条，是不是就能避免悲剧了？”珀尔认为，总有一天我们能够制造出具有自我意识的机器，能够进行反思，能够后悔——虽然他认为这不会很快。</p><h3 label="大标题" class="text-big-title">三、信息演化会形成意识吗？</h3><p>然而，并不是每个人都相信一个能够进行推理的强人工智能就一定会有我们所认为的“意识”。人工智能专家、《人造的你》<span class="text-remarks" label="备注">（Artificial You）</span>的作者苏珊·施耐德<span class="text-remarks" label="备注">（Susan Schneider）</span>与大卫·查尔莫斯一样，对智能行为与大脑产生的那种意识进行了区分。施耐德拥有罗格斯大学<span class="text-remarks" label="备注">（Rutgers）</span>的哲学博士学位，曾是普林斯顿大学神学研究中心的研究员。她现在在佛罗里达大西洋大学，管理着心智未来中心<span class="text-remarks" label="备注">（Center for the Future of the Mind）</span>，而且正在与同事一起建立一个机器人实验室。</p><p>她通过电话告诉我：“<strong>我认为我们需要区分意识和智能。原则上，我们可以创造出没有意识的高智能机器。</strong>想想人的大脑，它大部分的活动都是无意识的计算。所以我们知道，复杂的心理处理可以在没有意识的情况下发生。而且，从人工智能的发展中，我们还可以看到，机器学习有着令人印象深刻的发展——它正朝着更普遍的智能形式发展。而这些算法并不完全与大脑所做的事情相同。”施耐德以计算机围棋冠军为例：“那个算法用与我们不同的方式来下围棋。所以我完全不会假设机器有意识。我们需要对这种区别保持敏感。”</p><p>施耐德说，到目前为止，我们尚无对智能和意识间的区别十分敏感的需求，“因为，在生物领域，只要你看到了智能，你就看到了意识。”但随着人工智能的兴起，我们必须清楚地保持这种区分：<strong>计算机有智能行为的事实，并不证明它能够有主观经验。</strong>人工智能行业经常提供“可爱的人工智能”——像猫、像狗或者像我们的机器人，来掩盖计算机和大脑工作原理之间的基本区别。当一个机器人有一张脸——当它能微笑并且看着我们的眼睛——我们就更容易想象它有着和我们一样的经历。<strong>但这是一种投射，而不是从机器人的实际行为中做出的合理推断。</strong>就“机器能否拥有真正意义上的意识”这个问题，施耐德告诉我，她采取观望态度。</p><p>英国作家苏珊·布莱克摩尔<span class="text-remarks" label="备注">（Susan Blackmore）</span>毫不怀疑机器可以有意识；事实上，她相信它们至少在某种程度上已经有意识了。布莱克摩尔在年轻时有过灵魂出窍的经<span class="text-remarks" label="备注">历（out-of-body experience, OBE）</span>。以研究和试图理解这段经历为契机，她开始了她心理学和意识研究的职业生涯。在最近出版的《看到我自己：灵魂出窍的经历告诉我们关于生命、死亡和心灵的事情》<span class="text-remarks" label="备注">（Seeing Myself: What Out-of-Body Experiences Tell Us About Life, Death and the Mind）</span>的书中，她详细描述了这段经历。</p><p>多年来，她回顾了其他曾灵魂出窍的人的经历，以及对这种现象的科学调查，从中得出结论：并不存在“死后心灵仍能存在”的可靠证据。她开始相信，我们传统上认为的意识，不过是一种幻觉。这不是说意识并非真实存在，而是说它不是一个独立存在的非物质实体<span class="text-remarks" label="备注">（substance）</span>或本质<span class="text-remarks" label="备注">（essence）</span>。意识的存在并不意味着非物质灵魂的存在。布莱克摩尔认为，如果是这样的话，就没有理由不相信机器也可以有意识。</p><p>“我认为我们有理由期待强人工智能。”布莱克摩尔在我们通过Skype交谈时告诉我。但她对于强人工智能的看法以及它可能的发展形式与珀尔的想法非常不同。在布莱克摩尔看来，人们过于相信“人工智能完全是由人类制造的这个理念。大多数人似乎只关注‘我们先制造人工智能，然后将其放入某种机器’这个想法上。好吧，也许真的会这样，但也许不会。<strong>我真正感兴趣的是已经在主动演化，为了自己的利益而演化的人工智能。</strong>”</p><p>布莱克摩尔是“<strong>模因理论</strong>”<span class="text-remarks" label="备注">（meme）</span>的支持者——这套理论认为，人类的概念、行为、文化现象和宗教仪式随着时间的推移在人类社会中生存、传播和演变，其方式与达尔文演化论中的基因相同。像基因<span class="text-remarks" label="备注">（gene）</span>一样，它们通过简单的复制、变异和选择过程获得成功。按照布莱克摩尔的说法，我们可以看到，机器现在正在它们自己的世界里分享模因。事实上，她认为人工智能记忆——或者她所说的 “<strong>极因</strong>”<span class="text-remarks" label="备注">（tremes）</span>——是生命史上的第三个复制者：<strong>基因随着生物演化首先出现，接着是模因随着人类文化的爆炸而出现，现在，随着人工智能的出现，第三个伟大的复制者出现了</strong>。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202201/30/164610218616.gif" data-w="500" data-h="281" src="https://img.huxiucdn.com/article/content/202201/30/164610218616.gif" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">- Ambrose Yu -</p><p>她说：“‘极因’将包括互联网上的模因，也包括所有在我们不知情的情况下被处理的信息。我的意思是，互联网上的模因是介于基因与‘极因’之间的，因为在选择和篡改模因的是我们自己。”但是对于“极因”来说，大部分的复制是机器自己完成的。“你需要三个过程：复制、变异和选择。这就是基本的达尔文主义。所以我脑海里的问题是：<strong>这三件事中有多少是在没有人类干预的情况下已经完成的？</strong>”</p><p>复制是相当明显的：“所有东西在短时间内被复制到所有的云端，比如这个聊天记录的副本就将持续一段时间。我们的电子邮件也有很多份。”然后是变异。布莱克摩尔声称，现在的变异都由机器完成，几乎没有人的监督或者监测。“想想自动撰写的学生小论文，想想人造的新闻。现在已经有大量这样的程序与算法，能撰写报纸文章，和真人写的没什么区别。”最后是选择。而选择也是由机器完成的<span class="text-remarks" label="备注">（想想谷歌）</span>。“搜索引擎收到某个特定的人的查询，可以选择要为ta提供什么内容。”</p><p>布莱克摩尔认为，如果这一切正在发生，“这件事确实和产生人类智能的过程很像，都是<strong>一大堆不同的算法<span class="text-remarks" label="备注">（或者更笼统地说，一大堆过程）</span>，相互作用，相互喂养，通过演化，变得越来越复杂，越来越紧密联系。</strong>在我看来，这就是人工智能出现的方式。”</p><p>布莱克摩尔认为，在某些时候，这个过程将演变出强大的人工智能——不需要我们的帮助。她认为，那时候，机器的意识可以与人类的意识相媲美。“尽管意识在很多方面都非常神秘<span class="text-remarks" label="备注">（虽然我觉得它现在没那么神秘了）</span>，但在我看来，毫无疑问，<strong>意识是在我们社会交流的过程中，通过演化产生的</strong>，就像演化产生了我们所拥有的的大脑与身体一样。人类必须要有大脑、身体和他人，才能获得意识。机器也在这样做。而且它们正在演化，这是另一个层次的演化。” 布莱克摩尔的立场表明，生物学和技术之间没有不可渗透的界限：两者都受制于相同的基本自然规律。</p><h3 label="大标题" class="text-big-title">四、复杂的信息整合能形成意识吗？</h3><p>马克·弗农<span class="text-remarks" label="备注">（Mark Vernon）</span>是《基督教的秘密历史》<span class="text-remarks" label="备注">（A Secret History）</span>一书的作者，是训练有素的心理学家，也是圣公会的神学家。他不相信人工智能可以在任何意义上拥有意识。正如他通过电子邮件告诉我的那样：</p><blockquote><p>也许我们需要先问这样一个问题：什么是“活着”？从亚里士多德<span class="text-remarks" label="备注">（Aristotle）</span>到阿奎那<span class="text-remarks" label="备注">（Aquinas）</span>的经典答案是：“活着”的事物有一个来自内部的运动<span class="text-remarks" label="备注">（运动指的是任何形式的活动）</span>原则。因此，植物有一个内在的运动原则，亚里士多德称之为“植物的灵魂”；动物有另一个原则，即“动物的灵魂”，因为动物的运动中也有自发的因素；而人类<span class="text-remarks" label="备注">（还有一些高等动物）</span>又有另一个原则，因为我们可以在我们的运动原则中加入理性、自我意识等。它们的集合可以被称为人类的灵魂，作为身体内部的运动准则。</p></blockquote><p>弗农认为，人工智能不可能自移动<span class="text-remarks" label="备注">（self-moving）</span>。他说：“有机体的自移动是整个生物体所做的事情。这意味着，整个有机体是先于构成有机体的部件和‘程序’存在的。”这就是为什么你不能用零件来制造一个活的有机体<span class="text-remarks" label="备注">（尽管你能够做到更换活的有机体的某些部件）</span>。一个有机体的部分总是作为整体的一部分存在，而不是因自己的自主特性而存在。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202201/30/164611985490.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="500" data-h="481" src="https://img.huxiucdn.com/article/content/202201/30/164611985490.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">整个有机体是先于构成有机体的部件和‘程序’存在的。— Björn Öberg</p><p>人类的意识依赖于演化而来的身体。如果我们想创造出与我们一样有意识的人工智能，我们是否应该以类似演化论建构我们的方式来建构它？施耐德告诉我，实际上，她在心智未来中心的新实验室正在研究这种方法，将其作为长期项目之一。西雅图艾伦脑科学研究所<span class="text-remarks" label="备注">（Allen Institute for Brain Science）</span>的首席神经科学家克里斯多夫·科赫<span class="text-remarks" label="备注">（Christof Koch）</span>也很欣赏这种亚里士多德式的具身<span class="text-remarks" label="备注">（embodiment）</span>方法。他对人工智能系统能够并且终将成为有意识的系统非常有信心，这种信心基于一套可量化的整合信息理论<span class="text-remarks" label="备注">（Integrated Information Theory，IIT）</span>，该理论是由神经科学家与精神病学家朱利奥·托诺尼<span class="text-remarks" label="备注">（Giulio Tononi）</span>首先提出的，借鉴了亚里士多德“形式因”<span class="text-remarks" label="备注">（formal causality）</span>的概念。</p><p><strong>但在科赫看来，意识可能不需要与任何特定的物质基质<span class="text-remarks" label="备注">（material substrate）</span>挂钩</strong>：“大脑”可以是基于生物的，也可以是基于硅的。<strong>意识的涌现依赖于这样一个系统：该系统各部分之间的因果互动达到了一定程度<span class="text-remarks" label="备注">（其程度可被量化，在此用希腊字母Φ表示）</span>，并且根据定义是不可还原的。</strong>科赫认为，这一理论提供了一种方法，来解释“为什么某些类型的高度组织化的物质，特别是大脑，可以有意识。整合信息理论……从两个基本的公理出发，解释了世界现象性<span class="text-remarks" label="备注">（phenomenal）</span>的一面。它不只是单纯的哲学揣测，而且能带来具体的神经生物学洞见，能构建出对意识的度量<span class="text-remarks" label="备注">（meter）</span>。这个度量可以评估动物、婴儿、睡眠者、病人和其他不能谈论其经验的人的有意识程度”。</p><p>科赫在他最近的书《生命本身的感觉：为什么意识广泛存在但无法计算》<span class="text-remarks" label="备注">（The Feeling of Life Itself：Why Consciousness Is Widespread But Can’t Be Computed）</span>中阐述了这一观点。他在书中写道，整合信息理论是一种对亚里士多德形式因的使用。信息<span class="text-remarks" label="备注">（information）</span>一词来自拉丁语informare，即“赋予形式或形状”。“整合信息导致了因果结构的产生，因果结构是一种形式。整合信息是因果的、内在的和定性的：它从一个系统的内在角度进行评估，评估的标准是基于它的机制与当下状态如何塑造自己的过去和未来。系统如何制约其过去和未来的状态，决定了体验到的感觉是蓝天的颜色还是湿狗的气味。”</p><p>马克思·泰格马克<span class="text-remarks" label="备注">（Max Tegmark）</span>也是整合信息理论的倡导者。在他的书《生命3.0》<span class="text-remarks" label="备注">（Life 3.0）</span>中，他写道：</p><blockquote><p>几十年来，我一直认为，意识是信息以某些复杂的方式被处理时的感觉。IIT同意这一点，并且用一个精确的定义取代了我模糊的表述“某些复杂的方式”：信息处理需要被整合，也就是说，Φ需要很大。朱利奥对此的论证既简单又有力：意识系统需要被整合成一个统一的整体，因为如果它由两个独立的部分组成，那么它们就会是两个独立进行感知的意识实体，而不是一个。换句话说，如果大脑或计算机中某个有意识的部分不能与其它部分沟通，那么其它部分就不能成为其主观体验的一部分。</p></blockquote><p>有些人不赞同这一理论，或者不认为它提供了一个能有效探讨机器意识的背景。但是，如果科赫和泰格马克是对的——如果一台具有足够复杂性的机器不仅可以发展出智能，而且可以发展出意识——那么机器也会遭受痛苦，这种痛苦应由其创造者负责。施耐德相信，创造有意识的机器，本质上是在扮演上帝。如果我们认为自己很清楚该怎么做，那也太狂妄了。如果我们创造了能感到痛苦的机器，它们有权利吗？一个有意识的人工智能，如果不把它当做奴隶，应该当做什么呢？所以，如果人工智能没有意识，把它们当作只是为我们服务的工具会更容易。施耐德警告说：“<strong>我们应该对反乌托邦的可能性保持敏感。</strong>”</p><h3 label="大标题" class="text-big-title">五、结语</h3><p>如果我们很快就将与拥有自我意识的机器分享生存空间，这对人性的未来意味着什么呢？如果朱迪亚·珀尔的梦想成真，我们可以设计出能够抵制诱惑或屈服于诱惑的机器，那会怎样？无论这种强人工智能早出现、晚出现，或者根本不出现，下述观点是明确的：我们需要保持一定程度的谨慎和形而上学的谦逊，不仅在试图研究机器智能之时，也在神经科学中研究我们人类自己的智能之时。施耐德说：“对于创造其他形式的智能<span class="text-remarks" label="备注">（尤其是那些有意识智能）</span>的前景，我们应该非常谦卑，毕竟我们连人类自己的意识都尚未理解。”</p><p><span class="text-remarks" label="备注">*译者注</span></p><p><span class="text-remarks" label="备注">Alexa是亚马逊公司开发的人工智能语音助手。</span></p><p><span class="text-remarks" label="备注">原文：</span></p><p><span class="text-remarks" label="备注">https://www.commonwealmagazine.org/minds-without-brains</span></p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/smfpyyEhGPeeBFVtDQGTjg" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">Neugeist（ID：Neugeist）</span></a><span class="text-remarks">，作者：John Farrell</span></p>  
</div>
            