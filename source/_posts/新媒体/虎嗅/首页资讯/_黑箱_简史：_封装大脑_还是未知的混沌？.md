
---
title: '_黑箱_简史：_封装大脑_还是未知的混沌？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202108/25/212910752784.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
author: 虎嗅
comments: false
date: Wed, 25 Aug 2021 14:02:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202108/25/212910752784.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=MjM5NTA0MzIyMA==&mid=2649938191&idx=1&sn=a8c77c4fa7374db5c76186430406df92&chksm=bef8fbf4898f72e24021d1f193accbae43c24f019a623f094206727f12dd475f545cb6de35a1&mpshare=1&scene=1&srcid=0825g5w3CeqWv4Eq80g4BfaG&sharer_sharetime=1629898076025&sharer_shareid=a3289e4d177fbb88e81ed6ecd014575f&version=3.1.12.6001&platform=win#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">腾云（ID：tenyun700）</span></a><span class="text-remarks">，作者：贺久恒（腾云特约作者，康奈尔大学Science&Technology Studies在读博士），题图来自视觉中国</span></p><p>“黑箱”<span class="text-remarks" label="备注">（Black Box）</span>通常指在人类认识世界的过程中，遇到的一类客体：<strong>由于技术、知识及操作能力的限制，研究者无法直接研究其内部的结构和运行机制。</strong>对于这样的一类特殊的研究对象，控制论创始人诺伯特·维纳<span class="text-remarks" label="备注">（Norbert Wiener）</span>将之称为“黑箱”。</p><p>随后，罗斯·阿什比<span class="text-remarks" label="备注">（Ross Ashby）</span>为控制论研究奠基的著作《控制论导论》<span class="text-remarks" label="备注">（An introduction to cybernetics）</span>中，详细阐述了他对于黑箱的定义和如何研究黑箱的方法论。</p><p>自此，黑箱逐步成为一个被应用在计算机、心理学、医学、教育学、社会学等等领域的符号，意指我们无法充分研究清楚的封闭系统，只有通过其输入与输出来观察其行为，总结其中可能存在规律。</p><p>本文将回顾黑箱这一概念，如何从一个实际中的工程学概念演变为一个可以广泛用于各种客体的隐喻和符号。同时本文也将简要讨论黑箱概念对人工智能发展史的诸多影响；以及在机器学习为人工智能开发主流方式的今天，我们如何去理解常常被描述为黑箱的机器学习与神经网络算法。</p><h3 label="大标题" class="text-big-title">第二次世界大战中的“黑箱”</h3><p>黑箱<span class="text-remarks" label="备注">（Black box）</span>的概念在诞生伊始并非是一个符号或隐喻，而是指第二次世界大战期间中的一个真实存在的黑箱子。跟据冯·希尔格斯的历史考证<span class="text-remarks" label="备注">（von Hilgers，2011）</span>，黑箱说法起源自1940年的英国与美国共享最新科技进展的蒂泽德任务<span class="text-remarks" label="备注">（Tizard Mission）</span>。</p><p>在蒂泽德任务中，英方曾向美方运送过一个装载着磁控管的黑色箱子。当这个箱子抵达位于波士顿的麻省理工学院之后，“黑箱”这一名称以及其背后所隐含的寓意便随之传播。</p><p>1943年兰德公司内部报告中有一篇文章名为“从一个黑箱中建造出的轰炸机防御系统”<span class="text-remarks" label="备注">（Bomber Defense from a Little Black Box）</span>。彼时美国军方将磁控管称为一个黑箱，不仅因为其作为最新技术进展的技术复杂性，同时也出于军事机密保护的原因不愿具体提及磁控管的技术细节。</p><p>随后，“黑箱”<span class="text-remarks" label="备注">（Black box）</span>成为许多二战期间军事机密技术的俚称。由于许多负责操作这些机械的工程师并不了解其中的技术细节，他们往往只能通过黑箱的输入和输出来理解其工作的机制以及如何运用到实际场景中。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/25/212910752784.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="831" data-h="561" src="https://img.huxiucdn.com/article/content/202108/25/212910752784.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">通用电气实验室在二战期间建造的磁控管</p><p>20世纪40年代正是控制论领域方兴未艾的时期，控制论领域的奠基人维纳就曾在二战期间尝试为美国军方开发一套防空预警系统<span class="text-remarks" label="备注">（不过最终以失败告终）</span>。这一失败的尝试虽然没有为美国军方提供帮助，却使得维纳接触到了军方技术实践中大量存在的“黑箱系统”，启发了他后来对于黑箱系统的研究兴趣。</p><p>维纳所开发的防空预警系统实际折射出了彼时控制论研究者具备的巨大野心：跟据维纳的描述，这一防空预警系统能够通过一套复杂的反馈机制来预测敌方轰炸机飞行员是否要选择在某地投下炸弹<span class="text-remarks" label="备注">（Galison, 1994）</span>。因为维纳试图预测的是人类飞行员的行为，这样的防空预警系统堪称是20世纪最早的人工智能尝试之一，所以维纳无法在彼时的技术条件下完成他的预期也不足为奇。</p><p>在这个项目中，最值得注意的一点是：维纳所构想的建造类人智慧的机器并不需要我们理解人类大脑的组成，他期望通过反馈机制来建模<span class="text-remarks" label="备注">（model）</span>以模拟人类的行为。换言之，只要同样的输入进入到人类大脑中和进入到机器中能够得到同样的输出，那么他们内部的原理和计算过程是否一样，对于维纳来说<span class="text-remarks" label="备注">（或者对于有绝大多数控制论研究者来说）</span>也就不重要了。</p><p>这便是黑箱研究法的起源：放弃对于复杂系统运行原理的探究，转而使用建模的方式模拟人类大脑的输入与输出。</p><p>关于黑箱研究法，另一位控制论领域的巨擘罗斯·阿什比提出了更加明确的定义：</p><blockquote class="js_blockquote_wrap" data-type="2" data-url data-author-name data-content-utf8-length="149" data-source-title><p>对于黑箱理论不感兴趣的研究者往往会在遇到黑箱时不屑一顾，因为这样的案例无法回答他们最感兴趣的问题：“这个箱子里有什么？” 然而，我们更应该考虑的问题是：“对于一个黑箱的特征，作为研究者的我们能够归纳出哪些特征？有哪些手段能够帮助我们更加有效率的研究一个黑箱的运行规律？“ <span class="text-remarks" label="备注">（Ashby, 1961）</span></p></blockquote><h3 label="大标题" class="text-big-title">封装“大脑”：研究人类智能的控制论进路</h3><p>对于20世纪上半叶的控制论研究者来说，维纳所提出的反馈机制是他们研究开发人工智能的主要途径，同时维纳也深刻启发了许多来自心理学、生理学、物理学和工程学的学者投身于封装“大脑“的蓝图中。</p><p>一个典型的例子是，在1944年著名的美国实验心理学家埃德温·波林曾与维纳进行过一系列关于如何建模大脑的通信<span class="text-remarks" label="备注">（Petrick，2020）</span>。波林被维纳所提出的黑箱研究法所打动，他在信中提到了如何将大脑简化为一个黑箱：“所有的心理学现象毫无疑问都可以被操作化定义为一组‘刺激与反馈‘。”</p><p>如果心理学家能够确定这些刺激与反馈之间的关联，波林希望维纳能够帮助他使用电子机械系统来实现人类心理现象的复刻。波林信中所提到的”刺激与反馈“对于大脑这个黑箱来说，其实就是输入与输出。如果说我们放弃直接理解大脑究竟是如何运作的，那么只要搞清楚这些输入与输出，就存在理论上的可能来建造一个人类大脑的复制品，而且这个复制品能够帮助研究者理解人类大脑具体的运行机制。</p><p>在后续的通信中，波林甚至还详细的制作了一个列表，其中包含了他已经确定了的关于人类大脑的一些刺激与反馈的联系，他希望维纳至少能够帮助他实现部分大脑功能的复制。遗憾的是，我们无法知晓后来维纳是否帮助波林继续这项研究，因为在最后一封信中维纳希望能够当面和波林讨论这项研究的后续推进，而后也没有任何书面材料记述了关于该研究的后续进展。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/25/212914425367.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="831" data-h="590" src="https://img.huxiucdn.com/article/content/202108/25/212914425367.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">埃德加·波林（1886-1968）</p><p>在维纳以及其他控制论学者正在如火如荼的展开关于“封装大脑”的研究时，控制论领域内部也涌现出了一些对于黑箱研究法的不同声音。</p><p>其中一个重要的疑问在于：我们如何能够在完全不了解黑箱内部运作机制的基础上，确定我们复刻出来的机械真的能够具备黑箱完全相同的能力？即便能够做到完全的复刻，这样的尝试又能够对于我们理解黑箱本身提供多大的帮助呢？</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/25/212918372038.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="831" data-h="499" src="https://img.huxiucdn.com/article/content/202108/25/212918372038.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">诺伯特·维纳（1894-1964）</p><p>阿什比曾在他的私人日记中留下这样的一段文字：“<span class="text-remarks" label="备注">（黑箱研究）</span>一个非常明显的不确定性是，我们永远没有办法建立起黑箱与复制品之间的确定联系。事实上我们只能够假定在它们的输入和输出中存在着一种我们能观察范围内的相关性。”</p><p>阿什比在这里所强调的不确定性与逻辑经验主义在归纳悖论中所遇到的困难是一样的：即便在我们能够观察的所有范围内，黑箱的行为与我们所复刻出来的机器行为完全一致，我们也无法推理出任何它们之间的确定联系。</p><p>由于我们对于黑箱内部运行机制的一无所知，始终不存在一种逻辑上的证明使得我们确信研究者所复制出来的机械能够达到黑箱本身完全一致的功能。</p><p>换言之，黑箱研究法虽然能够帮助研究者绕开打开黑箱的困难，但研究者始终都处于“罗素的火鸡”所面临的不确定性中：火鸡永远无法知道明天会得到主人的午餐还是屠刀，研究者也永远无法知道黑箱在下一次实验中是否还会与复制品得出一样的结果。</p><h3 label="大标题" class="text-big-title">机器学习中的黑箱问题</h3><p>在人工智能领域发展过七十余年后的今天，建立人类大脑的模型所采用的研究进路已经和维纳、波林和阿什比等人所采用的方法完全不同。机器学习和神经网络在最近的三十年间成为人工智能开发的主要路径，然而黑箱作为一种隐喻往往成为研究者批判机器学习和神经网络的常见论调。</p><p>神经网络的算法往往被认为是一个黑箱，即便开发者写下了每一句代码来构建起一个神经网络，然而经过大量的训练后，没有人能够清楚的解释为什么一个神经网络算法能够得出研究者想要的结果。</p><p>研究者所能掌控的只是一种基于概率的部分确定性：算法在得到X作为输入后，有i的几率能够给出我们预期的结果Y。经过长时间的训练，概率i或许会不断逼近1，但是想要解释这一结果得出的运算过程反而会变得愈发困难。</p><p>从功利和实际的角度出发，我们当然可以这样为神经网络算法辩护：当算法有足够大的概率依照我们预期的方式给出结果，我们就不必要担心那些“黑天鹅”事件，毕竟没有万无一失的解决方案。</p><p>然而当我们把神经网络和机器学习推广至人类生活的方方面面时，人们不得不开始反思：<strong>把人类社会中一些非常至关重要的事务交给一个黑箱去处理，是否是一个明智的决定？</strong></p><p>笔者在这篇短文中显然无法给出一个明确的答案，但是毫无疑问的一点是，如何打开机器学习的黑箱会是人工智能研究者在未来一段时间里致力于解决的重要问题。</p><p>而可以肯定的是，“黑箱”作为一个隐喻，仍将活跃在计算机、哲学、社会科学、工程学等领域的学术探讨之中。</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=MjM5NTA0MzIyMA==&mid=2649938191&idx=1&sn=a8c77c4fa7374db5c76186430406df92&chksm=bef8fbf4898f72e24021d1f193accbae43c24f019a623f094206727f12dd475f545cb6de35a1&mpshare=1&scene=1&srcid=0825g5w3CeqWv4Eq80g4BfaG&sharer_sharetime=1629898076025&sharer_shareid=a3289e4d177fbb88e81ed6ecd014575f&version=3.1.12.6001&platform=win#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">腾云（ID：tenyun700）</span></a><span class="text-remarks">，作者：贺久恒（腾云特约作者，康奈尔大学Science&Technology Studies在读博士）</span></p>  
</div>
            