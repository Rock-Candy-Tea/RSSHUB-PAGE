
---
title: '苹果要偷看你手机电脑上的照片了'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202108/07/083905005494.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
author: 虎嗅
comments: false
date: Sat, 07 Aug 2021 01:39:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202108/07/083905005494.png?imageView2/2/w/1000/format/png/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODg4ODEwMA==&mid=2247508025&idx=1&sn=eb41611829ed5891278d0497c2a2fbb6&chksm=eb52cbf2dc2542e4d0be42eefe43e8102a4497f9a358044fe3564308d4b41a566bf9cee900cc&mpshare=1&scene=1&srcid=0807DODC9Mvi4UuJNzbTqDyV&sharer_sharetime=1628296709746&sharer_shareid=be8103098854364beb7fc7a4edcd2e7e&version=3.1.8.90228&platform=mac#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">硅星人（ID：guixingren123）</span></a><span class="text-remarks">，作者：光谱、杜晨，编辑：Lianzi，题图来自：unsplash</span></p><p>大家可能记得，苹果最近几年一直在用的，宣传 iOS 系统隐私性的广告语：</p><p>“What happens on your iPhone, stays on your iPhone.”</p><p>Or does it? 事实真的如此吗？</p><p>过去的事情暂且不提。我们现在可以肯定的是，在今年晚些时候发布的 iOS 15 和最新版 Mac 操作系统Monterey上，苹果就要堂而皇之地“偷看”你的照片了。</p><h3 label="大标题" class="text-big-title">发生了什么</h3><p>昨天，约翰·霍普金斯大学加密学教授 Matthew Green 在 Twitter 上突然爆出一条大新闻：多名知情人士确认，苹果即将发布一项用于扫描检测儿童色情虐待内容<span class="text-remarks" label="备注"> (Child Sexual Abuse Material) </span>的端侧工具。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083905005494.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="546" data-h="274" src="https://img.huxiucdn.com/article/content/202108/07/083905005494.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">端侧的意思就是扫描工作在用户设备上完成。截图来源：Matthew Green 的 Twitter 账号<br></p><p>今天，苹果也在官网正式宣布了这一消息：</p><p><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083906802084.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="765" data-h="887" style="text-align: center;" src="https://img.huxiucdn.com/article/content/202108/07/083906802084.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"><br></p><p label="图片备注" class="text-img-note">截图来源：苹果官网 https://www.apple.com/child-safety/<br></p><p>这个系统的工作原理大概是这样的：</p><p>首先，苹果会对用户在 iPhone 等各类苹果设备上接收、保存和发送的照片提取哈希值。</p><p>然后，苹果会用这个值和美国“国家失踪和被剥削儿童中心”的数据库进行比对，验证涉事照片是否属于儿童色情虐待内容。这个数据库将会保存在用户设备的本地。比对检测工作也是在本地完成的。</p><p>用户在 iMessage 上收到或者发送照片。系统会在后台完成比对检测工作。如果系统认为它属于露骨内容，iMessage 就会暂时屏蔽掉这张照片、询问，并再次确认用户是否要浏览或发送这张照片。</p><p>不仅如此，如果用户本身是少年儿童，并且设置了家庭账号的话，iOS 系统还会通知家长。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083908621458.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="817" data-h="570" src="https://img.huxiucdn.com/article/content/202108/07/083908621458.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">图片来源：苹果<br></p><p>如果你以为所有这些真的全部在本地完成的，不涉及到苹果公司层面的隐私嗅探行为，那你就太小看苹果了。苹果也会用类似的哈希算法对用户发送到 iCloud 保存的照片<span class="text-remarks" label="备注">（同样端到端加密）</span>进行检测，并且在上传之前给照片文件增加一串保密信息。</p><p>如果涉事照片被判定为儿童色情虐待内容，苹果的服务器将可以对照片进行解密，并且交由人工进行二次审核。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083909869960.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="727" data-h="209" src="https://img.huxiucdn.com/article/content/202108/07/083909869960.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>安全专家认为，苹果设计的这套打击儿童色情的技术，虽然设计目的是好的，但可能存在严重的安全和隐私风险，并且完全颠覆了“端到端加密”原本存在的意义。</p><h3 label="大标题" class="text-big-title">事件的影响</h3><p>“最初我的理解是，这项技术用于在端侧对云存储的照片进行扫描。但是最终，它可能会成为在加密通讯系统中增加监控的一个关键因素。”Green 评论道。他还表示，在端到端通讯系统中加入这样的扫描系统，一直以来都是全球各地执法部门的主要需求。</p><p>“棱镜”计划的爆料人爱德华·斯诺登也对苹果此举颇为不满，甚至在 Twitter 上发布了一张梗图吐槽：</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083911272154.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="593" data-h="522" src="https://img.huxiucdn.com/article/content/202108/07/083911272154.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">左边：苹果2015年：我们不让 FBI 查看死掉的恐怖分子的手机，只为保护你的隐私。右边：苹果2021年：我们会用官方黑名单检测你的相片册和 iCloud 照片，除了报警之外，还会告诉你家长……</p><p><strong>不管怎样，苹果将会在新版操作系统里“偷看”你的照片这件事，算是坐实了。</strong></p><p>至于什么"What happens on your iPhone, stays on your iPhone"，只是少数用户一厢情愿的假象了……</p><p>需要明确的是，苹果并不是第一家、唯一一家在做类似事情的公司。包括谷歌<span class="text-remarks" label="备注">（从2008年开始）</span>、微软<span class="text-remarks" label="备注">（2009年）</span>、Facebook<span class="text-remarks" label="备注">（2011年）</span>和 Twitter<span class="text-remarks" label="备注">（2013年）</span>等公司，都已经在用哈希算法等相关技术，对儿童色情虐待内容进行预防、侦测和打击了。</p><p>知名互联网用户权益机构“电子前线基金会”<span class="text-remarks" label="备注">（EFF）</span>在2019年曾经撰文指出：<strong>这种号称专为打击儿童色情内容而设计的所谓“用户端侧扫描工具”，是一个伪命题。</strong></p><p>首先，从技术上来讲，这类工具无法将其检测能力限制在儿童色情这一类内容上。</p><p>具体来说，这类检测技术核心原理都是对图片提取哈希值，然后和一个“官方”的数据库进行比对。</p><p>但是目前机器学习领域已经有了先进的生成对抗网络技术，可以对两个不同的文件，比如两张完全不同的照片，实现“哈希碰撞”<span class="text-remarks" label="备注">（也即这两张完全不同的照片拥有相同的哈希值）</span>：</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083912648827.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="612" data-h="686" src="https://img.huxiucdn.com/article/content/202108/07/083912648827.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">图示：右边一列的公司 logo 和中间一列用算法生成的“人脸”图片，实现了哈希碰撞。图片来源：Nick Locascio<br></p><p>任何拥有官方数据库操作权限的人，都可以自己添加新的哈希值条目到数据库，从而扩大这个图片检测系统，所检测和审查的对象范围。</p><p>EFF 指出，在这样的场景下，“由于数据库只包含哈希值，而儿童色情图片的哈希值和其它图片的哈希值<span class="text-remarks" label="备注">（可能）</span>没有区别，那么扫描儿童色情内容的系统，就无法从技术上只针对儿童色情内容。”</p><p><strong>其次，EFF 还指出，这类所谓的端侧扫描工具，实际上打破了端到端加密的承诺。</strong></p><p>端到端加密的普遍定义是：在一个通讯系统中，只有内容的发送端和接收端可以看到所发送的内容，其他任何人，包括其他用户，以及通讯系统的运营者<span class="text-remarks" label="备注">（苹果）</span>都无法看到，也没有能力对通过加密方式传送的信息进行解密。</p><p>“如果一个系统有直接、有效解密很大一部分信息的能力，它就不再是一个端到端加密的系统了，”EFF 指出。</p><p>再次，前面提到，<strong>苹果的这个检测系统，一旦侦测到可能的儿童色情内容，还会引入真人进行二次检验。这就进一步扩大了用户隐私泄露的风险。</strong></p><p>目前苹果没有透露究竟谁有权限查看这些照片，是苹果自己的员工还是外包机构——希望不是后者，毕竟之前苹果的外包维修商 Pegatron 就出过恶意泄露用户隐私照片的严重事故。</p><p>最后，这样的检测系统，其实很容易通过简单的方法逾越。</p><p>那些传播儿童色情内容的犯罪嫌疑人，可以更换其它通讯软件，抑或对图片进行简单的修改<span class="text-remarks" label="备注">（比如加上带有微弱遮盖效果的字幕）</span>，就可以让一张图片的哈希值“面目全非”。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/07/083914697190.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="700" data-h="302" src="https://img.huxiucdn.com/article/content/202108/07/083914697190.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">图片来源：Jens Segers<br></p><p>综合考虑到前面所有提到的关于这个系统的弊端，得出的结论是：它打开的隐私缺口太大，制约儿童色情内容传播的实效却无法保证。说好听，事倍功半；说难听点，反而会弄巧成拙。</p><p>你怎么看苹果这次“偷看用户照片”的反儿童色情内容传播系统？你觉得它会起到多大的帮助？你会担心它对端到端加密和用户隐私带来的负面效应吗？欢迎在评论区分享你的看法。</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODg4ODEwMA==&mid=2247508025&idx=1&sn=eb41611829ed5891278d0497c2a2fbb6&chksm=eb52cbf2dc2542e4d0be42eefe43e8102a4497f9a358044fe3564308d4b41a566bf9cee900cc&mpshare=1&scene=1&srcid=0807DODC9Mvi4UuJNzbTqDyV&sharer_sharetime=1628296709746&sharer_shareid=be8103098854364beb7fc7a4edcd2e7e&version=3.1.8.90228&platform=mac#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">硅星人（ID：guixingren123）</span></a><span class="text-remarks">，作者：光谱、杜晨，编辑：Lianzi</span></p>  
</div>
            