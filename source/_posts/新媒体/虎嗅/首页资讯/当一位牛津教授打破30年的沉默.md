
---
title: '当一位牛津教授打破30年的沉默'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://www.huxiu.com/article/undefined'
author: 虎嗅
comments: false
date: Sun, 20 Jun 2021 13:49:00 GMT
thumbnail: 'https://www.huxiu.com/article/undefined'
---

<div>   
<img alt="当一位牛津教授打破30年的沉默" data-v-ea68b0d0 src="https://www.huxiu.com/article/undefined" referrerpolicy="no-referrer"><p><span class="text-remarks" label="备注">作者 | 竺晶莹</span></p><p><span class="text-remarks" label="备注">题图 | 《模仿游戏》剧照</span></p><p>六年前，牛津大学的一个办公室里，电话铃声划破了寂寂的长廊，突然响个不停……</p><p>“请问是迈克尔·伍尔德里奇教授吗？我们来自BBC，想跟你求证一些关于AI的言论。近日，埃隆·马斯克说，AI在未来将摧毁人类。你怎么看呢？” 电话那头传来急促的声音。</p><p>伍尔德里奇教授忍俊不禁，从他的学院派眼光看来，马斯克的预测正如好莱坞迷恋AI统治世界的故事一样，尚属无稽之谈。</p><p>随着AI话题热度越来越高，伍尔德里奇教授30年来平静的研究生涯，自这通电话后开始被打破。他发现，相较艰深的技术分析，媒体显然更倾向于报道人工智能下的反乌托邦场景。只是，事实并非如此。这也是为什么他近年来撰写了《人工智能全传》一书，试图向大众破除关于AI的迷思。</p><p>英国议员马特·里德利曾盛赞他：“没有人比伍尔德里奇更了解人工智能这项新技术的过去和现在，以及它给人们带来的便利和危害。”</p><p>议员或许夸张，倒也并非过誉。时任牛津大学计算机学院院长的迈克尔·伍尔德里奇<span class="text-remarks" label="备注">（Michael Wooldridge）</span>，与我进行了一次对谈，希望帮我们厘清人工智能的发展简史。对话中，教授从图灵测试谈到深度思考，算法偏见如何制约了机器，“技术奇点”有何缺陷。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/20/213831537170.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="421" src="https://img.huxiucdn.com/article/content/202106/20/213831537170.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">伍尔德里奇教授被誉为英国计算机领域影响力最大的三位学者之一 / 图片来源：牛津大学官网</p><h3 label="大标题" class="text-big-title">祛魅AI</h3><p>“这个世界已经有足够多的担忧能让我们失眠，比如气候变化、核武器，我不建议大家再担心AI取代人类这种事了。” 伍尔德里奇教授无奈笑道，他的英式幽默有点冷。</p><p>在教授的回忆里，当时马斯克表示AI可能摧毁人类后不久，斯蒂芬·霍金竟也警示大家，AI对于人类而言是个潜在的威胁。这让他陷入了深思，为何像霍金这样伟大的头脑都作出了类似判断。</p><p>他或许找到了部分原因。过去十年间AI的飞速进展，让我们幻想未来几十年AI研究仍能以一种梦幻的速度实现超越。但是，伍尔德里奇指出，人们往往忽视了过去取得的进步，仅局限于特定的领域以及具体的程序中，比如AlphaGo、自动翻译。这会让人误以为，一个全知全能的拟人化AI快要降临了。但能下围棋的程序无法自动翻译，强人工智能时代也不会那么快到来。因此，特定程序的研发进步，让我们将乐观的情绪扩散到了AI全面进展上，但实际上这只是千里之行所累积的跬步而已。</p><p>“人们错误地认为，如果机器可以在某方面比人类做得更好，那么它们在任何方面都超越了人类，显然并非如此。一个程序若能比人类做得更好，那是它通过被大量训练使得程序最优化，然后在一个精细的领域里达到顶尖水平。”</p><p>比马斯克的言论更成体系的，大概是“技术奇点”<span class="text-remarks" label="备注">（Technological Singularity）</span>理论。20世纪50年代，计算机先驱冯·诺伊曼首次提出“奇点”，表述为一种可以撕裂人类历史结构的能力。60年代，数学家I.J.古德首创“智能爆炸”，指智能机器在无需人工干预的情况下不断设计出下一代。</p><p>2005年，美国发明家、预言学家雷·库兹韦尔<span class="text-remarks" label="备注">（Ray Kurzweil）</span>在《奇点临近》一书中大胆预测：科技正以史无前例的速度指数级发展，计算机将超越人类智能的各个方面。到2045年，奇点来临时，人工智能将完全超越人类智能。奇点之后，如果人的智能完全转移到计算机上，那么人将以软件形式实现永生。</p><p>库兹韦尔将历史分为六个纪元，每一个纪元的出现，都是利用上一个纪元的进化成果。人类在进化中产生思维能力，继而创造了技术，从简单的机械化发展为成熟的自动化设备。而接下来就将进入人机文明的纪元，由于人类技术呈现指数型发展，像基因技术、纳米技术、机器人技术都将呈现更大容量、更快速度与更强的知识分享能力。我们的人机文明将超越人脑的限制，奇点开始，并于第六纪元从地球拓展到全宇宙。</p><p>如果这段说明有点拗口，用伍尔德里奇教授的话来说就是，机器会不断自我学习让自己变得更聪明，而机器学习的速度远远超过生物。因此我们害怕，机器最终会脱离人类的控制，因为它将聪明到我们难以理解它，难以与它共处。</p><p>然而，伍尔德里奇指出了奇点理论有明显的不足——没有人致力于制造“奇点”；而这也不会在一夜之间发生，因为我们只有应用大量的科学与技术才能达到“奇点”，好比波音747的发明，就是一个无比漫长的工程学研究过程，而它在开发中必须首要考虑的就是，确保人类的安全。</p><p>“我并不担心奇点的到来，因为我们目前并不知道如何从现有的AI，演化到通用人工智能<span class="text-remarks" label="备注">（Artificial General Intelligence）</span>，这依旧是科学之谜。” 教授补充道。</p><p>尽管伍尔德里奇教授理性且克制地看待AI发展，但这并不代表他对于人工智能进步的观点过于保守。事实上，AI简史中有许多关键时刻令他感觉到兴奋。</p><p>“如果你来挑选AI发展过程中最关键的三个时刻，会是什么？” 我问。</p><p label="正文" class="text-normal">教授略一沉思，在他30余年的研究生涯里，见证过太多AI高光时刻，只挑三起事件，倒也为难。但他还是很快确认了对自己震撼最大的三个节点：1966-1972年，首台采用了人工智能学的移动机器人Shakey在美国斯坦福国际研究所<span class="text-remarks" label="备注">（Stanford Research Institute, SRI）</span>被发明；2005年，自动驾驶汽车Stanley完成了132英里的Mojava沙漠路线，在DARPA超级挑战赛上一举夺冠；2016年，谷歌DeepMind研发的AlphaGo击败围棋世界冠军李世石。</p><p>伍尔德里奇进而解释，当时斯坦福研究所团队试图制造一个自主机器人，你向它下达命令后，它得自己找到途径达成任务，比如你让它把箱子从这个角落搬到那个角落。而这需要许多步骤，首先它要听懂你的指令，其次它要弄清怎么完成指令，再来它还要辨识真实世界的场景，你需要把这些所有元素都内置到一个机器人上。Shakey展现了人工智能的应用，但更揭示了我们在AI领域远有更多路径需要探索。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/20/214226460035.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="556" src="https://img.huxiucdn.com/article/content/202106/20/214226460035.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">自主机器人Shakey / 图片来源：Google </p><p>Stanley在2005年挑战赛上的表现则证明无人驾驶技术的难点首次被突破。2004年第一届挑战赛上，没有一辆自动驾驶汽车能行驶超过7英里，甚至很多车都没开过起跑线。但没想到，仅隔一年，伍尔德里奇记得至少有七辆车能够自动驾驶140英里以上，只需按下按钮，斯坦福大学开发的Stanley就可以在复杂的地形上平均每小时行驶约 20 英里。他想，那简直就像第一次见证飞机飞行一样。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/20/214413646367.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="666" src="https://img.huxiucdn.com/article/content/202106/20/214413646367.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">无人驾驶汽车Stanley在2005年挑战赛中夺冠 / 图片来源：Google</p><p>AlphaGo在2016年在韩国首尔击败李世石，则超乎意料，学界本以为这种层次的技术在未来二十年才会发生，因此这是“深度学习”<span class="text-remarks" label="备注">（Deep Learning）</span>取得重大突破的明证。</p><h3 label="大标题" class="text-big-title">AI迷思</h3><p>那什么是所谓的“深度学习”呢？</p><p>如果用官方语言描述，那就是推动第三次神经网络的关键技术。伍尔德里奇教授指出，这个人工智能中最古老的想法之一，在过去十年中才开始取得成果。我们从大脑结构中汲取了灵感来构建AI系统，人类大脑约有1000亿个神经元彼此连接，那么类比在软件中就是神经网络。1990年的一个典型神经网络可能只有约100个神经元，2016年先进的神经网络已经拥有约100万个神经元。</p><p>深度学习的意义在于不断前进，构建更深的网络层级、更庞大的神经元结构、更广泛的神经元连接。</p><p>虽然AlphaGo是深度学习取得重大进展的标志之一，但它也存在缺点。比如一个拒绝为客户提供银行贷款的深度学习程序，无法告诉你它拒绝客户的原因。此外，神经网络的稳定性也存疑。如果对图像进行细微修正，这对人类来说不影响图片识别，但会导致神经网络将其错误分类。因此，同样的改图方式可以影响程序对路标的识别，在无人驾驶汽车中，神经网络就可能误读路标。</p><p>另一个常被提及的概念是“算法偏见”<span class="text-remarks" label="备注">（Algorithmic Bias）</span>。教授指出：“这并非算法的偏见，其实是算法继承了人类的偏见。”</p><p>这一说法可以追溯到1970年代，为了提高招生流程的效率，伦敦圣乔治医学院的Geoffrey Franglen博士编写了一个“模仿人类评估员”的算法来筛选学生的入学申请，其初衷也是为了抹平招生委员会的个体偏见，交由系统来完成“公平”的筛选。结果却适得其反，成功入学的申请者始终缺乏多样性。</p><p>原来，算法被设定了一些无关因素，比如出生地和姓名，来权衡申请者。如果他们的名字不是白人姓氏，筛选流程就会对他们不利，光是没有一个欧洲名字就会自动扣除申请者 15 分了。女性申请者平均要被扣掉3分。因此，算法只是在维持当时招生系统早已存在的偏见而已。</p><p>那么今天我们有希望解决算法偏见的问题吗？</p><p>伍尔德里奇表示，AI的工作原理就是，程序通过不断被训练来作出判断。假设一家银行在设计程序来判断客户是否该获得贷款。那么银行需要展示大量贷款申请，并告诉算法，这是优质或劣质的申请。但关键在于，训练算法的人本身就带有自己都没意识到的偏见，那么算法自然在大量习得数据的过程中也沾上了偏见。比如伦敦存在区域的“邮编歧视”，如果一个程序根据客户住址来判断他该不该获得贷款，由于以往数据显示偏远社区的用户偿还贷款能力不佳，这时算法就倾向于判断这类邮编的客户不该被批准申请。</p><p>这么看来，只要人类社会的偏见不消除，算法世界的偏见也不会消失。不过，从1970年代至今，人们至少在消除种族歧视、倡导性别平权上的呼吁已经得到些许进展，而只有现实世界里的进展才会延伸到算法系统中。<br></p><p>最终，这些关于机器能否思考的讨论，必然会溯源到阿兰・图灵<span class="text-remarks" label="备注">（Alan Turing）</span>身上。1950 年，图灵发表了一篇论文《计算机器与智能》，他提出了一个问题：“机器会思考吗？”</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/20/214639648256.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="583" src="https://img.huxiucdn.com/article/content/202106/20/214639648256.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">开启了人工智能时代的图灵 / 图片来源：Google</p><p>如果看过《模仿游戏》，那么对这位数学天才不会陌生。电影剧情中，二战时期，英国军情六处招募了一批人来破解德军Enigma密码机制造的暗号，但没有人能在24小时内解出无数种可能性，而一天过后又是新的密码。直到图灵意识到，只有机器才能打败机器。</p><p>伍尔德里奇指出电影有许多戏剧化的偏离现实情节，倒有助于大众认识到图灵。他说，图灵几乎是偶然发明了计算机，因为他1930年代在剑桥读博期间就尝试解决当时最重要的一个数学问题，为了解决它，图灵最终发现他必须发明一种通用机器。战后，他继续建造自己的机器，这实际上是他数学梦想的载体。</p><p>随即，图灵就发明了一种测试来检测机器是否会思考。英国有一种模仿游戏，一男一女分别位于不同房间，裁判需通过他们的手写对话来猜谁是谁，但男女双方都有可能在模仿对方。图灵被游戏启发，构思了一个思想实验，将其中一位选手换成了计算机。如果计算机在编程之下，让裁判无法断定自己究竟是跟人还是机器对话，图灵提出，那就有理由推断出机器和人类一样在“思考”。</p><p>这个思想实验被称作“图灵测试”，仍是AI界最具争议的话题之一。伍尔德里奇将这个测试形容为美妙，因为几乎是图灵开启了AI时代。</p><p>而那也可以被视作对哲学的一种挑衅。</p><p>哲学家Daniel Dennett表示，图灵测试本该是哲学对话的终结者，“与其无休止地争论思考的终极本质和要义，我们为什么不都就这一点达成一致呢？即无论其本质是什么，任何东西只要通过了这一测试，当然就拥有思考能力。”</p><p><span class="text-remarks" label="备注">此为“算法与活法”系列报道第四篇，该系列聚焦科技时代下我们的生活如何被“异化”，通过与学者或专家的访谈以期获得些许洞察。此前该系列篇目有：</span></p><p><span class="text-remarks" label="备注">《我们正掉入外卖陷阱》</span></p><p><span class="text-remarks" label="备注">《算法与活法：当你不再被需要》</span></p><p><span class="text-remarks" label="备注">《“人性第一”》</span></p>  
</div>
            