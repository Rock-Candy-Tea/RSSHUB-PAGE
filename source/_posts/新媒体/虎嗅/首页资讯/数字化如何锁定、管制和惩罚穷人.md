
---
title: '数字化如何锁定、管制和惩罚穷人'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202108/15/093125883838.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85'
author: 虎嗅
comments: false
date: Mon, 16 Aug 2021 00:00:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202108/15/093125883838.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">数字革命是否是一场由精英主导的游戏？普通人特别是贫困人口在数字时代的命运是什么？算法是否比人类更加中立、公正和明智？本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTU1OTU3MA==&mid=2247506208&idx=1&sn=0dece4a5644450aaa0619ebe3516d068&chksm=ce99a55df9ee2c4bacaf4811106b426d567659b11ae4289a37aa76f3e6709aa51ef0d552cddf&mpshare=1&scene=1&srcid=0815fQ0F1ZwJLwP9azmn9wmK&sharer_sharetime=1628990367934&sharer_shareid=71f767aac76a75906e709de91388a4e5&version=3.1.2.6203&platform=mac#rd" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks" label="备注">中国慈善家杂志（ID：cnscsj）</span></a><span class="text-remarks" label="备注">，作者：郜晓文，头图来自：视觉中国</span></p><p>去年，一篇题为《外卖骑手，困在系统里》的文章在社交媒体刷屏，互联网企业利用算法对骑手进行控制和劳动压榨的问题，引起社会上普遍关注。北京大学社会学系的陈龙博士对此作了专门研究，揭示了平台的数据算法系统对劳动者无休止地压迫式索取。</p><p>随着高科技日新月异的发展，数字革命如火如荼。数据追踪以及在此基础上的决策机制已经成为商业、行政管理甚至刑事判决惯用的工具。当我们欢呼数字化带来的便利时，纽约州立大学奥尔巴尼分校政治学副教授弗吉尼亚·尤班克斯<span class="text-remarks" label="备注">（Virginia Eubanks）</span>却发出追问：<strong>数字革命是否是一场由精英主导的游戏？普通人特别是贫困人口在数字时代的命运是什么？算法是否比人类更加中立、公正和明智？</strong></p><p>尤班克斯在《自动不平等》<span class="text-remarks" label="备注">（Automating Inequality）</span>一书中，通过生动的故事和深刻的分析，告诉人们一个简单的道理：<strong>技术不能代替正义。</strong></p><p>作者认为，标榜高效的自动化系统，并未在实质上改善贫困家庭的处境。恰恰相反，嵌入偏见的高科技工具使政府在做出和民众生活息息相关的决定时，“名正言顺”地摆脱了道德束缚。更令人后怕的是，书中揭露了伴随数据分析、统计模型与算法的监管网络，边缘人群正面临着更加严格的数字追踪、监控甚至惩罚，被牢牢困在这张网中。</p><h3 label="大标题" class="text-big-title">一、“数字济贫院” </h3><p>19世纪，美国政府为缓解贫困问题而建造了济贫院。尤班克斯认为<strong>“现在我们正在建设一所数字济贫院”——一所无形的“锁定穷人、管制穷人、甚至惩罚穷人”的机构，一旦穷人求助政府获取公共援助或寻求其他公共服务，就会被这所看似中立的数字济贫院“瞄准”。</strong></p><p>尤班克斯通过三个深入调查访问的案例，系统地分析了数据挖掘、政策算法和预测风险模型对美国贫困和工薪阶层的影响。</p><p><strong>第一个案例是印第安纳州试行的福利资格自动认证系统。</strong>全系统自动化运营，脆弱不堪的规则和设计不当的操作指标，加上自动决策工具永不出错的假设，意味着一旦发生错误，往往会归咎到申请人，而不是州政府或承包商。在这套系统下，成千上万人的福利申请遭到了拒绝，其中包括出生时就是脑瘫儿、医疗费用寄希望于政府的小苏菲。由于当地家庭与社会服务管理局社工的失误，苏菲家被直接归为“未能配合”政府工作，而被拒绝通过福利申请。</p><p><strong>第二个案例是洛杉矶为无家可归者提供服务的电子登记注册机构。</strong>根据其设计者的说法，该市的协调入住系统旨在“将最亟须帮助的群体与最合适的资源相匹配”。然而，大批无家可归者的个人信息被录入信息管理系统，生成所谓的“弱势指数”。次贷危机中失去一切流落街头的加里·伯特莱特，因为“弱势指数”不够高，只能在无尽等待中消磨希望，而这些无家可归者的信息也成了执法部门可以随意获取的数据，他们被当成了“天然的罪犯”。</p><p>第三个案例是宾夕法尼亚州阿勒格尼县的家庭筛查系统，根据一个人以往的行为模式来推测他将来可能采取的行动。<strong>在新的预测方式下，人们不仅会受到自己行为的影响，还会受到恋人、室友、亲戚和邻居行为的影响。</strong>预测模型和算法将穷人标记为“风险”和“问题父母”。随之而来的大量社会服务、执法活动和社区监督，使他们的一举一动全在监控之下，贫困成了“天然的风险指标”。</p><p> “今天，我们基于数据库、算法和风险模型造了一个‘数字济贫院’，它的覆盖范围和恶劣影响很有可能超越任何以往的类似机构。”尤班克斯指出，<strong>如果不重视算法中可能隐藏的偏见，不去规制算法可能产生的风险缺陷，那么这些致力于解决贫困的技术进步和效率提升，可能只会模糊贫困与犯罪之间的界限，将穷人永远桎梏在这所“数字济贫院”。</strong></p><p>随着数字时代来临，社会网络和信息技术日渐发达，智慧城市和数字治理成为时尚。在美国社会，算法科技被用于开展诸多政府项目，包括为无家可归者提供庇护场所、向生活困难者提供援助，以及儿童福利项目等。自动化系统决定哪些社区可能会被重点管制，哪些家庭能够获得救助，哪些群体面临欺诈调查，美其名曰算法治理。</p><p>决策者们依赖大数据分析本无可厚非，但在算法的高科技外表下，隐藏着重要的公平正义问题。高科技工具增加了对贫困和工薪阶层行为模式和日常选择的数据收集、存储和共享，以便政府干预、审查和监视。然而，<strong>这种监视被过多地用于寻找受助者的不法行为，从而导致穷人更易被归罪，他们的福利被转移。</strong></p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202108/15/093125883838.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="800" data-h="800" src="https://img.huxiucdn.com/article/content/202108/15/093125883838.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">《自动不平等》作者：[美]弗吉尼亚·尤班克斯，译者：李明倩 ，出版：商务印书馆，出版时间：2021年版</p><h3 label="大标题" class="text-big-title">二、贫困不容否认</h3><p>《自动不平等》涉及的一个关键问题是算法对社会不同阶层，特别是贫困群体的影响。这是人工智能伦理和算法治理无可回避的问题。</p><p><strong>算法应该怎样对待贫困？</strong>尤班克斯认为，这不仅仅是需要改变技术的问题。“对贫困、穷人和工薪阶层的看法与态度也需要有更广泛的转变。”她在书中列举了全美各地贫困民众面临的几种主要困难。比如，领取福利救济时因为一些“无心之失”而成为了福利欺诈的调查对象；无家可归者艰难地寻求可供容身的庇护住所，以及被迫与子女分离、将孩子送到寄养机构。</p><p>社会学家斯坦利·科恩将美国公众对贫困的态度称为“文化否认”，是一种使我们得以了解残忍、歧视和压迫，但从不公开承认其存在的过程。文化否认不是一种个体才有的人身或心理属性，它是一个由学校、政府、宗教、媒体，以及其他机构组织支持的社会过程。</p><p>比如，当我们在喧闹的街头经过流浪汉或者乞讨者身边时，已经习惯了 “无动于衷”和“视而不见”。<strong>因为整个社会文化已将穷人描绘成病态性地依赖社会的少数群体，他们被打上了毫无希望与价值的标签。公共政策也倾向于指责贫困，而不是纠正贫困造成的负面影响，或消除贫困的根源。</strong></p><p>在美国，贫困还是一种可被塑造的政治筹码。右翼往往谴责穷人是寄生虫，主张减少资助，左翼则以家长姿态对穷人无力改变自己生活的现状表示痛心，希望改造穷人。</p><p>无论如何，<strong>数量庞大、花费高昂的公共服务机构被主要用来调查个人的痛苦际遇是否可能由其自身过错导致，这使得人们可能即使身处贫困，却试图轻描淡写或予以否认，小心翼翼地求助社会服务项目。</strong>这种狭隘的认识使包括精英阶层在内的中产阶级对穷人的遭遇冷漠以待，那些旨在更加高效为有需要之人提供帮助的新技术，则被早早嵌入了对穷人的偏见和对贫困的否认。</p><p><strong>从文化的视角来看，限制人们视野的是将穷人与其他人相区分的叙事方式。</strong>尤班克斯在书中呼吁，直视贫困，承认贫困，聆听穷人的故事，建立理解贫困的同理心，改变我们对贫困的看法、言论和感受，“虽然无法从根本上解决贫困问题，但至少不会令这场正在改变我们生活的数字革命在惩罚穷人的道路上越走越远”。</p><p>美国《独立宣言》中将自由视为“不可剥夺的权利”，然而，数字济贫院的存在削弱了贫困和工薪阶层行使自主权和进行自治的能力，侵犯了他们行使这些权利的自由。数字济贫院的复杂性使目标对象感到无能为力，不知所措。很多时候，这些工具只会碾压一个人的决心，直到他们放弃本应享有的一切：资源、自主权、尊重和尊严。</p><p>20世纪60年代，马丁·路德·金博士在华盛顿特区领导了争取黑人工作机会和自由权的民权运动，号召消除美国以及全世界的贫穷，产生了广泛的社会影响。但是金死后，穷人运动虽仍在继续推进，却没有取得预期的结果。</p><p>数字技术在公共服务和福利制度中的应用，使消除贫困和种族歧视运动面临新的挑战。2020年11月，美国掀起的“黑命贵运动”核心在于反对种族歧视，动员不同阶层抵制警察暴行。尤班克斯认为，事件最应该引发公众注意的是采取措施制止司法系统对黑人身体、思想和心灵实施暴力行为，同样也要监督在公共服务、无家可归者服务和儿童保护服务中可能出现的暴行和非人性操作。</p><p>总之，揭露“数字济贫院”的残酷需要巨大的勇气，穷人运动是美国未竟的伟大征程之一。在数字技术日趋精密和普遍的今天，拆除锁定穷人、管制穷人、惩罚穷人的“数字济贫院”，不仅仅需要高科技，更需要文化、政治和个人道德的深刻变革。</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTU1OTU3MA==&mid=2247506208&idx=1&sn=0dece4a5644450aaa0619ebe3516d068&chksm=ce99a55df9ee2c4bacaf4811106b426d567659b11ae4289a37aa76f3e6709aa51ef0d552cddf&mpshare=1&scene=1&srcid=0815fQ0F1ZwJLwP9azmn9wmK&sharer_sharetime=1628990367934&sharer_shareid=71f767aac76a75906e709de91388a4e5&version=3.1.2.6203&platform=mac#rd" target="_blank" rel="nofollow"><span class="text-remarks">中国慈善家杂志（ID：cnscsj）</span></a><span class="text-remarks">，作者：郜晓文</span></p>  
</div>
            