
---
title: 'AI泡沫何去何从？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://picsum.photos/400/300?random=8418'
author: 虎嗅
comments: false
date: Tue, 03 Aug 2021 08:09:00 GMT
thumbnail: 'https://picsum.photos/400/300?random=8418'
---

<div>   
<p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/1IS6mceR2YL47MoiT-FfIg" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">观众席上的哈士奇（ID：gh_a045fdad01ce）</span></a><span class="text-remarks">，作者：草台班子，题图来自：视觉中国</span></p><p>字节跳动AI LAB总监李磊离职，加盟加州大学芭芭拉分校担任助理教授，有没有获得终身教职暂时还不知道。</p><p>前一个回归学术界的AI大佬是百度的吴恩达，他的学术内容是卖AI课程。随着AI从业人员的降薪、被裁，AI行业的泡沫也若隐若现。这个行业，似乎并不如看起来那么性感。</p><p>百度是中国AI界的黄埔军校。很大一部分叫得出名字来的AI独角兽创始人都是从百度出去的。一方面，这个行业的人才受到资本的追捧，能够很容易拿到一笔钱出来自立门户；另一方面也反映出，AI大规模应用短期很难落地，大公司没有在AI行业建立起足够的护城河和门槛，而在大公司里的AI从业人员短期内也很难实现商业化突破将公司给的激励机制变现。 </p><p>如果说移动互联网的开疆拓土是由苹果打响第一枪，然后资本快速跟进，必然中带着偶然；那么人工智能这个行业，从一开始就是资本刻意呵护培育的。说AI是一个“部分靠技术部分靠资本”堆砌起来的赛道也并不过分。那么AI是怎么被资本喂养却又一直长不大的呢？ </p><h3 label="大标题" class="text-big-title">一</h3><p>2008年以来的流动性宽松，让资本急需寻找爆发力强回报率高的行业。移动互联网撑起了金融危机之后头十年的高增速市场。但这还不够。</p><p>随着人口红利见顶，人们的大部分生活内容都已经由线下转至线上，移动互联网增速也日渐平缓，资本急需下一个高爆发力的赛道。</p><p>万物互联的时代之后是万物智能。只有人工智能能够撑得起资本的野心。</p><p>但是，尽管大把资本砸进去，行业的爆发点还远没有到来。虽然现在的AI赛道有一件件专利垒起来的城墙，但没有获得大规模应用的AI如无源之水无本之木。</p><p>大部分的AI公司目前都难以盈利。<strong>一方面，AI技术还处于高速发展阶段，即使有盈利，也需要将盈利再投资到研发中，研发费用居高不下。另一方面是，AI始终没有找到爆发性的应用场景。</strong></p><h3 label="大标题" class="text-big-title">二<br></h3><p>如果说AI应用分成三个层级，那么第一个层级是感知层面，让AI具备认知能力，能够识别外界的指令；第二个层级是决策层级，AI接受了指令之后能够出具方案。第三个层级是执行层级，AI能够将方案执行落地。</p><p>目前AI获得大规模应用的场景主要是语音识别，自然语言处理和视觉感知。这三个领域的代表性企业分别是科大讯飞、Open AI和海康威视。尽管这三个应用领域相对来说已经比较成熟，但它们其实只是涉及到了AI的感知层。真正核心的决策层技术还远没有到落地的时候。当然，不能否定AI发展到今天的成绩，视觉感知在安防应用方面，已经起到了非常重要的作用。 </p><p>AI在感知层面能够落地是有赖于海量的数据喂养。大量“可用数据”被分成“训练子集”和“测试子集”。通过“训练子集”让AI总结归纳数据的特点，通过“测试子集”来完善迭代AI识别的精确度。通过无数次反馈和迭代，一步一步让AI在感知层能够识别文字、语言、表情和物体。</p><p>但停留在感知层面的AI，很难带来生产力的大幅提升。感知层面的AI技术也并不如想象中的门槛那么高。这导致了今天AI赛道过于拥挤且变现困难。 </p><h3 label="大标题" class="text-big-title">三</h3><p>AI的另一个问题是，目前的AI并没有大家想象中智能。有一句话很有意思：AI消灭了多少旧的工作，就创造了多少新的工作。 </p><p>AI的监督训练需要海量数据。这些数据需要进行人工标注才能成为可用数据。数据标注这份工作枯燥且耗时，但在这个阶段，还真的没办法用机器取代人工标注。</p><p>之前科大讯飞还闹出AI翻译背后其实是人工翻译的闹剧。虽然这个后面已经被科大讯飞辟谣了，但是不能否认，有一些AI公司是披着AI的外衣，干着人工的活儿。</p><p>通用型AI还没有出现，那么专用型AI的发展程度又如何呢？<strong>其实即使是目前最先进的AI，离自然人都差距甚远。</strong>目前最先进的自然语言处理的标杆是Open AI的GPT-3。该系统有着1750亿个参数，已经能够自动生成人类可以理解的文本。尽管如此，GPT-3并不能理解真正意义上的写作，更多的是对人类自然语言的一种模仿。 </p><p>自然语言识别是神经网络训练的一大分支。据估算，人的大脑有约1000亿个神经元，能够形成100万-500万亿个突触连接。即使是海量参数如GPT-3，比起自然人的突触连接来看，也是千分之一的模拟突触数量。所以就算是在自然语言识别这一个细分领域，AI也远远没有达到人类的复杂程度。</p><h3 label="大标题" class="text-big-title">四<br></h3><p>目前的AI发展还有另外一个隐患。随着神经网络和深度学习的兴起，AI越来越依赖于从大数据中归纳相关性来学习，而不是从因果关系上学习。这就导致目前AI发展的另外一个困境：<strong>不可解释性</strong>。 </p><p>传统的AI算法是基于贝叶斯方程和决策树。这一类算法可追溯性强，注重因果关系，但是准确性不高。近年来大力发展的神经网络算法是基于模拟人脑的神经元网络，通过参数设置和数据喂养来提炼数据之间的相关性。这种方式虽然带来AI准确性的提升，但是却是黑盒操作，因果关系很难追溯，也就很难让人脑理解。正因为这种“不可解释性”，导致在很多涉及人身安全的领域，人类无法完全依赖于AI算法。</p><p><strong>AI还有一个落地的难点，就是数据的长尾效应。</strong>AI是基于大数据的喂养，但是大部分从现实生活中提炼的数据都会呈现类似正态分布，也就是大部分的数据其实是重复的。而长尾的数据，因为发生的频率低，很有可能采集不到。概率低风险高的事件也是导致一部分人工智能场景无法落地的重要原因，比如自动驾驶中的Corner Case。 </p><p>最后一个AI遇到的难题是AI技术的发展涉及面甚广。AI技术的发展涉及到AI芯片、云计算、底层操作系统等的协同发展。刚刚讲到，AI的数据需要大量人工标注，耗时耗力。但是即使解决了数据标注的问题，海量的运算也让目前的AI芯片算力出现瓶颈。摩尔定律接近极限让芯片性能难以再有突破。</p><p>不过也有好消息，在数据标注方面，特斯拉的Dojo可以减少人工标注数据的工作量，而英伟达的最新自动驾驶汽车芯片算力Drive Atlan可以达到1000TOPS，也就是每秒1000万亿次计算。 </p><h3 label="大标题" class="text-big-title">五</h3><p>过去十几年，资本的春天一直在滋养着AI的生态。但是万物都有周期，资本也是一样。在面对迟迟无法商业化，学术和技术无法变现的困境时，资本的耐心还能持续多久？</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/1IS6mceR2YL47MoiT-FfIg" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">观众席上的哈士奇（ID：gh_a045fdad01ce）</span></a><span class="text-remarks">，作者：草台班子</span></p>  
</div>
            