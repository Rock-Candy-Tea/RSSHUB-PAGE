
---
title: '这样发自拍，就不用再怕隐私泄露'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/cover/202105/09/163823375912.jpg?imageView2/1/w/1440/h/810/|imageMogr2/strip/interlace/1/quality/85/format/jpg'
author: 虎嗅
comments: false
date: Sun, 09 May 2021 08:38:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/cover/202105/09/163823375912.jpg?imageView2/1/w/1440/h/810/|imageMogr2/strip/interlace/1/quality/85/format/jpg'
---

<div>   
<img src="https://img.huxiucdn.com/article/cover/202105/09/163823375912.jpg?imageView2/1/w/1440/h/810/|imageMogr2/strip/interlace/1/quality/85/format/jpg" alt="这样发自拍，就不用再怕隐私泄露" data-v-30cd1b88 referrerpolicy="no-referrer"><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/2aKvoYLEUnANzZXJjgIzvA" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">品玩（ID：pinwancool）</span></a><span class="text-remarks">，作者：光谱 杜晨，原文标题：《这样发自拍，就不用再怕隐私泄露：5个技巧教你糊弄人脸追踪系统》</span></p><p>想象你注册了一个约会网站，上传了照片，没放太多的资料，避免不必要的隐私泄露。结果有无聊的人用你的照片去进行反向搜索，找到了你的全名、工作单位、教育经历，其它平台的账号等等……有了这些信息，他开始跟踪你，非常 creepy。</p><p>这并非你的错，但有什么自己能做的，可以避免类似的情况出现呢？</p><p>一家名叫 DoNotPay 的公司，最近推出了一项人脸反识别服务，叫做 Photo Ninja：在照片中肉眼不可察觉的地方进行像素级的修改，从而破坏掉人脸识别系统赖以工作的那些关键特征。最终的结果图片，就连 Google 这样的主流搜索引擎的图片搜索功能，都认不出来。</p><p>比如下面这张美国总统拜登的官方照片，一是做了镜像处理（左右对调），还在人脸上进行了更多微弱的处理。最终结果成功骗过了 Google，让它完全搜不出来图中人是谁，甚至找不到类似的照片结果。</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162021842083.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="663" data-h="512" src="https://img.huxiucdn.com/article/content/202105/09/162021842083.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>原图：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162023352018.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="938" src="https://img.huxiucdn.com/article/content/202105/09/162023352018.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>2015年，谷歌的AI研究员开发了一种全新的技术，能够在计算机视觉的算法层面对其进行“攻击”。</p><p>以物体为例，识别算法的工作方法，就是从非常细微的像素层面提取特征，总结出规律，才能识别物体。而如下图所示，只要在像素层面加入非常微弱的“噪点”，就能够达到攻击效果，导致神经网络输出完全不同的，错误的结果……</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162024120102.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="225" src="https://img.huxiucdn.com/article/content/202105/09/162024120102.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>这种技术名为对抗机器学习 (adversarial machine learning)，可以用于图像/物体和语音。今天我们介绍的 Photo Ninja，就是对抗机器学习的一种应用。</p><p>对抗机器学习概念的提出已经有相当长一段时间了，但随着技术的进步，在近几年的发展速度明显变快。刚才提到谷歌提出的攻击方式，在2015年成功击破了 GoogLeNet，而 GoogLeNet 前一年刚刚拿下 ImageNet 挑战赛的冠军……</p><p>技术没有好坏，但用技术的人有善恶之分。对抗机器学习也是一样，如果到了坏人手中，它可能会引发严重的后果。比如，坏人可以到马路上，“破坏” stop sign 等重要的交通指示牌，虽然不会影响到普通车辆和人类司机，但有可能严重干预自动驾驶系统的正常工作，导致交通事故的发生。</p><p>当然，至少在 Photo Ninja 案例中，对抗机器学习技术并没有被滥用。</p><p>硅星人的读者可能还记得我们之前写过 DoNotPay 这家公司。作为“Compound Startup”的代表，DoNotPay 只有一个手机app，却包含了上百种服务，主要都是帮用户省钱的，比如自动申诉交通罚单、切断自动续费服务、起诉电信诈骗、快速生成一次性信用卡、自动撰写各种法律文书等——堪称一个“掌上维权大师”app，资费只有$3/月。</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162025301984.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="418" src="https://img.huxiucdn.com/article/content/202105/09/162025301984.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>至于 Photo Ninja，该公司宣称，在面对亚马逊、微软、谷歌等主流公司开发的相关人脸识别系统时，这项照片反识别技术都能够取得大约99%的成功率。</p><p>当然，Photo Ninja 也并非没有势均力敌的对手。Clearview AI 是一家专注监控市场的 AI 公司，跟全美上千家执法部门都有合作。DoNotPay 的 CEO Joshua Browder 表示，Photo Ninja 没法保证能够骗过 Clearview AI 的技术。</p><p>这可能是由于，Clearview AI 早就从互联网的公开渠道抓取保存了超过30亿张的人脸照片，数据量之大，甚至超过美国政府和其它硅谷大公司的程度（该公司也因此饱受舆论争议。）</p><p>随着对抗机器学习技术的推进，攻击和防御的手段也都在进步。不排除有可能，该公司已经对照片进行过修改测试，开展过对抗攻击演练，然后进一步调整自己的识别算法——真是魔高一尺道高一丈啊！</p><p>去年，Clearview AI 自曝数据库被入侵，包含600多家客户的名单泄露。人们担心，拥有如此海量数据的一家监控公司，如果下一次整个图片数据库也失守，结果只会更加严重。</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162027623181.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="500" src="https://img.huxiucdn.com/article/content/202105/09/162027623181.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>回到文章开头所提出的那个情况。确实，这个年代想要安全地网上冲浪，简直有太多需要顾虑的东西了。那么，怎样才能继续发自拍，但又不用担心被不怀好意者嗅探隐私呢？以及，如果把范畴扩大到现实生活中，摄像头已经无处不在，还有什么办法，可以让我们至少在需要的时候，不被人脸识别系统抓到，保留最后的那一份隐私呢？</p><p>所幸，还有很多方法能够帮助我们避开人脸/图像识别系统，从软件/硬件思路出发的都有，而且成本并不算高。</p><p>去年，硅星人也有一篇文章简要介绍过几种能够让你在人脸识别系统里“隐形”的手段。今天，我们也可以分享更多的类似技术。</p><h3 label="大标题" class="text-big-title">“假脸” HyperFace</h3><p>2017年圣丹斯电影展上，一群女性开发者展示了一款能够骗过人脸识别系统的围巾。当然，围巾只是一个用于展示技术的原型产品，我们今天仅仅介绍这项技术。</p><p>在人脸识别算法“看来”，是有一种最理想化的人脸表达样式存在的（大概和下图差不多）：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162030664495.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="700" data-h="818" src="https://img.huxiucdn.com/article/content/202105/09/162030664495.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>而如果把这种样式变成图案，印制在围巾、帽子、上衣上，人脸识别系统就会过于关注这些图案，反而避开真实的人脸。如下面这张热力/显著图显示，高亮的区域是人脸识别系统最为关注的地方。</p><p>也就是说，HyperFace 的工作方式，是把人脸识别系统的注意力“带偏”。</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162031996232.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="509" src="https://img.huxiucdn.com/article/content/202105/09/162031996232.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>不过，仅就上面这个图案来说，它的有效性已经不是很高了，因为这个图案针对的是 OpenCV，而更新的人脸识别技术会采用卷积神经网络等更加复杂的算法，对应的图案也不一样，而且就算图案做出来了，效果也无法被保证。开发团队成员 Adam Harvey 也在项目网站上澄清，HyperFace 的原型图案已经过时。</p><p>但是，HyperFace 背后的技术思路还是行得通的。如果感兴趣的话，你可以自己找一些类似的图案，印在围巾上衣甚至口罩上试一试（毕竟疫情过后，一些人脸识别系统已经可以仅靠眼部露出的特征完成识别，口罩已经不能骗过它们了，甚至带着口罩都能解锁 iPhone。）</p><h3 label="大标题" class="text-big-title">“变脸” URME Surveillance</h3><p>很多人应该都看过吴宇森的《变脸》，剧情中 FBI 探员为了打入犯罪团伙内部，自愿和恐怖分子换脸，结果恐怖分子清醒后又抢走了探员的脸……</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162032017305.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="422" src="https://img.huxiucdn.com/article/content/202105/09/162032017305.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>这样的剧情在现实中不太可能出现。不过，一位艺术家 Leonardo Selvaggio 愿意把他的脸借给你，让你每天以他的身份招摇过市，让他来替代你承担隐私泄露的风险……</p><p>Selvaggio 对自己的脸进行了高精度扫描，然后生产出超高还原度的面罩，放到网上销售，价格$200。他把这个项目称为 URME（你就是我）</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162033108256.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="251" src="https://img.huxiucdn.com/article/content/202105/09/162033108256.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162034627739.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" data-w="400" data-h="400" src="https://img.huxiucdn.com/article/content/202105/09/162034627739.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>很遗憾，生产面罩的公司 ThatsMyFace 后来破产了，Selvaggio 还没有找到替代的生产商。不过与此同时，用户也可以下载脸图的平面版，自己打印出来戴上，只是看起来很假而已……</p><p>所以本质上讲，URME 并没有对人脸识别系统带来什么根本性的打击，只是用一个假身份去替代佩戴者的真实身份而已。</p><p>当然了，甭管黑猫白猫，能抓老鼠就是好猫……</p><h3 label="大标题" class="text-big-title">红外光</h3><p>前面我们提到，破坏掉人脸识别系统追踪的特征，就可以让这类系统失灵。和 Photo Ninja 低调的操作相比，红外光在破坏特征方面更加简单和暴力。</p><p>1）2018年，复旦、港中文、印第安纳大学和阿里巴巴共同发表了一项研究，在帽子上加装红外 LED，对着人脸，不仅能够骗过人脸识别系统——如果对 LED 灯的照明位置、方向进行细微的调整，从而扭曲佩戴者的面部特征，甚至还能让人脸识别系统以为佩戴者是其他人，如下图：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162036405110.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="716" data-h="537" src="https://img.huxiucdn.com/article/content/202105/09/162036405110.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>2）日本国立情报学研究所的一位教授，做了一个更加直接方案，把红外 LED 等直接放到眼镜上。LED 开启，人脸识别算法就无法将正确的区域识别为人脸了：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162038772339.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" data-w="400" data-h="225" src="https://img.huxiucdn.com/article/content/202105/09/162038772339.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>3）考虑到很多监控摄像头本身就在使用红外光进行照明，那么直接把眼镜的框架和镜片加入红外反射材料，会产生一个巨大的光斑，也能够达到反监控的效果。</p><p>Phantom 就是这样一款眼镜，由美国人 Scott Urban 制作并在 Kickstarter 上发布，售价$148，去年10月底已经发货。当你带着这副眼镜，其它人看到的你还是正常的样子：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162040528594.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="826" src="https://img.huxiucdn.com/article/content/202105/09/162040528594.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>然而在红外摄像头拍到的画面中，你看起来像神一样：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162041682715.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="423" src="https://img.huxiucdn.com/article/content/202105/09/162041682715.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><h3 label="大标题" class="text-big-title">“魔性”贴纸</h3><p>三位比利时科学家曾经做过一个有趣的实验：只是在身上加了一块怪异的贴图，在计算机的眼里，人就不再是人了：</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162042683998.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="627" data-h="456" src="https://img.huxiucdn.com/article/content/202105/09/162042683998.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>这个方法同样利用了本文前面提到的对抗机器学习，只是效果更肉眼可见而已。或者换一种说法：这个方法更好地解释了基于图片的对抗攻击方式的工作原理。出于某些原因，这些贴图会破坏了人形的特征，让识别系统无法正常工作。</p><figure><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/09/162043063212.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="750" data-h="517" src="https://img.huxiucdn.com/article/content/202105/09/162043063212.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p></figure><p>理论上，我们可以专门生产带有这类贴图印花的服装，穿上它走到监控摄像头面前，其实就跟隐形了一样……</p><p>综上所述，想要骗过人脸识别系统和无处不在的监控摄像头，还是有很多种途径的。只是，随着监控技术的不断进步和大规模推广，无论是在网上还是在现实中，想要完全保持”匿名“只会变得越来越难。</p><p>而就像本文一开始提的那个例子，在这样的环境中，那些监控技术滥用的受害者，并不一定是这些系统想要打击的坏人，反而更有可能是无辜者。</p>  
</div>
            