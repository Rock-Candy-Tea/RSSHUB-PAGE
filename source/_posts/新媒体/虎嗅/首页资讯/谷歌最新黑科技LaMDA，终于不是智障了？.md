
---
title: '谷歌最新黑科技LaMDA，终于不是智障了？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://www.huxiu.com/article/undefined'
author: 虎嗅
comments: false
date: Fri, 21 May 2021 11:40:00 GMT
thumbnail: 'https://www.huxiu.com/article/undefined'
---

<div>   
<img alt="谷歌最新黑科技LaMDA，终于不是智障了？" data-v-f85d0f0e src="https://www.huxiu.com/article/undefined" referrerpolicy="no-referrer"><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/FteWCcQ2c052bj2Bhl9H0w" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">腾讯研究院（ID：cyberlawrc）</span></a><span class="text-remarks">，作者：王焕超，原文标题：《谷歌最新黑科技LaMDA，能让你的语音助手不再智障吗？》，题图来自：视觉中国</span></p><p>到了今天，已经很少有人会把“智能语音助手”当回事，更多人把它看作是“智障”的同义词。</p><p>自苹果的Siri在2016年发布以来，相关技术一轮又一轮地革新，模仿者一个又一个地出现。但智能助手的智能化程度，并没有我们想象中提升得那么快。</p><p>不断失望之后，我们的要求也越来越低，除了让它帮忙订一个明早8:00的闹钟或打开某个App，已经别无他望。</p><p>最近热播的《爱，死亡和机器人》第2季，在第1集中也告诉了我们一个智障的语音助手会带来多严重的后果：在清洁机器人“发疯”并开始无差别攻击之后，女主人打电话给智能客服，不但没能解决任何问题，反而一直在添乱，最终靠人的力量才勉强逃出生天。啊，难道说，我们未来仍然要承受这么智障的语音助手吗？</p><p>好在事情出现了转机。美国时间2021年5月18日，一年一度的谷歌I/O大会如期而至。<strong>在一众产品和技术之间，LaMDA并不起眼，但它却可能是智障语音助手的拯救者。</strong></p><h3 label="大标题" class="text-big-title">一、LaMDA究竟是什么？</h3><h3 label="大标题" class="text-big-title"></h3><p>LaMDA的全称是LanguageModel for Dialogue Applications，简单而言，<strong>它是一种能力更强的语言模型，适用于对话应用程序。</strong></p><p>与前辈BERT、GPT-3一样，LaMDA也基于Transformer架构。后者是谷歌公司于2017年发布并开源的神经网络架构。利用该架构生成的模型，可以被训练阅读一组单词<span class="text-remarks" label="备注">（比如一句话或一个段落）</span>，并且关注这些单词之间的联系，然后预测接下来会是什么单词。<span class="text-remarks"><sup label="备注">[1]</sup></span>与其他模型不同的是，LaMDA在对话方面接受了更多训练。</p><p>在展开介绍之前，我们需要仔细想想，现有的语音助手为何如此“智障”？</p><p>智障的根本原因是技术能力不足，具体表现为“文不对题”——不能给我们想要的答案，这一点相对还好解决，只要加大训练量就能逐渐优化。<strong>但另一个更难以解决的问题是，语音智能助手只会孤立地理解我们提出的问题，并且孤立地给出答案。</strong>换句话说，你不能指望它联系上下文语境，跟我们进行长时间的“连续对话”。</p><p>要知道，我们在现实中的对话场景是完全开放性的，经常是从一个主题出发，延伸到另一个主题，最后在完全不相关的主题结束。比如，我们见到一个朋友，常常以“你吃饭了没？”打头，聊到前几天推出的一款新游戏，最后打算周末约一场电影。</p><p><strong>现实对话的开放性特征，使之成为机器学习领域最难解决的问题之一。</strong>它涉及到一项很重要的能力，即自然语言理解<span class="text-remarks" label="备注">（NLU）</span>，要求AI能够进行语义语境情感的判断，这是比自然语言处理<span class="text-remarks" label="备注">（NLP）</span>还要复杂的能力。</p><p>而现在大多数智能助手，往往按照狭窄的、预先定义好的对话路径被设计，并不能进行开放对话、连续对话。这就是它们看起来还相当智障的原因。</p><p>而LaMDA就针对这一问题进行了技术突破。LaMDA基于谷歌2020年的一项研究<sup><span class="text-remarks" label="备注">[2]</span></sup>，这项研究显示，基于Transformer架构的语言模型在经过对话训练后，能够谈论几乎所有话题。</p><p>在训练的过程中，LaMDA发现了开放式对话与其他形式语言的细微差别。它最为核心的，就是进行“开放域”<span class="text-remarks" label="备注">（Open Domain）</span>对话的能力。而这项能力的重要依托，就是相比于现有的对话模型，LaMDA更能理解对话的语境。它可以通过阅读句子或段落来“破译”对话意图，发现单词之间的关联，并能预测接下来可能出现的单词，从而做出合乎语境的回答。</p><p label="正文" class="text-normal">在这样的能力支撑下，LaMDA能够和人在无穷无尽的话题转换中聊下去，进行长时间的开放性对话。用谷歌官方的话来形容，就是<strong>“能够用自由流动的方式，谈论无穷无尽的主题”。</strong></p><h3 label="大标题" class="text-big-title">二、从“冥王星”到“纸飞机”</h3><p>在本次谷歌I/O大会上，LaMDA充分展示了强悍的对话能力。<span class="text-remarks"><sup label="备注">[3]</sup></span>演示环节中，LaMDA扮演了冥王星的角色，与用户进行对话。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/21/182249752674.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="562" src="https://img.huxiucdn.com/article/content/202105/21/182249752674.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>在示例场景中，LaMDA能够根据用户的提问作出精准回答，而且还能够将一个主题，引向另一个主题，不断推进对话。这种主题的过渡并不突兀，显得自然而合理。</p><p>当被问到：“你希望大家了解你的哪一面？”</p><p>它这样回答：“我希望人们知道我不仅仅是一颗随机的冰球<span class="text-remarks" label="备注">（random ice ball）</span>，我实际上是一个美丽的星球。”</p><p>对于“冥王星之前是否有过到访者”的问题，LaMDA也能给出准确的答案。它甚至还贴心地提醒用户，如果要访问冥王星，需要带上大衣，因为它非常冷。</p><p>这种对话给人的感觉，就像是在和一个知识渊博的朋友聊天。虽然话题天花乱坠、不断涌现，但LaMDA总能接住话茬，并且自然而然地展开对话。</p><p>在另一个演示中，LaMDA也展现了高超的对话能力。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202105/21/182251707279.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="558" src="https://img.huxiucdn.com/article/content/202105/21/182251707279.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>在这个演示中，LaMDA扮演的角色是一架纸飞机。当用户问，你曾经最糟糕的着陆地点是什么？它回答说：“可能是一个小水洼<span class="text-remarks" label="备注">（puddle）</span>。”</p><p>当被用户问到：“一架真正好的纸飞机的秘诀是什么？”</p><p>它主动追问用户：<strong>“‘好’是什么意思？”</strong>，体现了足够的灵活和机敏。</p><p>用户回答：“我关心距离<span class="text-remarks" label="备注">（distance）</span>。”LaMDA进而围绕“如何优化纸飞机的飞行距离”这一话题，分享了相关知识。</p><p>要知道，LaMDA的这些回复都不是预先设定的，而是自然生成的。这也就意味着，LaMDA不必再经过专门的训练才能进行另一次对话，也不会作出重复的回答。这样的能力确实令人惊奇。</p><p>这两个示例中，仅凭寥寥几语就能看出LaMDA使问题应答更有意义了，而这就是理解对话语境能力带来的结果。在这样的能力辅助下，LaMDA表现得相当理智和机敏。</p><p>谷歌公司也表示，理智和特异性并不是LaMDA所追求的唯一品质。他们还注重洞察力、幽默感等能力。与此同时，谷歌也非常关注事实性问题，也就是LaMDA的回答是否符合事实。<span class="text-remarks"><sup label="备注">[4]</sup></span><strong>毕竟对于一个语音助手来说，有趣很重要，正确更重要。</strong></p><h3 label="大标题" class="text-big-title">三、LaMDA的前路仍然遥远</h3><p>无论是更先进的AI还是更智能的聊天机器人，谷歌在过去几年一直在着力促进AI如何更好地与人类沟通。</p><p>皮查伊在演讲中提到，<strong>语言的丰富性和灵活性正在使其成为人类最伟大的工具之一，同时，它也成为计算科学的最大挑战之一。</strong>虽然现在LaMDA可以根据对话语境提供建议和答案，让对话不违和地进行下去，但它仍在研发初期，想要达到AI助手的功能，还需要时间的磨合。</p><p>问题是，提升AI助手的对话能力，究竟有什么意义？至少对于谷歌而言，这项能力作用重大，因为谷歌的很多重要产品都与信息检索有关，它们都基于对计算语言的解读，无论是翻译能力，还是对用户检索信息的理解。如果谷歌能让AI更好地理解语言，那么它就能改进相关的核心产品，比如Google Search、Assistant和Workspace。<strong>“它甚至可以将搜索变成对话，更自然流畅。”</strong>皮查伊如是说。</p><p>当然也不单单是对谷歌一家公司，对话能力的进步突破，无疑会给所有涉及到人机对话的领域带来全新想象力。</p><p>但语言的丰富性、灵活性以及随之伴生的复杂性，无疑使这项工作成为极大的挑战。可以说，面对这样一个困难领域，LaMDA的能力还称不上成熟。在现实运行中，它仍可能出错，给出荒谬的回应。</p><p>比如，在扮演冥王星的演示案例中，它就说到自己跳得很高<span class="text-remarks" label="备注">（jump really high）</span>，经常练习翻转动作，并且很乐于用它最喜欢的球——月球来玩接球游戏。这些回答显然是违背常识的。</p><p>除此之外，作为语言模型，LaMDA也无可避免地面临一些AI的老问题。比如它可能会被滥用或者传播偏见。算法偏见是个极为复杂的问题，既可能源于算法结构设计，也可能是训练数据集的问题，它的本质是社会偏见在算法层面的延伸。</p><p>如谷歌所言，<strong>“语言可能是人类最伟大的工具之一，但像所有工具一样，它可能会被滥用。接受语言训练的模型可能传播这种滥用行为——例如，通过内化偏见、反映仇恨言论或复制误导性信息。即使它所训练的语言经过仔细审查，模型本身仍然可能不被善用。”<span class="text-remarks"><sup label="备注">[5]</sup></span></strong></p><p>当然，LaMDA还会面临许多意想不到的现实风险。比如被违法犯罪分子用于网络欺诈，类似的新闻已经屡见不鲜。更仿真的对话能力，也就意味着更强大的欺诈能力。</p><p>即便在技术层面，LaMDA也有更大的优化空间。目前，LaMDA主要是围绕文本对话进行构建的，在未来，LaMDA可能会兼容其他的媒介形态，包括图像、音频、视频等等。这可以寄希望于同在本次大会发布的MUM<span class="text-remarks" label="备注">（多任务统一模型）</span>，未来人机交互手段或许会因这两项技术而出现革命性的变化。</p><p>LaMDA的具体作用如何，还待进一步观察，毕竟Google之前有过黑历史<span class="text-remarks" label="备注">（2017年，Google发布了餐厅订位服务AI Duplex，后来被发现背后有真人帮忙完成<sup>[6]</sup>）</span>。不过，人们和AI进行更自然、开放的对话，相信已经不再遥远了。</p><p><span class="text-remarks" label="备注">参考资料：</span></p><p><span class="text-remarks">1. https://www.blog.google/technology/ai/lamda</span></p><p><span class="text-remarks">2. https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html</span></p><p><span class="text-remarks">3. https://www.youtube.com/watch?v=aUSSfo5nCdM</span></p><p><span class="text-remarks">4. https://www.blog.google/technology/ai/lamda</span></p><p><span class="text-remarks">5. https://www.blog.google/technology/ai/lamda</span></p><p><span class="text-remarks">6.  https://wallstreetcn.com/articles/3567850</span></p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/FteWCcQ2c052bj2Bhl9H0w" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">腾讯研究院（ID：cyberlawrc）</span></a><span class="text-remarks">，作者：王焕超</span></p>  
</div>
            