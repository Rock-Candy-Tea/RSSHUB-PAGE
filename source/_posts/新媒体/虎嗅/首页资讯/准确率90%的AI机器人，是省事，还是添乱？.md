
---
title: '准确率90%的AI机器人，是省事，还是添乱？'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://www.huxiu.com/article/undefined'
author: 虎嗅
comments: false
date: Mon, 21 Jun 2021 02:45:00 GMT
thumbnail: 'https://www.huxiu.com/article/undefined'
---

<div>   
<img alt="准确率90%的AI机器人，是省事，还是添乱？" data-v-ea68b0d0 src="https://www.huxiu.com/article/undefined" referrerpolicy="no-referrer"><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/ogzArH5Bhe5mFQl1eJl0kw" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">高山书院（ID：gasadaxue）</span></a><span class="text-remarks">，内容根据Pieter Abbeel于2020年9月24~25日在“GMIC 在线 Pro”的演讲内容节选整理而成，作者：Pieter Abbeel（加州大学伯克利分校机器人学习实验室主任，人工智能实验室联合主任、covariant.ai 和 Gradescope 联合创始人），头图来自：《西部世界》剧照</span></p><p>说到机器人和自动化，很多人脑里可能会立刻浮现一些生产线，比如汽车工厂的情景——一群机器人既高效又精确地执行任务，一天到晚不知疲倦，表现惊人。</p><p>但若仔细一想，本质上，这些传统机器人只是在重复一遍又一遍相同的动作。而事实是，现实世界中的绝大部分任务，都要求我们对眼前的情况做出即时的调整。</p><p><strong>一个能超越重复性、根据情况调整和思考的机器人，什么时候能够面世?</strong></p><h3 label="大标题" class="text-big-title">AI机器人何时才能出现？</h3><p>对这个问题，很多科幻电影都做出了回应。</p><p>《未来战士》中，这些AI机器人来自未来，《西部世界》则遐想了它们将悄悄出现在我们身边。这些想象衍生出了一连串人工智能可能出现的未来场景，有的骇人听闻，有的振奋人心。</p><p>但从现实技术的层面来说，它未来的切入点究竟在哪里？实际上，它已经发生了——<strong>人工智能机器人已经不动声色地进入了人类世界，并创造了价值。</strong></p><p>那就是<strong>自主拣货。</strong></p><p>几年前，这还是天方夜谭；但2020年1月，《纽约时报》就报道了由Covariant Brain公司制造的Knapp pick-it-easy机器人，静悄悄地在某个低调的仓库中，自主分拣订单。</p><p>相对于传统机器人，pick-it-easy面对的，是不断在流水线中运转的，超过6万种的林林总总的货物。它过去从未见过这些货物，未来也会持续地见到其他新的货物及组合——无论面前是什么，它需要反复识别，并一再调整自己的动作，做出决策——从哪提取、到哪卸放。</p><p><video src="https://video.huxiucdn.com/mda-mfke3hdv1wq9i0ry/mda-mfke3hdv1wq9i0ry.mp4" poster="https://v2-img.huxiucdn.com/mda-mfke3hdv1wq9i0ry/mda-mfke3hdv1wq9i0ry.jpg" controls="controls" width="100%">您目前设备暂不支持播放</video><br></p><p>这是史上第一宗AI机器人的实例报导，一段长达一小时、连续无删减的视频，真实完整的向世人完整展示了机器人的运作流程：遇到什么问题，并如何调整。</p><p>AI机器人的自动化，不但已经发生，而且越来越重要。默默工作的过程中，它们正持续地累积经验，从经验中自我学习，一步步完善化。未来，我们将从沉闷的仓库，拓展出更多闪亮的应用场景。</p><h3 label="大标题" class="text-big-title">为什么AI机器人很难做？</h3><p>这样的机器人，技术难点究竟在哪里？</p><p label="小标题" class="text-sm-title">第一，识别</p><p>这个过程的程序要怎么写？并不是我们想象的那么简单，因为机器不认识图片或文字，只能识别数字。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/21/092712904751.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="334" data-h="251" src="https://img.huxiucdn.com/article/content/202106/21/092712904751.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">（计算机将图片像素转化为数字）<br></p><p>几十年来，计算机视觉领域通过视觉技术尝试让机器了解图像中的内容，但都没有成功。直到2012年，多伦多大学Geoffrey Hinton团队向世界展示了能以高准确度识别图像的机器。</p><p>那他们是怎么办到的呢？方法就是简单粗暴地问机器：图像里有什么。他们把问题分解成一系列的计算，最后导出图像中的内容。这一系列的计算，就是深度神经网络<span class="text-remarks" label="备注">（Deep Neural Network；DNN）</span>。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/21/092717477065.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="893" data-h="518" src="https://img.huxiucdn.com/article/content/202106/21/092717477065.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>神经网络由非常多的人造神经元组成。单独来看，每个神经元都做着简单的工作：接收信号、生成信号、输出信号，但合在一起，它们可以完成非常复杂、高阶的反应。</p><p>至于这些反应是什么，取决于这些神经元如何连结，以及连结有多强，尤其后者。随着这些神经元连接强度的不同变化，系统会做出不同的决定：“这是猫、狗、人或车……”</p><p>这样一来，识别图像的问题，就从“计算机视觉的分辨问题”，简化成了“神经元连接强度的调整问题”。但直接手动调整是不可行的，因为当中涉及了数以百万计的神经元需要调整。</p><p>那我们要怎样找到正确的设置？——给神经网络“投喂”足够多的例子，让它在猜测中学习。</p><p>一开始的猜测固然完全随机，但随着每一次失败，系统往回追溯，修改神经元之间的权重<span class="text-remarks" label="备注">（连结强度）</span>，把系统一步步推向正确的结果。周而复始，最后神奇的事发生了，机器能分辨出图像中的内容了。</p><p>在这个方法下，机器分辨得有多好？</p><p>在图像识别领域里，曾有个ImageNet国际挑战赛，2010年，最佳成绩约28%误差率，2011年也基本维持在相同水平线上，没有太大突破。2012年，Geoffrey采取了深度神经网络，将误差率一举降低到约15%，向前迈进了一大步。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/21/092719597519.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="734" src="https://img.huxiucdn.com/article/content/202106/21/092719597519.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">（从2010~2016年，各算法在图像识别的错误率）<br></p><p>随后几年，人们在神经网络的基础上进行修改，机器的误差率逐年下降，甚至超越了人类。如今，这个比赛已经彻底退出了历史舞台。</p><p label="小标题" class="text-sm-title">第二，行动</p><p>机器不但需要识别，还需要行动。如何让系统做出正确的行动决策？</p><p>2015年，DeepMind攻克了围棋，打败了世界冠军棋手。本来人们还以为这需要数十年的时间，但一夜之间就实现了。</p><p>DeepMind编了一个神经网络，自己和自己下棋——为求简化，这里说的是2017年的版本，AlphaGoZero——在每一盘自我对弈中摸索、试错、学习，越变越好，最后战胜棋手。</p><p>不单是围棋，其他游戏也被机器用同样的方式攻克了。</p><p>和识别不同的是，识别是单一步骤的事情，我们让系统去判断一张图是狗还是其他动物；而行动则不一样，你并没有告诉系统每一步该做什么。它只知道最后的结果是赢或输，然后从结果中自我改善。</p><p>具体来说，他们在赢<span class="text-remarks" label="备注">（或输）</span>的局面中找出共同点，在赢和输之间揪出差异，把它们分解出来。这就是强化学习<span class="text-remarks" label="备注">（Reinforcement Learning；RL）</span>。</p><p>而深度强化学习，是在强化学习模式下搭配一个神经网络吸收经验，根据每一段经验改变神经元的权重。</p><p>显然，除了棋牌和游戏，这个原理也适用于机器操作。</p><p>加利福尼亚大学伯克利分校通过类似的神经网络，编写了一个虚拟机器人，最开始半步都跨不出，后来踉踉跄跄，一直自我训练到能维持长时间奔跑的状态。我第一次看见的时候，心里激动不已。</p><p><video src="https://video.huxiucdn.com/mda-mfke3pziqsvnwwc8/mda-mfke3pziqsvnwwc8.mp4" poster="https://v2-img.huxiucdn.com/mda-mfke3pziqsvnwwc8/mda-mfke3pziqsvnwwc8.jpg" controls="controls" width="100%">您目前设备暂不支持播放</video><br></p><p>值得一提的是，这个程序可以重复在别的场合使用，即便是不一样的机器人、不一样的任务。事实上，加利福尼亚大学伯克利分校在这个实验中就赋能了机器人一系列的任务，比如翻跟斗、跨越障碍、高处跳落等等。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/21/092727907932.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" data-w="800" data-h="299" src="https://img.huxiucdn.com/article/content/202106/21/092727907932.gif?imageView2/2/w/1000/format/gif/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>接着，他们将这个虚拟程序安装到实际的机器人上，由此制造出机器人BRETT，让它将积木放到匹配的空位当中。要完成这项任务，它需要学习视觉识别系统，以及行为控制系统。</p><p>一开始，它完全不知道该怎么做，但随着每一次偶尔的成功，系统内不断进行强化，最终达到了能可靠完成任务的水平。</p><p><strong>如果能搭配一个机器人舰队，一起学习、共享神经网络，这个过程还能变得更简单、更快速。</strong></p><h3 label="大标题" class="text-big-title">AI机器人为什么还没普及？</h3><p>看起来，这一切已经万事俱备，只要把研究的成功复刻到现实，一切就会很完美。但直到今天，AI机器人依旧没有普及，差的东风在哪里？</p><p>值得注意的是，上述的成功都发生在虚拟或实验室的研究场景，而并非现实应用。</p><p>在实验室的研究中，研究人员专注的是从无到有、从0到1的过程，做一些过去没做过的事，对精准度的要求不高，往往是达到70%就会转到下一个指标。</p><p>但在现实中，我们对可靠性的要求完全不是一个等级。很多时候，精准度到90%都不足够。</p><p>以一个工厂实际场景为例，一个机器人每小时负责500~2000个任务，90%的准确率意味着每小时有50~200个需要修正的错漏。一般而言，修正比任务本身所花费的功夫还更大；换句话说，<strong>在90%准确率下，机器人带来的麻烦比省下的时间还多。</strong></p><p>就现实而言，机器人真正价值的体现，是当它们每小时只需要人类1~2次的干预；如此一来，人类就可以同时监督多处的多个机器人。这就意味着如果一个机器人负责500个任务，准确率必须在99.6以上；如果负责2000个任务，准确率则必须在99.9以上。</p><p>可见，这是和实验室的研究场景迥然不同的要求。</p><p>这时，有些人可能会想：这还不容易，建更大的神经网络、提供更多的经验数据，不断重复，不就行了？</p><p>如果是识别图像、识别字符之类的任务，这思路是可行的，因为任务本身比较单一，搜取更多的数据去提高精准度是可以办到的。但现实中我们希望让机器人处理的场景，比这些任务多更多的额外细节需要处理。</p><p><strong>首先，系统不能够忽视世界的长尾效应。</strong>我们身处的世界，是一个高变化、大方差的环境。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202106/21/092732344958.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="741" data-h="486" src="https://img.huxiucdn.com/article/content/202106/21/092732344958.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>在ImageNet识别测验里，系统仅仅是分辨一千个图；但在现实世界中，系统有百万、千万种物品需要辨识，同时还存在着程度不一的透明及反光视效，有些则极其凌乱，和不同的物体视觉混杂在一起等等。</p><p><strong>其次，系统不能够忽视世界的动态本质。</strong></p><p>学会奔跑的加利福尼亚大学伯克利分校的虚拟机器人，它的环境设定是不变的；可是现实世界，比如在一个货仓里，人来人去，每个人卸包裹、拆包裹的方式、位置都持续在变化。现实经常处于一个高速的动态环境中，而远不像机器训练时的静态环境。</p><p><strong>另外，系统不能够忽视自己的无知时刻。</strong></p><p>当系统遇到它不知道或不确定的情况，它必须知道自己不知道，转而求助于备份方案，比如交由其他熟悉的人处理等，而不是强行做出某个决策。</p><h3 label="大标题" class="text-big-title">AI机器人下一个应用场景在哪？</h3><p>无人机、自动驾驶、机械手，谁更有可能成为下一个实现的梦境？表面看来，无人机似乎最难，因为人类不会飞——但事实恰好相反。</p><p>无人机面对的场景相对简单，因为本质上它只是在空旷的空间里穿梭，直到到达某个目的地。当然，它也会遇到一些突发状况，比如附近出现一些移动物体，导致它忽然处于一个复杂的动态环境。但以实际的应用场景来说，真正的难点还是在于政府对领空的管辖，以及硬件质量的配合，而不是在于更聪明的人工智能。</p><p>至于自动驾驶和机械手，单从技术层面看，自动驾驶其实更简单。因为驾驶最主要的在于闪避危险，无需和环境互动；而机械手则需要接触物体，和物件进行互动，这又增加了一个维度的复杂性。</p><p>然而，从犯错代价的角度，自动驾驶一旦出现失误，最坏的情况可能是丢了性命，而在快递领域，失误顶多意味着送错或送不到。机械手也是类似，至少不是性命攸关。</p><p>所以，自动驾驶虽然是现在万众瞩目、众望所归的领域，我相信不会是第一波人工智能机器人付诸实现的应用场景。</p><p>总的来说，2020年，是人工智能机器人的元年——你或许还没看见，但它已经在仓库里无声启动。</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/ogzArH5Bhe5mFQl1eJl0kw" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">高山书院（ID：gasadaxue）</span></a><span class="text-remarks">，内容根据Pieter Abbeel于2020年9月24~25日在“GMIC 在线 Pro”的演讲内容节选整理而成，作者：Pieter Abbeel（加州大学伯克利分校机器人学习实验室主任，人工智能实验室联合主任、covariant.ai 和 Gradescope 联合创始人）</span></p>  
</div>
            