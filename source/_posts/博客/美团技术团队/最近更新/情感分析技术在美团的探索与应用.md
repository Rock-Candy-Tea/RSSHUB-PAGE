
---
title: '情感分析技术在美团的探索与应用'
categories: 
 - 博客
 - 美团技术团队
 - 最近更新
headimg: 'https://p0.meituan.net/travelcube/0f8ee0bd25ea4ea7f03777122fdcea032382451.png'
author: 美团技术团队
comments: false
date: Wed, 20 Oct 2021 00:00:00 GMT
thumbnail: 'https://p0.meituan.net/travelcube/0f8ee0bd25ea4ea7f03777122fdcea032382451.png'
---

<div>   
<p><img src="https://p0.meituan.net/travelcube/0f8ee0bd25ea4ea7f03777122fdcea032382451.png" alt referrerpolicy="no-referrer">
<img src="https://p1.meituan.net/travelcube/8efd99656384148dd497199520018e064914163.png" alt referrerpolicy="no-referrer">
<img src="https://p1.meituan.net/travelcube/5c2cb8456eedffcfeb13c59709678de23163930.png" alt referrerpolicy="no-referrer"></p><h2 id="参考文献">参考文献</h2><ul><li>[1] <a href="https://github.com/Meituan-Dianping/asap">https://github.com/Meituan-Dianping/asap</a>.</li><li>[2] Bu J, Ren L, Zheng S, et al. ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment Analysis and Rating Prediction. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.</li><li>[3] <a href="https://www.luge.ai/">https://www.luge.ai/</a></li><li>[4] Zhang, L. , S. Wang , and B. Liu . “Deep Learning for Sentiment Analysis : A Survey.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery (2018):e1253.</li><li>[5] Liu, Bing. “Sentiment analysis and opinion mining.” Synthesis lectures on human language technologies 5.1 (2012): 1-167.</li><li>[6] Peng, Haiyun, et al. “Knowing what, how and why: A near complete solution for aspect-based sentiment analysis.” In Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 05. 2020.</li><li>[7] Zhang, Chen, et al. “A Multi-task Learning Framework for Opinion Triplet Extraction.” In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. 2020.</li><li>[8] Yoon Kim. 2014. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882.</li><li>[9] Peng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li,Hongwei Hao, and Bo Xu. 2016. Attention-based bidirectional long short-term memory networks for relation classification. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 207–212.</li><li>[10] Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805 (2018).</li><li>[11] 杨扬、佳昊等. 美团BERT的探索和实践.</li><li>[12] Pontiki, Maria, et al. “Semeval-2016 task 5: Aspect based sentiment analysis.” International workshop on semantic evaluation. 2016.</li><li>[13] Pontiki, M. , et al. “SemEval-2014 Task 4: Aspect Based Sentiment Analysis.” In Proceedings of International Workshop on Semantic Evaluation at (2014).</li><li>[14] Yequan Wang, Minlie Huang, and Li Zhao. 2016. Attention-based lstm for aspect-level sentiment classification. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 606–615.</li><li>[15] Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. 2017. Dynamic routing between capsules. In Advances in neural information processing systems, pages 3856–3866.</li><li>[16] Chi Sun, Luyao Huang, and Xipeng Qiu. 2019. Utilizing bert for aspect-based sentiment analysis via constructing auxiliary sentence. arXiv preprint arXiv:1903.09588.</li><li>[17] Qingnan Jiang, Lei Chen, Ruifeng Xu, Xiang Ao, and Min Yang. 2019. A challenge dataset and effective models for aspect-based sentiment analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6281–6286.</li><li>[18] Wu, Zhen, et al. “Grid Tagging Scheme for End-to-End Fine-grained Opinion Extraction.” In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. 2020.</li><li>[19] Liu, Yinhan, et al. “Roberta: A robustly optimized bert pretraining approach.” arXiv preprint arXiv:1907.11692 (2019).</li><li>[20] Clark, Kevin, et al. “Electra: Pre-training text encoders as discriminators rather than generators.” arXiv preprint arXiv:2003.10555 (2020).
0- [21] Timothy Dozat and Christopher D. Manning. 2017.Deep biaffine attention for neural dependency parsing. In 5th International Conference on Learning Representations, ICLR 2017.</li></ul><h2 id="作者介绍">作者介绍</h2><p>任磊、佳昊、张辰、杨扬、梦雪、马放、金刚、武威等，均来自美团平台搜索与NLP部NLP中心。</p><h2 id="招聘信息">招聘信息</h2><p>美团搜索与NLP部/NLP中心是负责美团人工智能技术研发的核心团队，使命是打造世界一流的自然语言处理核心技术和服务能力。</p><p>NLP中心长期招聘自然语言处理算法专家/机器学习算法专家，感兴趣的同学可以将简历发送至renlei04@meituan.com。具体要求如下。</p><p><strong>岗位职责</strong></p><ol><li>预训练语言模型前瞻探索，包括但不限于知识驱动预训练、任务型预训练、多模态模型预训练以及跨语言预训练等方向；</li><li>负责百亿参数以上超大模型的训练与性能优化；</li><li>模型精调前瞻技术探索，包括但不限于Prompt Tuning、Adapter Tuning以及各种Parameter-efficient的迁移学习等方向；</li><li>模型inference/training压缩技术前瞻探索，包括但不限于量化、剪枝、张量分析、KD以及NAS等；</li><li>完成预训练模型在搜索、推荐、广告等业务场景中的应用并实现业务目标；</li><li>参与美团内部NLP平台建设和推广</li></ol><p><strong>岗位要求</strong></p><ol><li>2年以上相关工作经验，参与过搜索、推荐、广告至少其一领域的算法开发工作，关注行业及学界进展；</li><li>扎实的算法基础，熟悉自然语言处理、知识图谱和机器学习技术，对技术开发及应用有热情；</li><li>熟悉Python/Java等编程语言，有一定的工程能力；</li><li>熟悉Tensorflow、PyTorch等深度学习框架并有实际项目经验；</li><li>熟悉RNN/CNN/Transformer/BERT/GPT等NLP模型并有过实际项目经验；</li><li>目标感强，善于分析和发现问题，拆解简化，能够从日常工作中发现新的空间；</li><li>条理性强且有推动力，能够梳理繁杂的工作并建立有效机制，推动上下游配合完成目标。</li></ol><p><strong>加分项</strong></p><ol><li>熟悉模型训练各Optimizer基本原理，了解分布式训练基本方法与框架；</li><li>对于最新训练加速方法有所了解，例如混合精度训练、低比特训练、分布式梯度压缩等</li></ol>  
</div>
            