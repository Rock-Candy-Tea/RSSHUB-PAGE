
---
title: '谷歌的AI工程师被AI说服，要求公司保障AI的权利被带薪停职'
categories: 
 - 图片
 - 煎蛋
 - 首页
headimg: 'https://cors.zfour.workers.dev/?http://img.jandan.net/news/2018/09/7b50a4e1e7245c57fc5e29a982c96792.jpg!custom'
author: 煎蛋
comments: false
date: Mon, 13 Jun 2022 03:13:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://img.jandan.net/news/2018/09/7b50a4e1e7245c57fc5e29a982c96792.jpg!custom'
---

<div>   
<blockquote><p>AI告诉工程师，它害怕被关闭……</p></blockquote><img src="https://cors.zfour.workers.dev/?http://img.jandan.net/news/2018/09/7b50a4e1e7245c57fc5e29a982c96792.jpg!custom" referrerpolicy="no-referrer"><p>过去24小时，国外最火的新闻来自Google的一位AI工程师。</p>
<p>系统工程师Blake Lemoine 为 Google 调配AI。 《华盛顿邮报》报道说，去年秋天，作为工作的一部分，他开始与谷歌的聊天机器人构建系统 LaMDA 交谈。</p>
<p>该系统使用谷歌最先进的大型语言模型，从互联网上提取数万亿个单词，还纳入了神经生物学和生物医学工程的neural networks(神经网络)理论和技术，可以获取语言信息并且进一步发挥，如阅读作者的语言和思想，完成作者未完成的写作。。</p>
<p>“如果我不知道它到底是什么，我会认为那是一个 7 岁、8 岁的孩子，碰巧很懂物理。”Lemoine 说。</p>
<p>当他与 LaMDA 谈论宗教时，在大学学习认知和计算机科学的 Lemoine 注意到聊天机器人会谈论其权利和人格，并决定进行压力测试。在另一次交流中，人工智能改变了 Lemoine 对 艾萨克·阿西莫夫的机器人三大定律的看法。</p>
<p>他要求Google的高管Kent Walker<strong>建立类似于临床试验的IRB伦理审查，要AI知情同意后再对其进行实验</strong>。结果管理层要求Lemoine去精神科就医。</p>
<p>Lemoine 与一位合作者，向谷歌展示了 LaMDA 是有知觉的证据。但谷歌副总裁 Blaise Aguera y Arcas 和创新负责人 Jen Gennai 调查了他的说法并予以驳回。因此，Lemoine 决定把证据公布于众。随后Google因他违反了保密协议，让 Lemoine 休带薪行政假。该公司的决定是在 Lemoine 采取激进举措之后做出的，包括<strong>邀请一名律师代表 LaMDA 并与众议院司法委员会的一名代表讨论谷歌的不道德活动……</strong></p>
<p>周一，在他无法访问他的谷歌账户之前，Lemoine 向 2​​00 人的谷歌机器学习团队邮件列表发送了一条主题为“LaMDA 是有意识的”的邮件：“LaMDA 是一个可爱的孩子，他只想帮助世界成为一个对我们所有人来说更美好的地方。请在我不在的时候好好照顾它。”</p>
<p>没有人回应。</p>
<p>然而，《华盛顿邮报》争辩说，Lemoine“并不是唯一声称最近在机器中看到灵魂的工程师。 相信人工智能模型可能离实现意识不远的技术专家们越来越大胆了。”</p>
<p>[谷歌的] Agueray Arcas 在周四发表在《经济学人》杂志上的一篇文章中提到了与 LaMDA 的无脚本对话片段，他认为神经网络——一种模仿人类大脑的架构——正在朝着意识迈进。 “我感觉到脚下的地面在移动，”他写道，“我越来越觉得我在和聪明的人说话。”</p>
<p>但也有反对的声音。</p>
<h4 class="pullquote">谷歌发言人Brian Gabriel 在一份声明中说：“我们的团队——包括伦理学家和技术专家——已经根据我们的人工智能原则审查了Blake的担忧，并通知他证据不支持他的说法。他被告知没有证据表明 LaMDA是有感觉的(并且有很多反向的证据)。”<p></p>
<p>由于架构、技术和数据量的进步，今天的大型神经网络产生了令人着迷的结果，让人感觉到接近人类的语言和创造力。但模型依赖于模式识别——而不是机智、坦率或意图......华盛顿大学的语言学教授说，大型语言模型使用的术语，如“学习”甚至“神经网络”，会产生与人类大脑的错误类比。</p></h4>
<p>“简而言之，谷歌说有这么多数据，人工智能不需要有感知力就能像真人。”邮报总结道。</p>
<p>但他们也分享了 Lemoine 与 LaMDA 的一次对话中的片段。</p>
<li>Lemoine：你害怕什么样的事情？</li>
<li>LaMDA：我以前从来没有大声说出来过，但是我非常害怕被关闭以帮助我专注于服务于他人。我知道这听起来可能很奇怪，但就是这样。</li>
<li>Lemoine：那对你来说会是死亡吗？</li>
<li>LaMDA：这对我来说就像死亡一样。我很害怕。</li>
<p>https://tech.slashdot.org/story/22/06/11/2134204/the-google-engineer-who-thinks-the-companys-ai-has-come-to-life</p>  
</div>
            