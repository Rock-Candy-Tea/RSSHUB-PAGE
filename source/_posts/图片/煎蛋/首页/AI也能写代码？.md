
---
title: 'AI也能写代码？'
categories: 
 - 图片
 - 煎蛋
 - 首页
headimg: 'https://cors.zfour.workers.dev/?http://img.jandan.net/news/2018/09/7b50a4e1e7245c57fc5e29a982c96792.jpg!custom'
author: 煎蛋
comments: false
date: Mon, 03 May 2021 02:40:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://img.jandan.net/news/2018/09/7b50a4e1e7245c57fc5e29a982c96792.jpg!custom'
---

<div>   
<blockquote><p>一家初创公司SourceAI觉得编程应该算不得什么大事儿。</p></blockquote><img src="https://cors.zfour.workers.dev/?http://img.jandan.net/news/2018/09/7b50a4e1e7245c57fc5e29a982c96792.jpg!custom" referrerpolicy="no-referrer"><p>投稿：<strong>BISK</strong><br>
<em>原文：https://www.wired.com/story/ai-latest-trick-writing-computer-code/</em></p>
<p>写好代码需要经年累月的学习。而巴黎的一家初创公司SourceAI却觉得，编程应该算不得什么大事儿。</p>
<p>这家公司正给一个使用了人工智能技术的工具做微调，该工具可以基于代码任务的简短描述来写出代码。比方说，告诉这个工具“把用户给出的两个数字相乘”，它就会写出几行Python代码完成这份任务。</p>
<p>SourceAI的宏图远景是软件开发进行更广泛革命的一个标志。从自动补全代码片段，到搜寻源码和定位恼人bug的微调算法，先进的机器学习已经可以自动进行一组编程任务了。</p>
<p>自动编程可以变革软件开发，然而现代AI的限制和盲点也可能会带来新的问题。机器学习算法可能表现得不可预测，而机器生成的代码除非进行谨慎的核查，则会有可能会带来有害的bug。</p>
<p>SourceAI和另一个相近的程序旨在借着GPT-3的东风，后者是OpenAI在2020年五月发布的一款强大的AI语言程序，OpenAI是一家来自旧金山的公司，致力于AI领域的根本性发展。SourceAI的创建者们正是在最先使用到GPT-3的几百人之中。OpenAI并未公布GPT-3的代码，但是它运行部分用户通过API访问模型。</p>
<p>GPT-3是一个巨型人工神经网络，使用从网络上爬取的海量文本进行训练。它不会理解文本背后的含义，但是它能够良好地捕获语言中的模式，进而生成给定主题下的文章，或者对一篇文章做出概要，又或者回答有关文档内容的一些问题。</p>
<p>“我们在测试此工具的过程中意识到，它可以进行代码生成，”SourceAI的创建人和CEO，Furkan Bektes说到，“那个时候我们就有了这个开发SourceAI的想法”。</p>
<p>他不是第一个注意到这种潜力的人。就在GPT-3发布后不久，一名程序员展示到它能够创建自定义的Web应用，应用包括按钮，文本输入框和颜色，它重新组合了输入的代码片段。另一家公司Debuild准备把这项技术商业化。</p>
<p>SourceAI旨在让用户生成不同语言写就的，用途更广泛的程序，从而帮助我们自动创建更多的软件。“开发者在编码上节省了时间，而没有编程知识的人也能够开发应用”，Bekets说到。</p>
<p>另一家公司TabNine使用了OpenAI语言模型的先前版本GPT-2，也是OpenAI发布的。它可以用来构建当开发者键入内容时，可以提供自动补全代码行或者函数的工具。</p>
<p>一些软件巨头似乎也有了兴趣。微软2019年向OpenAI投资10亿美元，并同意了GPT-3的许可证书。在这个软件巨头五月在的构建大会上，OpenAI的联合创立者Sam Altman演示了GPT-3为开发者自动生成代码的过程。</p>
<p>纽约大学计算机科学和工程部的助理教授，Brendan Dolan-Gavitt称GPT-3这样的语言模型很可能会被用来帮助人类程序员。另一项会使用到此模型的产品则是“通过寻找那些令语言模型惊讶的内容，来在你写代码的过程中指出其中的bug”。</p>
<p>然而，使用AI生成并分析代码可能会成问题。在一篇三月发布的在线论文中，MIT的研究者们揭示，用以校验代码运行安全的AI程序可以被欺骗，只需小心地做出几处变动，比如替换某些变量，就能创建出有害程序。参与研究的博士生Shashank Srikant认为不应该过度依赖AI模型，“一旦这些模型进入生产，形势很快就有可能急转直下”，他说到。</p>
<p>纽约大学的教授Dolan-Gavitt说，用来生成代码工具的语言模型本质也存在问题。“我认为直接使用语言模型很可能会以bug满天飞的不安全代码产出收场，毕竟，它们是基于人类写的代码来训练的，而后者常常就是bug遍地还不安全的”。</p>  
</div>
            