
---
title: '一文搞定完整的云原生边缘基础设施堆栈'
categories: 
 - 编程
 - Dockone
 - 周报
headimg: 'https://img-blog.csdnimg.cn/2021051209122879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70'
author: Dockone
comments: false
date: 2021-05-12 04:09:58
thumbnail: 'https://img-blog.csdnimg.cn/2021051209122879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70'
---

<div>   
<br><blockquote><br> 作者简介<br>
  <br>
  <br> Janakiram MSV是Janakiram & Associates的首席分析师，也是国际信息技术学院的兼职教师。他也是Google    Qualified  Developer、亚马逊认证解决方案架构师、亚马逊认证开发者、亚马逊认证SysOps管理员和微软认证Azure专业人员。<br>
  <br>
  <br>Janakiram是云原生计算基金会的大使，也是首批Kubernetes认证管理员和Kubernetes认证应用开发者之一。他曾在微软、AWS、Gigaom  Research等知名公司工作。</blockquote>在之前的文章中，我们了解了云原生边缘计算堆栈的核心构件：K3s、Project Calico和Portworx。<br>
<br>本篇教程将带你了解在边缘集群上安装和配置这一软件，该集群是一组运行Ubuntu 18.04的英特尔NUC迷你电脑。这种基础设施可用于在边缘运行可靠、可扩展和安全的AI和IoT工作负载。<br>
<br><h2>为Calico自定义K3s安装</h2>默认情况下，K3s使用Flannel作为容器网络接口（CNI）运行，使用VXLAN作为默认后端。在本文中，我们将用Calico代替它。<br>
<br>要将K3s与网络堆栈Calico集成起来，我们需要自定义安装以启动CNI支持。<br>
<br>请注意在边缘你至少需要3个节点运行在K3s集群上以保证高可用。<br>
<br>在第一个指定为服务器的节点上，运行以下命令：<br>
<br><code class="prettyprint">export K3S_TOKEN=&quot;secret_edgecluster_token&quot;</code><br>
<br><code class="prettyprint">export INSTALL_K3S_EXEC=&quot;--flannel-backend=none --disable=traefik --cluster-cidr=172.16.2.0/24 --cluster-init&quot;</code><br>
<br><code class="prettyprint">curl -sfL https://get.k3s.io | sh -</code><br>
<br>如果在你的网络中172.16.2.0/24已经被占用，那么你必须选择一个不同的pod网络CIDR来代替上述命令中的172.16.2.0/24。<br>
<br>在其余server节点上，运行以下命令。请注意，我们在安装程序中添加<strong>--server</strong>开关，将其指向第一个节点的IP地址。<br>
<br><code class="prettyprint">export K3S_TOKEN=&quot;secret_edgecluster_token&quot;<br>
export INSTALL_K3S_EXEC=&quot;--flannel-backend=none --disable=traefik --cluster-cidr=172.16.2.0/24 --server https://10.0.0.60:6443&quot;<br>
curl -sfL https://get.k3s.io | sh -</code><br>
<br>运行以下命令配置worker节点或agent：<br>
<br><code class="prettyprint">export K3S_URL=https://10.0.0.60:6443<br>
export K3S_TOKEN=&quot;secret_edgecluster_token&quot;<br>
curl -sfL https://get.k3s.io | sh -</code><br>
<br>使用K3s server的IP地址代替<strong>K3S_URL</strong><br>
<br>这一步结束之后，你应该拥有一个带有4个节点的集群。<br>
<br>由于网络尚未配置，因此没有一个节点是ready的。只要我们将Calico specs应用到集群，这些节点的状态将会变成ready。<br>
<br><img src="https://img-blog.csdnimg.cn/2021051209122879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="图片" referrerpolicy="no-referrer"><br>
<br>在进行下一步之前，先从其中一个server节点复制<strong>/etc/rancher/k3s/k3s.yaml</strong>到你的本地工作站并将KUBECONFIG环境变量指向它。别忘了在YAML文件中更新<strong>master URL</strong>。这提供了通过kubectl CLI对K3s集群的远程访问。<br>
<br><h2>在多节点K3s集群上安装Calico</h2>我们将通过下载Calico manifests并修改它们来启动：<br>
<br><code class="prettyprint">wget https://docs.projectcalico.org/manifests/tigera-operator.yaml</code><br>
<br><code class="prettyprint">wget https://docs.projectcalico.org/manifests/custom-resources.yaml</code><br>
<br>在K3s安装过程中，打开<strong>custom-resources.yaml</strong>文件并更改CIDR到与上文提到的相同的IP地址段。<br>
<br>应用两个manifest为K3s集群配置Calico网络<br>
<br><code class="prettyprint">kubectl create -f tigera-operator.yaml<br>
kubectl create -f custom-resources.yaml</code><br>
<br>几分钟内，集群状态将变为ready<br>
<br><img src="https://img-blog.csdnimg.cn/20210512091317886.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="图片" referrerpolicy="no-referrer"><br>
<br>最后，在<strong>calico-system</strong>命名空间中修改<strong>cni-config configmap</strong>以启用IP转发：<br>
<br><code class="prettyprint">kubectl edit cm cni-config -n calico-system</code><br>
<br>改变以下所示的值，启用IP转发：<br>
<br><code class="prettyprint">&quot;container_settings&quot;: &#123;<br>
              &quot;allow_ip_forwarding&quot;: true<br>
          &#125;</code><br>
<br>验证Calico是否启动并使用以下命令运行：<br>
<br><code class="prettyprint">kubectl get pods -n calico-system</code><br>
<br><img src="https://img-blog.csdnimg.cn/20210512091451353.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" referrerpolicy="no-referrer"><br>
<br><h2>在K3s上安装Portworx</h2>Portworx 2.6及以上版本支持K3s，安装流程与其他Kubernetes发行版并无差异。如果你不太了解，可以根据以下链接中的教程安装Portworx：<br>
<br><a href="https://thenewstack.io/tutorial-install-and-configure-portworx-on-a-bare-metal-kubernetes-cluster/"></a><a href="https://thenewstack.io/tutorial-install-and-configure-portworx-on-a-bare-metal-kubernetes-cluster/" rel="nofollow" target="_blank">https://thenewstack.io/tutoria ... ster/</a><br>
<br>如果你手边没有etcd集群，你可以在PX-Central安装向导中选择内置的KVDB。<br>
<br><img src="https://img-blog.csdnimg.cn/20210512091533351.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="图片" referrerpolicy="no-referrer"><br>
<br>我选择了附加到每个主机的NVMe磁盘作为存储选项。你可以根据你的存储配置进行修改。<br>
<br><img src="https://img-blog.csdnimg.cn/20210512091546329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="图片" referrerpolicy="no-referrer"><br>
<br>K3s最重要的前提条件之一是支持CSI，所以请确保你在最后一步选择了<strong>Enable CSI</strong>选项。<br>
<br><img src="https://img-blog.csdnimg.cn/2021051209162397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" referrerpolicy="no-referrer"><br>
<br>复制规范并将其应用到你的集群中<br>
<br><img src="https://img-blog.csdnimg.cn/20210512091638357.png" alt="图片" referrerpolicy="no-referrer"><br>
<br>几分钟内，在K3s上的Portworx集群将会启动并运行：<br>
<br><code class="prettyprint">kubectl get pods -l name=portworx -n kube-system</code><br>
<br><img src="https://img-blog.csdnimg.cn/20210512091656363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" referrerpolicy="no-referrer"><br>
<br>CSI驱动作为一个sidecar连接到DaemonSet中的每一个Pod，这就是为什么我们在Pod中看到两个容器。<br>
<br>SSH进入其中一个节点，用下面的命令检查Portworx集群状态。<br>
<br><code class="prettyprint">sudo /opt/pwx/bin/pxctl status</code><br>
<br><img src="https://img-blog.csdnimg.cn/20210512092113789.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjA2ODEz,size_16,color_FFFFFF,t_70" alt="图片" referrerpolicy="no-referrer"><br>
<br>我们现在已经拥有了一个基于K3s、Calico和Portworx的边缘基础设施，并且配置完整。在下一篇文章中，我们将部署一个运行在边缘的AIoT工作负载。保持关注哟<br>
<blockquote><br>原文链接：<br>
  <br>
  <br><a href="https://thenewstack.io/tutorial-configure-cloud-native-edge-infrastructure-with-k3s-calico-portworx/" rel="nofollow" target="_blank">https://thenewstack.io/tutoria ... worx/</a></blockquote>
                                
                                                              
</div>
            