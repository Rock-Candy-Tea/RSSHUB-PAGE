
---
title: '深入浅出负载均衡'
categories: 
 - 编程
 - Dockone
 - 周报
headimg: 'https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/0efa27e4ea31f2a0d0529f3483185846.png'
author: Dockone
comments: false
date: 2021-12-04 11:07:34
thumbnail: 'https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/0efa27e4ea31f2a0d0529f3483185846.png'
---

<div>   
<br><h3>负载均衡简介</h3><h4>大型网站面临的挑战</h4>大型网站都要面对庞大的用户量，高并发，海量数据等挑战。为了提升系统整体的性能，可以采用垂直扩展和水平扩展两种方式。<br>
<br><strong>垂直扩展</strong>：在网站发展早期，可以从单机的角度通过增加硬件处理能力，比如 CPU 处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升。但是，单机是有性能瓶颈的，一旦触及瓶颈，再想提升，付出的成本和代价会极高。这显然不能满足大型分布式系统（网站）所有应对的大流量，高并发，海量数据等挑战。<br>
<br><strong>水平扩展</strong>：通过集群来分担大型网站的流量。集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点，这些节点共同分担访问压力。水平扩展有两个要点：<br>
<ul><li>应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。</li><li>负载均衡：将用户访问请求，通过某种算法，分发到集群中的节点。</li></ul><br>
<br><h4>什么是负载均衡</h4>负载均衡（Load Balance，简称 LB）是高并发、高可用系统必不可少的关键组件，目标是 尽力将网络流量平均分发到多个服务器上，以提高系统整体的响应速度和可用性。<br>
<br>负载均衡的主要作用如下：<br>
<ul><li>高并发：负载均衡通过算法调整负载，尽力均匀的分配应用集群中各节点的工作量，以此提高应用集群的并发处理能力（吞吐量）。</li><li>伸缩性：添加或减少服务器数量，然后由负载均衡进行分发控制。这使得应用集群具备伸缩性。</li><li>高可用：负载均衡器可以监控候选服务器，当服务器不可用时，自动跳过，将请求分发给可用的服务器。这使得应用集群具备高可用的特性。</li><li>安全防护：有些负载均衡软件或硬件提供了安全性功能，如：黑白名单处理、防火墙，防 DDos 攻击等。</li></ul><br>
<br><h3>负载均衡的分类</h3>支持负载均衡的技术很多，我们可以通过不同维度去进行分类。<br>
<h4>载体维度分类</h4>从支持负载均衡的载体来看，可以将负载均衡分为两类：<strong>硬件负载均衡、软件负载均衡</strong>。<br>
<br><strong>硬件负载均衡</strong><br>
<br>硬件负载均衡，一般是在定制处理器上运行的独立负载均衡服务器，价格昂贵，土豪专属。硬件负载均衡的主流产品有：F5 和 A10。<br>
<br>硬件负载均衡的优点：<br>
<ul><li>功能强大：支持全局负载均衡并提供较全面的、复杂的负载均衡算法。</li><li>性能强悍：硬件负载均衡由于是在专用处理器上运行，因此吞吐量大，可支持单机百万以上的并发。</li><li>安全性高：往往具备防火墙，防 DDos 攻击等安全功能。</li></ul><br>
<br>硬件负载均衡的缺点：<br>
<ul><li>成本昂贵：购买和维护硬件负载均衡的成本都很高。</li><li>扩展性差：当访问量突增时，超过限度不能动态扩容。</li></ul><br>
<br><strong>软件负载均衡</strong><br>
<br>软件负载均衡，应用最广泛，无论大公司还是小公司都会使用。<br>
<br>软件负载均衡从软件层面实现负载均衡，一般可以在任何标准物理设备上运行。<br>
<br>软件负载均衡的主流产品有：<strong>Nginx、HAProxy、LVS</strong>。<br>
<ul><li>LVS 可以作为四层负载均衡器。其负载均衡的性能要优于 Nginx。</li><li>HAProxy 可以作为 HTTP 和 TCP 负载均衡器。</li><li>Nginx、HAProxy 可以作为四层或七层负载均衡器。</li></ul><br>
<br>软件负载均衡的优点：<br>
<ul><li>扩展性好：适应动态变化，可以通过添加软件负载均衡实例，动态扩展到超出初始容量的能力。</li><li>成本低廉：软件负载均衡可以在任何标准物理设备上运行，降低了购买和运维的成本。</li></ul><br>
<br>软件负载均衡的缺点：<br>
<ul><li>性能略差：相比于硬件负载均衡，软件负载均衡的性能要略低一些。</li></ul><br>
<br><h4>网络通信分类</h4>软件负载均衡从通信层面来看，又可以分为四层和七层负载均衡。<br>
<br>七层负载均衡：就是可以根据访问用户的 HTTP 请求头、URL 信息将请求转发到特定的主机。<br>
<ul><li>DNS 重定向</li><li>HTTP 重定向</li><li>反向代理</li></ul><br>
<br>四层负载均衡：基于 IP 地址和端口进行请求的转发。<br>
<ul><li>修改 IP 地址</li><li>修改 MAC 地址</li></ul><br>
<br><strong>DNS 负载均衡</strong><br>
<br>DNS 负载均衡一般用于互联网公司，复杂的业务系统不适合使用。大型网站一般使用 DNS 负载均衡作为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。DNS 负载均衡属于七层负载均衡。<br>
<br>DNS 即 域名解析服务，是 OSI 第七层网络协议。DNS 被设计为一个树形结构的分布式应用，自上而下依次为：根域名服务器，一级域名服务器，二级域名服务器，……，本地域名服务器。显然，如果所有数据都存储在根域名服务器，那么 DNS 查询的负载和开销会非常庞大。<br>
<br>因此，DNS 查询相对于 DNS 层级结构，是一个逆向的递归流程，DNS 客户端依次请求本地 DNS 服务器，上一级 DNS 服务器，上上一级 DNS 服务器，……，根 DNS 服务器（又叫权威 DNS 服务器），一旦命中，立即返回。为了减少查询次数，每一级 DNS 服务器都会设置 DNS 查询缓存。<br>
<br>DNS 负载均衡的工作原理就是：基于 DNS 查询缓存，按照负载情况返回不同服务器的 IP 地址。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/0efa27e4ea31f2a0d0529f3483185846.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/0efa27e4ea31f2a0d0529f3483185846.png" class="img-polaroid" title="1.png" alt="1.png" referrerpolicy="no-referrer"></a>
</div>
<br>
DNS 重定向的优点：<br>
<ul><li>使用简单：负载均衡工作，交给 DNS 服务器处理，省掉了负载均衡服务器维护的麻烦</li><li>提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址（类似 CDN 的原理），可以加快访问速度，改善性能；</li></ul><br>
<br>DNS 重定向的缺点：<br>
<ul><li>可用性差：DNS 解析是多级解析，新增/修改 DNS 后，解析时间较长；解析过程中，用户访问网站将失败；</li><li>扩展性低：DNS 负载均衡的控制权在域名商那里，无法对其做更多的改善和扩展；</li><li>维护性差：也不能反映服务器的当前运行状态；支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）。</li></ul><br>
<br><strong>HTTP 负载均衡</strong><br>
<br>HTTP 负载均衡是基于 HTTP 重定向实现的。HTTP 负载均衡属于七层负载均衡。<br>
<br>HTTP 重定向原理是：根据用户的 HTTP 请求计算出一个真实的服务器地址，将该服务器地址写入 HTTP 重定向响应中，返回给浏览器，由浏览器重新进行访问。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/9316a87532a478f09be1ac6a171f2397.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/9316a87532a478f09be1ac6a171f2397.png" class="img-polaroid" title="2.png" alt="2.png" referrerpolicy="no-referrer"></a>
</div>
<br>
HTTP 重定向的优点：方案简单。<br>
<br>HTTP 重定向的缺点：<br>
<ul><li>性能较差：每次访问需要两次请求服务器，增加了访问的延迟。</li><li>降低搜索排名：使用重定向后，搜索引擎会视为 SEO 作弊。</li><li>如果负载均衡器宕机，就无法访问该站点。</li></ul><br>
<br>由于其缺点比较明显，所以这种负载均衡策略实际应用较少。<br>
<br><strong>反向代理负载均衡</strong><br>
<br>反向代理（Reverse Proxy）方式是指以代理服务器来接受网络请求，然后将请求转发给内网中的服务器，并将从内网中的服务器上得到的结果返回给网络请求的客户端。反向代理负载均衡属于七层负载均衡。<br>
<br>反向代理服务的主流产品：<strong>Nginx、Apache</strong>。<br>
<br>正向代理与反向代理有什么区别？<br>
<ul><li>正向代理：发生在客户端，是由用户主动发起的。翻墙软件就是典型的正向代理，客户端通过主动访问代理服务器，让代理服务器获得需要的外网数据，然后转发回客户端。</li><li>反向代理：发生在服务端，用户不知道代理的存在。</li></ul><br>
<br><div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/6bb83bfc2f2221548aca26af752dcfda.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/6bb83bfc2f2221548aca26af752dcfda.png" class="img-polaroid" title="3.png" alt="3.png" referrerpolicy="no-referrer"></a>
</div>
<br>
反向代理是如何实现负载均衡的呢？以 Nginx 为例，如下所示：<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/7bd7224ff8c907968d3c8c9769bf2d0e.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/7bd7224ff8c907968d3c8c9769bf2d0e.png" class="img-polaroid" title="4.png" alt="4.png" referrerpolicy="no-referrer"></a>
</div>
<br>
首先，在代理服务器上设定好负载均衡规则。然后，当收到客户端请求，反向代理服务器拦截指定的域名或 IP 请求，根据负载均衡算法，将请求分发到候选服务器上。其次，如果某台候选服务器宕机，反向代理服务器会有容错处理，比如分发请求失败 3 次以上，将请求分发到其他候选服务器上。<br>
<br>反向代理的优点：<br>
<ul><li>多种负载均衡算法：支持多种负载均衡算法，以应对不同的场景需求。</li><li>可以监控服务器：基于 HTTP 协议，可以监控转发服务器的状态，如：系统负载、响应时间、是否可用、连接数、流量等，从而根据这些数据调整负载均衡的策略。</li></ul><br>
<br>反向代理的缺点：<br>
<ul><li>额外的转发开销：反向代理的转发操作本身是有性能开销的，可能会包括创建连接，等待连接响应，分析响应结果等操作。</li><li><br>增加系统复杂度：反向代理常用于做分布式应用的水平扩展，但反向代理服务存在以下问题，为了解决以下问题会给系统整体增加额外的复杂度和运维成本：<br>
<ul><li>反向代理服务如果自身宕机，就无法访问站点，所以需要有高可用方案，常见的方案有：主备模式（一主一备）、双主模式（互为主备）。</li><li>反向代理服务自身也存在性能瓶颈，随着需要转发的请求量不断攀升，需要有可扩展方案。</li></ul></li></ul><br>
<br><strong>IP负载均衡</strong><br>
<br>IP 负载均衡是在网络层通过修改请求目的地址进行负载均衡。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/3696a7621ba7552d2d054bd5d23de257.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/3696a7621ba7552d2d054bd5d23de257.png" class="img-polaroid" title="5.png" alt="5.png" referrerpolicy="no-referrer"></a>
</div>
<br>
如上图所示，IP 均衡处理流程大致为：<br>
<ul><li>客户端请求 192.168.137.10，由负载均衡服务器接收到报文。</li><li>负载均衡服务器根据算法选出一个服务节点 192.168.0.1，然后将报文请求地址改为该节点的 IP。</li><li>真实服务节点收到请求报文，处理后，返回响应数据到负载均衡服务器。</li><li>负载均衡服务器将响应数据的源地址改负载均衡服务器地址，返回给客户端。</li></ul><br>
<br>IP 负载均衡在内核进程完成数据分发，较反向代理负载均衡有更好的从处理性能。但是，由于所有请求响应都要经过负载均衡服务器，集群的吞吐量受制于负载均衡服务器的带宽。<br>
<br><strong>数据链路层负载均衡</strong><br>
<br>数据链路层负载均衡是指在通信协议的数据链路层修改 mac 地址进行负载均衡。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/3bb56836225057962bfd80d5f94f8cce.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/3bb56836225057962bfd80d5f94f8cce.png" class="img-polaroid" title="6.png" alt="6.png" referrerpolicy="no-referrer"></a>
</div>
<br>
在 Linux 平台上最好的链路层负载均衡开源产品是 LVS（Linux Virtual Server）。LVS 是基于 Linux 内核中 netfilter 框架实现的负载均衡系统。netfilter 是内核态的 Linux 防火墙机制，可以在数据包流经过程中，根据规则设置若干个关卡（hook 函数）来执行相关的操作。<br>
<br>LVS 的工作流程大致如下：<br>
<ul><li>当用户访问 <a href="http://www.sina.com.cn/" rel="nofollow" target="_blank">www.sina.com.cn</a> 时，用户数据通过层层网络，最后通过交换机进入 LVS 服务器网卡，并进入内核网络层。</li><li>进入 PREROUTING 后经过路由查找，确定访问的目的 VIP 是本机 IP 地址，所以数据包进入到 INPUT 链上</li><li>IPVS 是工作在 INPUT 链上，会根据访问的 <strong>vip + port</strong> 判断请求是否 IPVS 服务，如果是则调用注册的 IPVS HOOK 函数，进行 IPVS 相关主流程，强行修改数据包的相关数据，并将数据包发往 POSTROUTING 链上。</li><li>POSTROUTING 上收到数据包后，根据目标 IP 地址（后端服务器），通过路由选路，将数据包最终发往后端的服务器上。</li></ul><br>
<br>开源 LVS 版本有 3 种工作模式，每种模式工作原理截然不同，说各种模式都有自己的优缺点，分别适合不同的应用场景，不过最终本质的功能都是能实现均衡的流量调度和良好的扩展性。主要包括三种模式：DR 模式、NAT 模式、Tunnel 模式。<br>
<h3>负载均衡算法</h3>负载均衡器的实现可以分为两个部分：<br>
<ul><li>根据负载均衡算法在候选服务器列表选出一个服务器；</li><li>将请求数据发送到该服务器上。</li></ul><br>
<br>负载均衡算法是负载均衡服务核心中的核心。负载均衡产品多种多样，但是各种负载均衡算法原理是共性的。负载均衡算法有很多种，分别适用于不同的应用场景，本文仅介绍最为常见的负载均衡算法的特性及原理：<strong>轮询、随机、最小活跃数、源地址哈希、一致性哈希</strong>。<br>
<br><strong>注</strong>：负载均衡算法的实现，推荐阅读《<a href="https://dubbo.apache.org/zh/docs/v2.7/dev/source/loadbalance/">Dubbo 官方负载均衡算法说明</a>》，源码讲解非常详细，非常值得借鉴。<br>
<h4>随机</h4><strong>随机算法</strong><br>
<br>随机（Random）算法将请求随机分发到候选服务器。<br>
<br>随机算法适合服务器硬件相同的场景。学习过概率论的都知道，调用量较小的时候，可能负载并不均匀，调用量越大，负载越均衡。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/ef9941e76ac2d72292c1d9b1a9ab8f8b.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/ef9941e76ac2d72292c1d9b1a9ab8f8b.png" class="img-polaroid" title="7.png" alt="7.png" referrerpolicy="no-referrer"></a>
</div>
<br>
随机算法实现示例：<br>
<br>负载均衡接口：<br>
<pre class="prettyprint">public interface LoadBalance<N extends Node> &#123;<br>
<br>
N select(List<N> nodes, String ip);<br>
<br>
&#125; <br>
</pre><br>
负载均衡抽象类：<br>
<pre class="prettyprint">public abstract class BaseLoadBalance<N extends Node> implements LoadBalance<N> &#123;<br>
<br>
@Override<br>
public N select(List<N> nodes, String ip) &#123;<br>
    if (CollectionUtil.isEmpty(nodes)) &#123;<br>
        return null;<br>
    &#125;<br>
<br>
    // 如果 nodes 列表中仅有一个 node，直接返回即可，无需进行负载均衡<br>
    if (nodes.size() == 1) &#123;<br>
        return nodes.get(0);<br>
    &#125;<br>
<br>
    return doSelect(nodes, ip);<br>
&#125;<br>
<br>
protected abstract N doSelect(List<N> nodes, String ip);<br>
<br>
&#125; <br>
</pre><br>
服务器节点类：<br>
<pre class="prettyprint">public class Node implements Comparable<Node> &#123;<br>
<br>
protected String url;<br>
<br>
protected Integer weight;<br>
<br>
protected Integer active;<br>
<br>
// ...<br>
&#125; <br>
</pre><br>
随机算法实现：<br>
<pre class="prettyprint">public class RandomLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
private final Random random = new Random();<br>
<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
    // 在列表中随机选取一个节点<br>
    int index = random.nextInt(nodes.size());<br>
    return nodes.get(index);<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
<strong>加权随机算法</strong><br>
<br>加权随机（Weighted Random） 算法在随机算法的基础上，按照概率调整权重，进行负载分配。<br>
<br>加权随机算法实现示例：<br>
<pre class="prettyprint">public class WeightRandomLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
private final Random random = ThreadLocalRandom.current();<br>
<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
<br>
    int length = nodes.size();<br>
    AtomicInteger totalWeight = new AtomicInteger(0);<br>
    for (N node : nodes) &#123;<br>
        Integer weight = node.getWeight();<br>
        totalWeight.getAndAdd(weight);<br>
    &#125;<br>
<br>
    if (totalWeight.get() > 0) &#123;<br>
        int offset = random.nextInt(totalWeight.get());<br>
        for (N node : nodes) &#123;<br>
            // 让随机值 offset 减去权重值<br>
            offset -= node.getWeight();<br>
            if (offset < 0) &#123;<br>
                // 返回相应的 Node<br>
                return node;<br>
            &#125;<br>
        &#125;<br>
    &#125;<br>
<br>
    // 直接随机返回一个<br>
    return nodes.get(random.nextInt(length));<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
<h4>轮询</h4><strong>轮询算法</strong><br>
<br>轮询（Round Robin）算法的策略是：将请求依次分发到候选服务器。<br>
<br>如下图所示，负载均衡器收到来自客户端的 6 个请求，(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/7470fc02b3e29628d5294337a0367021.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/7470fc02b3e29628d5294337a0367021.png" class="img-polaroid" title="8.png" alt="8.png" referrerpolicy="no-referrer"></a>
</div>
<br>
该算法适合场景：各服务器处理能力相近，且每个事务工作量差异不大。如果存在较大差异，那么处理较慢的服务器就可能会积压请求，最终无法承担过大的负载。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/d13fc4a67a5f649e8460338767cebca1.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/d13fc4a67a5f649e8460338767cebca1.png" class="img-polaroid" title="9.png" alt="9.png" referrerpolicy="no-referrer"></a>
</div>
<br>
轮询算法示例：<br>
<br>轮询负载均衡算法实现：<br>
<pre class="prettyprint">public class RoundRobinLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
private final AtomicInteger position = new AtomicInteger(0);<br>
<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
    int length = nodes.size();<br>
    // 如果位置值已经等于节点数，重置为 0<br>
    position.compareAndSet(length, 0);<br>
    N node = nodes.get(position.get());<br>
    position.getAndIncrement();<br>
    return node;<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
<strong>加权轮询算法</strong><br>
<br>加权轮询（Weighted Round Robbin）算法在轮询算法的基础上，增加了权重属性来调节转发服务器的请求数目。性能高、处理速度快的节点应该设置更高的权重，使得分发时优先将请求分发到权重较高的节点上。<br>
<br>如下图所示，服务器 A 设置权重为 5，服务器 B 设置权重为 1，负载均衡器收到来自客户端的 6 个请求，那么（1, 2, 3, 4, 5）请求会被发送到服务器 A，(6) 请求会被发送到服务器 B。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/8319fe0d3ed84cc727e5e33b46c1b846.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/8319fe0d3ed84cc727e5e33b46c1b846.png" class="img-polaroid" title="10.png" alt="10.png" referrerpolicy="no-referrer"></a>
</div>
<br>
加权轮询算法实现示例：<br>
<br>以下实现基于 Dubbo 加权轮询算法做了一些简化。<br>
<pre class="prettyprint">public class WeightRoundRobinLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
/**<br>
 * 60秒<br>
 */<br>
private static final int RECYCLE_PERIOD = 60000;<br>
<br>
/**<br>
 * Node hashcode 到 WeightedRoundRobin 的映射关系<br>
 */<br>
private ConcurrentMap<Integer, WeightedRoundRobin> weightMap = new ConcurrentHashMap<>();<br>
<br>
/**<br>
 * 原子更新锁<br>
 */<br>
private AtomicBoolean updateLock = new AtomicBoolean();<br>
<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
<br>
    int totalWeight = 0;<br>
    long maxCurrent = Long.MIN_VALUE;<br>
<br>
    // 获取当前时间<br>
    long now = System.currentTimeMillis();<br>
    N selectedNode = null;<br>
    WeightedRoundRobin selectedWRR = null;<br>
<br>
    // 下面这个循环主要做了这样几件事情：<br>
    //   1. 遍历 Node 列表，检测当前 Node 是否有相应的 WeightedRoundRobin，没有则创建<br>
    //   2. 检测 Node 权重是否发生了变化，若变化了，则更新 WeightedRoundRobin 的 weight 字段<br>
    //   3. 让 current 字段加上自身权重，等价于 current += weight<br>
    //   4. 设置 lastUpdate 字段，即 lastUpdate = now<br>
    //   5. 寻找具有最大 current 的 Node，以及 Node 对应的 WeightedRoundRobin，<br>
    //      暂存起来，留作后用<br>
    //   6. 计算权重总和<br>
    for (N node : nodes) &#123;<br>
        int hashCode = node.hashCode();<br>
        WeightedRoundRobin weightedRoundRobin = weightMap.get(hashCode);<br>
        int weight = node.getWeight();<br>
        if (weight < 0) &#123;<br>
            weight = 0;<br>
        &#125;<br>
<br>
        // 检测当前 Node 是否有对应的 WeightedRoundRobin，没有则创建<br>
        if (weightedRoundRobin == null) &#123;<br>
            weightedRoundRobin = new WeightedRoundRobin();<br>
            // 设置 Node 权重<br>
            weightedRoundRobin.setWeight(weight);<br>
            // 存储 url 唯一标识 identifyString 到 weightedRoundRobin 的映射关系<br>
            weightMap.putIfAbsent(hashCode, weightedRoundRobin);<br>
            weightedRoundRobin = weightMap.get(hashCode);<br>
        &#125;<br>
        // Node 权重不等于 WeightedRoundRobin 中保存的权重，说明权重变化了，此时进行更新<br>
        if (weight != weightedRoundRobin.getWeight()) &#123;<br>
            weightedRoundRobin.setWeight(weight);<br>
        &#125;<br>
<br>
        // 让 current 加上自身权重，等价于 current += weight<br>
        long current = weightedRoundRobin.increaseCurrent();<br>
        // 设置 lastUpdate，表示近期更新过<br>
        weightedRoundRobin.setLastUpdate(now);<br>
        // 找出最大的 current<br>
        if (current > maxCurrent) &#123;<br>
            maxCurrent = current;<br>
            // 将具有最大 current 权重的 Node 赋值给 selectedNode<br>
            selectedNode = node;<br>
            // 将 Node 对应的 weightedRoundRobin 赋值给 selectedWRR，留作后用<br>
            selectedWRR = weightedRoundRobin;<br>
        &#125;<br>
<br>
        // 计算权重总和<br>
        totalWeight += weight;<br>
    &#125;<br>
<br>
    // 对 weightMap 进行检查，过滤掉长时间未被更新的节点。<br>
    // 该节点可能挂了，nodes 中不包含该节点，所以该节点的 lastUpdate 长时间无法被更新。<br>
    // 若未更新时长超过阈值后，就会被移除掉，默认阈值为60秒。<br>
    if (!updateLock.get() && nodes.size() != weightMap.size()) &#123;<br>
        if (updateLock.compareAndSet(false, true)) &#123;<br>
            try &#123;<br>
                // 遍历修改，即移除过期记录<br>
                weightMap.entrySet().removeIf(item -> now - item.getValue().getLastUpdate() > RECYCLE_PERIOD);<br>
            &#125; finally &#123;<br>
                updateLock.set(false);<br>
            &#125;<br>
        &#125;<br>
    &#125;<br>
<br>
    if (selectedNode != null) &#123;<br>
        // 让 current 减去权重总和，等价于 current -= totalWeight<br>
        selectedWRR.decreaseCurrent(totalWeight);<br>
        // 返回具有最大 current 的 Node<br>
        return selectedNode;<br>
    &#125;<br>
<br>
    // should not happen here<br>
    return nodes.get(0);<br>
&#125;<br>
<br>
protected static class WeightedRoundRobin &#123;<br>
<br>
    // 服务提供者权重<br>
    private int weight;<br>
    // 当前权重<br>
    private AtomicLong current = new AtomicLong(0);<br>
    // 最后一次更新时间<br>
    private long lastUpdate;<br>
<br>
    public long increaseCurrent() &#123;<br>
        // current = current + weight；<br>
        return current.addAndGet(weight);<br>
    &#125;<br>
<br>
    public long decreaseCurrent(int total) &#123;<br>
        // current = current - total;<br>
        return current.addAndGet(-1 * total);<br>
    &#125;<br>
<br>
    public int getWeight() &#123;<br>
        return weight;<br>
    &#125;<br>
<br>
    public void setWeight(int weight) &#123;<br>
        this.weight = weight;<br>
        // 初始情况下，current = 0<br>
        current.set(0);<br>
    &#125;<br>
<br>
    public AtomicLong getCurrent() &#123;<br>
        return current;<br>
    &#125;<br>
<br>
    public void setCurrent(AtomicLong current) &#123;<br>
        this.current = current;<br>
    &#125;<br>
<br>
    public long getLastUpdate() &#123;<br>
        return lastUpdate;<br>
    &#125;<br>
<br>
    public void setLastUpdate(long lastUpdate) &#123;<br>
        this.lastUpdate = lastUpdate;<br>
    &#125;<br>
<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
<h4>最小活跃数</h4>最小活跃数（Least Active）算法将请求分发到连接数/请求数最少的候选服务器（目前处理请求最少的服务器）。<br>
<ul><li>特点：根据候选服务器当前的请求连接数，动态分配。</li><li>场景：适用于对系统负载较为敏感或请求连接时长相差较大的场景。</li></ul><br>
<br>由于每个请求的连接时长不一样，如果采用简单的轮循或随机算法，都可能出现某些服务器当前连接数过大，而另一些服务器的连接过小的情况，这就造成了负载并非真正均衡。虽然，轮询或算法都可以通过加权重属性的方式进行负载调整，但加权方式难以应对动态变化。<br>
<br>例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开。该系统继续运行时，服务器 2 会承担过大的负载。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/1d7d2e69c8457ddc1374eee8cdeb1bb8.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/1d7d2e69c8457ddc1374eee8cdeb1bb8.png" class="img-polaroid" title="11.png" alt="11.png" referrerpolicy="no-referrer"></a>
</div>
<br>
最小活跃数算法会记录当前时刻，每个候选节点正在处理的连接数，然后选择连接数最小的节点。该策略能够动态、实时地反应服务器的当前状况，较为合理地将负责分配均匀，适用于对当前系统负载较为敏感的场景。<br>
<br>例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/bc6619195c89e3f1a87cedac0de3ffb6.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/bc6619195c89e3f1a87cedac0de3ffb6.png" class="img-polaroid" title="12.png" alt="12.png" referrerpolicy="no-referrer"></a>
</div>
<br>
<strong>加权最小活跃数（Weighted Least Connection）</strong>在最小活跃数的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。<br>
<br>最小活跃数算法实现要点：活跃调用数越小，表明该服务节点处理能力越高，单位时间内可处理更多的请求，应优先将请求分发给该服务。在具体实现中，每个服务节点对应一个活跃数 active。初始情况下，所有服务提供者活跃数均为 0。每收到一个请求，活跃数加 1，完成请求后则将活跃数减 1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求、这就是最小活跃数负载均衡算法的基本思想。<br>
<br>最小活跃数算法实现：<br>
<br>以下实现基于 Dubbo 最小活跃数负载均衡算法做了些许改动。<br>
<pre class="prettyprint">public class LeastActiveLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
private final Random random = new Random();<br>
<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
    int length = nodes.size();<br>
    // 最小的活跃数<br>
    int leastActive = -1;<br>
    // 具有相同“最小活跃数”的服务者提供者（以下用 Node 代称）数量<br>
    int leastCount = 0;<br>
    // leastIndexs 用于记录具有相同“最小活跃数”的 Node 在 nodes 列表中的下标信息<br>
    int[] leastIndexs = new int[length];<br>
    int totalWeight = 0;<br>
    // 第一个最小活跃数的 Node 权重值，用于与其他具有相同最小活跃数的 Node 的权重进行对比，<br>
    // 以检测是否“所有具有相同最小活跃数的 Node 的权重”均相等<br>
    int firstWeight = 0;<br>
    boolean sameWeight = true;<br>
<br>
    // 遍历 nodes 列表<br>
    for (int i = 0; i < length; i++) &#123;<br>
        N node = nodes.get(i);<br>
        // 发现更小的活跃数，重新开始<br>
        if (leastActive == -1 || node.getActive() < leastActive) &#123;<br>
            // 使用当前活跃数更新最小活跃数 leastActive<br>
            leastActive = node.getActive();<br>
            // 更新 leastCount 为 1<br>
            leastCount = 1;<br>
            // 记录当前下标值到 leastIndexs 中<br>
            leastIndexs[0] = i;<br>
            totalWeight = node.getWeight();<br>
            firstWeight = node.getWeight();<br>
            sameWeight = true;<br>
<br>
            // 当前 Node 的活跃数 node.getActive() 与最小活跃数 leastActive 相同<br>
        &#125; else if (node.getActive() == leastActive) &#123;<br>
            // 在 leastIndexs 中记录下当前 Node 在 nodes 集合中的下标<br>
            leastIndexs[leastCount++] = i;<br>
            // 累加权重<br>
            totalWeight += node.getWeight();<br>
            // 检测当前 Node 的权重与 firstWeight 是否相等，<br>
            // 不相等则将 sameWeight 置为 false<br>
            if (sameWeight && i > 0<br>
                && node.getWeight() != firstWeight) &#123;<br>
                sameWeight = false;<br>
            &#125;<br>
        &#125;<br>
    &#125;<br>
<br>
    // 当只有一个 Node 具有最小活跃数，此时直接返回该 Node 即可<br>
    if (leastCount == 1) &#123;<br>
        return nodes.get(leastIndexs[0]);<br>
    &#125;<br>
<br>
    // 有多个 Node 具有相同的最小活跃数，但它们之间的权重不同<br>
    if (!sameWeight && totalWeight > 0) &#123;<br>
        // 随机生成一个 [0, totalWeight) 之间的数字<br>
        int offsetWeight = random.nextInt(totalWeight);<br>
        // 循环让随机数减去具有最小活跃数的 Node 的权重值，<br>
        // 当 offset 小于等于0时，返回相应的 Node<br>
        for (int i = 0; i < leastCount; i++) &#123;<br>
            int leastIndex = leastIndexs[i];<br>
            // 获取权重值，并让随机数减去权重值<br>
            offsetWeight -= nodes.get(leastIndex).getWeight();<br>
            if (offsetWeight <= 0) &#123;<br>
                return nodes.get(leastIndex);<br>
            &#125;<br>
        &#125;<br>
    &#125;<br>
    // 如果权重相同或权重为0时，随机返回一个 Node<br>
    return nodes.get(leastIndexs[random.nextInt(leastCount)]);<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
<h4>源地址哈希</h4>源地址哈希（IP Hash）算法根据请求源 IP，通过哈希计算得到一个数值，用该数值在候选服务器列表的进行取模运算，得到的结果便是选中的服务器。<br>
<br>可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）。<br>
<br>特点：保证特定用户总是请求到相同的服务器，若服务器宕机，会话会丢失。<br>
<br>源地址哈希算法实现示例：<br>
<pre class="prettyprint">public class IpHashLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
    if (StrUtil.isBlank(ip)) &#123;<br>
        ip = "127.0.0.1";<br>
    &#125;<br>
<br>
    int length = nodes.size();<br>
    int index = hash(ip) % length;<br>
    return nodes.get(index);<br>
&#125;<br>
<br>
public int hash(String text) &#123;<br>
    return HashUtil.fnvHash(text);<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
<h4>一致性哈希</h4>一致性哈希（Consistent Hash）算法的目标是：相同的请求尽可能落到同一个服务器上。<br>
<br>一致性哈希可以很好的解决 稳定性问题，可以将所有的 存储节点 排列在 首尾相接的 Hash 环上，每个 key 在计算 Hash 后会顺时针找到临接的存储节点存放。而当有节点加入或退出时，仅影响该节点在 Hash 环上顺时针相邻的后续节点。<br>
<div class="aw-upload-img-list active">
<a href="http://dockone.io/uploads/article/20211203/a94e6bc67cddee76e563e884a57b3871.png" target="_blank" data-fancybox-group="thumb" rel="lightbox"><img src="https://cors.zfour.workers.dev/?http://dockone.io/uploads/article/20211203/a94e6bc67cddee76e563e884a57b3871.png" class="img-polaroid" title="13.png" alt="13.png" referrerpolicy="no-referrer"></a>
</div>
<br>
相同的请求是指：一般在使用一致性哈希时，需要指定一个 key 用于 hash 计算，可能是：<br>
<ul><li>用户 ID  </li><li>请求方 IP  </li><li>请求服务名称，参数列表构成的串</li></ul><br>
<br>尽可能是指：服务器可能发生上下线，少数服务器的变化不应该影响大多数的请求。<br>
<br>当某台候选服务器宕机时，原本发往该服务器的请求，会基于虚拟节点，平摊到其它候选服务器，不会引起剧烈变动。<br>
<br><strong>优点</strong>：加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。<br>
<br><strong>缺点</strong>：加减节点会造成哈希环中部分数据 无法命中。当使用少量节点时，节点变化将大范围影响哈希环中数据映射，不适合少量数据节点的分布式方案。普通的一致性哈希分区在增减节点时需要增加一倍或减去一半 节点才能保证数据和负载的均衡。<br>
<br><strong>注意</strong>：因为 一致性哈希分区的这些缺点，一些分布式系统采用虚拟槽 对一致性哈希进行改进，比如 Dynamo 系统。<br>
<br>一致性哈希算法示例：<br>
<pre class="prettyprint">public class ConsistentHashLoadBalance<N extends Node> extends BaseLoadBalance<N> implements LoadBalance<N> &#123;<br>
<br>
private final ConcurrentMap<String, ConsistentHashSelector<?>> selectors = new ConcurrentHashMap<>();<br>
<br>
@SuppressWarnings("unchecked")<br>
@Override<br>
protected N doSelect(List<N> nodes, String ip) &#123;<br>
    // 分片数，这里设为节点数的 4 倍<br>
    Integer replicaNum = nodes.size() * 4;<br>
    // 获取 nodes 原始的 hashcode<br>
    int identityHashCode = System.identityHashCode(nodes);<br>
<br>
    // 如果 nodes 是一个新的 List 对象，意味着节点数量发生了变化<br>
    // 此时 selector.identityHashCode != identityHashCode 条件成立<br>
    ConsistentHashSelector<N> selector = (ConsistentHashSelector<N>) selectors.get(ip);<br>
    if (selector == null || selector.identityHashCode != identityHashCode) &#123;<br>
        // 创建新的 ConsistentHashSelector<br>
        selectors.put(ip, new ConsistentHashSelector<>(nodes, identityHashCode, replicaNum));<br>
        selector = (ConsistentHashSelector<N>) selectors.get(ip);<br>
    &#125;<br>
    // 调用 ConsistentHashSelector 的 select 方法选择 Node<br>
    return selector.select(ip);<br>
&#125;<br>
<br>
/**<br>
 * 一致性哈希选择器<br>
 */<br>
private static final class ConsistentHashSelector<N extends Node> &#123;<br>
<br>
    /**<br>
     * 存储虚拟节点<br>
     */<br>
    private final TreeMap<Long, N> virtualNodes;<br>
<br>
    private final int identityHashCode;<br>
<br>
    /**<br>
     * 构造器<br>
     *<br>
     * @param nodes            节点列表<br>
     * @param identityHashCode hashcode<br>
     * @param replicaNum       分片数<br>
     */<br>
    ConsistentHashSelector(List<N> nodes, int identityHashCode, Integer replicaNum) &#123;<br>
        this.virtualNodes = new TreeMap<>();<br>
        this.identityHashCode = identityHashCode;<br>
        // 获取虚拟节点数，默认为 100<br>
        if (replicaNum == null) &#123;<br>
            replicaNum = 100;<br>
        &#125;<br>
        for (N node : nodes) &#123;<br>
            for (int i = 0; i < replicaNum / 4; i++) &#123;<br>
                // 对 url 进行 md5 运算，得到一个长度为16的字节数组<br>
                byte[] digest = md5(node.getUrl());<br>
                // 对 digest 部分字节进行 4 次 hash 运算，得到四个不同的 long 型正整数<br>
                for (int j = 0; j < 4; j++) &#123;<br>
                    // h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进行位运算<br>
                    // h = 1 时，取 digest 中下标为 4 ~ 7 的4个字节进行位运算<br>
                    // h = 2, h = 3 时过程同上<br>
                    long m = hash(digest, j);<br>
                    // 将 hash 到 node 的映射关系存储到 virtualNodes 中，<br>
                    // virtualNodes 需要提供高效的查询操作，因此选用 TreeMap 作为存储结构<br>
                    virtualNodes.put(m, node);<br>
                &#125;<br>
            &#125;<br>
        &#125;<br>
    &#125;<br>
<br>
    public N select(String key) &#123;<br>
        // 对参数 key 进行 md5 运算<br>
        byte[] digest = md5(key);<br>
        // 取 digest 数组的前四个字节进行 hash 运算，再将 hash 值传给 selectForKey 方法，<br>
        // 寻找合适的 Node<br>
        return selectForKey(hash(digest, 0));<br>
    &#125;<br>
<br>
    private N selectForKey(long hash) &#123;<br>
        // 查找第一个大于或等于当前 hash 的节点<br>
        Map.Entry<Long, N> entry = virtualNodes.ceilingEntry(hash);<br>
        // 如果 hash 大于 Node 在哈希环上最大的位置，此时 entry = null，<br>
        // 需要将 TreeMap 的头节点赋值给 entry<br>
        if (entry == null) &#123;<br>
            entry = virtualNodes.firstEntry();<br>
        &#125;<br>
        // 返回 Node<br>
        return entry.getValue();<br>
    &#125;<br>
<br>
&#125;<br>
<br>
/**<br>
 * 计算 hash 值<br>
 */<br>
public static long hash(byte[] digest, int number) &#123;<br>
    return (((long) (digest[3 + number * 4] & 0xFF) << 24)<br>
        | ((long) (digest[2 + number * 4] & 0xFF) << 16)<br>
        | ((long) (digest[1 + number * 4] & 0xFF) << 8)<br>
        | (digest[number * 4] & 0xFF))<br>
        & 0xFFFFFFFFL;<br>
&#125;<br>
<br>
/**<br>
 * 计算 MD5 值<br>
 */<br>
public static byte[] md5(String value) &#123;<br>
    MessageDigest md5;<br>
    try &#123;<br>
        md5 = MessageDigest.getInstance("MD5");<br>
    &#125; catch (NoSuchAlgorithmException e) &#123;<br>
        throw new IllegalStateException(e.getMessage(), e);<br>
    &#125;<br>
    md5.reset();<br>
    byte[] bytes = value.getBytes(StandardCharsets.UTF_8);<br>
    md5.update(bytes);<br>
    return md5.digest();<br>
&#125;<br>
<br>
&#125; <br>
</pre><br>
以上示例基于 Dubbo 的一致性哈希负载均衡算法做了一些简化。<br>
<br>参考资料：<br>
<ol><li><a href="https://www.youtube.com/watch?reload=9&app=desktop&v=iqOTT7_7qXY" rel="nofollow" target="_blank">https://www.youtube.com/watch% ... _7qXY</a></li><li>《大型网站技术架构：核心原理与案例分析》</li><li><a href="https://www.cnblogs.com/itfly8/p/5043435.html" rel="nofollow" target="_blank">https://www.cnblogs.com/itfly8/p/5043435.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/32841479" rel="nofollow" target="_blank">https://zhuanlan.zhihu.com/p/32841479</a></li><li><a href="https://avinetworks.com/what-is-load-balancing/" rel="nofollow" target="_blank">https://avinetworks.com/what-is-load-balancing/</a></li><li><a href="https://dubbo.apache.org/zh/docs/v2.7/dev/source/loadbalance/" rel="nofollow" target="_blank">https://dubbo.apache.org/zh/do ... ance/</a></li><li><a href="https://segmentfault.com/a/1190000004492447" rel="nofollow" target="_blank">https://segmentfault.com/a/1190000004492447</a></li><li><a href="https://segmentfault.com/a/1190000002578457" rel="nofollow" target="_blank">https://segmentfault.com/a/1190000002578457</a></li></ol><br>
<br>原文链接：<a href="https://mp.weixin.qq.com/s/69AGivVfwjEzCNvwJ1_2tQ" rel="nofollow" target="_blank">https://mp.weixin.qq.com/s/69AGivVfwjEzCNvwJ1_2tQ</a>
                                                                <div class="aw-upload-img-list">
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </div>
                                
                                                                <ul class="aw-upload-file-list">
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </ul>
                                                              
</div>
            