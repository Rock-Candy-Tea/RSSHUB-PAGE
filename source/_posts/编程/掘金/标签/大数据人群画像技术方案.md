
---
title: '大数据人群画像技术方案'
categories: 
 - 编程
 - 掘金
 - 标签
headimg: 'https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/24034f73769847d5aa96b2109b202641~tplv-k3u1fbpfcp-watermark.image'
author: 掘金
comments: false
date: Sat, 03 Jul 2021 22:16:22 GMT
thumbnail: 'https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/24034f73769847d5aa96b2109b202641~tplv-k3u1fbpfcp-watermark.image'
---

<div>   
<div class="markdown-body"><style>.markdown-body&#123;word-break:break-word;line-height:1.75;font-weight:400;font-size:15px;overflow-x:hidden;color:#333&#125;.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6&#123;line-height:1.5;margin-top:35px;margin-bottom:10px;padding-bottom:5px&#125;.markdown-body h1&#123;font-size:30px;margin-bottom:5px&#125;.markdown-body h2&#123;padding-bottom:12px;font-size:24px;border-bottom:1px solid #ececec&#125;.markdown-body h3&#123;font-size:18px;padding-bottom:0&#125;.markdown-body h4&#123;font-size:16px&#125;.markdown-body h5&#123;font-size:15px&#125;.markdown-body h6&#123;margin-top:5px&#125;.markdown-body p&#123;line-height:inherit;margin-top:22px;margin-bottom:22px&#125;.markdown-body img&#123;max-width:100%&#125;.markdown-body hr&#123;border:none;border-top:1px solid #ddd;margin-top:32px;margin-bottom:32px&#125;.markdown-body code&#123;word-break:break-word;border-radius:2px;overflow-x:auto;background-color:#fff5f5;color:#ff502c;font-size:.87em;padding:.065em .4em&#125;.markdown-body code,.markdown-body pre&#123;font-family:Menlo,Monaco,Consolas,Courier New,monospace&#125;.markdown-body pre&#123;overflow:auto;position:relative;line-height:1.75&#125;.markdown-body pre>code&#123;font-size:12px;padding:15px 12px;margin:0;word-break:normal;display:block;overflow-x:auto;color:#333;background:#f8f8f8&#125;.markdown-body a&#123;text-decoration:none;color:#0269c8;border-bottom:1px solid #d1e9ff&#125;.markdown-body a:active,.markdown-body a:hover&#123;color:#275b8c&#125;.markdown-body table&#123;display:inline-block!important;font-size:12px;width:auto;max-width:100%;overflow:auto;border:1px solid #f6f6f6&#125;.markdown-body thead&#123;background:#f6f6f6;color:#000;text-align:left&#125;.markdown-body tr:nth-child(2n)&#123;background-color:#fcfcfc&#125;.markdown-body td,.markdown-body th&#123;padding:12px 7px;line-height:24px&#125;.markdown-body td&#123;min-width:120px&#125;.markdown-body blockquote&#123;color:#666;padding:1px 23px;margin:22px 0;border-left:4px solid #cbcbcb;background-color:#f8f8f8&#125;.markdown-body blockquote:after&#123;display:block;content:""&#125;.markdown-body blockquote>p&#123;margin:10px 0&#125;.markdown-body ol,.markdown-body ul&#123;padding-left:28px&#125;.markdown-body ol li,.markdown-body ul li&#123;margin-bottom:0;list-style:inherit&#125;.markdown-body ol li .task-list-item,.markdown-body ul li .task-list-item&#123;list-style:none&#125;.markdown-body ol li .task-list-item ol,.markdown-body ol li .task-list-item ul,.markdown-body ul li .task-list-item ol,.markdown-body ul li .task-list-item ul&#123;margin-top:0&#125;.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul&#123;margin-top:3px&#125;.markdown-body ol li&#123;padding-left:6px&#125;.markdown-body .contains-task-list&#123;padding-left:0&#125;.markdown-body .task-list-item&#123;list-style:none&#125;@media (max-width:720px)&#123;.markdown-body h1&#123;font-size:24px&#125;.markdown-body h2&#123;font-size:20px&#125;.markdown-body h3&#123;font-size:18px&#125;&#125;</style><h1 data-id="heading-0">1：项目背景</h1>
<p>当一个app达到一定的体量，千人千面、个性化营销是每一个app提升留存、付费必备法宝。最终始终离不开营销利器，用户画像。项目从0到1构建画像体系，由T+1升级为实时。过程中不断的优化画像方案，赋能产品、业务。在个性化营销的路上越来越顺滑。</p>
<h1 data-id="heading-1">2：整体的技术方案</h1>
<h5 data-id="heading-2">1：实时画像通过flink stream job</h5>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/24034f73769847d5aa96b2109b202641~tplv-k3u1fbpfcp-watermark.image" alt="画像流程图.jpg" loading="lazy" referrerpolicy="no-referrer">
        1: app上报log日志到springboot,springboot 处理相关逻辑到kafka 。</p>
<p>        2: db binlog 通过maxwell 发送到kafka。</p>
<p>        3：所有的日志都到kafka, 画像、推荐相关的服务不需要消费所有的event。所以需要做一次二次分流降低处理所有消息的压力。我们根据具体的业务场景，把对应需要消费的数据对应的topic配置在db中。flink通过双流join (broadcast) 处理配置信息。</p>
<p>        4：项目中把埋点、binlog 分为两个实时流，两个流不操作任何存储。把需要同步的结果发送到kafka. 启动专门的画像同步流到hbase 或es。</p>
<p>       5：补充说明一下，我们的画像体系要满足多个app的使用。所以一定需要一个id_mapping 服务，人与设备的关系，设备与人的关系（建议保存最近的两条）。推荐、画像相关的服务需要用到mapping关系。另外appstore也禁用idfa,用户重装、以后设备信息就会发生变化。</p>
<pre><code class="hljs language-js copyable" lang="js">FlinkKafkaConsumer<Event> eventConsumer = <span class="hljs-keyword">new</span> FlinkKafkaConsumer<>(Topics.TEST, <span class="hljs-keyword">new</span> EventSchema(), kafkaConsumerProperties);
DataStreamSource<Event> eventStream = env.addSource(eventConsumer);

<span class="hljs-comment">//创建规则</span>
MapStateDescriptor<<span class="hljs-built_in">String</span>, HashMap<<span class="hljs-built_in">String</span>, HashSet<<span class="hljs-built_in">String</span>>>> topicRulesBroadcastState = <span class="hljs-keyword">new</span> MapStateDescriptor<>(
        <span class="hljs-string">"topicRulesBroadcastState"</span>,
        BasicTypeInfo.STRING_TYPE_INFO,
        TypeInformation.of(<span class="hljs-keyword">new</span> TypeHint<HashMap<<span class="hljs-built_in">String</span>, HashSet<<span class="hljs-built_in">String</span>>>>() &#123;
        &#125;));

<span class="hljs-comment">//EventRedistributeSource extends RichSourceFunction run method ,sleep 1-5分钟同步一次规则</span>
DataStreamSource<List<TopicRedistribute>> topicInfo = env.addSource(<span class="hljs-keyword">new</span> EventRedistributeSource());

BroadcastStream<List<TopicRedistribute>> broadcast = topicInfo.broadcast(topicRulesBroadcastState);
KeyedStream<EventResult, <span class="hljs-built_in">String</span>> eventResultStringKeyedStream = eventStream.connect(broadcast).process(<span class="hljs-keyword">new</span> EventRedistributeProcess(topicRulesBroadcastState)).
                keyBy(<span class="hljs-keyword">new</span> KeySelector<EventResult, <span class="hljs-built_in">String</span>>() &#123;
                    @Override
                    public <span class="hljs-built_in">String</span> getKey(EventResult eventResult) throws Exception &#123;
                        <span class="hljs-keyword">return</span> eventResult.getTopic();
                    &#125;
                &#125;);
<span class="copy-code-btn">复制代码</span></code></pre>
<h5 data-id="heading-3">2：离线画像通过spark sql</h5>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/960b3acb49474d5bb3424988d580291d~tplv-k3u1fbpfcp-watermark.image" alt="Snip20210704_11.png" loading="lazy" referrerpolicy="no-referrer">
        1：所有的业务数据收集通过spark streaming消费kafka存储到 hdfs.</p>
<p>        2: 凌晨1点通过dolphinscheduler 调度spark sql 跑所有分层数据。如果app整体的埋点体系构建比较完善，历史遗留无效埋点比较少，可以设置所有埋点都可以上报。如果埋点建设有一定的混乱，建议部分埋点开启。很多无效埋点会占数据块，如果小文件管理不善，可能会导致整个集群宕机的情况。</p>
<p>        3：dwd层的数据建议把不同APP,同一个行为的数据按照project,staticdate 时间分区。这样用户同一个行为数据集中在一起，方便后续的etl .</p>
<p>        4: dm层的数据建议设置优先级，因为同一层的数据可能存在相互依赖的情况。一定要把数据来源， sink 目标表，ddl,exec_sqls(建议 JsonArray存储),app项目，分区，exec_level(建议越小约优先执行)，状态，创建人，时间，修改人，时间(方便以后问题追踪)，还可以扩展到kylin，clickhouse 等olap场景是否使用。</p>
<p>        5：ads 层的数据基本都是聚合数据，目标数据更新到hbase ,elasticsearch 建议不要通过外表的方式更新。hbase的更新建议通过bulkload更新到hbase, elasticsearch的更新建议到通过spark rdd 通过发送kafka消息更新到画像体系。</p>
<p>        6: etl的过程一定要记录一下执行时间，以及失败以后的重试。因为每一层的数据都是层层依赖，不然执行失败以后业务的同学发现数据有问题了。数据的同学再去补充数据，是很尴尬的做法。</p>
<pre><code class="hljs language-js copyable" lang="js"><span class="hljs-keyword">for</span> (i <- execSQLList.indices) &#123;
        <span class="hljs-keyword">var</span> calculateStatus = <span class="hljs-number">0</span>
        val sql: <span class="hljs-built_in">String</span> = HiveUtils.hiveStaticdateReplace(execSQLList(i), jobParams.staticdate)
        val start: Long = System.currentTimeMillis()
        <span class="hljs-keyword">try</span> &#123;
          spark.sql(sql)
          calculateStatus = <span class="hljs-number">1</span>
        &#125; <span class="hljs-keyword">catch</span> &#123;
          <span class="hljs-keyword">case</span> e: <span class="hljs-function"><span class="hljs-params">Exception</span> =></span>
            calculateStatus = <span class="hljs-number">2</span>
            <span class="hljs-keyword">throw</span> e
        &#125; <span class="hljs-keyword">finally</span> &#123;
          val end: Long = System.currentTimeMillis()
          updateDwLoadInfo(job.getId, i + <span class="hljs-number">1</span>, start, end, end - start, calculateStatus,job.getCreator)
        &#125;
 &#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<h5 data-id="heading-4">3：画像结果存储问题 hbase& elasticsearch</h5>
<p>        1：当时做人群画像的时候，没有人群画像的经验。在网上找一些通用化的解决方案，一方面降低技术风险，另外一方面没有独立的服务给业务同学（业务系统有几千的qps）,当时不敢大刀阔斧的干。</p>
<p>       2：存储在hbase中主要方便实时画像，通过用户id或设备id判断用户属性是否满足规则。</p>
<p>      3:  存储在elasticsearch中，一方面通过 elasticsearch-sql 把所有的规则拼装成sql,直接查询画像结果的预估数据，另外一方面我们的画像第一版本是离线的，创建画像结果以后我们通过spark任务，把符合目标的数据存储在redis中。做到与业务系统的解耦，起码不能因为服务问题导致业务系统出现问题。</p>
<p>      4：业务人员根据标签选择对应的规则以后，我们通过规则动态拼装成sql 。sql再解析成dsl，最终的结果通过spark job 存储在redis 中。注意elasticsearch 支持elaticsearch-sql 需要安装对应的plugin. 相关细节可以见：<a href="https://github.com/NLPchina/elasticsearch-sql" target="_blank" rel="nofollow noopener noreferrer">github.com/NLPchina/el…</a></p>
<pre><code class="hljs language-js copyable" lang="js"> <dependency>
       <span class="xml"><span class="hljs-tag"><<span class="hljs-name">groupId</span>></span>org.nlpcn<span class="hljs-tag"></<span class="hljs-name">groupId</span>></span></span>
       <span class="xml"><span class="hljs-tag"><<span class="hljs-name">artifactId</span>></span>elasticsearch-sql<span class="hljs-tag"></<span class="hljs-name">artifactId</span>></span></span>
       <span class="xml"><span class="hljs-tag"><<span class="hljs-name">version</span>></span>7.4.2.0<span class="hljs-tag"></<span class="hljs-name">version</span>></span></span>
 </dependency>

<span class="hljs-comment">/**
     * SQL转换DSL
     *
     * <span class="hljs-doctag">@param <span class="hljs-variable">sql</span></span>
     * <span class="hljs-doctag">@return</span>
     * <span class="hljs-doctag">@throws <span class="hljs-variable">Exception</span></span>
     */</span>
    private <span class="hljs-built_in">String</span> sqlToEsQuery(<span class="hljs-built_in">String</span> sql) throws Exception &#123;
        <span class="hljs-keyword">try</span> &#123;
            Settings settings = Settings.builder().build();
            ThreadPool threadPool = <span class="hljs-keyword">new</span> ThreadPool(settings);
            Client client = <span class="hljs-keyword">new</span> NodeClient(settings, threadPool);
            SearchDao searchDao = <span class="hljs-keyword">new</span> SearchDao(client);
            <span class="hljs-keyword">return</span> searchDao.explain(sql).explain().explain();
        &#125; <span class="hljs-keyword">catch</span> (Exception ex) &#123;
            logger.error(<span class="hljs-string">"error code  xxx"</span> <span class="hljs-built_in">String</span>.format(<span class="hljs-string">"error in xxx sqlToEsQuery method: %s "</span>, sql) + ex);
            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> Exception(xxx, ex);
        &#125;
    &#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<h5 data-id="heading-5">4：业务系统如何提交spark 任务</h5>
<p>1：业务系统封装相关提交参数，http请求通过SparkLauncher 提交spark 任务到yarn 上执行。具体可以在github 搜索一下 SparkLauncher。</p>
<pre><code class="hljs language-js copyable" lang="js"> SparkLauncher launcher = <span class="hljs-keyword">new</span> SparkLauncher()
                .setSparkHome(<span class="hljs-string">"/opt/cloudera/parcels/CDH-6.1.2/lib/spark"</span>)
                .setAppResource(sparkAppPara.getJarPath())
                .setMainClass(sparkAppPara.getMainClass())
                .setMaster(sparkAppPara.getMaster())

                .setDeployMode(sparkAppPara.getDeployMode())
                .setConf(<span class="hljs-string">"spark.driver.memory"</span>, sparkAppPara.getDriverMemory() + <span class="hljs-string">"g"</span>)
                .setConf(<span class="hljs-string">"spark.executor.memory"</span>, sparkAppPara.getExecutorMemory() + <span class="hljs-string">"g"</span>)
                .setConf(<span class="hljs-string">"spark.executor.instances"</span>, sparkAppPara.getExecutorInstances())
                .setConf(<span class="hljs-string">"spark.executor.cores"</span>, sparkAppPara.getExecutorCores())
                .setConf(<span class="hljs-string">"spark.yarn.queue"</span>, <span class="hljs-string">"root.default"</span>);
<span class="copy-code-btn">复制代码</span></code></pre>
<p>2：后续通过团队的同学研究，可以通过livy rest 服务提交spark 任务。我们的kylin cube 构建都是通过livy 提交，整体的性能有较大的提升。b站上有很丰富的livy 介绍，大家可以自行学习。</p>
<h5 data-id="heading-6">5：实时的画像如何毫秒级别响应</h5>
<p>1：我们的大数据部署基于cdh，datanode与hbase混布。如果yarn任务执行起来cpu或内存使用较多，hbase的响应比较慢。基于成本考虑，我们的另外一套hbase没有重新部署一套。而是将数据存储在aliyun hbase 。整体性能比较稳定rt 20ms-50ms左右。</p>
<p>2：hbase 存储问题搞定，hbase查询也是一个问题，到底是基于rowkey 多 column 批量查询，还是基于rowkey 直接把同一个列簇对应的所有数据查出。我们在压测的过程中各有利弊，在这里就不做发散。</p>
<p>基于同一个rowkey,批量查询row对应的不同 column</p>
<pre><code class="hljs language-js copyable" lang="js"><span class="hljs-comment">/**
     * 多列查询数据返回column名以及对应数据
     *
     * <span class="hljs-doctag">@param <span class="hljs-variable">tableName</span></span>
     * <span class="hljs-doctag">@return</span>
     * <span class="hljs-doctag">@throws <span class="hljs-variable">IOException</span></span>
     */</span>
    public <span class="hljs-built_in">Map</span><<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>> batchQueryTableByColumnForMap(<span class="hljs-built_in">String</span> tableName, <span class="hljs-built_in">String</span> rowKey, <span class="hljs-built_in">String</span> family, List<<span class="hljs-built_in">String</span>> column) throws IOException &#123;
        Table table = <span class="hljs-literal">null</span>;
        <span class="hljs-built_in">Map</span><<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>> value = Maps.newHashMap();
        <span class="hljs-keyword">if</span> (StringUtils.isBlank(tableName) || CollectionUtils.isEmpty(column)) &#123;
            <span class="hljs-keyword">return</span> value;
        &#125;

        <span class="hljs-keyword">try</span> &#123;
            table = connection.getTable(TableName.valueOf(tableName));
            List<Get> getList = <span class="hljs-keyword">new</span> ArrayList();
            <span class="hljs-keyword">for</span> (<span class="hljs-built_in">String</span> c : column) &#123;
                Get get = <span class="hljs-keyword">new</span> Get(Bytes.toBytes(rowKey));
                get.addColumn(Bytes.toBytes(family), Bytes.toBytes(c));
                getList.add(get);
            &#125;
            Result[] results = table.get(getList);<span class="hljs-comment">//重点在这，直接查getList<Get></span>
            <span class="hljs-keyword">for</span> (Result result : results) &#123;<span class="hljs-comment">//对返回的结果集进行操作</span>
                <span class="hljs-keyword">for</span> (Cell cell : result.rawCells()) &#123;
                    value.put(Bytes.toString(Bytes.copy(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength())), Bytes.toString(CellUtil.cloneValue(cell)));
                &#125;
            &#125;
        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;
            e.printStackTrace();
        &#125; <span class="hljs-keyword">finally</span> &#123;
            <span class="hljs-keyword">try</span> &#123;
                assert table != <span class="hljs-literal">null</span>;
                table.close();
            &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;
                e.printStackTrace();
            &#125;
        &#125;
        <span class="hljs-keyword">return</span> value;
    &#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<p>    根据rowkey查询出一个列簇对应的所有字段</p>
<pre><code class="hljs language-js copyable" lang="js"><span class="hljs-comment">/**
     * 获取值
     * expression : get 'tableName','rowkey','family:column'
     *
     * <span class="hljs-doctag">@param </span>rowKey 行id
     * <span class="hljs-doctag">@param </span>family 列族名
     * <span class="hljs-doctag">@return <span class="hljs-variable">string</span></span>
     */</span>
    public  <span class="hljs-built_in">Map</span><<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>> <span class="hljs-function"><span class="hljs-title">getRowKeyValueMap</span>(<span class="hljs-params"><span class="hljs-built_in">String</span> tableName, <span class="hljs-built_in">String</span> rowKey, <span class="hljs-built_in">String</span> family</span>)</span> &#123;

        Table table = <span class="hljs-literal">null</span>;
        <span class="hljs-built_in">Map</span><<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>> value = Maps.newHashMap();


        <span class="hljs-keyword">if</span> (StringUtils.isBlank(tableName) || StringUtils.isBlank(family) || StringUtils.isBlank(rowKey)) &#123;
            <span class="hljs-keyword">return</span> value;
        &#125;

        <span class="hljs-keyword">try</span> &#123;
            table = connection.getTable(TableName.valueOf(tableName));
            Get g = <span class="hljs-keyword">new</span> Get(rowKey.getBytes());
            Result result = table.get(g);
            List<Cell> ceList = result.listCells();
            <span class="hljs-keyword">if</span> (ceList != <span class="hljs-literal">null</span> && ceList.size() > <span class="hljs-number">0</span>) &#123;
                <span class="hljs-keyword">for</span> (Cell cell : ceList) &#123;
                    value.put(Bytes.toString(Bytes.copy(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength())), Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));
                &#125;
            &#125;
        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;
            e.printStackTrace();
        &#125; <span class="hljs-keyword">finally</span> &#123;
            <span class="hljs-keyword">try</span> &#123;
                assert table != <span class="hljs-literal">null</span>;
                table.close();
            &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;
                e.printStackTrace();
            &#125;
        &#125;
        <span class="hljs-keyword">return</span> value;
    &#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<h5 data-id="heading-7">6：如何根据数据动态判断画像结果</h5>
<p>        1：这里要非常感谢一下阿里的qlexpress，ql判断支持丰富，大部分语法跟sql类似。我们只需要业务的同学创建规则的时候，把相关规则转为ql语法，动态的传入相关画像参数。废话不多说，上代码。（目前来看运行比较稳定）</p>
<pre><code class="hljs language-js copyable" lang="js"> public <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> main(<span class="hljs-built_in">String</span>[] args) throws Exception &#123;
        ExpressRunner runner = <span class="hljs-keyword">new</span> ExpressRunner();
        DefaultContext<<span class="hljs-built_in">String</span>, <span class="hljs-built_in">Object</span>> context = <span class="hljs-keyword">new</span> DefaultContext<<span class="hljs-built_in">String</span>, <span class="hljs-built_in">Object</span>>();
        context.put(<span class="hljs-string">"vip_endtime"</span>,1623513700000L);
        context.put(<span class="hljs-string">"vip_accumulat_count"</span>,<span class="hljs-string">"11"</span>);
        context.put(<span class="hljs-string">"last_buy_member_type"</span>,<span class="hljs-number">2</span>);
        context.put(<span class="hljs-string">"keyword"</span>,<span class="hljs-string">"你视频打啊啊"</span>);
        context.put(<span class="hljs-string">"from_app"</span>,<span class="hljs-number">12</span>);
        <span class="hljs-built_in">String</span> express = <span class="hljs-string">" (   ( vip_accumulat_count != null  and  vip_accumulat_count> 0 ) and  (  ( (  (vip_endtime !=null && vip_endtime >= 1623513600000 and vip_endtime < 1624204800000 )  ) )"</span> +
                <span class="hljs-string">" and (last_buy_member_type!=null && last_buy_member_type != 1))) and  from_app ==12  and keyword  like '%你好%' "</span>;
        <span class="hljs-built_in">Object</span> r = runner.execute(express, context, <span class="hljs-literal">null</span>, <span class="hljs-literal">true</span>, <span class="hljs-literal">true</span>);
        System.out.println(r);

    &#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<h1 data-id="heading-8">3：画像的一些理解</h1>
<p>人群画像不是万金油，如果想要做好用户留存，付费。还是需要回归到用户的核心诉求中。根据相关用户行为分析把核心功能做好，吃透。相信用户会为你提供的服务买单。欢迎大家一起交流学习。</p></div>  
</div>
            