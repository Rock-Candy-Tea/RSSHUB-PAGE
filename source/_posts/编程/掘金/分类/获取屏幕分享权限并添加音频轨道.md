
---
title: '获取屏幕分享权限并添加音频轨道'
categories: 
 - 编程
 - 掘金
 - 分类
headimg: 'https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/68e714511cf24dd9bd045e041295dcdb~tplv-k3u1fbpfcp-watermark.image'
author: 掘金
comments: false
date: Fri, 09 Jul 2021 22:35:48 GMT
thumbnail: 'https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/68e714511cf24dd9bd045e041295dcdb~tplv-k3u1fbpfcp-watermark.image'
---

<div>   
<div class="markdown-body"><style>.markdown-body&#123;word-break:break-word;line-height:1.75;font-weight:400;font-size:15px;overflow-x:hidden;color:#333&#125;.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6&#123;line-height:1.5;margin-top:35px;margin-bottom:10px;padding-bottom:5px&#125;.markdown-body h1&#123;font-size:30px;margin-bottom:5px&#125;.markdown-body h2&#123;padding-bottom:12px;font-size:24px;border-bottom:1px solid #ececec&#125;.markdown-body h3&#123;font-size:18px;padding-bottom:0&#125;.markdown-body h4&#123;font-size:16px&#125;.markdown-body h5&#123;font-size:15px&#125;.markdown-body h6&#123;margin-top:5px&#125;.markdown-body p&#123;line-height:inherit;margin-top:22px;margin-bottom:22px&#125;.markdown-body img&#123;max-width:100%&#125;.markdown-body hr&#123;border:none;border-top:1px solid #ddd;margin-top:32px;margin-bottom:32px&#125;.markdown-body code&#123;word-break:break-word;border-radius:2px;overflow-x:auto;background-color:#fff5f5;color:#ff502c;font-size:.87em;padding:.065em .4em&#125;.markdown-body code,.markdown-body pre&#123;font-family:Menlo,Monaco,Consolas,Courier New,monospace&#125;.markdown-body pre&#123;overflow:auto;position:relative;line-height:1.75&#125;.markdown-body pre>code&#123;font-size:12px;padding:15px 12px;margin:0;word-break:normal;display:block;overflow-x:auto;color:#333;background:#f8f8f8&#125;.markdown-body a&#123;text-decoration:none;color:#0269c8;border-bottom:1px solid #d1e9ff&#125;.markdown-body a:active,.markdown-body a:hover&#123;color:#275b8c&#125;.markdown-body table&#123;display:inline-block!important;font-size:12px;width:auto;max-width:100%;overflow:auto;border:1px solid #f6f6f6&#125;.markdown-body thead&#123;background:#f6f6f6;color:#000;text-align:left&#125;.markdown-body tr:nth-child(2n)&#123;background-color:#fcfcfc&#125;.markdown-body td,.markdown-body th&#123;padding:12px 7px;line-height:24px&#125;.markdown-body td&#123;min-width:120px&#125;.markdown-body blockquote&#123;color:#666;padding:1px 23px;margin:22px 0;border-left:4px solid #cbcbcb;background-color:#f8f8f8&#125;.markdown-body blockquote:after&#123;display:block;content:""&#125;.markdown-body blockquote>p&#123;margin:10px 0&#125;.markdown-body ol,.markdown-body ul&#123;padding-left:28px&#125;.markdown-body ol li,.markdown-body ul li&#123;margin-bottom:0;list-style:inherit&#125;.markdown-body ol li .task-list-item,.markdown-body ul li .task-list-item&#123;list-style:none&#125;.markdown-body ol li .task-list-item ol,.markdown-body ol li .task-list-item ul,.markdown-body ul li .task-list-item ol,.markdown-body ul li .task-list-item ul&#123;margin-top:0&#125;.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul&#123;margin-top:3px&#125;.markdown-body ol li&#123;padding-left:6px&#125;.markdown-body .contains-task-list&#123;padding-left:0&#125;.markdown-body .task-list-item&#123;list-style:none&#125;@media (max-width:720px)&#123;.markdown-body h1&#123;font-size:24px&#125;.markdown-body h2&#123;font-size:20px&#125;.markdown-body h3&#123;font-size:18px&#125;&#125;</style><h2 data-id="heading-0">WebRTC简介</h2>
<p>WebRTC是一个由Google发起的实时通信解决方案，</p>
<p>其中包含音视频采集、编解码、数据传输、音视频展示等功能。</p>
<p>虽然其名为WebRTC，但是实际上它不仅支持Web之间的音视频通讯，还支持Android和iOS端。</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/68e714511cf24dd9bd045e041295dcdb~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p>
<p>底层技术</p>
<ul>
<li>图像引擎（VideoEngine）
<ul>
<li>VP8编解码</li>
<li>jitter buffer：动态抖动缓冲</li>
<li>Image enhancements：图像增益</li>
</ul>
</li>
<li>声音引擎（VoiceEngine）
<ul>
<li>iSAC/iLBC/Opus等编解码</li>
<li>NetEQ语音信号处理</li>
<li>回声消除和降噪</li>
</ul>
</li>
<li>会话管理（Session Management）</li>
<li>iSAC音效压缩</li>
<li>VP8 Google自家WebM项目的影片编解码器</li>
<li>APIs（Native C++ API，Web API）</li>
</ul>
<p>WebRTC 虽然底层实现极其复杂，但是面向开发者的API还是非常简洁的，主要分为三个方面：</p>
<ul>
<li>Network Stream API
<ul>
<li>MediaStream 媒体数据流</li>
<li>MediaStreamTrack 媒体源</li>
</ul>
</li>
<li>RTCPeerConnection
<ul>
<li>RTCPeerConnection 允许用户在两个浏览器之间直接通讯</li>
<li>RTCIceCandidate ICE协议的候选者</li>
<li>RTCIceServe</li>
</ul>
</li>
<li>DataChannel</li>
</ul>
<h3 data-id="heading-1">Network Stream API</h3>
<p>主要有两个API：MediaStream与MediaStreamTrack。</p>
<p>MediaStreamTrack 代表一种单类型数据流（VideoTrack或AudioTrack），</p>
<p>一个MediaStreamTrack代表一条媒体轨道，这给我们提供了混合不同轨道实现多种特效的可能性。</p>
<p>MediaStream 是一个完整的音视频流，可以包含多个 MediaStreamTrack 对象，</p>
<p>它的主要作用是协同多个媒体轨道同时进行播放，这就是我们平时说的音画同步。</p>
<p>eg：</p>
<p>LocalMediaStream 表示来自本地媒体捕获设备（如网络摄像头、麦克风等）的媒体流。</p>
<p>要创建和使用本地流，web应用程序必须通过 getUserMedia() 函数请求用户访问。</p>
<p>一旦应用程序完成，它可以通过调用 LocalMediaStream 上的 stop() 函数来撤销自己的访问权限。</p>
<h3 data-id="heading-2">RTCPeerConnection</h3>
<p>上面我们只是成功的拿到了MediaStream流媒体对象，但是仍然仅限于本地查看。</p>
<p>如何将流媒体与对方互相交换（实现音视频通话）？</p>
<p>答案是我们必须建立<strong>点对点连接（peer-to-peer）</strong>，这就是RTCPeerConnection要做的事情。</p>
<p>在此之前，我们得了解一个概念：<strong>信令服务器</strong>。</p>
<p>两台公网上的设备要互相知道对方是谁，需要有一个中间方去协商交换它们的信息。</p>
<p>信令服务器干的就是这个事情 —— 牵线搭桥。</p>
<p>一旦建立了对等连接，就可以将媒体流（临时定义的 MediaStream 对象）直接发送到远程浏览器。</p>
<h3 data-id="heading-3">DataChannel</h3>
<p>每个流实际上代表一个单向逻辑通道，提供顺序传送的概念。</p>
<p>消息序列可以有序或无序发送。消息传递顺序仅保留给在同一流上发送的所有有序消息。</p>
<p>但是，DataChannel API 已被设计为双向的，这意味着每个 DataChannel 都是由传入和传出SCTP流的捆绑组成的。</p>
<p>当在实例化的 PeerConnection 对象上首次调用 CreateDataChannel() 函数时，将执行 DataChannel 设置（即创建SCTP关联）。</p>
<p>随后每次对 CreateDataChannel() 函数的调用都只会在现有SCTP关联内创建一个新的 DataChannel。</p>
<h2 data-id="heading-4">数据处理和传输过程</h2>
<p>WebRTC <strong>对外</strong>提供两个线程：Signal和Worker，前者负责信令数据的处理和传输，后者负责媒体数据的处理和传输。</p>
<p>WebRTC <strong>对内</strong>有一系列线程各司其职，相互协作完成数据流管线。</p>
<p>以一个video数据的处理流程为例，</p>
<p>Capture线程从摄像头采集原始数据，接下来到达Worker线程，</p>
<p>Worker线程起搬运工的作用，没有对数据做特别处理，而是转发到Encoder线程，</p>
<p>Encoder线程调用具体的编码器（如VP8、H264）对原始数据进行编码，编码后的输出进一步进行RTP封包形成RTP数据包，</p>
<p>然后RTP数据包发送到Pacer线程进行平滑发送，Pacer线程会把RTP数据包推送到Network线程，最终发送到网络Internet中。</p>
<h4 data-id="heading-5">音视频录制原理</h4>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/14a63fa396264000b24ca137728954a0~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p>
<h4 data-id="heading-6">音视频播放原理</h4>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bd05ab70ff354438a11cd2c216524797~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p>
<h2 data-id="heading-7">获取摄像头的视频流</h2>
<p>MediaStream 接口用于表示媒体数据流。（流可以是输入或输出，也可以是本地或远程）</p>
<p>单个 MediaStream 可以包含零个或多个轨道。（每个轨道都有一个对应的 MediaStreamTrack 对象）</p>
<p>MediaStreamTrack 表示包含一个或多个通道的内容，其中，通道之间具有定义的已知的关系。</p>
<p>MediaStream 中的所有轨道在渲染时是同步的。</p>
<p>下图显示了由单个视频轨道和两个不同的音频（左声道和右声道）轨道组成的 MediaStream。</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6f81d04f4a7c4d2f847233b888f4ff74~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p>
<p>平时我们在开发时总是习惯于定义 &#123;video: true, audio: true&#125; 这两个参数，然后通过写css样式控制展示视频窗口。</p>
<p>但其实API本来带有一种约束，可以初始化视频的宽高比，面向照相机的模式（正面或背面），音频和视频帧率等等。</p>
<pre><code class="copyable">navigator.mediaDevices
    .getUserMedia(&#123;
        audio: true,
        video: &#123;
            width: 1280,
            height: 720
        &#125;
    &#125;)
    .then(stream => &#123;
    console.log(stream);
&#125;);
<span class="copy-code-btn">复制代码</span></code></pre>
<p>如果想实现录屏（屏幕共享）的话，就是获取媒体的参数改一下，比如将摄像头改成屏幕：</p>
<pre><code class="copyable">navigator.mediaDevices
    .getUserMedia(&#123;
        video: &#123;
            mediaSource: 'screen'
        &#125;
    &#125;)
    .then(stream => &#123;
    console.log(stream);
&#125;);
<span class="copy-code-btn">复制代码</span></code></pre>
<p>这个目前只有火狐浏览器支持，（而Chrome和Edge是采用另外的方式，见下文）</p>
<p>然后就会弹一个框询问要录制的应用窗口，如下图所示：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5996eb50eb6e4d659e639717de6e58b8~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p>
<p>约束的详细用法可以看这篇博客： <a href="https://link.juejin.cn/?target=https%3A%2F%2Fblog.addpipe.com%2Fgetusermedia-video-constraints%2F" target="_blank" rel="nofollow noopener noreferrer" title="https://blog.addpipe.com/getusermedia-video-constraints/" ref="nofollow noopener noreferrer">getUserMedia() Video Constraints</a></p>
<p>Ok~ 这部分内容非常简单，下面是一个简单的Demo：</p>
<pre><code class="copyable"><!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
  </head>
  <body>
    <h1><code>getUserMedia()</code> very simple demo</h1>
    <video></video>
    <script>
      navigator.getUserMedia =
        navigator.getUserMedia ||
        navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia;
 
      const localVideo = document.querySelector('video');
      // MediaStreamConstraints 用于指定请求哪种轨道（音频，视频或两者）
      const constraints = &#123; audio: false, video: true &#125;;
 
      function successCallback(stream) &#123;
        localVideo.srcObject = stream;
        localVideo.play();
      &#125;
 
      function errorCallback(error) &#123;
        console.error('navigator.getUserMedia error: ', error);
      &#125;
 
      if (navigator.mediaDevices.getUserMedia) &#123;
        navigator.mediaDevices
          .getUserMedia(constraints)
          .then(successCallback)
          .catch(errorCallback);
      &#125; else &#123;
        navigator.getUserMedia(constraints, successCallback, errorCallback);
      &#125;
    </script>
  </body>
</html>
<span class="copy-code-btn">复制代码</span></code></pre>
<p>上面我们了解了屏幕分享的API，感觉跟我们常用的“屏幕共享”好像。</p>
<p>那么可不可以用此进行一个屏幕录制呢？</p>
<p>“纸上得来终觉浅，觉知此事要躬行。”看着挺简单的一个东西，没有落实都算说大话。</p>
<p>首先画上三个按钮：</p>
<pre><code class="copyable"><button @click="start" :disabled="disabled.start">开始录制</button>
<button @click="stop" :disabled="disabled.stop">结束录制</button>
<button @click="download" :disabled="disabled.download">下载文件</button>
<span class="copy-code-btn">复制代码</span></code></pre>
<p>添加上简单的样式：</p>
<pre><code class="copyable">button &#123;
    margin: 0 1em 1em 0;
    padding: 0.5em 1.2em 0.6em 1.2em;
    border: none;
    border-radius: 4px;
    background-color: #d84a38;
    font-family: 'Roboto', sans-serif;
    font-size: 0.8em;
    color: white;
    cursor: pointer;
&#125;
button:hover &#123;
    background-color: #c03434;
&#125;
button[disabled] &#123;
    background-color: #c03434;
    pointer-events: none;
&#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<p>初始化数据：</p>
<pre><code class="copyable">data() &#123;
    return &#123;
        // 本地流
        stream: null,
        // 媒体录制
        mediaRecorder: null,
        // 数据块
        chunks: [],
        // 录制结果
        recording: null,
        // 按钮禁用
        disabled: &#123;
            start: false,
            stop: true,
            download: true
        &#125;
    &#125;
&#125;,
<span class="copy-code-btn">复制代码</span></code></pre>
<p>需要的方法：</p>
<pre><code class="copyable">methods: &#123;
    // 获取屏幕分享的权限
    openScreenCapture() &#123;
        ...
    &#125;,
     // 开始屏幕分享录制
    async start() &#123;
        ....
    &#125;,
    // 停止屏幕分享录制
    stop() &#123;
        ...
    &#125;,
    // 下载录制的视频内容
    download() &#123;
        ...
    &#125;
&#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<p>ok~ 下面进入每个方法内部看看都需要些什么操作。</p>
<p>首先我们要获取屏幕分享的权限，</p>
<p>由于每个浏览器的实现不同，所以这里需要做个兼容处理。</p>
<pre><code class="copyable">// 获取屏幕分享的权限
openScreenCapture() &#123;
    if (navigator.getDisplayMedia) &#123;
        return navigator.getDisplayMedia(&#123; video: true &#125;);
    &#125; else if (navigator.mediaDevices.getDisplayMedia) &#123;
        return navigator.mediaDevices.getDisplayMedia(&#123; video: true &#125;);
    &#125; else &#123;
        return navigator.mediaDevices.getUserMedia(&#123;
            video: &#123; mediaSource: 'screen' &#125;,
        &#125;);
    &#125;
&#125;,
<span class="copy-code-btn">复制代码</span></code></pre>
<p>当点击“开始录制”按钮后，依次设置三个按钮的禁用状态，</p>
<p>如果之前录制的内容没有清空，那么就用revokeObjectURL方法移除。</p>
<p>获取屏幕分享权限后，实例化一个MediaRecorder对象进行录制存储。</p>
<p>监听dataavailable，当有可用数据时，将其push进数据块中进行存储。</p>
<pre><code class="copyable">// 开始屏幕分享录制
async start() &#123;
    this.disabled.start = true;
    this.disabled.stop = false;
    this.disabled.download = true;
    if (this.recording) &#123;
        window.URL.revokeObjectURL(this.recording);
    &#125;
    // 获取屏幕分享权限
    this.stream = await this.$options.methods.openScreenCapture();
    // 实例化一个MediaRecorder对象
    this.mediaRecorder = new MediaRecorder(this.stream, &#123;mimeType: 'video/webm'&#125;);
    // 监听可用数据
    this.mediaRecorder.addEventListener('dataavailable', event => &#123;
        if (event.data && event.data.size > 0) &#123;
            this.chunks.push(event.data);
        &#125;
    &#125;);
    // 开始录制
    this.mediaRecorder.start(10);
&#125;,
<span class="copy-code-btn">复制代码</span></code></pre>
<p>当点击“停止录制”按钮后，需要将数据块保存到一个内存URL中方便后续下载使用。</p>
<pre><code class="copyable">// 停止屏幕分享录制
stop() &#123;
    this.disabled.start = true;
    this.disabled.stop = true;
    this.disabled.download = false;
    // 停止录制
    this.mediaRecorder.stop();
    // 释放MediaRecorder
    this.mediaRecorder = null;
    // 停止所有流式视频轨道
    this.stream.getTracks().forEach(track => track.stop());
    // 释放getDisplayMedia或getUserMedia
    this.stream = null;
    // 获取当前文件的一个内存URL
    this.recording = window.URL.createObjectURL(new Blob(this.chunks, &#123;type: 'video/webm'&#125;));
&#125;,
<span class="copy-code-btn">复制代码</span></code></pre>
<p>当点击“下载文件”按钮时，更新下载元素的链接href，并自动触发点击事件进行弹窗提示下载。</p>
<pre><code class="copyable">// 下载录制的视频内容
download() &#123;
    this.disabled.start = false;
    this.disabled.stop = true;
    this.disabled.download = true;
       
    const downloadLink = document.querySelector('a#download');
    downloadLink.href = this.recording;
    // download 规定作为文件名来使用的文本
    downloadLink.download = 'screen-recording.webm';
    downloadLink.click();
&#125;
<span class="copy-code-btn">复制代码</span></code></pre>
<p>当进行完以上操作后，发现确实将屏幕分享的导出一段视频了。</p>
<p>但是…</p>
<p>这个视频是没有声音的，音量按钮处为一个“静音”标识，且不能调节音量大小。</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c150dec5f386433d9b876473ae16cb12~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p>
<p>getDisplayMedia 默认只支持视频轨道，不支持音频轨道，</p>
<p>反正我试了几个浏览器均不支持音频轨道，没能验证有的博客写的如下开启音频轨道：</p>
<pre><code class="copyable">navigator.mediaDevices.getDisplayMedia(&#123;
    video: true,
    audio: true
&#125;)
<span class="copy-code-btn">复制代码</span></code></pre>
<p>不过，在经过上一章节的学习，我们知道MediaStream是由多个MediaStreamTrack组成的，</p>
<p>那么应该就可以给当前getDisplayMedia获取的视频轨道，再加上一个音频轨道，组成一个MediaStream。</p>
<p>其他部分不用更改，只用在MediaRecorder录制这个MediaStream之前，将其进行改造即可。</p>
<pre><code class="copyable">...
// 获取麦克风权限
const audioTrack = await navigator.mediaDevices.getUserMedia(&#123; audio: true &#125;);
// 获取屏幕分享权限
this.stream = await this.$options.methods.openScreenCapture();
// 给MediaStream添加音频轨道
this.stream.addTrack(audioTrack.getAudioTracks()[0]);
// 实例化一个MediaRecorder对象
this.mediaRecorder = new MediaRecorder(this.stream, &#123;mimeType: 'video/webm'&#125;);
...
<span class="copy-code-btn">复制代码</span></code></pre>
<p>此刻，就变成一个有声音的真正的屏幕分享了 ~</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2ef3aaa1b3754925940c140d08ebdb7a~tplv-k3u1fbpfcp-watermark.image" alt="image.png" loading="lazy" referrerpolicy="no-referrer"></p></div>  
</div>
            