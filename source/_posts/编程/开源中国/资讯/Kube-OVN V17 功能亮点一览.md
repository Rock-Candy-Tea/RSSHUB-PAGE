
---
title: 'Kube-OVN V1.7 功能亮点一览'
categories: 
 - 编程
 - 开源中国
 - 资讯
headimg: 'https://picsum.photos/400/300?random=6064'
author: 开源中国
comments: false
date: Tue, 27 Jul 2021 14:35:00 GMT
thumbnail: 'https://picsum.photos/400/300?random=6064'
---

<div>   
<div class="content">
                                                                    
                                                        <p>我们上月发布的Kube-OVN V1.7版本相比之前做了一些比较大的调整，发布短短几周之内得到了用户的大量下载和使用反馈，之后又紧接着发布了Kube-OVN V1.71，对bug做了一些修正，并增加了以下几个新功能：</p> 
<p>1. 重构 underlay/vlan 模式，增加更灵活的网卡选择和多网络支持</p> 
<p>2. kubectl ko 新增ovn集群状态展示备份等操作</p> 
<p>3. 支持集群内不同名网卡建立隧道</p> 
<p>4. 修复 1.7.0 内的 bug，增强稳定性和性能</p> 
<p>首先感谢大家对新版本的关注，下面详细介绍一下 V1.7的功能亮点，欢迎社区用户们下载、试用、提交pr以及参与讨论。</p> 
<h4><strong>01. VPC 可以支持外部的 NAT 网关</strong></h4> 
<p>我们上一个版本的VPC做了网络地址的隔离，但是对于用户自定义的VPC如何出网，没有提供一套完整的解决方案，更多的是需要依赖用户自定义的网关或者是负载均衡来实现这样的内外互通。但是从1.7版本开始，我们通过内置一个外部的NAT网关，用户体验类似在公有云上使用VPC，有一个单独的网关给每个租户来提供这样出网的设置。</p> 
<p>这个功能是由天翼云的社区贡献者集成进来的。天翼云在Kube-OVN的VPC方面做了很多的功能，大家如果有兴趣的话可以和我们一起来探讨。</p> 
<h4><strong>02. Pod支持多个OVN网络</strong></h4> 
<p>了解Kube-OVN的小伙伴都知道，之前的版本是支持多网络的，但是我们的多网络功能限于主网卡是Kube-OVN，附属网卡是另一个网络，我们可以给第二个网卡提供比如像子网还有固定IP这样的功能。</p> 
<p>从V1.7版本开始，我们已经做到容器里面的多网络、多张网卡都属于Kube-OVN的网络，也就是说一个容器可以属于多个子网，这几个子网都是在Kube-OVN中定义好的，这样更方便流量进行编排处理。这个功能也是和VPC相互配合的。现在用户可以设定某一个pod是运行在多个子网上，实现多个网卡的管理。</p> 
<h4><strong>03. 支持集中式网关的多活</strong></h4> 
<p>在之前的旧版本里，Kube-OVN的集中式网关的高可用是一个储备的方式。也就是说在同一个时间点，yaml里面写了多个节点，只有一个会真正承担流量，当这个节点挂了的时候，才会做节点的切换。</p> 
<p>现在Kube-OVN v1.7版本我们支持多活的集中式网关，如果yaml里面在集中式网关里写多个节点，这多个节点之间会同时承担流量，进行负载均衡。一方面，增加整个集中式网关出口的带宽，不会出现以前单点瓶颈，并且在故障切换的时候，损失时间和切换时间变得更短。我们其实是通过ECMP的路由来实现的，把出网的流量通过路由的方式分散到多个节点上，并且不断探测多个节点的存活。这种解决方案对于生产环境用户，或者是对整体性能非常有要求的用户来说是比较好的。</p> 
<h4><strong>04. 实现Overlay和Underlay的混合模式</strong></h4> 
<p>在之前的一些部署模式里面，Overlay和Underlay这两种模式在部署的时候是需要进行区分的，也就是说集群要么都是Overlay的，要么都是Underlay的。</p> 
<p>从v1.7版本开始，我们支持混合部署，相当于集群在部署好Kube-OVN网络之后，可以再根据每个子网分别定义属于Overlay还是属于Underlay，实现了两种网络模式在一个集群内共存，对于用户来说使用体验更加友好。因为不是所有的容器都需要固定某一种模式，现在可以根据实际情况，将一个容器部署在Overlay的网络，或者是部署在Underlay的网络，能够更加适应复杂的场景需求。</p> 
<h4><strong>05. 支持将外出的流量重新定向到另一个外部网关</strong></h4> 
<p>此功能是Kube-OVN和F5一起完成的。F5可以作为整个集群的出网的网关，这样用户可以在出网的网关这一侧进行安全策略的设置和统一的策略处理。同时，Kube-OVN这一侧可以将外出流量定向到某个指定的网关节点，这个网关节点可以是任何自定义用户的网关。当用户把所有的外出流量都重定向到一个指定的机器或者网关上之后，就可以在网关上实现更复杂的出网的策略。</p> 
<p>我们知道，Kubernetes 目前有ingress的概念，但是egress目前还没有很明确的定义。如果我们从网络的角度来看，ingress可以进行管控，那么egress其实也应该有集中式的管控，这样整体的网络方案才是一个比较完整的方案。</p> 
<h4><strong>06. 对Vxlan进行支持</strong></h4> 
<p>大家知道旧版本中是Geneve这种类型的封装模式，在某些场景下，对用户和硬件合作伙伴来说，Vxlan的方式会更友好一些。但由于OVN目前的一些限制，Vxlan在ACL上的一些功能会受到一些阉割，所以如果大家对ACL没有需求，但是对Vxlan这种封装格式有需求的话，可以在V1.7版本选择使用Vxlan的方式来做 overlay网络。</p> 
<p><strong>关于 Kube-OVN</strong></p> 
<p>Kube-OVN是一款由灵雀云自主研发的<strong>开源企业级云原生Kubernetes容器网络编排系统</strong>，它通过将OpenStack领域成熟的网络功能平移到Kubernetes，极大增强了Kubernetes容器网络的安全性、可运维性、管理性和性能，为Kubernetes生态的落地带来了独特的价值。</p> 
<p>Kube-OVN可提供跨云网络管理、传统网络架构与基础设施的互联互通、边缘集群落地等复杂应用场景的能力支持，解除Kubernetes网络面临的性能和安全监控的掣肘，为基于Kubernetes架构原生设计的系统提供最为成熟的网络底座，提升用户对Kubernetes生态Runtime的稳定性和易用性。</p> 
<p>2021年初，<strong>Kube-OVN成为全球范围内首个被CNCF纳入托管的开源CNI网络项目</strong>，也是中国容器公司首次将独立设计研发的项目成功贡献进入CNCF基金会。</p>
                                        </div>
                                      
</div>
            