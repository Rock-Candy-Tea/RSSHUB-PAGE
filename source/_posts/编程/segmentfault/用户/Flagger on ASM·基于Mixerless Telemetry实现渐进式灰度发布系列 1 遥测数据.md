
---
title: 'Flagger on ASM·基于Mixerless Telemetry实现渐进式灰度发布系列 1 遥测数据'
categories: 
 - 编程
 - segmentfault
 - 用户
headimg: 'https://segmentfault.com/img/bVcRomy'
author: segmentfault
comments: false
date: 2021-04-20 04:09:54
thumbnail: 'https://segmentfault.com/img/bVcRomy'
---

<div>   
<p>简介： 服务网格ASM的Mixerless Telemetry技术，为业务容器提供了无侵入式的遥测数据。遥测数据一方面作为监控指标被ARMPS/prometheus采集，用于服务网格可观测性；另一方面被HPA和flaggers使用，成为应用级扩缩容和渐进式灰度发布的基石。 本系列聚焦于遥测数据在应用级扩缩容和渐进式灰度发布上的实践，将分三篇介绍遥测数据(监控指标)、应用级扩缩容，和渐进式灰度发布。<br>序<br>服务网格ASM的Mixerless Telemetry技术，为业务容器提供了无侵入式的遥测数据。遥测数据一方面作为监控指标被ARMPS/prometheus采集，用于服务网格可观测性；另一方面被HPA和flaggers使用，成为应用级扩缩容和渐进式灰度发布的基石。</p><p>本系列聚焦于遥测数据在应用级扩缩容和渐进式灰度发布上的实践，将分三篇介绍遥测数据(监控指标)、应用级扩缩容，和渐进式灰度发布。</p><p>总体架构<br>本系列的总体架构如下图所示：</p><p>ASM下发Mixerless Telemetry相关的EnvoyFilter配置到各ASM sidecar(envoy)，启用应用级监控指标的采集。<br>业务流量通过Ingress Gateway进入，各ASM sidecar开始采集相关监控指标。<br>Prometheus从各POD上采集监控指标。<br>HPA通过Adapter从Prometheus查询相关POD的监控指标，并根据配置进行扩缩容。<br>Flagger通过Prometheus查询相关POD的监控指标，并根据配置向ASM发起VirtualService配置更新。<br>ASM下发VirtualService配置到各ASM sidecar，从而实现渐进式灰度发布。<br><span class="img-wrap"><img class="lazy" src="https://segmentfault.com/img/bVcRomy" alt="image.png" title="image.png" referrerpolicy="no-referrer"></span></p><p>Flagger渐进式发布流程<br>Flagger官网描述了渐进式发布流程，这里翻译如下：</p><p>探测并更新灰度Deployment到新版本<br>灰度POD实例数从0开始扩容<br>等待灰度POD实例数到达HPA定义的最小副本数量<br>灰度POD实例健康检测<br>由flagger-loadtester实例发起acceptance-test验证<br>灰度发布在验证失败时终止<br>由flagger-loadtester实例发起load-test验证<br>在配置流量复制时开始从生产全流量复制到灰度<br>每分钟从Prometheus查询并检测请求成功率和请求延迟等监控指标<br>灰度发布在监控指标不符预期的数量到达阈值时终止<br>达到配置中迭代的次数后停止流量复制<br>开始切流到灰度POD实例<br>更新生产Deployment到新版本<br>等待生产Deployment滚动升级完毕<br>等待生产POD实例数到达HPA定义的最小副本数量<br>生产POD实例健康检测<br>切流回生产POD实例<br>灰度POD实例缩容至0<br>发送灰度发布分析结果通知<br>原文如下：</p><p>With the above configuration, Flagger will run a canary release with the following steps:</p><p>detect new revision (deployment spec, secrets or configmaps changes)<br>scale from zero the canary deployment<br>wait for the HPA to set the canary minimum replicas<br>check canary pods health<br>run the acceptance tests<br>abort the canary release if tests fail<br>start the load tests<br>mirror 100% of the traffic from primary to canary<br>check request success rate and request duration every minute<br>abort the canary release if the metrics check failure threshold is reached<br>stop traffic mirroring after the number of iterations is reached<br>route live traffic to the canary pods<br>promote the canary (update the primary secrets, configmaps and deployment spec)<br>wait for the primary deployment rollout to finish<br>wait for the HPA to set the primary minimum replicas<br>check primary pods health<br>switch live traffic back to primary<br>scale to zero the canary<br>send notification with the canary analysis result<br>前提条件<br>已创建ACK集群，详情请参见创建Kubernetes托管版集群。<br>已创建ASM实例，详情请参见创建ASM实例。<br>Setup Mixerless Telemetry<br>本篇将介绍如何基于ASM配置并采集应用级监控指标(比如请求数量总数istio_requests_total和请求延迟istio_request_duration等)。主要步骤包括创建EnvoyFilter、校验envoy遥测数据和校验Prometheus采集遥测数据。</p><p>1 EnvoyFilter<br>登录ASM控制台，左侧导航栏选择服务网格 >网格管理，并进入ASM实例的功能配置页面。</p><p>勾选开启采集Prometheus 监控指标<br>点选启用自建 Prometheus，并填入Prometheus服务地址：`prometheus:9090(本系列将使用社区版Prometheus，后文将使用这个配置)。如果使用阿里云产品ARMS，请参考集成ARMS Prometheus实现网格监控。<br>勾选启用 Kiali(可选)<br><span class="img-wrap"><img class="lazy" src="https://segmentfault.com/img/bVcRomA" alt="image.png" title="image.png" referrerpolicy="no-referrer"></span></p><p>点击确定后，我们将在控制平面看到ASM生成的相关EnvoyFilter列表：</p><p><span class="img-wrap"><img class="lazy" src="https://segmentfault.com/img/bVcRomD" alt="image.png" title="image.png" referrerpolicy="no-referrer"></span></p><p>2 Prometheus<br>2.1 Install<br>执行如下命令安装Prometheus(完整脚本参见：demo_mixerless.sh)。</p><p>kubectl --kubeconfig "$USER_CONFIG" apply -f $ISTIO_SRC/samples/addons/prometheus.yaml<br>2.2 Config Scrape<br>安装完Prometheus，我们需要为其配置添加istio相关的监控指标。登录ACK控制台，左侧导航栏选择配置管理>配置项，在istio-system下找到prometheus一行，点击编辑。</p><p><span class="img-wrap"><img class="lazy" src="https://segmentfault.com/img/bVcRomF" alt="image.png" title="image.png" referrerpolicy="no-referrer"></span></p><p>在prometheus.yaml配置中，将scrape_configs.yaml中的配置追加到scrape_configs中。</p><p><span class="img-wrap"><img class="lazy" src="https://segmentfault.com/img/bVcRomH" alt="image.png" title="image.png" referrerpolicy="no-referrer"></span></p><p>保存配置后，左侧导航栏选择工作负载>容器组，在istio-system下找到prometheus一行，删除Prometheus POD，以确保配置在新的POD中生效。</p><p>可以执行如下命令查看Prometheus配置中的job_name：</p><p>kubectl --kubeconfig "$USER_CONFIG" get cm prometheus -n istio-system -o jsonpath=&#123;.data.prometheus\.yml&#125; | grep job_name</p><ul><li>job_name: 'istio-mesh'</li><li>job_name: 'envoy-stats'</li><li>job_name: 'istio-policy'</li><li>job_name: 'istio-telemetry'</li><li>job_name: 'pilot'</li><li>job_name: 'sidecar-injector'</li><li>job_name: prometheus<br>  job_name: kubernetes-apiservers<br>  job_name: kubernetes-nodes<br>  job_name: kubernetes-nodes-cadvisor</li><li>job_name: kubernetes-service-endpoints</li><li>job_name: kubernetes-service-endpoints-slow<br>  job_name: prometheus-pushgateway</li><li>job_name: kubernetes-services</li><li>job_name: kubernetes-pods</li><li>job_name: kubernetes-pods-slow<br>Mixerless验证</li><li>podinfo<br>1.1 部署<br>使用如下命令部署本系列的示例应用podinfo：</li></ul><p>kubectl --kubeconfig "$USER_CONFIG" apply -f $PODINFO_SRC/kustomize/deployment.yaml -n test<br>kubectl --kubeconfig "$USER_CONFIG" apply -f $PODINFO_SRC/kustomize/service.yaml -n test<br>1.2 生成负载<br>使用如下命令请求podinfo，以产生监控指标数据</p><p>podinfo_pod=$(k get po -n test -l app=podinfo -o jsonpath=&#123;.items..metadata.name&#125;)<br>for i in &#123;1..10&#125;; do<br>   kubectl --kubeconfig "$USER_CONFIG" exec $podinfo_pod -c podinfod -n test -- curl -s podinfo:9898/version<br>  echo<br>done<br>2 确认生成(Envoy)<br>本系列重点关注的监控指标项是istio_requests_total和istio_request_duration。首先，我们在envoy容器内确认这些指标已经生成。</p><p>2.1 istio_requests_total<br>使用如下命令请求envoy获取stats相关指标数据，并确认包含istio_requests_total。</p><p>kubectl --kubeconfig "$USER_CONFIG" exec $podinfo_pod -n test -c istio-proxy -- curl -s localhost:15090/stats/prometheus | grep istio_requests_total<br>返回结果信息如下：</p><p>:::: istio_requests_total ::::</p><h1>TYPE istio_requests_total counter</h1><p>istio_requests_total&#123;response_code="200",reporter="destination",source_workload="podinfo",source_workload_namespace="test",source_principal="spiffe://cluster.local/ns/test/sa/default",source_app="podinfo",source_version="unknown",source_cluster="c199d81d4e3104a5d90254b2a210914c8",destination_workload="podinfo",destination_workload_namespace="test",destination_principal="spiffe://cluster.local/ns/test/sa/default",destination_app="podinfo",destination_version="unknown",destination_service="podinfo.test.svc.cluster.local",destination_service_name="podinfo",destination_service_namespace="test",destination_cluster="c199d81d4e3104a5d90254b2a210914c8",request_protocol="http",response_flags="-",grpc_response_status="",connection_security_policy="mutual_tls",source_canonical_service="podinfo",destination_canonical_service="podinfo",source_canonical_revision="latest",destination_canonical_revision="latest"&#125; 10</p><p>istio_requests_total&#123;response_code="200",reporter="source",source_workload="podinfo",source_workload_namespace="test",source_principal="spiffe://cluster.local/ns/test/sa/default",source_app="podinfo",source_version="unknown",source_cluster="c199d81d4e3104a5d90254b2a210914c8",destination_workload="podinfo",destination_workload_namespace="test",destination_principal="spiffe://cluster.local/ns/test/sa/default",destination_app="podinfo",destination_version="unknown",destination_service="podinfo.test.svc.cluster.local",destination_service_name="podinfo",destination_service_namespace="test",destination_cluster="c199d81d4e3104a5d90254b2a210914c8",request_protocol="http",response_flags="-",grpc_response_status="",connection_security_policy="unknown",source_canonical_service="podinfo",destination_canonical_service="podinfo",source_canonical_revision="latest",destination_canonical_revision="latest"&#125; 10<br>2.2 istio_request_duration<br>使用如下命令请求envoy获取stats相关指标数据，并确认包含istio_request_duration。</p><p>kubectl --kubeconfig "$USER_CONFIG" exec $podinfo_pod -n test -c istio-proxy -- curl -s localhost:15090/stats/prometheus | grep istio_request_duration<br>返回结果信息如下：</p><p>:::: istio_request_duration ::::</p><h1>TYPE istio_request_duration_milliseconds histogram</h1><p>istio_request_duration_milliseconds_bucket&#123;response_code="200",reporter="destination",source_workload="podinfo",source_workload_namespace="test",source_principal="spiffe://cluster.local/ns/test/sa/default",source_app="podinfo",source_version="unknown",source_cluster="c199d81d4e3104a5d90254b2a210914c8",destination_workload="podinfo",destination_workload_namespace="test",destination_principal="spiffe://cluster.local/ns/test/sa/default",destination_app="podinfo",destination_version="unknown",destination_service="podinfo.test.svc.cluster.local",destination_service_name="podinfo",destination_service_namespace="test",destination_cluster="c199d81d4e3104a5d90254b2a210914c8",request_protocol="http",response_flags="-",grpc_response_status="",connection_security_policy="mutual_tls",source_canonical_service="podinfo",destination_canonical_service="podinfo",source_canonical_revision="latest",destination_canonical_revision="latest",le="0.5"&#125; 10</p><p>istio_request_duration_milliseconds_bucket&#123;response_code="200",reporter="destination",source_workload="podinfo",source_workload_namespace="test",source_principal="spiffe://cluster.local/ns/test/sa/default",source_app="podinfo",source_version="unknown",source_cluster="c199d81d4e3104a5d90254b2a210914c8",destination_workload="podinfo",destination_workload_namespace="test",destination_principal="spiffe://cluster.local/ns/test/sa/default",destination_app="podinfo",destination_version="unknown",destination_service="podinfo.test.svc.cluster.local",destination_service_name="podinfo",destination_service_namespace="test",destination_cluster="c199d81d4e3104a5d90254b2a210914c8",request_protocol="http",response_flags="-",grpc_response_status="",connection_security_policy="mutual_tls",source_canonical_service="podinfo",destination_canonical_service="podinfo",source_canonical_revision="latest",destination_canonical_revision="latest",le="1"&#125; 10<br>...<br>3 确认采集(Prometheus)<br>最后，我们验证Envoy生成的监控指标数据，是否被Prometheus实时采集上来。对外暴露Prometheus服务，并使用浏览器请求该服务。然后在查询框输入istio_requests_total，得到结果如下图所示。</p><p><span class="img-wrap"><img class="lazy" src="https://segmentfault.com/img/bVcRomS" alt="image.png" title="image.png" referrerpolicy="no-referrer"></span><br>本文为阿里云原创内容，未经允许不得转载。</p>  
</div>
            