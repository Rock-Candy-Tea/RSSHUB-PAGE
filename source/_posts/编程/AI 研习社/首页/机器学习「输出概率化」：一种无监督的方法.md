
---
title: '机器学习「输出概率化」：一种无监督的方法'
categories: 
    - 编程
    - AI 研习社
    - 首页

author: AI 研习社
comments: false
date: Wed, 07 Nov 2018 07:01:58 GMT
thumbnail: 'https://www.yanxishe.com/static/ue/themes/default/images/spacer.gif'
---

<div>   
<blockquote><p>本文原载于微调的知乎专栏<a href="https://www.zhihu.com/people/breaknever/posts">「数据说」</a>。</p></blockquote><p>以常见的二分类问题为例，工具库的输出结果为[0,1]或者[-1,1]，分别代表不同的两个类别（如正例和反例）。困扰初学者的一个问题是：模型输出的结果0和1是如何得到的？模型的原始输出结果是什么？</p><p>这个问题的答案是：不同模型的原始输出各不相同，比如K-近邻的输出结果应该是K个最近邻的所对应的标签的平均数（或是以反向距离为权重的加权平均），而逻辑回归的输出结果可以被直接理解为概率，在[0,1]之间。尽管像sklearn一样的工具库为大部分监督<span class="k_pendant" data-id="1324">算法</span>都提供了概率输出，但大部分模型的原始输出结果其实都不是0或者1。它可以是某个浮点数，可正可负。</p><p>在正例和负例假设数目相当的前提下，那么可以得到阈值k为中值，所有输出小于k就被划分为0，而所有大于等于k的数据则被分到1中。换句话说，我们得到的二分类标签是原始模型输出的硬性划分结果。举个简单的例子：<img id="loading_jo6t3l3n" src="https://www.yanxishe.com/static/ue/themes/default/images/spacer.gif" title="正在上传..." referrerpolicy="no-referrer"><img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573589901397.png" title="1541573589901397.png" alt="微信截图_20181107145255.png" width="221" height="24" referrerpolicy="no-referrer">，假设k=0.5，那么y被硬分类后的值为 <img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573627427368.png" alt="微信截图_20181107145332.png" title="1541573627427368.png" width="156" height="25" referrerpolicy="no-referrer"> 。通过调整阈值k的取值，最终输出的二分标签结果也可以相对应的变化，这也是评估ROC的基本方法（不断调整阈值）。</p><p>因此k=0.5或者中值只是一种特例，仅当假设正负例个数相等时成立。当正例和负例不平衡时，调整阈值k也是一种处理方法，如另 <img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573659147786.png" alt="微信截图_20181107145405.png" title="1541573659147786.png" width="144" height="67" referrerpolicy="no-referrer"> 使其等于正例占到总体的比例。</p><p>在实际问题中，将模型的输出结果转化为概率[0,1]是一个很重要的问题。转化为概率有很多重要意义：</p><ul class=" list-paddingleft-2"><li><p>便于人们理解输出结果，因为概率的基本知识深入人心</p></li><li><p>相较于0和1，储存了更多信息，比如顺序关系：0.8比0.7更倾向于正例</p></li><li><p>便于整合多个模型。在结合多个模型时，融合不同模型的输出的前提是在同一维度上，概率是最符合直觉的维度</p></li></ul><hr><p>将模型的输出结果转化为概率在监督学习中往往是可得的，可以通过计算后验概率，用贝叶斯公式，用softmax（多分类）公式就可以求出某个数据点属于某个类别的“概率”，今天暂时不表。感兴趣的朋友可以参考sklearn中不同的分类器所对应的predict_proba()函数，要注意不同算法的计算方法可能不同，且不是每个监督算法都适合算概率。值得注意的一点是，对监督模型的输出概率化往往是可行的，而无监督的情况下并不容易。</p><p>因此本文讨论的是，对于没有约束的的无监督模型输出，如何将其转化并解释为概率。</p><p>首先我们给出几个样本：</p><p><img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573732319370.png" title="1541573732319370.png" alt="微信截图_20181107145514.png" width="788" height="123" referrerpolicy="no-referrer"></p><p>假设这三个序列都是模型的输出结果，数值越小越倾向于被归类为0，而数值越大越倾向于被归类为1。我们的目标是为他们分别找到一个 转换函数<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573769554545.png" alt="微信截图_20181107145558.png" title="1541573769554545.png" width="39" height="30" referrerpolicy="no-referrer"> ，使得S1， S2，S3的输出均为概率。</p><p>首先定义转换函数<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573769554545.png" alt="微信截图_20181107145558.png" title="1541573769554545.png" width="39" height="30" referrerpolicy="no-referrer"> 需要满足：</p><ol class=" list-paddingleft-2"><li><p>规律性（regular）：所有未经转换的值应处于区间 <img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573826930876.png" title="1541573826930876.png" alt="微信截图_20181107145652.png" width="50" height="27" referrerpolicy="no-referrer"></p></li><li><p>取值归一（normal）：最终的输出范围为<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573855609524.png" title="1541573855609524.png" alt="微信截图_20181107145722.png" width="46" height="26" referrerpolicy="no-referrer"> ，这样才能被解读为是概率</p></li><li><p>顺序性（ordinal）： <img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573910266652.png" alt="微信截图_20181107145750.png" title="1541573910266652.png" width="217" height="31" referrerpolicy="no-referrer"> ，转化过程不能改变原始输出中的顺序，排序信息应该保存（ranking-stable），（经过评论区朋友的建议修改为）可类比编程中的稳定排序</p></li></ol><p>概率化就是设计转换函数<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573769554545.png" alt="微信截图_20181107145558.png" title="1541573769554545.png" width="39" height="30" referrerpolicy="no-referrer"> ，第一步解决数据规律性的问题，说白了就是把数据重新缩放（scaling）到<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573826930876.png" title="1541573826930876.png" alt="微信截图_20181107145652.png" width="50" height="27" referrerpolicy="no-referrer">上。介绍几种简单的方法：</p><ul class=" list-paddingleft-2"><li><p>最暴力的方法是直接在每个值减去最小值即可，以S2为例，每个数都应减去最小值1最终得到<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573956590273.png" title="1541573956590273.png" alt="微信截图_20181107145901.png" width="173" height="34" referrerpolicy="no-referrer"> ，这个方法同理对负数有效。</p></li><li><p>对于取值跨度较大的数或者有特定需求的序列，可以用log进行缩放。</p></li></ul><p>值得一提的是，输出范围为大于等于0实数的单调函数都可以被改造用于规律化序列。此处专门提到单调函数的原因是：规律化的序列依然需要满足顺序性，因此非单调函数不能用。</p><p>第二步就是把规律化后的函数放到<img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573855609524.png" title="1541573855609524.png" alt="微信截图_20181107145722.png" width="46" height="26" referrerpolicy="no-referrer"> 的范围上，也就是归一化。一说归一化，很多朋友说这我门清。没错，最简单的方法就是常见的线性归一（min-max scaler）：</p><ul class=" list-paddingleft-2"><li><p><img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541573998992108.png" alt="微信截图_20181107145948.png" title="1541573998992108.png" width="121" height="63" referrerpolicy="no-referrer"> ，其基本假设就是类似于均匀分布</p></li></ul><p>但如果我们对于y的分布有假设的话，更加有效方法是使用相对应的概率密度函数来转换。让我们以高斯分布为例，我们可以首先计算高斯误差函数（Gaussian Error Function），此处定为 <img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541574030720324.png" alt="微信截图_20181107150018.png" title="1541574030720324.png" width="65" height="29" referrerpolicy="no-referrer"> ，那么可用</p><ul class=" list-paddingleft-2"><li><p><img src="https://static.leiphone.com/uploads/new/sns/article/201811/1541574054610491.png" title="1541574054610491.png" alt="微信截图_20181107150042.png" width="258" height="70" referrerpolicy="no-referrer">，此处的 <img src="http://www.zhihu.com/equation?tex=%5Cmu" alt="\mu" referrerpolicy="no-referrer"> 和 <img src="http://www.zhihu.com/equation?tex=%5Csigma" alt="\sigma" referrerpolicy="no-referrer"> 是序列的均值和标准差</p></li></ul><p>上面介绍的两个函数都是单调的，因此整个顺序是稳定的，只要对序列中的所有数重复以上操作即可。</p><p>总结，当我们的模型不存在标签时，将输出处理为概率是一件非常重要的事情，可以用于融合多个模型。当我们设计转化函数时，应保证其符合上文所提到的三个特性，尤其是顺序性。</p><p>如果我们对数据分布没有了解，一般假设高斯分布比较合理，在低维时可以假设伽马分布。任何分布函数都可以使用累计分布函数（cdf）来进行转化。即使使用最简单的归一化（min-max scaler），一般也有不错的效果。</p><p><br></p><hr><p>感兴趣的读者可以进一步阅读：</p><p>Wasserman, L., 2013. <em>All of statistics: a concise course in statistical inference</em>. Springer Science & Business Media.</p><p>Kriegel, H.P., Kroger, P., Schubert, E. and Zimek, A., 2011, April. Interpreting and unifying outlier scores. In <em>Proceedings of the 2011 SIAM International Conference on Data Mining </em>(pp. 13-24). Society for Industrial and Applied Mathematics.</p><p>Aggarwal, C.C., 2015. Outlier analysis. In <em>Data mining</em>. Springer, Cham.</p><p><br></p><p style="text-align: center;"><img src="https://static.leiphone.com/uploads/new/sns/article/201809/1538126929964269.png" alt="asamu.png" referrerpolicy="no-referrer"></p>  
</div>
            