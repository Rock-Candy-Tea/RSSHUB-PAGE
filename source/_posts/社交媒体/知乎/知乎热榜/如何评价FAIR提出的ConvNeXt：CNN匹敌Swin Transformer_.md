
---
title: '如何评价FAIR提出的ConvNeXt：CNN匹敌Swin Transformer_'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://pic4.zhimg.com/v2-d964fbad5160d0e960b30815c736eb21_1440w.jpg'
author: 知乎
comments: false
date: Wed, 12 Jan 2022 11:49:59 GMT
thumbnail: 'https://pic4.zhimg.com/v2-d964fbad5160d0e960b30815c736eb21_1440w.jpg'
---

<div>   
深度眸的回答<br><br><p data-pid="x2g2_6il">首先，MetaAI 这篇 ConvNeXt 论文实验做的非常充分，符合其论文的一贯风格，读起来赏心悦目，推荐大家去读读原文。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-d964fbad5160d0e960b30815c736eb21_1440w.jpg" data-caption data-size="normal" data-rawwidth="722" data-rawheight="471" data-default-watermark-src="https://pic1.zhimg.com/v2-eb90f3eb6304cfc11e33dade34afce64_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic4.zhimg.com/v2-d964fbad5160d0e960b30815c736eb21_r.jpg" referrerpolicy="no-referrer"></figure><p data-pid="NGgC6cPa">从 ResNet 出发通过不断的 Swin Transformer 化验证了 Conv 其实不比 Transformer 差什么。<b>这是一个自然的结论，是一个很容易想到的结论，</b>下面详细说说为啥？</p><p data-pid="4UCACJ1H"><b>(1) 从 ResNet 到 ViT</b></p><p data-pid="kNwKXsFX">ResNet 是一个非常优雅的 ConvNet，采用滑动窗口模式提取特征，并输出多层金字塔特征图，非常适合各种下游任务。相比 ResNet，ViT 采用全局感受野的注意力机制提取特征，从一开始 ViT 就强调相比 ResNet 这种 Conv 局部感受野特征提取操作，全局自注意力模式会更加优异，当数据量巨大时候性能优异度更加明显。</p><p data-pid="zNBBgRzI">ViT 的这种全局自注意力特征提取模式的优异性，慢慢已经得到了大家的认可，后续的诸多 SOTA 刷榜论文也证明了这点。</p><p data-pid="HOcSzqVk"><b>(2) 从 ViT 到 MLP-Mixer 到 ConvMixer</b></p><p data-pid="PP2cKzM4">随着 Transformer 的发展，上述结论被人质疑，典型的如 MLP-Mixer 和 ConvMixer。</p><p data-pid="Zb5L0R4P">MLP-Mixer 认为其实无需注意力机制 Attention ,仅仅需要 Token-Mixing MLP 和 Channel-Mixing MLP 即可。因为自注意力模块做的事情是 token mixing，而后续的 FNN 模块做的事情是 channel mixing，MLP-Mixer 中证明采用 MLP 实现 token mixing 功能，而无需自注意力模块，性能也是和 ViT 类似。</p><p data-pid="7dguxvE3">ConvMixer 也是相同思路，但是他的 Token-Mixing 不再采用自注意力或者 MLP，而是直接用 3x3 DW 卷积即可。</p><p data-pid="Cez1CA50"><b>上述两篇论文都间接说明了 ViT 或者 Transformer 中强调的全局自注意力优异性并不成立，ViT 的成功或许来自 Transformer 整体精心设计的架构</b></p><p data-pid="NrPs_MdH">相同的观点做法有很多，典型的还有 ResMLP、CycleMLP、gMLP、MetaFormer 和 An Empirical Study of CNN, Transformer, and MLP 等等。</p><p data-pid="S9rwY31p"><b>(3) 从 ViT 到 Swin Transformer</b></p><p data-pid="JZgliuNv">在 ViT 的诸多改进中，Swin Transformer 算是一个非常成功的改进。其针对 CV 任务中一般是多尺度图片，且图片分辨率很大的问题，创造性的提出了局部注意力计算模块 LSA，即仅仅在窗口内计算自注意力，相比 ViT，性能也有极大的提升，将 Transformer 实用性提升了一大步。</p><p data-pid="esDPzAbs"><b>(4) 从 Swin Transformer 到 ELSA</b></p><p data-pid="U7X3PP4Z">Swin Transformer 解决了巨大计算量问题，但是依然有自身的问题：</p><ul><li data-pid="n0VZLKZk">其实现非常复杂，特别是移位的 LSA 计算方式</li><li data-pid="IAYCv3P0">难以部署，他的 OP 比较特殊，这非常不好</li><li data-pid="Q3EFLHue">随着诸多最新发现，自注意力和逐深度方向卷积 DW Conv 可以等价，那么 Swin Transformer 和 Conv 结合会咋样，有待研究</li></ul><p data-pid="H8Gbsx0A">解决前两个问题的典型算法是 Imporved MViT、Twin 和 Shuffle Transformer 等等，这类算法都是在考虑如何在去掉移位 LSA OP，而是通过其他方式引入窗口间信息交互。</p><p data-pid="-J6ArS3_">一个更彻底的研究 Swin Transformer 的算法是 ELSA，其发现一个现象</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-648af7a1ad3b6a73ccad5589e1af69c9_1440w.jpg" data-caption data-size="normal" data-rawwidth="723" data-rawheight="350" data-default-watermark-src="https://pic2.zhimg.com/v2-0083d945825a669e1ff3fa2b550a84cd_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic4.zhimg.com/v2-648af7a1ad3b6a73ccad5589e1af69c9_r.jpg" referrerpolicy="no-referrer"></figure><p data-pid="LSoyXg7N">作者以 Swin Tiny 版本为例，将其中的局部窗口注意力模块 LSA 替换为 DW Conv、decoupled dynamic filter (DDF)，从上图可以看出 DWConv 和 DDF 性能都比 LSA 强的，特别是 DW Conv，在参数量和 FLOPs 更小的情况下性能会比 Swin Transformer 高。</p><p data-pid="1GYrRvDE">这说明 LSA 其实也没有想象中那么好，DW Conv 同样可以胜任。抛开 ELSA 的具体改进不谈，我们从上述诸多论文中可以发现 ：</p><ul><li data-pid="FDKpUCui"><b>自注意力层可以和 DW Conv 等价，将自注意力层替换为 DW Conv 模块，性能也是非常类似的</b></li><li data-pid="JQAIvuj1"><b>ViT 等 Transformer 等算法成功的关键在于精心设计的 Transformer 架构</b></li></ul><p><br></p><p data-pid="ieRCzQOm"><b>(5)  从  Swin Transformer 到 ConvNeXt </b></p><p data-pid="_ZDpJYfq">既然 ViT 和 Swin Transformer 等的成功并不是来自所谓的注意力机制，而是精心设计的 Transformer 架构，那么<b>自然会有疑问这个精心设计的架构为啥如此优异，一经提出就超越 ResNet？</b>现在诸多论文都是在探讨 Transformer 架构中的某个部件对整体性能的影响，例如 Patch 切分模式等，而 ConvNeXt 虽然没有正面回答为何 Transformer 性能优异，但是从实践角度，<b>参考 Swin Transformer 架构，升级了 ResNet 架构，提出 ConvNeXt ，从而使得 ResNet 依然如此伟大。</b></p><p><br></p><p data-pid="1d0NtblZ"><b>从上述发展来看，从 ResNet 到 ViT，再到 Swin Transformer，最终又回到 ResNet，是一个非常自然的过程。简单来说发展历程是某人突然发现一个非常好的网络架构(一开始没有意识到架构的重要性)，然后中间大家一起来魔改，最后大家发现其实都走偏了，现在又有人开始回归架构本身了，而不是所谓的自注意力和 Conv 谁更优异之争。</b></p><p data-pid="CF9qua_W"><b>虽然 ConvNeXt 很优秀，但是依然没有深入探讨 Transformer 架构的伟大之处，或许总有一天能够研究清楚，带领大家认识架构设计的本质吧！</b></p><p data-pid="To8dLqjh">当然上述是我一家之言，不一定理解的非常到位！</p><p data-pid="lRdvsSDP">附加：很高兴看到 MetaAI (前身 FAIR)选择了 MMDetection 来作为算法 base 实现了目标检测部分，作为 MMDetection 维护者，希望大家都能够基于 MMDetection，将其应用于各种场合，不断打磨升级，将易用性提高一大步。目前随着 MMRazor 和 MMDeploy 的发布，从标注到训练到压缩到部署全链条都已经打通，相信会极大的方便用户。如果你觉得不错，欢迎给 Star </p><a href="http://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmdetection" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">MMDetection</a>  
</div>
            