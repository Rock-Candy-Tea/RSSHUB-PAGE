
---
title: '如何看待智源、清华等单位论文 A Roadmap for Big Model 中大量段落被指涉嫌抄袭？'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://pic2.zhimg.com/v2-9ea1952ed2570480340db588537048ce_1440w.jpg?source=b1748391'
author: 知乎
comments: false
date: Wed, 13 Apr 2022 02:06:53 GMT
thumbnail: 'https://pic2.zhimg.com/v2-9ea1952ed2570480340db588537048ce_1440w.jpg?source=b1748391'
---

<div>   
谢圜不是真名的回答<br><br><p data-pid="tMPXR29_"><b>Update</b>：智源方面已经在调查了。我也很期待调查结果，希望最后能有一个合理的解释。</p><p data-pid="Tsu5Obvo">我统计了一下原文提及的涉嫌抄袭段落出现的地方：2.3.1，2.4.3，8.3.1，10.2，12.2.3，14.2.2……</p><p data-pid="xC0yQ9O7"><b>我震惊地发现，这不是某一处集中出现了抄袭嫌疑，跨度这么大的涉嫌抄袭行为，绝对不止涉及个别作者！</b></p><p data-pid="sPdE9TMH">现在推特的相关讨论让人真心感慨……ViT作者Lucas Beyer毫不留情地说，“我也不确定我会相信一个<b>剽窃团体</b>的声明；在约130pg的内容中，有10个抄袭的区块，来自约100个作者。”</p><p data-pid="VXvXQac1">如果这类综述大文章是分工完成的，那可想而知，这个学术环境令人头皮发麻；如果这篇文章是一个团队的结果，却挂上了不同团队的名字（是的，我曾见过这样的文章，而且是一个和更可能的解释），那不过是从一类学术不端跳到另一类学术不端罢了。</p><p data-pid="IG-KTSmC"><b>学术声誉的建立是一辈子的事情，然而要推倒只需要一瞬间。</b></p><hr><p data-pid="99YYMT7U">之前一些学术不端的工作中，其实有很多大佬讨论过关于论文署名的问题。原则上来说，一篇文章的所有署名人员必须：</p><blockquote data-pid="zTQErm_L">（1）对研究工作的思路或设计有重要贡献，或者为研究获取、分析或解释数据；<br>（2）起草研究论文或者在重要的智力性内容上对论文进行修改；<br>（3）对将要发表的版本作最终定稿；<br>（4）同意对研究工作的各个方面承担责任以确保与论文任何部分的准确性或诚信有关的问题得到恰当的调查和解决。<br><br><br></blockquote><p data-pid="cXlb8yXL">也就是说，涉及到学术不端的论文，其<b>所有署名的作者</b>都负有责任（这类分工式的综述类大文章可能比较特别，但每章的那些作者是跑不了的）。一开始轻飘飘把名字挂上，后面把自己的责任摘出去的回应是不被允许的。</p><p data-pid="nmP0Dka4">讲道理，100多个名字的论文就很离谱。看看这篇文章：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-9ea1952ed2570480340db588537048ce_1440w.jpg?source=b1748391" data-rawwidth="1506" data-rawheight="1149" data-size="normal" data-caption data-default-watermark-src="https://pica.zhimg.com/v2-609ab08c51a7800c3e2a63cd9bbbaf13_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic2.zhimg.com/v2-9ea1952ed2570480340db588537048ce_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p data-pid="gNfrGSdY">虽然我也见过共同一作很多的文章，但……<b>快一半的人都是共同一作，还有1/4的人是共同通讯</b>，我真的是第一次见到。可能这就是大模型需要的大社群吧。</p><p data-pid="VSL_Clgl">现在这篇文章因为这样可悲的错误，被Google Brain的研究员一通捶，而且arxiv的页面下面已经添加了文字重合的警示，想必这篇文章在纯学术上的影响力会<b>跌得很严重</b>（毕竟大家都希望引用更具代表性的<b>原创</b>工作），失去了这篇文章本来应有的地位和意义。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-40c1755c04704b74552874fb77895e30_1440w.jpg?source=b1748391" data-rawwidth="1170" data-rawheight="245" data-size="normal" data-caption data-default-watermark-src="https://pic1.zhimg.com/v2-5645b8bead63a6a482c4b61b54749525_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic1.zhimg.com/v2-40c1755c04704b74552874fb77895e30_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p data-pid="KZ8w5538">学术声誉对于一家学术机构来说还是很重要的。预测一下智源后面的反映：</p><ol><li data-pid="g-ZcG162">在arxiv上撤稿，后续找时间重新提交修改后的版本。（概率几乎100%）</li><li data-pid="F7UWIfVx">机构公开道歉。（概率10%）</li><li data-pid="GMEpy7eV">一些作者以个人身份道歉。（概率80%）</li><li data-pid="bDq5ohEm">然后当这事没发生过。（概率90%）</li></ol><hr><p data-pid="V62fhdIT">推特讨论节选：</p><p data-pid="4kveCihv">滑铁卢大学教授：即使这篇多作者的论文有分工，我对<b>没有一个人注意到并采取措施纠正这一点感到吃惊</b>。</p><figure data-size="normal"><img src="https://pica.zhimg.com/v2-028097da1c226577631bc72ce4458958_1440w.jpg?source=b1748391" data-rawwidth="1234" data-rawheight="211" data-size="normal" data-caption data-default-watermark-src="https://pic2.zhimg.com/v2-5524312b8597d7825d85cc767bcccc5f_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pica.zhimg.com/v2-028097da1c226577631bc72ce4458958_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p data-pid="_lHo5oNj">ViT作者：他们大概会推一个作者出来背锅。（临时工再显神威？）</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-a9536341a40dd25b02dc89f681131a31_1440w.jpg?source=b1748391" data-rawwidth="1240" data-rawheight="408" data-size="normal" data-caption data-default-watermark-src="https://pic1.zhimg.com/v2-9f20556870b89b5fdfcc2216a2ede58d_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-a9536341a40dd25b02dc89f681131a31_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p data-pid="MgIQo7a7">我<b>不确定会相信一个剽窃团体的声明</b>。在约130页的内容中，有10个区域被抄袭。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-a48ccef8dda926c1205c0ce9ec6c456d_1440w.jpg?source=b1748391" data-rawwidth="1206" data-rawheight="437" data-size="normal" data-caption data-default-watermark-src="https://pic2.zhimg.com/v2-04e1caf53617b78de74a449e876ac206_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic2.zhimg.com/v2-a48ccef8dda926c1205c0ce9ec6c456d_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p data-pid="NyajLl6K">每个人都乐于分享多作者论文的功劳/引文--但当<b>涉及到责任时，也会分享吗</b>？应该吗？</p><figure data-size="normal"><img src="https://pica.zhimg.com/v2-a01575ee48fefa2e59bd1ef225eff329_1440w.jpg?source=b1748391" data-rawwidth="1211" data-rawheight="404" data-size="normal" data-caption data-default-watermark-src="https://pica.zhimg.com/v2-dae9f56713a63704cf772dcb159db156_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pica.zhimg.com/v2-a01575ee48fefa2e59bd1ef225eff329_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><hr><p data-pid="KyqWn57x">把原文翻译过来：</p><blockquote data-pid="gZTB73xi">I recently came to be aware of a case of plagiarism in the machine learning research space. The paper <a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/2203.14101" class=" wrap external" target="_blank" rel="nofollow noreferrer">A Roadmap for Big Model</a> plagiarized several paragraphs from one of my recent papers <a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/2107.06499" class=" wrap external" target="_blank" rel="nofollow noreferrer">Deduplicating Training Data Makes Language Models Better</a>. (There is some irony in the fact that the Big Models paper copies from a paper about data copying. This irony was not lost on us.) This is unfortunate, but to my dismay, our paper was not the only paper copied from: the Big Models paper copied from at least a dozen other papers.</blockquote><p data-pid="gFHbfdGq">我最近意识到了机器学习研究领域的一个抄袭案例。A Roadmap for Big Model这篇论文抄袭了我最近的一篇论文中的几个段落，即重复训练数据使语言模型更好。(大模型的论文抄袭了一篇关于数据复制的论文，这有一些讽刺意味。这种讽刺对我们来说并不陌生）。这是不幸的，但令我沮丧的是，我们的论文并不是唯一被抄袭的论文：Big Models的论文至少抄袭了其他十几篇论文。</p><blockquote data-pid="ctU4Q8au">In the grand scheme of things, this particular form of copying isn’t the worst thing ever. It’s not like a paper has directly copied the method of a prior result and claimed it as its own. But even putting aside the fact that claiming someone else's writing as one's own is wrong, the value in survey papers is in how they re-frame the field. A survey paper that just copies directly from the prior paper hasn't contributed anything new to the field that couldn't be obtained from a list of references.</blockquote><p data-pid="dEhxJUb-">从总体上看，这种特殊形式的抄袭并不是最糟糕的事情。这并不像一篇论文直接抄袭先前的结果的方法，并声称它是自己的。但是，即使抛开把别人的文章说成是自己的文章是错误的这一事实，调查报告的价值在于它们如何重新构筑这个领域。一篇只是直接抄袭前一篇论文的调查报告并没有对该领域做出任何新的贡献，而这是无法从参考文献列表中获得的。</p><blockquote data-pid="kIVnlCTp">(Please note the Big Models paper has a hundred authors. Likely only a few of the authors have participated in this copying. Misconduct by a small fraction of the authors should not be held against the majority of well-behaving authors.)</blockquote><p data-pid="9Rw32ujV">(请注意，《大模型》论文有一百个作者。很可能只有少数作者参与了这种抄袭。一小部分作者的不当行为不应该被用来指责大多数行为良好的作者）。</p><blockquote data-pid="wjLMJHUp">See below for a few of the more egregious examples of this, with text from the Big Models paper on the left and the corresponding text from the original paper on the right. Copied text is highlighted in green.</blockquote><p data-pid="KJzAJVdf">下面是几个比较恶劣的例子，左边是大模型论文的文字，右边是原始论文的相应文字。复制的文字以绿色标出。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-bc065d7832c4e7fc22544c777acaaaa4_1440w.jpg?source=b1748391" data-rawwidth="720" data-rawheight="890" data-size="normal" data-caption data-default-watermark-src="https://pic3.zhimg.com/v2-2eb5e41ed7b3e121744da143b4b5ed8e_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic4.zhimg.com/v2-bc065d7832c4e7fc22544c777acaaaa4_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><blockquote data-pid="ZaNet3v3">One of my coauthors was reading the Big Models paper and noticed that some of the text seemed oddly familiar, and after quickly looking things over we found that in fact a bunch of the text was directly copied from our paper.</blockquote><p data-pid="oQmY34Vg">我的一位合作者在阅读《大模型》的论文时，注意到其中的一些文字似乎很奇怪，在快速查看之后，我们发现事实上有一堆文字是直接从我们的论文中复制的。</p><blockquote data-pid="4z0sHj_T">Given that this happened to us, we then set out to see if there were other examples too. As part of a prior project, I had collected a dataset of PDFs for (almost) every accepted paper at top machine learning venues (ICML/ICLR/NeurIPS/AAAI/ACL/etc). So all I did to find the above copied text was to take these PDFs, extract out all of the text and dump it into a single .txt file, and then run our <a href="http://link.zhihu.com/?target=https%3A//github.com/google-research/deduplicate-text-datasets" class=" wrap external" target="_blank" rel="nofollow noreferrer">dataset deduplication tools</a> (that we developed for the paper that was copied from!) to find all repeated sequences that were contained both in the Big Models paper along with some other prior publication. To rule out false positives, I only considered sequences of</blockquote><p data-pid="t0iYxw19">鉴于这种情况发生在我们身上，我们就着手看看是否也有其他的例子。作为之前一个项目的一部分，我收集了一个数据集，其中包括顶级机器学习场所（ICML/ICLR/NeurIPS/AAAI/ACL/等）接受的每篇论文的PDF文件。因此，为了找到上述复制的文本，我所做的就是把这些PDF文件提取出来，把所有的文本转储到一个.txt文件中，然后运行我们的重复数据集工具（这是我们为被复制的论文开发的！），找到所有重复的序列，这些序列既包含在大模型论文中，也包含在其他先前的出版物中。为了排除假阳性，我只考虑：</p><blockquote data-pid="jl9LpjkF">1. at least 10 words (after whitespace normalization),<br>2. that are contained sequentially in the Big Models paper,<br>3. and also present in a prior paper,<br>4. but are not present in more than one prior paper.<br><br><br></blockquote><ol><li data-pid="1Pzrn6J4">至少10个字的序列（经过空白规范化处理）。</li></ol><p data-pid="HHqO9gpk">2. 按顺序出现在《大模型》论文中。</p><p data-pid="s8CyxpZL">3. 并且也出现在之前的论文中。</p><p data-pid="5dTf-bDk">4. 没有出现在一篇以上的论文中。</p><blockquote data-pid="1Vd2CMhL">This ensures that I won’t flag any common phrases as copied (e.g., copyright blocks, citations to prior paper titles or author names, etc).</blockquote><p data-pid="rx1iVf4V">这确保了我不会将任何常见的短语标记为抄袭（例如，版权块、对先前论文标题或作者姓名的引用，等等）。</p><blockquote data-pid="161PfsBb">And then from there, it was just a matter of quickly manually reviewing a few of the most egregious cases (shown above). There were other examples of self-plagiarism where the paper that was copied from shared an author with the new paper that I have omitted–while this isn’t an ideal practice, it’s less concerning.</blockquote><p data-pid="qAH_0M8u">然后，从那里开始，只是快速地手动审查一些最令人震惊的案例（如上图所示）。还有一些自我抄袭的例子，其中被抄袭的论文与我省略的新论文有共同的作者--虽然这不是一个理想的做法，但它不太令人担忧。</p><blockquote data-pid="RYC_gASZ">Because of this filtering process, and because my dataset of papers is not exhaustive over all prior publications (notably, it only contains accepted papers, not arXiv preprints), it is possible there is more copying going on here than I have identified. However even what we have found so far is already more than should happen, and I am saddened that this is happening at all.</blockquote><p data-pid="jlnT7QvQ">由于这个过滤过程，以及我的论文数据集并不包括所有先前的出版物（特别是，它只包含被接受的论文，而不是arXiv预印本），这里有可能存在比我所发现的更多的抄袭。然而，即使是我们目前发现的情况也已经超过了应该发生的程度，我对这种情况的发生感到悲哀。</p><hr><p></p>  
</div>
            