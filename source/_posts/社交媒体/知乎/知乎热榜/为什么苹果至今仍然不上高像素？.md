
---
title: '为什么苹果至今仍然不上高像素？'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://pic2.zhimg.com/v2-392f5299166a50b481a3f204f9ef9495_720w.jpg'
author: 知乎
comments: false
date: Tue, 15 Jun 2021 18:28:50 GMT
thumbnail: 'https://pic2.zhimg.com/v2-392f5299166a50b481a3f204f9ef9495_720w.jpg'
---

<div>   
Puddle的回答<br><br><p>我们都知道，在iPhone Xs以后，苹果加入了Smart HDR功能。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-392f5299166a50b481a3f204f9ef9495_720w.jpg" data-caption data-size="normal" data-rawwidth="400" data-rawheight="360" class="content_image" referrerpolicy="no-referrer"></figure><p>在Smart HDR效果下，每次拍摄时，手机就会拍摄4帧缓冲图像，它们有着不同的曝光度，苹果可以挑选出每一张照片中最优秀的部分，并且合成至一张图片。</p><p>得益于A12 bionic的强大性能，iPhone Xs可以做到“<b>所见即所得</b>”的HDR效果。</p><p>换言之，你在相机取景器里看到的是什么样子，最后的成片就是什么样子。</p><p>而在2019年10月，在苹果发布的iOS 13.2中，苹果再次发布了Smart HDR功能的进阶版——Deep Fusion。</p><blockquote>据报道，Deep Fusion是通过机器学习，以低到中等的光线拍摄照片，连续拍摄九张照片，最终合成高细节、低噪点图片。<br>Apple高级副总裁Phil Schiller，在发布会上称其为“疯狂的摄影算法”。<sup data-text="Deep Fusion-百科" data-url="https://baike.baidu.com/item/Deep%20Fusion/57220426?fr=aladdin" data-draft-node="inline" data-draft-type="reference" data-numero="1">[1]</sup><br></blockquote><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-899950ab0134f5a432a617cc6779790f_1440w.jpg" data-caption data-size="normal" data-rawwidth="800" data-rawheight="410" data-default-watermark-src="https://pic1.zhimg.com/v2-8cdcc7b1728c63abef72e9e407414f54_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-899950ab0134f5a432a617cc6779790f_r.jpg" referrerpolicy="no-referrer"></figure><p>在Deep Fusion的加持下，iPhone11在硬件规格没有较大进步的情况下，取得了更好的拍照效果。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-7b6ef7d2518ef8c1d3b56608ca40d88a_1440w.jpg" data-caption data-size="normal" data-rawwidth="728" data-rawheight="462" data-default-watermark-src="https://pic3.zhimg.com/v2-5eec2ea5d3f1be1cab206c16fd56e138_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic1.zhimg.com/v2-7b6ef7d2518ef8c1d3b56608ca40d88a_r.jpg" referrerpolicy="no-referrer"></figure><p>当然，<b>因为对算力的巨大要求</b>，Deep Fusion仅仅支持iPhone 11之后的机型。</p><p>也就是，决定苹果拍照质量的，除了摄像头的硬件规格，更重要的还是芯片的算力和照相机的算法。</p><p>当我们明确了这个问题以后，我们或许就能理解“苹果不上高像素”的原因。</p><p>一方面，更多的像素，意味着需要同时处理更多的数据，虽然目前的A14芯片虽然已经很强了，但是，可能还是目前的算力，仍然没有办法保证，在高像素之下，苹果依然维持“所见即所得”的效果。</p><p>另一方面，更大的底，更高的像素，意味着更大的后置镜头模组，虽然，苹果算是引领了突出摄像头的风潮（iPhone 6），但是，一直以来，苹果的机身设计还是相对比较克制的，如果摄像头突出的太过严重，也不符合苹果一直以来的设计理念。</p><p>为了同时兼具“良好快速的使用体验”以及“相对美观的机身设计”，苹果就只能暂时舍弃高像素了。</p><p>不过，随着芯片算力的进步，未来，说不准真的能等到高像素的iPhone呢？</p><p><b>以上为个人愚见，欢迎各位大佬批评指正。</b></p>  
</div>
            