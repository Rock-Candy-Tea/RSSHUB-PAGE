
---
title: '中国首个虚拟学生华智冰加入清华大学，其背后有哪些值得关注的技术亮点？'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://picsum.photos/400/300?random=194'
author: 知乎
comments: false
date: Thu, 03 Jun 2021 10:13:24 GMT
thumbnail: 'https://picsum.photos/400/300?random=194'
---

<div>   
墨华的回答<br><br><p>看到了大佬的名字，不敢乱说话，稍微揣摩几句。至今没找到论文，只能猜了。</p><p>首先要明确模型生成和模型训练的区别，前者是自己针对不同的任务生成所需的模型自己训练，后者是基于由人类设计好的模型进行训练。</p><p>这玩意应该主要优势还是在于模型训练而非生成。现在神经网络的研究还没有到能用一个通用网络不加调整地完成所有通用任务的地步（如果有，那现在一众顶会针对各种任务具体优化输入输出就没有意义了）。</p><p>所以我很怀疑，这东西其实就是一个网络整合，把各种已有的模型（绘画模型，翻译模型，情感分类模型等等）放在一起组合起来，配个调度器处理。</p><p>至于模型生成，这部分应该是纯粹炼丹撞大运了，假如真能在有限算力下训练出一个万能且足够高效的模型生成器，那如今一大堆会议都要当场去世了。。。。</p><p>或者，说白了，你让她画画可以，和你聊天可以（这些都是一开始人工设置好的），但让她做一开始不会的东西，临时学，效果八成惨不忍睹。</p><p>这东西意义应该一半在于撞大运，一半在于多方协同来训练已有的大型模型。指望她变成真的通用智能，这不现实。</p><p>——————</p><p>举个例子吧，讲讲现在人们是怎么设计一个AI来执行特定任务的，刚看了一篇paper是利用人的呼吸节律识别不同的人（类似指纹，只不过变成了“呼吸纹”）</p><p>首先，研究人员发现，呼吸可以影响电脑wifi的信号接收。</p><p>于是，作者利用电脑接收wifi信号，获取到的信号是有背景噪声的（其他wifi源，人的走动对wifi信号影响等），因此需要利用滤波算法去除噪音，这个算法由作者针对呼吸特点专门设计，从而最大限度保留信号里有用的信息。</p><p>接下来，作者根据呼吸特点，把连续的多次呼吸的信号切分成一次次的独立呼吸的信号（每段信号表示一次呼吸）。</p><p>然后，作者对这些数据分别计算几个统计量（从均值，方差等里面人工选取，这可能需要反复尝试）。</p><p>最后，作者把时序信号转换成选取的统计量（称为特征）<b>送进神经网络（AI）</b>，进而实现不同人的识别。至此，经过研究者的各种操作，加上最后一步里神经网络（AI）的运行，一个能够完成<b>一项特定任务</b>的AI诞生了。</p><p>显然，这个过程里面，<b>AI只占了很小的一部分，很大一部分的工作集中在前期数据的处理，</b>即“应该送什么东西给AI让他学”，这也是这个研究的价值所在。</p><p>这个过程显然不可能自动完成，否则像这样的学界顶级研究就是笑话一桩。</p><p>或者再说明白一点，现在的AI相当于一个洗碗机，你把需要的碗和洗洁精按照正确的方法放进去，机器还你一套干净的餐具。如果你把油盐酱醋也一并放进去让机器自己选，那不好意思，你碗没了。</p><p>而如果没法让这个过程自动完成，AI自然不可能像人一样“学会新技能”，更别说“通过图灵测试”“成为真正会思考的人”了。</p><p>当然，对媒体来说，忽悠两句“真人工智能即将到来”，煽动两下“AI统治世界”，话题出了，流量有了。</p>  
</div>
            