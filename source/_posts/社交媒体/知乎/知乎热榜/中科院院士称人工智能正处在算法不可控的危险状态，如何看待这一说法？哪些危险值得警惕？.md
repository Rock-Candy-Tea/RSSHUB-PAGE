
---
title: '中科院院士称人工智能正处在算法不可控的危险状态，如何看待这一说法？哪些危险值得警惕？'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://pic3.zhimg.com/v2-47d88f2db067801cde4b63821ea6a5d4_1440w.jpg?source=b1748391'
author: 知乎
comments: false
date: Mon, 22 Aug 2022 15:51:45 GMT
thumbnail: 'https://pic3.zhimg.com/v2-47d88f2db067801cde4b63821ea6a5d4_1440w.jpg?source=b1748391'
---

<div>   
桔了个仔的回答<br><br><p data-pid="bc6MCb4A">看了一下这个问题和链接，发现其实这个问题在我和 <a class="member_mention" href="http://www.zhihu.com/people/e3f5794fa10022aa07c05b0b9e6dc537" data-hash="e3f5794fa10022aa07c05b0b9e6dc537" data-hovercard="p$b$e3f5794fa10022aa07c05b0b9e6dc537">@微调</a> <a class="member_mention" href="http://www.zhihu.com/people/4a0d3a504b9859139f2c003005230717" data-hash="4a0d3a504b9859139f2c003005230717" data-hovercard="p$b$4a0d3a504b9859139f2c003005230717">@霍华德</a> 其中一期《知聊八点半》讲到过。</p><h2>什么是不可控？</h2><p data-pid="bZ9GSCPt">原文说到：</p><blockquote data-pid="0eImEbly">因为我们处于不可控状态，比如说用深度学习的方法开发出来的人工智能算法没有可靠性保证的</blockquote><p data-pid="S3xJOKuS">这种不可控的状态，并不是说机器已经失控了，开始统治人类了，而是说在使用AI时，AI的输出结果并不是稳定的（鲁棒性低）。</p><p data-pid="yMg9PHHW">下面这个例子我已经在知乎举了好多次了。在how are you的语音里加入一点「噪声」，就会被AI识别成「open the door」；在熊猫的图片里加入一点「白噪声」，就会被识别成长臂猿。当然，这个问题可以通过数据增强等方式去尽量避免，但是没法杜绝，因为你不知道模型是怎么推理的。 目前模型的可解释性与安全性依然是一个重要研究课题。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-47d88f2db067801cde4b63821ea6a5d4_1440w.jpg?source=b1748391" data-caption data-size="normal" data-rawwidth="1252" data-rawheight="668" data-default-watermark-src="https://pic4.zhimg.com/v2-8a6e542a78b809a24bf9522e25a32f37_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-47d88f2db067801cde4b63821ea6a5d4_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p><br></p><p data-pid="mv_EYxrF">其中在我之前的很多回答里，多次提到AI其实产生了很多不可信的结果，例如：</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-48d593a6988f28286675e2de14dc1abb_1440w.jpg?source=b1748391" data-size="normal" data-rawwidth="690" data-rawheight="484" data-default-watermark-src="https://pic3.zhimg.com/v2-2d49b981106796713767ec7014e2da5a_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic2.zhimg.com/v2-48d593a6988f28286675e2de14dc1abb_r.jpg?source=b1748391" referrerpolicy="no-referrer"><figcaption>董明珠在公交车的广告，被误认为董明珠闯红灯</figcaption></figure><p data-pid="zLASiUfy">同样的，赵雅芝也遇到了。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-7c6c1d7994565e04486fcfada8e21d13_1440w.jpg?source=b1748391" data-size="normal" data-rawwidth="1024" data-rawheight="1365" data-default-watermark-src="https://pic2.zhimg.com/v2-e172f8219a22148c1b20fb7d7184f0e2_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-7c6c1d7994565e04486fcfada8e21d13_r.jpg?source=b1748391" referrerpolicy="no-referrer"><figcaption>人在家中坐，锅从天上来</figcaption></figure><p data-pid="ZL3HjKUw">虽然这次检测对了，这次是真的人而不是印在公交车的图片。但这违法原因有点不讲武德了。</p><figure data-size="normal"><img src="https://picx.zhimg.com/v2-32d411a751907b79d36a89fb29327c22_1440w.jpg?source=b1748391" data-size="normal" data-rawwidth="1062" data-rawheight="1321" data-default-watermark-src="https://pic1.zhimg.com/v2-1e6e9d0ccd6d61698b1da0c66a5926c3_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://picx.zhimg.com/v2-32d411a751907b79d36a89fb29327c22_r.jpg?source=b1748391" referrerpolicy="no-referrer"><figcaption>偷袭我一岁的小同志，不讲武德！</figcaption></figure><p data-pid="4hWAgyns">去年有个新闻，研究者通过戴着一副特制的眼镜，就能破解很多手机的人脸识别系统，这确实给很多人造成了恐慌。背后原理<a href="https://www.zhihu.com/question/441671834/answer/1706305334" class="internal">我之前的回答</a>里写过，感兴趣的小伙伴可以去看看。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-ce74888df3fdbb40abca68e566adb3e4_1440w.jpg?source=b1748391" data-caption data-size="normal" data-rawwidth="720" data-rawheight="430" data-default-watermark-src="https://pic1.zhimg.com/v2-3869fdc96fdf20d94bdd03f75444fbda_720w.jpg?source=b1748391" class="origin_image zh-lightbox-thumb" data-original="https://pic1.zhimg.com/v2-ce74888df3fdbb40abca68e566adb3e4_r.jpg?source=b1748391" referrerpolicy="no-referrer"></figure><p data-pid="5OLYjNOg">我想以上的例子，才是院士说的「不可控」。也就是说，现在AI的不可控，指的是「输出结果不可控」，而不是AI有自主意识摆脱人类控制。也就是 <a class="member_mention" href="http://www.zhihu.com/people/a0265e93117d3d366adda36310194727" data-hash="a0265e93117d3d366adda36310194727" data-hovercard="p$b$a0265e93117d3d366adda36310194727">@平凡</a> 在回答区里讲到的：</p><blockquote data-pid="X7VcVKIg">unreliable<br>untrustworthy<br>insecure<br><br></blockquote><p data-pid="yKlun-OZ">其实院士的讲话就引出了一个问题：</p><h2>如何创造可信的AI？</h2><p data-pid="AXm9rvvG"><br>关于如何创造可信的AI，我可以推荐一本书，名字就叫《如何创造可信的AI》，作者是Gary Marcus（盖瑞马库斯）。<br></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-546deca0b1868e2f6ecffb63185d7cb5_720w.jpg?source=b1748391" data-caption data-size="normal" data-rawwidth="350" data-rawheight="350" data-default-watermark-src="https://pic1.zhimg.com/v2-4b6dea0d81a7fbfbefc41874e6716b23_720w.jpg?source=b1748391" class="content_image" referrerpolicy="no-referrer"></figure><p data-pid="boZ6akGy">他在书中，分享了AI鸿沟（The AI Chasm）的三大坑：</p><blockquote data-pid="-15wmKf5">轻信坑：这是由于人类进化的现实过程还没有发展出清晰辨别人类与机器之间区别的能力，导致我们往往用基于人类的认知模式去看待机器的能力，从而容易轻信机器拥有人类般的智慧。<br>虚幻进步坑：每当AI技术的进展攻克了一类新的问题时，我们往往错误地假设AI技术就能解决以此推及的、现实世界中的类似任务。但是AI学术上的问题往往是定义在狭义而简化的假设下，而现实世界的具体任务都有很大的复杂性和不确定性<br>鲁棒坑：受限于当前深度学习算法和训练数据，对容错性很低特别是使命关键的应用领域比如无人驾驶等，今天的AI还没能达到实际「落地」的能力。<br><br></blockquote><p data-pid="osEQfszK">马库斯告诫我们必须关注「AI鸿沟」，因为踩坑的代价是非常高的。</p><p data-pid="Zt7XLs-V">那么怎么才能构建出可信的AI呢？短期方案读者估计也能想到，就是对亲手构建的AI进行限制，纠正我们发现的每一个错误。但我们也能看出，这是头痛医头脚痛医脚的措施。</p><p data-pid="DU-Lsj6e">那么长期方案呢？很可惜，在这本书里面，没有很系统的从技术角度来展开阐述如何才能创造可信的AI，只从理论方向提到了几点，我概括下：</p><ol><li data-pid="bymACsqI">就是着手建造具备常识、认知模型和强大推理工具的机器。</li><li data-pid="7NQexMkK">例如「用深度理解取代深度学习」</li><li data-pid="rXq2FBY8">「机器还需要由其创造者赋予道德价值观」</li></ol><h2>哪些危险值得警惕？</h2><ol><li data-pid="PJZHPH6i">轻信AI。过度相信AI导致自己受伤害，例如有的人大胆地把方向盘交给辅助驾驶系统，结果出车祸了。</li><li data-pid="ZmuSWMuo">AI被攻击。例如前面提到的「特制眼镜破解手机」，其实就是「对抗攻击」，怎么防止AI系统被对抗攻击，是一个无尽的课题，因为攻防是无限来回的。</li></ol>  
</div>
            