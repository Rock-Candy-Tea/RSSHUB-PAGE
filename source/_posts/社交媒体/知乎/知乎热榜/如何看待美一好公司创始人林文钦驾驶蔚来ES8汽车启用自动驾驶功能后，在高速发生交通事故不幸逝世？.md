
---
title: '如何看待美一好公司创始人林文钦驾驶蔚来ES8汽车启用自动驾驶功能后，在高速发生交通事故不幸逝世？'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://pic4.zhimg.com/v2-896d6452a917ec63f63e996d14eb32cf_1440w.jpg'
author: 知乎
comments: false
date: Sat, 14 Aug 2021 19:12:33 GMT
thumbnail: 'https://pic4.zhimg.com/v2-896d6452a917ec63f63e996d14eb32cf_1440w.jpg'
---

<div>   
洪泽鑫的回答<br><br><p>作为一名自动驾驶行业的从业者，看完讣告后心里挺难过的。</p><p>可能很多年后，历史会这么记录这一时期：</p><h2>“自动驾驶技术刚出现的时候，还很不成熟，但却有不少人以为已经足够成熟了，并因此丢掉了性命。”</h2><p><br></p><p>早在2013年，谷歌就在研发一批具备一定自动驾驶能力的车，而且征集了一部分员工进行内部测试，给他们每人分发了一辆车，告诉他们在车上不能分神，注意力必须放在驾驶上，并且很严肃地警告他们，如果车内的摄像头发现他们没有严格遵守这个规定，会马上收回车辆。</p><p>但在测试的过程中，谷歌发现有好几个员工都没有严格遵守规定，并且有一位员工直接在车上睡着了——他睡着的时候，车辆正以55英里每小时的速度在路上飞奔。</p><p>在这件事发生了以后，谷歌就彻底关闭了这个项目，并开始专心研发L4级别的无人驾驶技术。<sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text data-url="https://www.businessinsider.com/google-ditched-system-similar-to-tesla-autopilot-in-2013-2019-9">[1]</sup></p><p>可以说，在2013年谷歌就意识到类似NOP的功能的普及需要挑战人性。</p><h2>蔚来的NOP是什么？</h2><p>NOP的全称是Navigate on Pilot，中文是领航辅助，一般对外宣传会说是“实现A点到B点自动领航驾驶，包括自动上下匝道、超车、并线、巡航行驶等功能”。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-896d6452a917ec63f63e996d14eb32cf_1440w.jpg" data-rawwidth="1600" data-rawheight="600" data-size="normal" data-caption data-default-watermark-src="https://pic2.zhimg.com/v2-8ac218a97b43ecac52f2eee1c49ec340_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic4.zhimg.com/v2-896d6452a917ec63f63e996d14eb32cf_r.jpg" referrerpolicy="no-referrer"></figure><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-b2eabb89568e65ec2b3b5108fdef5199_1440w.jpg" data-rawwidth="1207" data-rawheight="369" data-size="normal" data-caption data-default-watermark-src="https://pic3.zhimg.com/v2-4c504fb504d06d28876ba6ce86687634_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic4.zhimg.com/v2-b2eabb89568e65ec2b3b5108fdef5199_r.jpg" referrerpolicy="no-referrer"></figure><p><br></p><p>属于介于L2至L3级别之间的自动驾驶功能。</p><p><br></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-459093c2c73a9c907e6659ded709368d_1440w.jpg" data-rawwidth="800" data-rawheight="607" data-size="normal" data-caption data-default-watermark-src="https://pic3.zhimg.com/v2-b3edec705eb0c69521295f58e0185361_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-459093c2c73a9c907e6659ded709368d_r.jpg" referrerpolicy="no-referrer"></figure><p>说实话，最大的作用只在于你对路不熟的时候不容易开错路，因为方向盘会提醒你一下。</p><p>绝对不要让车辆自己驾驶，重要的事情说三遍：</p><p>不要走神。</p><p>不要走神。</p><h3>不要走神。</h3><p><br></p><h2>为什么自动驾驶会出问题？</h2><p>无人驾驶技术目前还存在没解决的问题，或许技术上已经解决了90%的问题，但剩下的10%却可能要花费同样多甚至更多的精力，这10%包括很多长尾问题，经常被称为Corner Case。在没有全部解决这些长尾问题的情况下，就依然需要有人员介入。</p><p>目前已经量产的车辆不涉及特别复杂的车辆控制问题，所以目前这些问题大都集中在感知领域，也就是错误识别物体或者根本没有能识别出有物体。</p><p>单纯靠摄像头没法保证能识别所有东西。人靠眼睛在开车，摄像头离人类的眼睛还有很长距离的，人的眼睛是非常强大的传感器，低功耗，大部分光线情况下都能起作用，还自带防尘装置——眼皮。</p><p>大家会说人工智能不是很神了嘛，为什么那么大一台车在前面还识别不出来？</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-04c768923ebdbc853d86078e44ae9899_1440w.jpg" data-rawwidth="858" data-rawheight="926" data-size="normal" data-caption data-default-watermark-src="https://pic4.zhimg.com/v2-25593189b08794a546bcfc71189d215d_720w.jpg" class="origin_image zh-lightbox-thumb" data-original="https://pic2.zhimg.com/v2-04c768923ebdbc853d86078e44ae9899_r.jpg" referrerpolicy="no-referrer"></figure><p>根源是在于人工智能的“可解释性”挑战，现在的机器学习就像一个黑盒子，你给这个黑盒子一个照片，黑盒子会告诉你这个照片里有什么没有什么，但黑盒子却不会告诉你为什么有或者为什么没有。</p><p>不可解释的黑盒子系统是不能用在关乎安全的应用领域的，自动驾驶尤其是这样。</p><p>有不少人工智能公司会认为大量的数据就能让人工智能更精准、更智能，但终究还是一个黑盒子，根本不是单纯靠大量数据能解决的。</p><p>这也是为什么越来越多车厂在新车上装激光雷达，激光雷达和摄像头之间可以交叉验证、互为冗余，摄像头看不到的东西激光雷达能感知到，激光雷达感知不到的，摄像头可以。</p><p><br></p><h2>L3级别的自动驾驶出了问题能找谁？</h2><p>事故责任只能是自己承担。</p><p>L3级别的自动驾驶要求司机随时把注意力都放在驾驶上，所以出事故了，按照现有交通法规，只能认定是司机在违规驾驶。</p><p>2016年1月20日，是中国首例“自动驾驶”致死车祸发生的时间，也是全球首例。当时在京港澳高速河北邯郸段上，一辆特斯拉轿车直接撞上一辆正在作业的道路清扫车，特斯拉司机高雅宁当场身亡。<sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text data-url="http://www.xinhuanet.com/auto/2018-03/05/c_1122486792.htm">[2]</sup></p><p><br></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-967485c6b900a5335ba5c1ebc7cd611a_1440w.jpg" data-rawwidth="480" data-rawheight="217" data-size="normal" data-caption class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-967485c6b900a5335ba5c1ebc7cd611a_r.jpg" referrerpolicy="no-referrer"></figure><p><br></p><p>后来经交警认定，在这起追尾事故中驾驶特斯拉的司机高雅宁负主要责任。</p><p>家属状告特斯拉只能以“宣传误导”的名义，索赔一万元，但这起案件过去五年了，至今还悬而未决。<sup data-draft-node="inline" data-draft-type="reference" data-numero="3" data-text data-url="https://baijiahao.baidu.com/s?id=1698451502425177543&wfr=spider&for=pc">[3]</sup></p><p><br></p><h2>没有法律法规能管一管吗？</h2><p>没有。</p><p>联合国欧洲经济委员会（UNECE）在2020年6月发布了《 ALKS 车道自动保持系统条例》，要求汽车制造商必须满足该法规中明确的性能要求，才能销售配备 ALKS 的车辆。</p><p>这是全球范围内第一个针对具备L3 级自动驾驶能力量产车型的国际法规，但中国表示暂时不会应用该法规。</p><p>国内近期的一项相关法规是前两天工信部印发的《关于加强智能网联汽车生产企业及产品准入管理的意见》，其中要求：<sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text data-url="https://www.miit.gov.cn/jgsj/zbys/wjfb/art/2021/art_7cb8a0949a8e45c5979c0f73788d1184.html">[4]</sup></p><blockquote>企业实施在线升级活动前，应当确保汽车产品符合国家法律法规、技术标准及技术规范等相关要求并向工业和信息化部备案，涉及安全、节能、环保、防盗等技术参数变更的应提前向工业和信息化部申报，保证汽车产品生产一致性。未经审批，不得通过在线等软件升级方式新增或更新汽车自动驾驶功能。</blockquote><p>但具体怎么审报、怎么审批才能保证车辆的软件到达一定水平？</p><p>仍然是一个未解的难题，详细可看：<a href="https://www.zhihu.com/question/479186205/answer/2055151413" class="internal">工信部发布意见：企业不得擅自升级新增汽车自动驾驶功能，会带来哪改变？</a>。</p><p><br></p><h2>如何正确地挑选配备了L3级别自动驾驶功能的车？</h2><p>L3级别自动驾驶一定要配合完善的驾驶员监控系统（DMS，Driver Monitoring System）才能保证安全。</p><p>驾驶员监控系统一般是用摄像头来监控司机的状态的，会实时地监测你的视线是否在前方，如果监测到你持续一段时间分神，便会通过声音或振动来提醒你。如果出现了系统应付不了的情况，比如恶劣天气、没有GPS信号的隧道等，系统也会提醒你及时接管。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-c0bce9f00bef7676b95206aa868eb5aa_1440w.jpg" data-rawwidth="1184" data-rawheight="430" data-size="normal" data-caption class="origin_image zh-lightbox-thumb" data-original="https://pic1.zhimg.com/v2-c0bce9f00bef7676b95206aa868eb5aa_r.jpg" referrerpolicy="no-referrer"></figure><p>还有的是给方向盘装监控传感器，假如监测到司机脱离方向盘超过一定时间，就会报警，并自动停车。</p><p>有了驾驶员监控系统，才不会让你过度放松警惕，把自己的生命暴露在危险之下。</p>  
</div>
            