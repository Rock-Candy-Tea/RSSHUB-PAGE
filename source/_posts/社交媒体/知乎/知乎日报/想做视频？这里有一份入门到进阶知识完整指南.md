
---
title: '想做视频？这里有一份入门到进阶知识完整指南'
categories: 
 - 社交媒体
 - 知乎
 - 知乎日报
headimg: 'https://pic3.zhimg.com/v2-97e92f7ff7354ae4287d8a0734af1133_l.jpg?source=8673f162'
author: 知乎
comments: false
date: 2021-07-12 14:06:40
thumbnail: 'https://pic3.zhimg.com/v2-97e92f7ff7354ae4287d8a0734af1133_l.jpg?source=8673f162'
---

<div>   
<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder">



</div>

<div class="content-inner">



<div class="question">
想做视频？这里有一份入门到进阶知识完整指南 ​
<div class="answer">

<strong>
<img class="avatar" src="https://pic3.zhimg.com/v2-97e92f7ff7354ae4287d8a0734af1133_l.jpg?source=8673f162" referrerpolicy="no-referrer">
<span class="author">李明殊，</span><span class="bio">数码胶片XX法师群群成员(33/79)</span>
</strong>

<div class="content">
<p>​【<strong>万字长文，解释你在视频制作时会用到的知识和术语</strong>，以及在器材选择时应该注意的问题，有点长，可以先收藏下来，慢慢看】 ​</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-ebdde659e030c07c0e9ce3d56d38341a_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>​</p>
<p>不可置疑的是，这是一个视频的时代。</p>
<p>不论是相机还是手机厂商，每次发布会也会用很长的篇幅来解释他们产品的视频能力。 也很有多朋友为了更好的视频质量，不在满足于手机拍摄，开始选择单反或者微单开始自己视频的创作。 选购肯定也会遇到何种乱七八糟的参数，什么 10bit ,什么 422，super35，这是都是什么，又有什么作用？ 今天我们就来认真地讨论一下这些东西。</p>
<p>​</p>
<p><strong>4K 即正义？分辨率</strong></p>
<p>当你在 B 站看小姐姐跳舞的时候，有时候可能会看到这个标志【4k 超清】。</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-e003ff23b00c7d5cd40f19fc5cc5888a_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>这也许是大家最熟悉的一个的参数——分辨率，不论是视频也好，还是显示器或者电视机都会用到这个，很简单，也很容易理解，分辨率越高，视频画质越好。 ​</p>
<p>通常上，还会用这样的一张图，来解释不同视频分辨率的效果。我们也会把这个分辨率称为『输出分辨率』。</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-f0d93cd8f4e5a062e1cf93c85bfec81d_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>有聪明的小朋友要问了，我的手机或者显示器不过是 1080P 的，那么还有必要搞 4K 么？ ​</p>
<p>即使最终都是输出为 1080P 的，拍摄的素材为 4K，会包含更多的色彩信息，感官上会感觉更加的清晰，色彩更加丰富（这个过程就是超采，下文会详细解释），而且也方便你进行画面的裁剪或者稳定。 ​</p>
<p>拍摄 8K 同理，即使最终输出为 4K 的视频，也会获得更好的画面，但是问题就在于能够拍摄 8K 的设备普遍不便宜，对于存储和处理的要求会更高。除了相机之外，你还得更新电脑，买更贵的显卡和更大的硬盘才行。 ​</p>
<p>所以目前来讲，<strong>4k 无疑更具有实用性</strong>，而且几乎每一台手机，哪怕是入门级别的相机，也都开始普及 4K 视频了。 ​</p>
<p>注： 4K 分辨率其实是一个统称，画面横向像素在 4000 个左右，纵向在 2000 个像素左右的，都可以称之为 4k 分辨率，不同的设备和场景下，所以就有了不同的 4k 分辨率。 ​</p>
<p>最为常见的，是我们日常的网络视频以及很多显示器的比例，16：9，分辨率为 3840 × 2160，手机相机也通常也以这个分辨率捕获素材。 ​</p>
<p>当然，还有其他规格的 4k 分辨率，可参考下表：</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-f9d5108e8fc41c56ec0fb4bc8e701097_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>部分相机也能拍摄 DCI-4K 的视频，比如松下的 GH5s，S1H，以及万元最强全画幅视频微单 S5。</p>
<p>​</p>
<p><strong>为什么拍视频的时候，画面有变化？裁切与超采</strong></p>
<p>现在请你拿出你的手机，从拍照模式切换到录像模式，你会发现一个有趣的现象，画面的视角好像发生了变化。</p>
<figure><img class="content-image" src="https://pic1.zhimg.com/v2-8ed33d5c93c3e4bf43571e909b11942c_b.gif" alt referrerpolicy="no-referrer"></figure><p>为什么呢？ ​</p>
<p>其实很好理解，拍摄 4K 视频，分辨率为 3840 × 2160，像素不过 800 万左右，但是问题现在手机像素通常都在 1200 万像素之上，相机呢，普遍的像素值在 2000 万左右。 ​</p>
<p>那多出来的这些像素，怎么办？ ​</p>
<p>第一种解法就是，多出来就多出来呗，不用就行，于是就有了裁切这种方式，拍摄视频的时候，我只使用中间那部分需要的像素就够了。</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-42f413c6db1c21ff16988a6bafd8b865_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>缺点显而易见，就是本来能够拍摄的到视角变小了。 ​</p>
<p>比如裁切系数为 1.7 倍，你使用一只 24mm 的广角镜头，拍摄出来的画面相当于 40mm 镜头拍的，丧失了广角端。 ​</p>
<p>顺便也提醒大家一点，厂家往往很鸡贼，会把这个裁切系数用很小很小的字体写在备注里。</p>
<figure><img class="content-image" src="https://pic1.zhimg.com/v2-56844b28915425c0986f0ee66889c5b0_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>既然集中使用中间的像素会丧失视角，那么我尽量使用整个传感器呗。 ​</p>
<p><strong>于是『跳采』这种方式出现。</strong>简单来说，就是每间隔几个像素记录一个像素点的信息，其它像素的信息就不要了，如图所示。</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-7a04ec980152ed632e92cf4585e6a435_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>很棒，解决了视角裁切的问题，但是缺点也很明显，舍弃了一部分像素的信息，不论是画质上还是颜色上，都会有所欠缺。 ​</p>
<p>有没有更好的解法，<strong>有，就是超采。 ​</strong></p>
<p>在理解超采之前，得先理解传感器是如何记录颜色的。 ​</p>
<p>实际上，像素点是不会记录颜色信息的，他只能记录光的强度，那么如果还原真实世界的色彩呢？ 不得不提『拜尔滤镜』了。在像素上放上滤色片，然后记录不同颜色的滤色片对光的过滤效果，就可以得到颜色信息。 ​</p>
<blockquote>具体的光学知识可以参考之前的这个回答。</blockquote>
<p><a class="internal" href="https://www.zhihu.com/answer/1721715927">李明殊：彩色胶片主要是什么原理?</a></p>
<p class="ztext-empty-paragraph"> <br><br>但是像素不是胶片的感光剂，摞三个滤色片在上边，也不能记录色彩信息，于是拜尔想了一个办法，把<a class=" wrap external" href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/RGB" target="_blank" rel="nofollow noreferrer">RGB</a>滤色器按照一定的方式排列在相邻像素上，这样就可以根据周边的颜色数值，来算出一个『颜色』。<br><br></p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-71f767145414cedbdf9a10f541fa8f6d_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>既然是『算出来』，那么就不是真实的。 ​</p>
<p>​</p>
<p>但是不可否认的是，<strong>只要我输入的条件够多，结果应该更加准确，接近真实。</strong> 超采就是这么一个类似的过程—— ​</p>
<p>采集传感器上所有像素的信息，然后根据周边像素的信息算出来一个数值，然后记录。 ​</p>
<p>为了便于理解超采，我们举一个不太严谨的例子，假如现在有一个 3200 万像素的相机，需要拍摄 4K 视频。也就是需要将四个像素变为一个像素。</p>
<p>假设四个像素的情况如图所示： ​</p>
<p>跳采，选择其中一个颜色直接记录，比如 1 中的红色； 超采，就是根据周边的的像素，来计算出一个颜色，然后作为记录。无疑，这种方式可以获得更准确的颜色，更加锐利清晰的画面。</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-582ac1bc7e85a2bbe9d0dd21f12cf653_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>看起来很棒了，超采就没有什么问题了嘛？ ​</p>
<p>有。 ​</p>
<p>由于超采需要计算，而计算是需要一定的时间，就会导致果冻效应更加明显。</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-b738fab57fe8e3586addcebff4362f61_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>你在车上拍的电线杆子，也就会更歪一点了。</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-cd02e430fb1d3597bf9327893f0c6483_1440w.jpg" alt referrerpolicy="no-referrer"></figure><blockquote>注: <br>即使具有超采功能的相机，不是所有的视频规格都有超采，不同的分辨率和帧率下的设定会不同。 <br>比如索尼的大部分相机，4k 视频是从 6K 分辨率超采而来，但是 1080P 的规格不是； <br>超采不一定会用到整个传感器，即使是超采，也会有画面裁切（但是这个比例通常很小），只要采集的像素比最终输出的像素多，就可以称之为超采。 ​<br><br><br></blockquote>
<p>​</p>
<p><strong>为什么是 23.98？关于帧率</strong></p>
<p>戈达尔说：</p>
<blockquote>电影是每秒 24 格的真理。</blockquote>
<p>因为视觉暂留，一秒 24 帧的画面，看起来流畅而且自然。 ​</p>
<p>为了拍摄电影感的视频，你把相机的帧率调整为 24 帧，然后兴冲冲的拍了一段视频，但是当你把视频导入到电脑上，右键属性的时候，或者把素材放到剪辑软件中，会发现，视频的帧率是 23.98。</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-c35eb85358b43f97bb4ccc95035830e3_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>说好的 24p，怎么还差我 0.02，剪辑个视频都有中间商赚差价吗？ ​</p>
<p>实际上，23.98 也是个近似值，准确的数值应该是 23.976，为什么是这么一个奇葩的数字？ 鲁(niu)迅(dun)曾经说过——</p>
<blockquote>一切看起来不合理的设定背后，都是历史遗留问题。</blockquote>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-4b0725848043fa53a60451127d04d246_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>美国的电源频率是 60Hz，所以当年电视诞生后，电视的场频也是 60Hz。 ​</p>
<p>当时的电视采用的是隔行扫描，也就是一秒钟需要记录 30 张画面，也就是 30fps。</p>
<p>但是后来彩色电视诞生，需要传输和记录色度信息，彩色副载波与亮度信号和音频载波之间的相互干扰。</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-b90e2e0e4f63c26fb79bdec94ba09b56_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>工程师为了解决这个问题，把频率下降千分之一，场频变为 59.94，同理，帧率就是 59.94✖️1/2=29.97。</p>
<p>电影的帧率也下降千分之一，24/1.001=<strong>23.976</strong>，看，这个神奇的数字出现了。</p>
<blockquote>更多详细内容，可以参考<a class="internal" href="https://zhuanlan.zhihu.com/p/66319869"><span class="invisible">https://</span><span class="visible">zhuanlan.zhihu.com/p/66</span><span class="invisible">319869</span><span class="ellipsis"></span></a>这篇文章。</blockquote>
<p>当人们想用电视看电影的时候，问题就出现了，电视是 29.97，电影是 23.976，这帧率不一样，还怎么看？</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-86e53144a18d61d80a1a9cff208ffca9_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>也就是说电影画面每四帧要塞到电视的五帧里，怎么塞? ​</p>
<p>于是 就有了 3：2pulldown 的技术。</p>
<figure><img class="content-image" src="https://pic1.zhimg.com/v2-1009a52ad1c9034ac7ca92ac6199d058_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>还记得之前说的隔行扫描吗？</p>
<p>每个画面经过隔行之后，会产生两个画面，然后按照 2323 这样的方式排列，最后就可以把四帧的画面塞到五帧中。 ​</p>
<p>虽然说已经是数字时代了，但是还有一些地区和在使用模拟信号的电视或者广播，所以 23.976 这样的帧率的兼容性会更好的一点。 ​</p>
<p>其实还有一个最为主要的原因，目前的消费领域的拍摄设备，基本上都是 23.98（23.976），真 24p 的相机或者录像机，往往比较贵。不过就相差这么一点，看不出来什么的。 ​</p>
<p class="ztext-empty-paragraph"> <br><br>视频的制式根据各国使用的电源频率不同，分为​<strong>PAL 制和 NTSC 制。</strong><br><br></p>
<ul><li>前者有中国和德国为代表，电源频率为 50Hz，视频的帧率就是 25P，50P 或者 100P；</li>
<li>后者以美国和日本为代表，电源频率为 60Hz，视频的帧率就是 30P，60P 或者 120P。</li>
</ul><figure><img class="content-image" src="https://pic4.zhimg.com/v2-696b202b9e3a0d181d00645de86f7687_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>这就是有的小朋友经常会问到的一个问题，为什么我的相机宣传可以拍摄 120 帧的视频，为什么菜单设置里只有 100P，切换一下制式就好了。</p>
<blockquote>这是必须得吐槽一下，索尼的相机，切换个制式还得格式化，搞不懂为什么会有这么奇葩的设定。</blockquote>
<p>有小朋友又要问了，那我使用 N 制还是 P 制？</p>
<p>其实现在的视频大多是网络使用，不论是 N 制还是 P 制，关系不大，选哪个都行，你开心就好，如果你有电视或者广播播放的需求，那还是选择对应的国家，以免后期的麻烦。 ​</p>
<p>如果你有多个设备，建议还是将拍摄制式统一。 ​</p>
<p>另外，还有一点得注意，如果你发现拍摄的场景有照明灯光，画面中出现闪烁的情况，建议还是调节成当地的制式，帧率和电源频率匹配时，就可以解决这个问题。 ​</p>
<p>我们经常说道的慢动作拍摄，其实是一秒钟拍摄更多的画面，比如 120 帧，然后播放的时候按照正常的帧率播放（24 帧），这样本来 1s 的画面，需要 5 秒的时间播放，自然就慢了。 ​</p>
<p>这个过程也就是我们所说的升格。 ​</p>
<p class="ztext-empty-paragraph"> <br><br><strong>既然有升格，那么就有降格</strong>，相反的，一秒钟记录更少的画面，然后以正常的速度播放，就会有视频加快的感觉，最常见的降格，其实是延时摄影。 ​<br><br>但是更高的帧率和分辨率会导致更大的数据量，在很多基础的相机上，高帧率和高分辨是不可兼得的，需要作出取舍。<br><br>这也是为什么目前大家对 4k/60 这个参数情有独钟的原因，在画质和帧率上达到了一个不错的平衡。 ​<br><br>​<br><br><strong>为什么我的 4K 这么差 ，码率</strong><br><br>一个显而易见的例子，手机拍摄的 4k 画面，有时候还不如相机拍摄的 1080P。 ​<br><br>按理说，4k 的画面要比 1080P 好多很多啊，为什么？ ​<br><br>决定画质的，除了分斌率，还有码率。 ​<br><br>这也就是一些国内的视频网站，所谓的超高清的视频的画面看起来并不那么高清，除了分辨率虚标之外（720P 就是超清，1080P 就是蓝光，那 4K 不得起飞了？）<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br></p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-f7af8c6e67ef3d5012b43501b65e3496_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>视频的码率也惨不忍睹（大多数的视频码率在 2M-4M 之间）。</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-595956abb24f4843239b9618fe8cea12_1440w.jpg" alt referrerpolicy="no-referrer"></figure><blockquote>B 站的码率其实都算良心的了。</blockquote>
<p>​</p>
<p>所谓码率，就是一秒钟记录的数据量，数据量越多，画质越好。码率决定了你文件的大小。</p>
<p>通常手机这种设备的码率厂家已经给你写死了，没有办法调节。 ​</p>
<p>问题来了。 对于相机这类设备来说，是否需要将码率设为最高。 ​</p>
<p>答案也不一定，一切都要按需出发。 因为在一定的分辨率下，不断提高码率所带来的画面提升已经肉眼不可见了，文件体积却在不断地增大。 ​</p>
<p>一个比较实用的做法是，使用你手头的机器，使用不同的码率拍摄一段看起来复杂的画面。 然后正常的进行后期调色，找到一个你分辨不出来画面差异的码率，然后用它就行了。 ​</p>
<p><strong>H.265 MP4.编码与封装</strong><strong>找一个盒子装起来：封装格式</strong></p>
<p>先来说格式封装，这个是大家最常见到的东西，也就是你文件的后缀名。 ​</p>
<p>常见的格式，有 MP4，和 MOV，FLV 等。</p>
<p>本质上你可以把格式理解为一个容器，可以装进去所有关于视频内容，除了帧画面，还有音频甚至字幕。 比如你在网上下载电影来看，很多都是 MKV 这种格式，可以塞进去多轨音频甚至多轨字幕，这也就是为什么有的电影能够切换声道的原因。</p>
<p>​</p>
<p><strong>存储的方式，编码</strong></p>
<p>下来说说编码，编码就是记录画面的方式。 ​</p>
<p>有两种记录的方式，一个是帧内编码，比如苹果的 PRORES。 这种很好理解，就是直接记录每一帧画面，后期电脑直接按顺序播放这些画面就 ok 了。 优点就是几乎不需要什么算力，播放起来很流畅，缺点就是会占用更大的空间。</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-5e9c09f2c0bfdd13efb4bf4e85822c05_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>这也就是为什么同样的配置的电脑，往往使用 Final cut Pro 剪辑要比 Adobe Primier 流畅很多的原因，正是因为 Final Cut Pro 使用 PRORES 的编码方式，但本质上，这是一种『以空间换速度』的做法。 ​</p>
<p>很多小伙伴们用 Final Cut 剪视频，剪到一半，突然发现硬盘空间没了，就是这个原因。</p>
<p>不过可以在剪辑完成后删除这类优化代理渲染文件，来节省空间，不过如果你有大量的素材，那建议还是搞个外置的大容量 SSD 或者直接连接 Nas 剪辑，体验会更好。 ​</p>
<p>PRORES 是一种中间编码，仅用于中间的视频编辑过程，也就是说，最后视频输出还得靠 H.264。</p>
<p>H.264 是一种帧间编码。</p>
<p>简单来说，他只记录每帧之间的变化值，然后解码器根据变化来『算出』中间的画面。</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-afc5ab4ff8a658414ab61f2ab79ae992_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>比如我拍摄一个采访视频，嘉宾基本上坐着不动，背景啥的都没有变化，只记录变化的部分，最大的好处文件体积就会小很多，但是解码播放时，却增加了算力的要求。 ​</p>
<p>H.264 应用十分广泛，几乎应用在所有的设备和产品上。</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-7765a7001ebe1dbc0c315da619829417_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>他的下一代是 H.265，更好的体积压缩，更好的画质。 ​</p>
<p>但是我们目前的播放和处理设备对于 H.265 的支持都不太好，也就是说，你直接用当前的电脑剪辑 H265 编码的视频，会卡的惨不忍睹。</p>
<p>卡了怎么办？除了换电脑之外，买显卡之外，还可以通过剪辑软件生成代理素材来剪辑。</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-db47846040c6df5336c3b4dced840bab_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>是一种『以时间换性能的做法』。 ​</p>
<p><strong>10bit 422—色深与色度采样</strong></p>
<p>10bit 422， 8Bit 420 这是我们在看相机参数时，经常会看到的一串数值。 他们到底说的是啥？ ​</p>
<p><strong>越深越好，色深</strong></p>
<p>先说这个 10bit ,色深。 如果你经常使用 Photoshop，或者一些设计软件。会经常看到#FFB6C1 这样的数值，他们称之为色值。</p>
<figure><img class="content-image" src="https://pic4.zhimg.com/v2-cddc2294c47565a5794b1818e3259d2f_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>通常由 6 位十六进制字符代表，红绿蓝 每种颜色占用两位。 ​</p>
<p>也就是说，每一种颜色有 16*16 种变化，这个数值正好的 2 的 8 次方，所以我们把这种颜色称为 8 位色深，也就是 8bit。 ​</p>
<p>很容易计算，8bit 色深的颜色一共有 256×256×256=16,777,216 种颜色，也就是我们经常说的 1600 万色。 ​</p>
<p>虽然看起来也不少了，但是在实际的拍摄体验中，尤其是渐变的场景，后期稍微拉一下，就会遇到色彩断层的问题。</p>
<figure><img class="content-image" src="https://pic1.zhimg.com/v2-3a31a4c48177e43e8738628c6fa50dfc_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>而 10bit，最终色彩总量可以达到 10 亿色，由于颜色增多，色彩的过渡会更加的自然，哪怕最终输出的还是 8bit 的画面，依旧可以获得很不错的画面。 ​</p>
<p>​</p>
<p>​</p>
<p><strong>谁还不是为了省钱啊：色度采样</strong></p>
<p>​</p>
<p>为了数字化的记录颜色，人们搞出来了『色彩空间』这样一个模型。</p>
<figure><img class="content-image" src="https://pic1.zhimg.com/v2-9d84b3c081572d1558a148294d4a0f5c_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>不同的色彩空间有着不同的特点，应用于不同的领域： 我们最为熟悉的 RGB，是一种加法色，应用最为广泛，设备显示，图像处理； CMYK，是一种减法色，通常用印刷行业； RGB 发光屏幕的加色模式，依赖于光线，CMYK 是一种颜色反光的印刷减色模式，依赖于颜料。有<strong>所依赖就会有所不足</strong>。所以 Lab 模式诞生，理论上，Lab 可以包含所有色彩。 ​</p>
<p>但是在电视或者数码摄影系统中，我们通常上使用 Y'CBCR 这种色彩模式。</p>
<blockquote>实际上，Y'CBCR 不是一种绝对色彩空间，而是 YUV 压缩和偏移的版本，但是由于 Y'CBCR 的应用实在是太广泛了，所有大多时候，我们口中所说 YUV 指的就是 Y'CBCR。</blockquote>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-1a7b62a75e45b29098b0c53437130dbd_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>其中：</p>
<p>Y'代表光的浓度，也就是亮度，而且这个值是非线性的。</p>
<p>Cb 和 Cr 代表蓝色和红色浓度的偏移量，包含色度和色差信息。 ​</p>
<p>常见的格式有以下几种,用一个三分比值表示：</p>
<ul><li>4:4:4</li>
<li>4:2:2</li>
<li>4:2:0​</li>
</ul><p>第一个值，区域的宽度，也就是区域的像素数量，通常上为 4；</p>
<p>第二个值，第一行像素的色度抽样数目；</p>
<p>第三个值，第二行的色度采样值。</p>
<figure><img class="content-image" src="https://pic1.zhimg.com/v2-cb2de30cf8990d5da5bbe1ea9181c730_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>比如我们来看 4:4:4 这种格式，区域的宽度为 4 个像素，第一行抽样的数值为 4，第二行也是 4，也就是所有的信息都被采集到了。这是一种对于色彩细节保留最好的格式。 ​</p>
<p>同理，4:2:2 和 4:2:0 的取样情况如下。</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-5b18cd70a502658eb8a7a8c13937f39e_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>可以明显看到，4:2:2 损失了 50%的信息，而 4:2:0 几乎损失了 75%的信息。 ​</p>
<p>即使如此，损失了 50%的 4:2:2 也被视为<strong>高品质的专业视频格式，</strong>比如索尼家的微单相机，目前应该只有 A7S3 和 A1 支持 4:2:2 的视频格式，其他的主流机型，目前还停留在 4:2:0 上。</p>
<blockquote>注：<br>在比较图像质量，比值才是重点，你可以把 4:4:4 称为 1:1:1，但是习惯和约定俗成的情况下，取样的总样本范围还是为 4，这也就是为什么没人 16:10 称为 8:5 的原因，无他，习惯耳。<br></blockquote>
<p>​</p>
<p>可能有小伙伴要问了，为什么要采样呢，搞的这么复杂？ ​</p>
<p>鲁(niu)迅(dun)又曾经说过——</p>
<blockquote>人们的很多选择，多半是为了效率（省钱）。</blockquote>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-9b267035f50c2c72be95f96d2be65a61_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>要使用 4:4:4 不仅是对于拍摄器材的性能要求极高，存储上，也吃不消。 ​</p>
<p>还有一个最主要的原因是，眼睛<strong>对于微调的色度不太敏感。</strong><strong>​</strong></p>
<p>也就是说，Cr 和 Cb 可以用<strong>一点点的样本就能进行编码，而且可见的质量损失微乎其微</strong>，却节省了大量的数据量。</p>
<p>这也就是你即使用保留了 25%的色彩信息的 4:2:0 去拍，实际的观感也没有那么差的原因。 ​</p>
<p>但是你如果要进行复杂的后期，甚至抠像特效的时候，你就会发现，4:2:0 的画面用起来就有点捉襟见肘了，还是得上 4:2:2。</p>
<p><strong>RAW，Log，Rec709，HLG 又是什么</strong><strong>RAW，（生）肉</strong></p>
<p>玩摄影的朋友，想必对于 RAW 很熟悉了，记录了传感器采集到的所有的光线的信息。 严格来说，RAW 并不是一种图片格式，而是一个数据包。</p>
<p>拍的 RAW 格式的视频，与图片类似（本质上视频就是一张张图片拼接起来嘛）。 ​</p>
<p><strong>拥有的最大的后期空间</strong>，但是能够拍摄 RAW 视频的器材不多，都是比较专业的摄影机，比如 RED，ARRI 之流，都十分的昂贵，但是有一个例外，就是适马 fp，机身小巧，也不算贵，能够拍摄 cinemaDNG 序列（也算是一种 RAW 视频了）。 ​</p>
<p>其实所有的拍摄设备，都有 RAW 的这个过程，为什么不把 RAW 数据直接给你呢？ ​</p>
<p>RAW 是个数据量杀手，你刚塞进去一张 128G 的 SD 卡，还没有一分钟呢，嚯，卡满了。而是对于后期处理也是一个大难题，流程繁琐，并不适合大多数据消费者使用。 ​</p>
<p><strong>Log，指数观察世界</strong></p>
<p>人眼能看清楚明亮的天空，也能辨别阴影的细节。 这就说明人眼对于光线的感知并不是线性的，这也就是中性灰是 18%，而不是 50%的原因。 ​</p>
<p>为了尽量的拟合人眼识光线明暗的特点，人们找到了 log 这个函数来模拟。</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-d643b12381600664f5e99ab68600e809_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>为的就是记录更多的明暗数据，换句话说，就是把暗部拉上去，把亮度压下来（是不是像极了后期照片时减高光，加阴影的操作？）来让画面有用更高的动态范围。 ​</p>
<p>不同的厂家有着不同的 Log 曲线，比如佳能的是 C-log，索尼家的是 S-log，富士家是 F-log，松下的是 V-log（注意不是拍的吃饭旅游的那个玩意）。 ​</p>
<p>即使是同一家厂商，Log 曲线也有不同的版本，比如 C-log 就有 1，2，3 的区别，在暗部，亮部的捕获表现上都会有细微的差异。</p>
<p>但是直接观看 Log 画面，会显得十分的『灰』。 ​</p>
<p>如何观看正确的色彩呢？这时候 LUT 就登场了。 基本上所有的厂家都会提供自己 log 模式的还原 Lut，可以很轻易的地官网找到。</p>
<figure><img class="content-image" src="https://pic3.zhimg.com/v2-843d22d2e3e74800f3ce30c9d3d006ae_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>日常使用 Log 拍摄时，需要注意以下两个问题： ​</p>
<p>起跳 ISO，比如，索尼的 Slog3 的起跳 ISO 是 800，如果在打白天，也想使用大光圈拍摄，那么减光镜就是不可或缺的配件； ​</p>
<p>对于精准曝光要求极高，所以你得上监视器，或者使用直方图，斑马纹来确认你的曝光是否准确，相信我，大多数新手拍 Log 会在精准曝光上载无数个跟头，一个比较实用的曝光的经验是，<strong>在保留画面信息的基础上，尽量向右曝光。</strong></p>
<blockquote>注:<br>有些相机厂商虽然也支持 RAW 外录和 N-log，但是需要你『花钱』升级​固件，比如尼康 Z6/7<br></blockquote>
<p><strong>Lut：是滤镜吗</strong></p>
<p>Lut，即为 look up table，直译就是颜色查找表，输入一个值，然后换成另外一个值，从而达到调色的目的。 是不是看起来跟滤镜的作用一样，但实际上原理是相当不同的。 你可以简单理解为，LUT 是颜色替换，而滤镜是计算。 ​</p>
<p>当然，你也可以在网上找到无数的 Lut，有兴趣的话，也可以自己做一个。​</p>
<p><strong>HLG</strong></p>
<p>随着技术的进步，HDR 设备开始普及，包括你手头的旗舰手机几乎都开始支持 HDR 了。</p>
<blockquote>关于更多关于 HDR 的介绍，可以参考我之见的回答。</blockquote>
<p><a class="internal" href="https://www.zhihu.com/question/19774840/answer/660920430">HDR 是什么？有哪些具体介绍？</a></p>
<p>​</p>
<p>相机们也可以加入了 HDR 视频的拍摄能力。 ​</p>
<p>这里就不得不提 HLG 标准了，HLG 是 BBC 和 NHK 联合开发 HDR 标准，提供了编码宽动态范围（HDR）的能力，也保留了标准动态范围（SDR）的支持，使得他的兼容性很好。</p>
<p>而且 HLG 标准并不需要你掏专利费，所以很多厂商也纷纷投入了 HLG 怀抱，比如索尼，松下，甚至大疆的大多数设备，都可以拍摄 HLG 视频。由于采用的是相同的标准，即使是不同厂家的设备拍摄的 HLG 视频，后期在颜色匹配上也比较完美。 ​</p>
<blockquote>p.s <br>iPhone12 拍摄的 HDR 视频，标准为杜比视界。实际上 iPhone12 拍摄的也是 HLG 视频，只不过加了一层杜比视界的元数据层。<br></blockquote>
<p>​</p>
<p>相对于 Log，HLG 还有以下两个特点： ​</p>
<p>画面没有那么灰，颜色显示较为正常，甚至不用处理也可以直出使用； 没有起跳 ISO 的限制，使用起来比较方便。 ​</p>
<p>HLG 同 Log 一样，也有 HLG1，HLG2，HLG3 的区别，在暗部和亮部的保留和取舍上各有倾向。要依据你实际拍摄的画面而定。有空了可以深入探讨这个问题。 ​</p>
<p>对于日常使用或者新手来讲，HLG 明显更加友好。 ​</p>
<p>​</p>
<p><strong>Rec.709，色彩标准</strong></p>
<p>​</p>
<p>这是一个 1990 年发布的统一色彩标准，色域和 sRGB 相同。 ​</p>
<p>这个色域并不大，多数设备拍摄的素材都可以轻松超过，但是一些显示设备或者产品服务，就只支持这个标准，你大于这个标准拍摄的画面，实际播放是没有任何意义的。 ​</p>
<p>也就是说，为了能在电视上，普通显示器上正确的显示色彩，就得按照 Rec.709 的规定来。 ​</p>
<p>但是随着 HDR 设备的普及，就连 B 站也开始支持 HDR 了，Rec.709 这个标准貌似不太够用了，于是新的标准也诞生了，BT2020，支持 4k，8K，最高 120 帧的速率，以及 12 位的深度。 ​</p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-f0bcc6186be34fd1ebbcab74a95c4c81_1440w.jpg" alt referrerpolicy="no-referrer"></figure><p>所以你在拍摄 Log 或者 HLG 视频时，可以将色域选择为 bt2020，这样可以在 HDR 显示上获得更好的观影体验。</p>
<p><strong>快门角度还是速度</strong></p>
<p>​</p>
<p>照相机除了拍照也可以拍视频，电影机也可以拍照，那他们的区别到底是什么？ 其实最明显的一个操作逻辑上的区别，就是快门。 ​</p>
<blockquote>关于快门的前世今生，可以参考我之前的这篇文章： <a class="internal" href="https://www.zhihu.com/question/36033197/answer/1693671720"><span class="invisible">https://www.</span><span class="visible">zhihu.com/question/3603</span><span class="invisible">3197/answer/1693671720</span><span class="ellipsis"></span></a> ​</blockquote>
<p>如果你用过 Bmpcc，之类的摄影机，在快门参数的调节上，使用的是快门角度。 ​</p>
<p class="ztext-empty-paragraph"> <br><br>这个概念其实来自于电影拍摄，电影为 24 帧每秒，那每一帧的快门速度就为 1/24s。但是人们发现这个速度的动态模糊太大了，导致视频看起来一点都不清晰。 那么如何调节胶片拍摄的时候的快门速度呢？加上一个旋转快门就好了。 ​<br><br>比如这个 180°的快门装置，就能遮挡一半的光线，让快门速度来到 1/48s。<br><br><br><br></p>
<figure><img class="content-image" src="https://pic2.zhimg.com/v2-b2114d86ca73d5272122b3624f4469f1_b.gif" alt referrerpolicy="no-referrer"></figure><p>当然也有 45°的快门和 270°的快门，做法也比较简单，调节快门板的角度就好了。 ​</p>
<p>人们发现，180°的时候，在画面锐度和动态模糊间达到了一个完美的平衡，所以，以前的电影机和摄影机基本上都是以 180°的快门角度来拍摄视频。 ​</p>
<p>在摄影机上，设置为 180 度的快门角度就好了，但是对于普通相机来说，快门速度要按照二倍帧率的倒数来设定：</p>
<ul><li>24 帧，快门速度为 1/50s；</li>
<li>60 帧，快门速度为 1/120s;</li>
<li>120 帧，快门速度为 1/250s</li>
</ul><p>来达到类似的效果。 ​</p>
<p>不过当前的相机基本上都提供能自定义拍摄参数的保存，方便你快速切换。 ​</p>
<p>​</p>
<p><strong>不可忽视的限制</strong></p>
<p>使用相机或者单反拍视频时，总是存在各种各样的限制。</p>
<p>这个限制主要是来自于数据量，拍摄高分辨率高帧率的视频，会产生很大热量，散热如果不给力的话，相机就会做录制时长的限制，比如很多相机只能连续录制 30 分钟的视频，要么就直接给你来一个过热警告。</p>
<p>另一个是高分辨率高帧率的视频对存储卡的写入速度也提出了要求，而高速卡的价格往往也不便宜。 ​</p>
<p>而且数据量的增大，会增加相机的运算负担，一些功能在高分辨或者高帧率下就被禁用，比如：</p>
<p>大部分相机在 1080P/120 帧的模式下，无法启用人脸 / 人眼对焦，只能使用最为传统的反差对焦；</p>
<p>代理视频的录制功能，只能后期通过电脑生成代理视频。 ​</p>
<p><strong>是时候按下录制键了</strong></p>
<p>无论你使用怎样的设备，无论这个设备的性能如何，最重要的是出去拍。 以上讲的所有知识，都只是为了让你获得一个更加好看的画面，让你的画面更加锐利，减少噪点，但是画面永远不是全部，他只是锦上添花的部分。 ​</p>
<p>更加重要的是内容和故事。 如何讲好一个故事，才是你应该不断思考的问题。 ​</p>
<p>​</p>
<p>你还对那些视频制作的知识感兴趣，或者有哪些你认为不对的地方，可以在评论区里边提出来，我们一起讨论。 ​​</p>
<p class="ztext-empty-paragraph"> <br><br>以上。 ​<br><br><a class="internal" href="https://www.zhihu.com/xen/market/remix/paid_column/1339602918698377216">2021 相机推荐与选购：这款相机该不该买？看看硬核摄影科普</a><br><br>相关阅读：<br><br><a class="internal" href="https://www.zhihu.com/question/439458908/answer/1682895110">哪位大神可以详细讲解下关于相机 ISO 方面的介绍？</a><br><br><a class="internal" href="https://www.zhihu.com/question/31142439/answer/1711732441">为什么相机光圈 F 值越大，实际光圈越小，谁发明的，有什么来由吗？</a><br><br><a class="internal" href="https://zhuanlan.zhihu.com/p/305714803">李明殊：李明殊的摄影类回答文章导航</a><br><br><br><br><br><br><br><br><br><br><br><br></p>
<p class="ztext-empty-paragraph"><br>​<br></p>

<div class="view-more"><a href="https://zhuanlan.zhihu.com/p/387948491">查看知乎讨论</a></div>

</div>
</div>
</div>


</div>
</div></div>  
</div>
            